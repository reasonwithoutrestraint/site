---
title: Why Consequentialism should be rejected
---
Following the Stanford Encyclopedia of Philosophy (SEP), [consequentialism](https://plato.stanford.edu/entries/consequentialism/) is a moral theory that states that the moral rightness of an act depends only on the goodness of certain consequences associated with the act. There are many different consequentialist systems, e.g. ethical egoism vs utilitarianism, act-consequentialism vs rule-consequentialism, etc. What consequentialist views share in common is that they take facts about the "right" to depend only on facts about the "good". This is sometimes expressed by saying that [the "good" is prior to the "right"](https://plato.stanford.edu/entries/ethics-deontological/#DeoFoiCon). In other words, once we know about the _goodness_ of certain consequences associated with an act (or rules permitting the act), we have all the information necessary to determine the moral _rightness_ of the act. This is unlike non-consequentialists such as Rawls or Kant who believe that the "right" to be in some ways prior to the "good", or at least that the "right" is separate from the "good". I agree with Rawls and Kant in this respect. Consequentialists are incorrect to state that facts about the "right" depend only on facts about the "good". While the goodness of consequences is certainly _relevant_ to determining the rightness of an action, I will argue in this post that there are _additional_ features that are morally relevant as well. Before getting to the argument, we must first understand what is meant by "good" and "right".

## The "right" and the "good" as distinct concepts

----------

One's immediate reaction to hearing that the "right" is prior to the "good" might be confusion. After all, don't "good" and "right" pretty much express the same concept? They are both normative concepts that are ascribed to things that are in some way desirable or favorable, so in what sense can one be prior to the other? The "right" and the "good" might be related, but it can be shown that they do not express the same concept because they don't have the same _meaning_. They do not have the same meaning because the terms cannot be substituted with one another in a sentence without altering the meaning of the sentence. In the chapter "[The Meaning of Right](http://www.ditext.com/ross/right1.html)" from William David Ross's book _[The Right and the Good](https://www.oxfordscholarship.com/view/10.1093/0199252653.001.0001/acprof-9780199252657)_ - which is "arguably one of the most important works of moral philosophy published in the twentieth century" according to the SEP entry on [the author](https://plato.stanford.edu/entries/william-david-ross/) - Ross (1930) argued famously that the _right_ and the _good_ have different meanings:

> It seems to me clear that 'right' does not mean the same as 'morally good'; and we can test this by trying to substitute one for the other. If they meant the same thing we should be able to substitute, for instance, 'he is a right man' for 'he is a morally good man'; nor is our inability to do this merely a matter of English idiom, for if we turn to the sort of moral judgement in which we do use the word 'right_, such as '_this is the right act, it is clear that by this we mean 'this act is the act _that ought to be done_', 'this act is _morally obligatory_'; and to substitute either of these phrases for 'morally good' in 'he is a morally good man' would obviously be not merely unidiomatic, but absurd. It should be obvious, then, that 'right' and 'morally good' mean different things.

The differences between the concept of _right_ and the concept of _good_ can be illustrated by contrasting the two normative classes that these concepts respectively belong to. _Right_ is a _deontic_ concept whereas _good_ is an _evaluative_ concept. Deontic concepts include normative concepts such as _right_, _wrong_, _duty_, _ought_, _reason_, _must_, _warrant,_ _permitted, prohibited,_ etc. Evaluative concepts include normative concepts such as _good_, _bad,_ _noble,_ _desirable, admirable,_ _worthy,_ _etc._ [Christine Tappolet (2014)](https://philpapers.org/archive/TAPTNO.pdf) has highlighted some of the key distinctions between deontic and evaluative concepts (p. 1):

> The concepts that count as normative can appear quite heterogenous. However, some groupings seem natural. Thus, it is generally admitted that we can divide these concepts into two large distinct groups: evaluative or axiological concepts (from the latin _valores_ or the Greek axos, both meaning that which has worth), such as _good_ and _bad_, and deontic concepts (from the Greek _deon_, meaning that which is binding), such as _obligatory_ and _permissible_... The distinction between evaluative and deontic consists in a generalisation of the traditional opposition between the good and the right .

Throughout the paper, she highlights a number of distinctions between the two conceptual families. Some examples include the following: the fact that we can make logical inference _within_ either family but we can not (obviously) make such inference across families (p. 4); the fact that evaluative concepts can be applied to a wider range of things (e.g. actions, persons, objects, states of affairs can all be _good_, _bad_, _admirable_, etc.) whereas deontic concepts are typically restricted to what is subject to the will of an agent (p. 10); the fact that deontic concepts are typically affirmed only of attitudes that an agent _can_ adopt (e.g. "[ought implies can](https://en.wikipedia.org/wiki/Ought_implies_can)") whereas evaluative concepts can be affirmed independently of the agent's abilities (p. 11); etc.

So clearly deontic concepts are at least prima-facie distinguishable from evaluative concepts, which would mean that the concept _right_ is not the same as the concept _good_. However, this alone does not imply that consequentialists are wrong to claim that the rightness of an action depends only on the goodness of certain consequences related to the action. Consequentialists can make this claim coherently, so long as they maintain that the dependence is not _conceptual_, i.e. so long as they don't argue that "right" _means_ "good", or that the _meaning_ of either can be reduced to the _meaning_ of the other. For example, hedonists do not make an error in _meaning_ (although I would argue that they are nevertheless _incorrect_) when they claim that pleasure is the only intrinsic good. However, due to [Moore's Open Question Argument](https://plato.stanford.edu/entries/moore-moral/#1), a hedonist _would_ make an error in _meaning_ if they claimed that "good" _means_ the same thing as "pleasurable".

Now that preliminaries are out of the way, we can get into why I believe consequentialism is wrong. First, I will show that consequentialism broadly can avoid most of the issues that plague utilitarianism (issues that I outlined in a [previous post](https://reasonwithoutrestraint.com/why-im-not-a-utilitarian/)). This can be done with a less ambitious consequentialism that does not attempt to precisely specify either how collective goodness is to be measured or how collective goodness relates to one's moral duties. However, I will then argue that even this less ambitious consequentialism should be rejected because there are special features relevant to the moral rightness of an action that cannot be reduced to the goodness of any consequences associated with the action. Ultimately, my argument will consist in appealing to intuitions (which I think are held by most reasonable people), which means the argument will not persuade a die-hard consequentialist who does not feel moved by the same intuitions.

## Non-utilitarian consequentialism

----------

In a [previous post](https://reasonwithoutrestraint.com/why-im-not-a-utilitarian/), I argued that classic utilitarianism (a particular form of consequentialism) should be rejected because some components of the theory are unreasonable. In this section, I consider whether consequentialism broadly can avoid those criticisms by abandoning these unreasonable components. To recap, I rejected utilitarianism because of the following components of the theory: _hedonism_, _total consequentialism_, _agent-neutrality_, _equal consideration_, _actual consequentialism_ and _maximizing consequentialism_. Some of these components can be easily replaced under a different form of consequentialism. Consider the following examples.

-   Hedonism can be replaced with a [different theory of well-being](https://plato.stanford.edu/entries/well-being/#TheWelBei), such as e.g. a desire-theory.
-   A consequentialist theory can base moral rightness on _intended_ or _foreseeable_ consequences rather than _actual_ consequences, which is more plausible.
-   A consequentialist theory can adopt an _agent-relative_ theory of goodness to avoid the problems with agent-neutrality and equal consideration. For example, ethical egoism is a fully agent-relative form of consequentialism that only gives weight to the goodness of the agent performing the action when determining the rightness of an action. Or, more plausibly, a consequentialist moral system can be partially agent-relative and partially agent-neutral. For example, [Douglas Portmore (2007, p. 11)](http://www.public.asu.edu/~dportmor/Consequentializing_Moral_Theories.pdf) describes a kind of consequentialism where agents can assign additional weight to their own utility while still taking into account the utility of others.

However, while consequentialism can adequately handle those issues, it's not clear to me if a consequentialist system can avoid all of the unreasonable components of utilitarianism. Specifically, it does not seem that a consequentialist system can replace _total consequentialism_ and _maximizing consequentialism_ with adequate substitutes. I base this on the following reasons.

1.  While consequentialism need not adopt total consequentialist, it seems that alternatives may have equally damning flaws. For example, _average_ consequentialism states that the goodness of a group depends on the average goodness of each individual. But on this theory, the world would be worsened by producing a life that is worse than the average life in the world, even if the new life is of very high quality and even if it doesn't make anyone else worse off. This seems unintuitive; creating a life of very high quality that doesn't harm anyone else is never bad. In general, I am skeptical that any consequentialist aggregation function can avoid extremely unintuitive conclusions. It seems that we lose important information when we try to measure the goodness of _multiple_ individuals into a _single_-dimensional metric. I'm also suspicious of whether the concept of an "overall" or "collective" goodness - as something distinct from individual goodness - is even intelligible. For example, it might make sense to say that one state of affairs is _better for_ a particular group of people affected, and _worse for_ another group, but it does not seem sensible to say that it is _better_ _simpliciter_. Partially, this is because I agree with [Christine Korsgaard (2013)](http://www.people.fas.harvard.edu/~korsgaar/CMK.Relational.Good.pdf) that the concept of _good-for_ is prior to the notion of _good_ itself, or, in her own words, that "there is something essentially relational about the notion of the good itself" (although I don't mean to imply that Korsgaard shares my skepticism of the notion of collective goodness).
2.  It is not clear whether a consequentialist theory could adequately replace the _maximizing component_ of utilitarianism with a suitable replacement. For example, [satisficing consequentialism](https://philpapers.org/browse/maximizing-and-satisficing-consequentialism), while perhaps allowing for supererogatory actions and moral options, might suffer similar [demandingness issues](https://philpapers.org/browse/demandingness-of-consequentialism) as maximizing consequentialism. For example, if a large enough number of people are below some satisfactory threshold, and if the only way to bring others up to a satisfactory level is for one to make _extreme_ personal sacrifices, then one would be morally obligated to make such sacrifices under satisficing consequentialism. This seems implausible. However, one response could be to adopt a proviso that agents are never morally obligated to make unreasonable sacrifices to themselves. I'm not sure how feasible this strategy is.

So I am not confident that consequentialism can find suitable replacements for total and maximizing consequentialism. However, fortunately for consequentialists, consequentialism does _not need_ to _replace_ these components. A less ambitious consequentialist could abandon those components and refuse to replace them. The only component of consequentialism that is _essential_ is the following proposition: _the moral rightness of an act depends only on the value (or goodness) of certain consequences associated with that act_. However, a theory can adopt this principle without having a systematic method of _measuring_ collective goodness, or fleshing out in precise details the relationship between collective goodness and moral rightness. These are structural, systematic details which, while commonly associated with forms of consequentialism, are not required for consequentialism per se. In fact, [Olson and Svensson (2003)](https://www.semanticscholar.org/paper/A-Particular-Consequentialism%3A-Why-Moral-and-Need-Olson-Svensson/d190f40e8e397869fe89463ab0f8932db211fc86https://www.semanticscholar.org/paper/A-Particular-Consequentialism%3A-Why-Moral-and-Need-Olson-Svensson/d190f40e8e397869fe89463ab0f8932db211fc86) have even argued that one can simultaneously be both a consequentialist and a [particularist](https://plato.stanford.edu/entries/moral-particularism/). For example, a consequentialist particularist might propose a list of consequentialist pro-tanto or prima-facie principles (similar to W.D. Ross's [prima-facie duties](https://plato.stanford.edu/entries/william-david-ross/#Rig)). One such list of consequentialist principles might include the following:

1.  _Good Promotion._ The good or lack of badness that obtains in the foreseeable outcome of an action (relative to alternative actions) contributes to the rightness of that action.
2.  _Harm Reduction_. The badness or lack of good that obtains in the foreseeable outcome of an action (relative to alternative actions) contributes to the wrongness of that action.
3.  _Prioritarianism_. The goodness contributed to worse-off individuals contributes more to the amount of goodness in the world than equal amounts of goodness contributed to better-off individuals.
4.  _Agent-Relativity_. The amount of goodness _relative to an agent_ in the intended or foreseeable outcome of an action contributes more towards the rightness of an action than the amount of _goodness_ _simpliciter_.

These are just possible consequentialist pro-tanto or prima-facie principles that I chose arbitrarily. A different consequentialist could select entirely different principles. They could remove some of the principles here, or they might add some new principles such as: the principle against producing harm takes priority over the principle of producing goodness, a large amount of small benefits is not as valuable as a small amount of big benefits, etc. A consequentialist might also say, like Ross's prima-facie duties, that these principles can conflict, and that there is no higher principle to systematically settle which principle to follow in the case of such conflicts. Further, a consequentialist need not supply a method for measuring overall goodness. We might expect these methods from specific consequentialist "systems", but they are not required for consequentialism _per se_. A less ambitious consequentialist theory that consists only of pro-tanto or prima-facie principles will remain purely consequentialist so long as the rightness of an action depends _only on_ the goodness of certain consequences associated with the action.

So it seems like consequentialism _can_ avoid all of the aforementioned problems that plagued utilitarianism. The question to be asked now is: are consequentialist principles the _only_ principles that determine the rightness of an act? Are there _ever_ instances where the moral rightness of an act depends on some special features _other than_ the goodness of certain outcomes associated with the act? As should be obvious from the title, I believe that there _are_ some such special features. I will list some of these special features in the next section.

## Features relevant to the right but not to the good

----------

I believe consequentialism should be rejected because, sometimes, there _are_ facts relevant to an action's rightness other than just the goodness of the action's consequences. These include special features related to either the agent performing the action or the agents affected by the action. These morally relevant special features include:

1.  The _responsibility_ of the person(s) impacted by the action. Typically, for example, an agent has _some_ moral reason to alleviate serious harm to another person if the agent can do so by undergoing a "reasonable" sacrifice. However, if the person is _responsible_ for their harm, then this can reduce the agent's reason or obligation to alleviate their harm, and this can reduce the level of sacrifice that the agent is obligated to endure. For example, if an agent has to choose between alleviating an identical burden from person A and person B, where person B is _responsible_ for needy situation and person A is _not_ responsible, then (assuming all else is equal) the agent should prioritize alleviating the burden from person A.
2.  The _[desert](https://plato.stanford.edu/entries/desert/)_ of the person(s) impacted by the action. Typically, for example, an agent has _some_ moral reason to provide a large benefit to another person if the agent can do so at a little or no cost to themselves. However, if the person is _deserving_ of that benefit, then this can be _amplify_ the agent's reason to provide them the benefit. For example, if an agent has to choose between distributing an identical benefit to two different persons, then (assuming all else is equal) the agent should prioritize distributing the benefit to the person who is more deserving of the benefit.
3.  The _debts_ owed by the agent performing the action. Typically, for example, an agent has _some_ moral reason to alleviate serious harm to another person if the agent can do so by undergoing a "reasonable" sacrifice. However, if the agent has _wronged_ the person in the past, then this can _amplify_ the agent's reason to alleviate the harm, and this can _increase_ the level of sacrifice that the agent is obligated to endure. For example, if one has to choose between alleviating an identical burden from person A and person B, where person A's burden was the result of being _wronged_ by the agent and person B's burden has some other cause, then (assuming all else is equal) the agent should prioritize alleviating the burden from person A.
4.  The _past agreements_ (consent, contracts, [promises](https://plato.stanford.edu/entries/promises), etc.) that have been made by person(s) involved in the action. Past agreements by agents can modify our moral obligations and moral permissions in at least two ways. For example, an agent's moral obligation to alleviate the harms to a person can be _mitigated_ if the person previously consented to endure (or risk enduring) those harms. Or, an agent's moral obligation to alleviate a certain harm can be _amplified_ if the agent previously agreed or promised to alleviate the harm.
5.  The _[rights](https://plato.stanford.edu/entries/rights/)_ of the person(s) involved in the action. Two actions with the same amount of goodness/harm in their outcome may have different statuses as right/wrong if one action, but not the other, violates someone's rights. For example, a certain action may be morally permissible in ordinary circumstances because it promotes a certain balance of goodness over harm, but a different action that produces the same balance of goodness over harm might not be morally permissible if it violates someone's _rights_. Consider rights to bodily autonomy as one common example.
6.  The _reasonableness_ of the interests of the person(s) affected by an action. When assessing the moral status of an action, the goodness/harm that would be produced from the fulfillment of an _unreasonable_ or _illegitimate_ interest should not have as much weight as the same amount of goodness/harm that would be produced from the fulfillment of a reasonable interest.

### Responsibility

For an example of the relevance of responsibility, consider imprisonment. Most people would agree that we should imprison _guilty_ suspects (i.e. criminals) for crimes but we should not imprison _innocent_ suspects. This is a clear case where the rightness and wrongness of certain actions (namely, the act of imprisoning a person) depends on facts about responsibility (namely, whether the person is _responsible_ for committing the relevant crime).

A consequentialist could object by saying that responsibility is not _intrinsically_ morally relevant in this case. Rather, responsibility is merely _instrumentally_ relevant. The consequentialist might say that the only factor that matters _intrinsically_ is the expected benefits that are produced by imprisoning the suspect, and whether a suspect is guilty of committing a crime conveys information about the expected benefits that would be produced by imprisoning him. For example, if Adam is guilty of recklessly killing a pedestrian while driving under the influence, then that raises the probability that he will produce similar harms in the future. Therefore, imprisoning Adam has the positive expected benefit of reducing such injuries and deaths in the future, and it has the expected benefit of rehabilitation and deterrence.

However, while these benefits are definitely relevant, they are usually not _sufficient_ to justify imprisonment. Let's assume that imprisoning Adam – the guilty drunk-driver – for 5 years is expected to prevent, say, 2 car accidents within the next 5 years because the number of potential drunk drivers on the road is reduced by 1. Now, imagine that we have a crystal ball that reveals that imprisoning Bob – a perfectly innocent driver – for 5 years will result in a slightly different flow of traffic which results in 2 fewer car accidents. It seems clear to me that it would be _wrong_ to imprison Bob in this example even though the benefits of doing so are comparable to the benefits of imprisoning Adam. This implies that benefits are (usually) not sufficient to justify imprisoning someone; the suspect must also be _responsible_ for committing the relevant crime (I say "usually" because the benefits may be sufficient in unusual circumstances, e.g. if imprisoning an innocent person somehow resulted in stopping a nuclear fallout). This means that _responsibility_ is also relevant to the _rightness_ of an action independently of the benefit of the action.

### Rights

For an example of the relevance of rights, consider actions that violate one's bodily autonomy in order to produce a larger benefit for someone else. In ordinary situations, one might be justified in imposing a minor harm on someone in order to alleviate a more serious harm or to produce a major amount of good for others. For example, enacting a system of mandatory confiscation of wealth from the rich to be redistributed to the poor (i.e. taxation) seems morally justified because the goodness produced by the action far outweighs the harm produced by the action. However, similar reasoning does not apply when the action involves violating the bodily autonomy of the one who is harmed. For example, taking a kidney from a healthy person is a relatively minor harm compared to the benefit it might bestow on someone else (i.e. saving someone else's life). However, it would nevertheless be morally wrong to enact a system of mandatory confiscation of kidneys from healthy people to be redistributed to unhealthy people. Such a system would be wrong even if we used a crystal ball to only confiscate kidneys from persons whom we knew would not need them in the future. What explains the different moral status of mandatory confiscation of wealth vs mandatory confiscation of bodily organs? The difference is related to the _rights_ that persons have. People have _rights_ to their bodily organs that are far stronger than any rights that they might have to their wealth (if people even have rights to their wealth).

Keep in mind that none of this implies that rights can never be violated. The point is simply to note that whether an action would violate someone's rights is a morally relevant consideration. This morally relevant consideration, of course, may be overridden by stronger moral considerations. For example, it would be morally right to take someone's kidney in order to prevent the world from being destroyed, even though this would nevertheless violate that person's right. The explanation for this is that the reasons against violating someone's rights in this case are outweighed by the reasons in favor of preventing the world from being destroyed. However, in ordinary situations, the mere fact that an action produces more benefit than harm is not sufficient to justify violating someone's rights (as the kidney example shows). This shows that we cannot merely consider the benefits and harms that would be produced by the action. Rights must also be taken into account when considering the moral rightness and wrongness of an action.

### Unreasonable interests

One example of an unreasonable or illegitimate interest is the pleasure that a sadist takes in the unconsented suffering of others. Another example might be someone who unjustifiably believes that a particular group of people are inferior, which leads to this person judging that their dignity has been assaulted (resulting in a kind of subjective harm for that person) when he is treated equally as members of that group. Harms that are produced that stem from these unreasonable or illegitimate interests do not have as much weight as harms that stem from reasonable interests. Typically, unreasonable interests are interests that an agent _could_ have avoided holding (e.g. if they had a better upbringing and socialization), but this need not be a necessary condition.

For a more specific example of the importance of unreasonable interests, imagine we have the power to distribute valuable resources (e.g., money, food, health, etc.) to two individuals – Adam and Bob. Let's also make a fairly reasonable assumption about Adam and Bob: the marginal benefit of each unit of resource decreases for both individuals as they acquire more total resources (diminishing returns). Now, let's assume we have three scenarios:

-   In scenario 1, Adam and Bob are completely isolated from one another; neither individual has access to any information the other. Also, both individuals derive equal benefit from the same amount of resources. In this scenario, it seems plausible that the morally right action is to distribute equal resources to both Adam and Bob. A consequentialist moral theory can explain this intuition because the only considerations that seem morally relevant in this situation are the benefits that would be produced for Adam and Bob by these valuable resources.
-   In scenario 2, Adam and Bob are again completely isolated from one another. But, unlike scenario 1, both individuals do not derive equal benefit from the same amount of resources. Adam requires slightly more resources than Bob in order to derive the same amount of goodness (i.e. well-being). The reason for this is that Adam needs slightly more resources to help him manage a physical disability caused by a genetic disorder. In this scenario, it seems plausible that the morally right action is to distribute more resources to Adam. A consequentialist moral theory can explain this intuition because, again, the only considerations that seem morally relevant in this situation are the benefits that would be produced for Adam and Bob by these valuable resources.
-   In scenario 3, Adam and Bob are not isolated from each other. Like scenario 2, both individuals do not derive equal benefit from the same amount of resources; Adam requires slightly more resources than Bob in order to derive the same amount of goodness. But, unlike scenario 2, the reason for this is not that Adam has a physical disability; rather, Adam believes that Bob belongs to an inferior race and therefore would feel that his dignity has been assaulted (which causes some subjective suffering) if he is provided with equal resources as Bob. Adam will feel respected only if he is provided with substantially more resources than Bob. Because of Adam's racist beliefs, slightly _more_ goodness would be produced by giving slightly more resources to Adam at the expense of Bob; this strikes the perfect balance between raising goodness by appeasing Adam's racist beliefs and raising goodness by providing resources to Bob. Despite this, it still seems plausible that the morally right action is to distribute equal resources to both Adam and Bob; this might not maximize the amount of goodness because of Adam's racist beliefs, but the goodness produced by Adam's racist beliefs should not be given weight in this context because his racist beliefs are an _unreasonable_ or _illegitimate_ interest.

### Qualifications

Further examples shouldn't be too difficult to imagine. Simply stipulate that two actions will produce identical distributions of goodness to a set of agents. Then further stipulate that the agents involved differ with respect to their responsibility, desert, rights violations, previous agreements or the reasonableness in their interests. If it seems that these differences constitute _morally relevant_ differences, then that is sufficient to show that these features are relevant to the rightness of actions in a way that doesn't depend on their relation to the goodness of the action's outcome. I have a few points to note about the features I mentioned:

1.  This list is not exhaustive. Possibly, there are other morally relevant features that I have yet to think of. For example, in Thomas Scanlon's _What We Owe to Each Other_, Scanlon argues that the inherent _unfairness_ of an action can directly contribute to its wrongness, even if all alternative actions produce similar goods/harms (see the SEP [entry on contractualism](https://plato.stanford.edu/entries/contractualism/#ReaBeyWelBei)).
2.  Some of the features may be reducible to the other features mentioned there. For example, it seems plausible that the relevance of _desert_ can be explained in terms of the relevance of _responsibility_. Indeed, some even say that the _concept_ of desert is explained by the _concept_ of responsibility (although [this is debated](https://www.iep.utm.edu/desert/#SSH1ci)). For another example, it also seems plausible that the relevance of responsibility and the relevance of past agreements can be explained in terms of the relevance of _choice_. This post will remain agnostic about the irreducibility of these features.
3.  Many of the features mentioned here are themselves moral (or, at least, normative) concepts. For example, there is no straightforward non-normative account of what it means for an agent to be "responsible", to be "deserving", to have certain "rights", or for an interest to be "reasonable". Likely, these would need to be defined according to some broader moral theory.
4.  Finally, these features provide _pro-tanto_ reasons for or against the rightness/wrongness of an action; they do not provide _overriding_ or _conclusive_ reasons. For example, the fact that an agent is responsible for the harm that they experience is a pro-tanto reason against others having a moral duty to alleviate that harm, but this can be overridden due to other moral considerations (e.g. the harm may be so large that we have a moral duty to assist them even if they're fully responsible).

I believe that the features listed in this section constitute good reasons for abandoning consequentialism. These are all features that are relevant to the moral _rightness_ of an action even in cases where they are not relevant to the _goodness_ of any outcome associated with the action. If this is correct, then this suffices to show that the moral rightness of an action does not depend _only_ on the goodness of outcomes, which suffices to show that consequentialism is false.

There are a few types of responses a consequentialist might give here. Firstly, one might move away from _act_-consequentialism to something like _rule-_consequentialism to account for the moral relevance of the aforementioned features under a consequentialist theory. I find this response unsatisfactory because (1) rule-consequentialism has its own [set of objections](https://www.iep.utm.edu/util-a-r/#SH4b) which I hope to investigate in a future post; and (2) the aforementioned features are morally relevant under rule-consequentialism _only if_ certain rules respecting those features would increase the goodness of society, but it seems to me that those features would still be morally relevant _even if_ such rules had, say, a negligible impact on the goodness of society. Secondly, a consequentialist could _deny_ that these features are morally relevant if they have no impact on the goodness of an action's outcome. I have no interest in entertaining such an absurd idea here. Finally, a consequentialist might insist that the features that I mentioned above are morally relevant _because_ they are relevant to an action's _goodness_. For example, the consequentialist could provide a theory of goodness that makes direct reference to responsibility, desert, etc. I will consider this response in the next section.

## Keeping the "right" and the "good" separate

----------

I reject the idea that we should build responsibility, desert, rights, respect for previous agreements, etc. into a theory of the _good_. This, or something like this, is recommended by some consequentialists who believe that all moral theories can (and should) be "consequentialized", which [Campbell Brown (2011](https://www.research.ed.ac.uk/portal/files/12473535/BROWN_C_Consequentialize_This.pdf)) has defined as follows: "To 'consequentialize' is to take a putatively nonconsequentialist moral theory and show that it is actually just another form of consequentialism." [James Dreier (1993, p. 23)](https://www.brown.edu/academics/philosophy/sites/brown.edu.academics.philosophy/files/uploads/StructuresOfNormativeTheories_0.pdf) states that "The main strategy for “consequentializing” any given moral theory" is to "take the features of an action that the theory considers to be relevant, and build them into the consequences".

While this strategy is _technically_ feasible, I reject it because I don't think responsibility, desert, respect for rights, etc. _should_ be a part of a theory of goodness (i.e. they are not inherently relevant to the amount of goodness in the world). [John Dreier (1993, p. 24)](https://www.brown.edu/academics/philosophy/sites/brown.edu.academics.philosophy/files/uploads/StructuresOfNormativeTheories_0.pdf) has argued that to reject this strategy is actually _conceptually_ confused because he believes "every moral view is consequentialist". He [(2011)](https://www.brown.edu/academics/philosophy/sites/brown.edu.academics.philosophy/files/uploads/Dreier%20In%20Defense%20of%20Consequentizling.pdf) has argued that our concept of _good_ is inextricably tied to our concept of _right_, so there cannot be any meaningful substantive divergence between them. In fact, he claims that if two theorists agree about what's _right_ but disagree about what's _good_, then this is merely a notational dispute. I believe that [Schroeder (2017)](https://philarchive.org/archive/SCHCAI-11v1) has given a good rebuttal to Drier's conceptual claim, but I won't directly address this debate here. Instead, I'll give an indirect argument against Dreier's conceptual claim by arguing from intuitive moral judgments for why responsibility, desert, rights, etc. are not _inherently_ related to the amount of goodness in the world.

1.  [premise] The amount of _goodness_ in the world is reducible to what is _good for_ each individual in the world.
2.  [premise] What is _good_ _for_ an individual is reducible to what contributes to the [well-being](https://plato.stanford.edu/entries/well-being/) of that individual.
3.  [premise] Desire-satisfaction and/or happiness are the only features that are _inherently_ relevant to the well-being of an individual. All other features are merely _instrumentally_ relevant to well-being, contingent upon their ability to produce desire-satisfaction and/or happiness.
4.  [premise] Responsibility, desert, promises, etc. are not _identical_ to any individual's desire-satisfaction or happiness.
5.  [from 3 and 4] Therefore, responsibility, desert, promises, etc. are never _inherently_ relevant to any individual's well-being. Rather, they may be sometimes _instrumentally_ relevant to some individual's well-being.
6.  [from 2 and 5] Therefore, responsibility, desert, promises, etc. are never _inherently_ relevant to what is _good for_ an individual.
7.  [from 1 and 6] Therefore, responsibility, desert, promises, etc. are never _inherently_ relevant to the amount of goodness in the world.

I believe that the most controversial premise in this argument is premise 3, but even that is fairly uncontroversial. I think most people accept some form of desire-theory or happiness theory of well-being. This merely excludes certain [objective-list](https://plato.stanford.edu/entries/well-being/#ObjLisThe) theories of well-being which posit that certain factors are components of an individual's well-being independently of that agent's desires or happiness. I won't argue this here because I take it that most find such objective-list theories to be fairly unintuitive. Assuming the other premises in the argument are true (which seems uncontroversial), it follows that responsibility, desert, promises, etc. are not inherently relevant to the amount of goodness in the world. But, if the earlier points in this post are correct, these features _are_ relevant to the rightness of an action. Thus, these features would demonstrate that there are features relevant to the rightness of an action which are not relevant to the goodness associated with that action. This suffices to show that consequentialism should be abandoned. An alternative moral system should be adopted to account for a more complete range of all morally relevant features.

----------

### Further Questions

Some issues that have been touched on here that I hope to explore further in the future.

1.  I expressed my skepticism that the concept of an "overall" or "collective" goodness is intelligible. I hope to elaborate on why I believe this in a future post.
2.  I would like to provide an explanation for why the moral features that I listed - responsibility, desert, previous agreements, rights, interest reasonableness - are morally relevant. Likely, this will involve appealing to some broader moral theory, which leads to my next point.
3.  If consequentialism is not a viable option as a moral theory, I should investigate an adequate replacement. I'm currently inclined towards [contractualism](https://plato.stanford.edu/entries/contractualism/), which (I believe) explains the intrinsic moral relevance of some of the aforementioned moral features and which captures the way most people engage in moral reasoning.

### Relevant works

The Right vs The Good and Deontic vs Evaluative concepts

-   Mark Schroeder, "[Value Theory](https://plato.stanford.edu/entries/value-theory/#RelDeo)" (2016) in _Stanford Encyclopedia of Philosophy_ - Specifically, the section "Relation to the Deontic"
-   William David Ross, "[The Meaning of Right](http://www.ditext.com/ross/right1.html)" from _The Right and the Good_ (1930) [[archive](https://web.archive.org/web/20171217235227/http://www.ditext.com/ross/right1.html)].
-   Christine Tappolet, "[The Normativity of Evaluative Concepts](https://philpapers.org/archive/TAPTNO.pdf)" (2014) [[archive](https://web.archive.org/web/20180721021115/https://philpapers.org/archive/TAPTNO.pdf)]

The consequentializing debate

-   John Dreier, "[Structures of Normative Theories](https://www.brown.edu/academics/philosophy/sites/brown.edu.academics.philosophy/files/uploads/StructuresOfNormativeTheories_0.pdf)" (1993) [[archive](https://web.archive.org/web/20190127232617/https://www.brown.edu/academics/philosophy/sites/brown.edu.academics.philosophy/files/uploads/StructuresOfNormativeTheories_0.pdf)]
-   Douglas Portmore, "[Consequentializing moral theories](http://www.public.asu.edu/~dportmor/Consequentializing_Moral_Theories.pdf)" (2007) [[archive](https://web.archive.org/web/20161023100834/http://www.public.asu.edu/~dportmor/Consequentializing_Moral_Theories.pdf)]
-   Campbell Brown, "[Consequentialize This](https://www.research.ed.ac.uk/portal/files/12473535/BROWN_C_Consequentialize_This.pdf)" (2011) [[archive](https://web.archive.org/web/20190427225229/https://www.research.ed.ac.uk/portal/files/12473535/BROWN_C_Consequentialize_This.pdf)]
-   James Drier, "[In defense of consequentialization](https://www.brown.edu/academics/philosophy/sites/brown.edu.academics.philosophy/files/uploads/Dreier%20In%20Defense%20of%20Consequentizling.pdf)" (2011) [[archive](https://web.archive.org/web/20190127232459/https://www.brown.edu/academics/philosophy/sites/brown.edu.academics.philosophy/files/uploads/Dreier%20In%20Defense%20of%20Consequentizling.pdf)]
-   Stephen Schroeder, "[Consequentializing and Its Consequences](https://philarchive.org/archive/SCHCAI-11v1)" (2017) [[archive](https://web.archive.org/web/20191129031957/https://philarchive.org/archive/SCHCAI-11v1)]

Other referenced papers

-   Christine Korsgaard, "[The Relational Nature of the Good](http://www.people.fas.harvard.edu/~korsgaar/CMK.Relational.Good.pdf)" (2013) [[archive](https://web.archive.org/web/20170407234808/http://www.people.fas.harvard.edu/~korsgaar/CMK.Relational.Good.pdf)]
-   Olson and Svensson, "[A Particular Consequentialism: Why Moral Particularism and Consequentialism Need Not Conflict](https://pdfs.semanticscholar.org/d190/f40e8e397869fe89463ab0f8932db211fc86.pdf)" (2003) [[archive](https://web.archive.org/web/20191129073307/https://pdfs.semanticscholar.org/d190/f40e8e397869fe89463ab0f8932db211fc86.pdf?_ga=2.183173542.100959440.1575012706-2048259272.1566015406)]