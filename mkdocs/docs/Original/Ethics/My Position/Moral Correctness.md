# Moral Correctness

There seems to be a connection between moral norms and rationality. Insofar as an agent does what is morally wrong, or fail to see what really is morally wrong, we believe the agent is being *irrational*. They are not receptive to the *moral reasons* that apply to them. The question, then, is how to characterize moral reasons. 

There are at two kinds of reasons special to morality

1. "X is morally wrong" = society has reason to blame someone who does X.
2. "X is morally wrong" = someone has reason to accept a principle that forbid X assuming they had the aim of finding principles that would be reasonable to others similarly motivated.

The former is inherent to the definition of moral judgments.
Standards of correctness will be based on standards of correctness for blame.
This is based on standards of correctness fo attitudes in general, i.e. some form of dispositionalism.

The latter is found only in cultures where morality is debated/argued.
Standards of correctness will be based on the constructed standards implicit in moral argument.
Call this kind of reasoning intersubjective justification, the upshot of which determines intersubjective reasons.
Intersubjective justification is what determines the content of correct moral principles.

They are combined together so that moral truth consist in the following.
"X is wrong" = We have intersubjective reason to blame someone for X.

Two kinds of moral reasons and two different standards of truth

## Sentimentalist

Sentimental morality (aesthetic): truth predicated on the appropriateness of moral attitudes. This will be rational sentimentalism (assuming there is anything constituitive of moral attitudes) or dispositionalism. This emphasizes the *expressive* role of moral feelings (think: X is disgusting!).

The standards of correctness reduce to the appropriateness of the attitudes in question. This works the same as standards of correctness for aesthetic judgments in general, and for reasons in general (e.g. perhaps by appealing to the refined attitudes that would be had by the speaker if he were more informed and idealized).

The standards of correctness (either constituitive of dispositional) will have to depend on the particular nature of moral emotions (i.e. blame, shame, resentment, anger, etc.). Because correctness depends on contingent psychological sensibilities, correctness is not mind-dependent in a way sufficient for objectivity. This is similar to aesthetic judgments in general (think ettiquette) and perhaps secondary properties. Therefore, any true applications of these norms to someone must require that the standards can *motivate* the agent, or they would *motivate* an ideal agent.

### Theories

Two classes of moral attitudes:
1. Generic attitudes of approval/disapproavl
2. Specific natural emotions: anger, guilt, shame, etc.

Non-cognitive features of generic attitudes:
- *Expressive*: Moral attitudes are generic evaluative attiudes expressing approval or disapproval.
- *Prescriptive*: Moral attitudes are tools for modifying social behavior.

A note about Specific Natural Emotions:
- While some natural emotions (e.g. fear) have specific constitutive conditions for their appropriateness, it seems moral emotions might not. E.g. the appropriateness of anger can not be understood in purely non-normative terms; fear is appropriate only when someone has been wronged.

Some standards include dispositionalism and rational sentimentalism.

### Dispositionalism

To judge that X is morally wrong is to judge that one has reason to feel emotional response R with regard to X. One has reason to feel R with regard to X if and only if X is such as to elicit R in circumstances c. The circumstances C can be given several formulations such as, e.g., normal circumstances.

This is similar to the truth conditions for when an entity is a certain color. I.e. X is red if and only if X is such as to elicit the perception of redness in normal humans under normal circumstances.

This will not work for moral terms because:

1. It cannot be used to criticize conventional moral responses.
2. It doesn't explain why one's evaluative judgments influence their emotional response, whereas one's judgments about color concepts don't influence their color perceptions. 
3. It doesn't explain why moral truth can be discovered a priori under reflection, whereas truth about color concepts cannot.

This may be improved by focusing on *idealized* circumstances rather than *normal* circumstances.

### Rational Sentimentalism

To judge that X is morally wrong is to judge that one has reason to feel emotional response R with regard to X. One has reason to feel R with regard to X if and only if X has the properties ascribed by the emotional response R. 

For example, to fear X involves some sort of perception that it is dangerous. This is constitutive of fear, and there is clear evolutionary reason to develop such a psychological faculty. One has reason, then, to fear X if and only if X is dangerous. Moral emotions, e.g. blame, resentment, guilty, etc., are emotions like that.

This is kind of siimilar to "thick" ethical concepts, except with sentimentalism the attitudes are guiding the correct application of the concepts as opposed to the concepts being constructed in a way that picks out certain features.

## Constructivism

Note:
- We could have a society where we only have personal private reasons for blame/shame
- But insofar as we judge that we have reason to find intersubjective justifications, we do have such reasons (because global constructivism is true).
- We do judge that we have reason to find intersubjective justifications, i.e. we think it's important to have an objective methodology for settling moral disputes. 
- Some people don't make these judgments; they can be ignored.
- Thus, 

Constructivist morality: truth predicated predicated on standards implicit in moral *discussion*. Implicit in moral discussion is that the considerations that each parties presents counts as *reasons* for the other party to take into account. This emphasizes the *prescriptive* role of moral arguments ("Don't do X" or "shame the behavior of X"), i.e. as tools to shape the attitudes of others.

The standards of correctness reduce to the reasons that other agents have to obey the prescriptions, i.e. to refrain from doing X or to shaming the doing of X. These are not just reasons as such (because there isn't a shared set of reasons shared by everyone), but reasons contingent upon a goal of establishing a system of norms to coordinate the behavior of others in society. 

There are objective standards of correctness for this form of moral judgments, as there is a fixed goal which there are objectively (in)correct methods for satisfying the goal. This form of moral correctness is the form that grounds claims of *justice* (when political institutions are *wrong* in a way stronger than just saying they warrant blame/shame). Note that these standards are not motivating for (even ideal versions of) all individuals/societies, particularly those individuals/societies that don't use discussion/argument (rather than rhetoric, emotional, threats, force, divinity, etc.) as a means to persuading others to adopt certain moral norms. Such norms would still be applicable to these parties (i.e. we could still call them morally wrong), but they could never appreciate these standards.

This locates the source of rationality that we feel is implicit in morality. We find that we really don't think people are *irrational* per se when they are immoral, i.e. we probably wouldn't acuse Hitler, psychopaths, war enemies, etc. of being irrational when they do something we find immoral. And we don't even acuse them of being irrational for believing that they're morally justified (assuming their judgments are consistent with the judgments of their idealized selves). We acuse them of being irrational when they try to justify their actions to us in moral *argument* and *discussion*. 

The framework

1. Constructivism
2. Implicit commitments
3. Communicative commitments
4. Impartiality 
5. Reasons for everyone to accept ...

### Communicative Commitments

Standards of correctness. Some examples:
* Explicit: if someone says "X is P", then we can look at the *content* of that proposition to determine some standards of correctness. E.g. if we were to also say "X is not P", then by merely looking at the *content*, we could deduce that the proposition must be incorrect.
* Hard Implication: if someone were to speak "I am not speaking", we could not look purely at the *content* of the proposition to determine whether it were false. If we know nothing about a person, then such a proposition could be true or false. Instead, we look at the *assertion* of the statement, whether than the *content* of the statement, to determine that the statement must be false.
* Soft Implication: in moral discussion, the *issuing* of a moral command implies that the receiver has reason to follow the rule. I.e. it would be strange for someone to say "you are morally obligated to X" while simultaneously saying "you have no reason to X". Of course, this is coherent, but it would be strange. It's similar to if someone said "I have reason to X, but I don't endorse X" or if someone said "Today is Monday, but I believe it's Tuesday". These statements are intelligible, but they are strange.

To determine ultimate truth for a system, we cannot merely look internally at the judgments to systematize them into a coherent order. Because there can be conflicting internally coherent systems. We look to the meaning of the terms used and the context in which they are used. Normative terms like "right", "wrong", "good", "bad", "ought", etc. are all constructive. They only make sense with reference to an agent with specific goals and ends.

Communicative constraints regarding reasons for belief and/or conversations/arguments generally.
- Burden of proof depends on the speaker who asserts a claim, not on the mere content of the proposition. That someone asserts a claim has a burden of proof cannot be entailed from the content of the propositions expressed. When Mike says "God Exists", it follows that he has reason to follow the rule, even though this reason is not trivially included in the rational extension of his motivational set for beliefs.
- Even though an anecdotal experience might provide one with a personal reason for belief, it would not provide everyone with a reason for belief (e.g. a scientific reason).
- How to know what the standards are? We check what would happen if everyone accepted it. If no one accepted a burden of proof, the central goal of argument would be defeated.
- Don't interrupt others, cut them off, etc. Listen to them.

### Moral commitments

#### Impartiality

Impartiality: Moral reasons can be distinguished from practical reasons in that the moral reasons are reasons for action with some impartiality constraint (e.g. science = interpsonal reasons for belief). Possible conceptions of moral norms
- Individual practical reasons that everyone individual has.
	- Korsgaard: Valuing anything requires valuing the capacity to value.
	- Denial of Metaphysical Egoism: There is no valid distinction to make between different individuals.
- Aggregation
	- Reasons that follow after considering everyone's individual goodness. 
	- Maximizing the total utility of everyone (e.g. utilitarianism).
	- Technical problem with aggregate
		- The idea of there being a numerical assessment of well-being is dubious. What would the numbers mean?
	- Intuitive problems with aggregation
		- If we must choose between causing one person extreme harm and N people minor harm, then it the size of N doesn't matter.
		- If we must choose between causing one person harm and N people comparable harm, then it the size of N does matter.
		- If we must choose between causing one person extreme harm and N people serious but not as extreme harm (e.g. paralysis versus loss of limb), then does the size of N matter? There may be no determinate answer to cases like this.
- Veil of Ignorance
	- Personal reasons a person has under the veil of ignorance.
- Contractualist:
	- Norms no one could reasonably reject as a basis for unenforced, informed cooperation given that one has such a desire.
	- This does suggest that all agents should be treated as ends in themselves? (maybe not as strong as in the Kantian sense). If agents are not ends, then why does it matter if they can reasonably reject a principle?
- Universalization:
	- Maxims that A can rationally willed to be a maxim followed by agents. This requires:
		- It be conceivable for the maxim to be universalizable, and
		- It be possible for someone to rationally will the maxim to be universalizable. E.g. Kant says (1) for any agent A, A's ends sometimes require help, (2) if all agents adopted a maxim whereby they never helped anyone, then this would frustrate A's end, therefore (3) A cannot rationally will a maxim that prescribe agents to never help.
	- Necessary but not sufficient.
		- Provides some formal constraints on possible maxims.
		- May need to be supplanted (e.g. with Contractualism) to account for immoral ends which are conceivable and rational.
	- Cannot account for moral actions that are inconceivable as universal laws
		- e.g. Donate to charity more than the average
	- Cannot account for immoral actions that are conceivable/rational as universal laws
		- e.g. Ritualized bullying for newcomers.
	- Too stringent, e.g. Never Lie
	- Non-rational creatures have no moral consideration
- Kantian Contractualism (from Parfit)
	- Everyone ought to follow the principles whose universal acceptance everyone could rationally will.
	- "An act is wrong unless such acts are permitted by some principle whose universal acceptance everyone could rationally will"
	- Different from standard Kantianism which says "follow principles whose universal acceptance YOU could rationally will."

Note that the personal reasons a person has under the veil of ignorance =/= norms no one could reasonably reject as a basis for informed cooperation. The difference is that the former is concerned with individual, personal reasons constrained with regard to information, whereas the latter are constituted by impartial, social reasons. E.g. even though it is rational to accept a system under the veil of ignorance that left everyone great except for one person who sufferred immensely, it would be rational for that one person to reject those norms as a basis for cooperation given a desire for cooperation.

#### Implied Content

Implications of A advocating for a norm in moral discussion:
- (Regulative) A thinks the the norm should regulate our actions, our societal standards for shame/praise, and individual standards for guilt/pride. 
- (Negotiative) A is willing to negotiate to cooperate and coordinate plans.
- (Impartial) A thinks the norm applies to, and can be justified to, everyone, including himself.
- (Speaker Motivational) A *is disposed to* regulate his behavior as prescribed by the norm.
- (Communal Motivation) A thinks others are *capable* of being motivated to regulate their behavior in accord with the norm; they are capable of being receptive to the reasons favoring the norm. E.g. while it might make sense for A to *dislike* B's preference for ice crean, it doesn't make sense for A to *disapprove* of B's preference for ice cream, but it would make sense it B regarded A as his dietary adviser. This is true even when B's actions might harm A. E.g. it doesn't make sense for A to disapprove of B's attack against him if B would be completely unreceptive (e.g. animal, child, evil person, alien,s etc.), but it would make sense for someone who was receptive (i.e. normal rational agent).
- (Rationality) A thinks that he and others in society *have reason to* regulate their behavior as prescribed by the norm.

Implications on good moral discussion
(1) Object of inquiry: moral discussion concerns primarily what *norms* to accept in society. Particular actions are assessed secondarily based on their conformity with those norms. This allows for some rule-consequential reasoning about the justification of norms, which is not possible when focusing strictly on actions. This is not to say that all justifications must be rule-consequentialist. There might also be deontological justification of certain rules.
- Issue regarding the relevance of the consequences of accepting a principle. In a certain sense, the consequences of accepting a certain principle is relevant, e.g. the harm caused by accepting a principle that permitted the raping unconscious persons is a reason against accepting the principle. On the other hand, it seems that sometimes the consequences don't matter, e.g. imagine that an evil demon would destroy the world if a certain principle were accepted. That may be a reason agains the principle, but the wrong kind of reason against the principle. 
(2) Content of the norms: the norms must be impartial. The norms cannot make reference to any particular persons, but rather particular circumstances.
(3) Justification of norms: norms are justified not because they are reasonable to an agent with a particular point of view. They are justified because they can be reasonable from the "moral point of view". Because all values are not teleological and because there can be reasons that dismiss the relevance of other reasons, this means that certain considerations can be excluded from counting as moral reasons:
- Considerations that neglect the fully rational interests of an agent for no counterveiling reasons (e.g. see below).
	- This can extend beyond a narrow conception of well-being understood as sensory experiences.
- Fairness: considerations that are indexical can be discounted
- Responsibility: Harm to those who are responsible is more justifiable tham harm to those who are irresponsible.
- Degenerate Interests: Interests based upon desire for the harm of others.
- Aggregation: aggregation in itself doesn't matter. See T.M. Scanlon
- Hard question: how to handle norms that harm some and help others.

## Extensions of other systems

### Constructed normative domains

Imagine social games with their own personal rules.
We can use those rules as standards of criticism without rationally criticizing an agent.

Or consider the constructed standards of relationships
- To stand in a certain relation to someone (e.g. friend, lover, partner, cooperator, self-respecting individuals, etc.) has certain expectations for behavior by the parties involved. To the extent that someone violates these expectations, it is appropriate to not extend those behaviors to them, since they would now stand outside of the relationship. 
- This might work for friends and ettiquette (i.e. to the extent that someone doesn't uphold the standards of good friendship, ettiquette, it is appropriate to not treat them as a friend, or with ettiquette). Maybe it also works for aesthetic morality. But maybe this doesn't work for forceful morality (maybe if someone is immoral, we still have moral obligations towards them, i.e. we can exclude them from society, but we cannot kill them).

Other constructed normative domains
- Prudential Rationality: there are no independent standards for bodily movements. But insofar as one is deliberative and reflective and evaluates their own actions, i.e. one is a rational agent, there are standards for behavior.
- Games: there are no independent standards for moving small pieces across a checkered board. But insofar as one is playing chess, there are constituitive standards of the activity that entail standards of correctness.
- Relationships: there are no independent standards of kindness, respect, loyalty, etc. with regard to how to treat others. But insofar as one is being a friend, partner or other normatively-laden relationships, there are constituitive standards of the activity that entail standards of behavior.
- Communication: there are no independent standards of speaking or language. But insofar as one is communicating as a means to transfer ideas to someone else, there are standards of correctness.
- Conversation: To engage in a *discussion* or *conversation* with someone, one implies that they will listen to the other party, not cut them off, etc. even though there may be no independent reason to do thees things. 
- Negotiation: To engage in a *negotiation* implies that people are willing to sacrifice or deviate from their most preferred plan to help satisfy the interests of others. Now, one might have no reason to do these things (i.e. if they had full power), but then they wouldn't be negotiating. They would be bad negotiators. 
- Morality: there are no independent standards of behavior. But insofar as one is engaged in moral argument as a procedure for finding *impartial reasons*, or reasons that all can accept, there are constituitive standards of correctness.

#### Intersubjective Justification

Many normative domains are concerned with what can be justified to different agents, not any individual agent. E.g.

- Personal experience / intuition / presuppositions might provide an individual agent with reasons for believe. But they cannot independently provide anyone else with a reason for belief (unless the other agent believes the other person's experience/intuition/etc. are accurate). Science is a system that searches for intersubjective justification for beliefs. Thus, such instances are not scientifically justified.
- That a principle benefits A at the expense of everyone else might be a reason for A to adopt the principle, but that is no reason for anyone else to accept it (e.g. a principle that said everyone has a moral obligation to maximize my pleasure). Thus, such a principle cannot be morally justified.

#### Golden Rule

- Golden Rule: Treat others in the way you would want to be treated.
	- Upshot: don't kill if you wouldn't want to be killed. 
	- Problem 1: what if I would have different desires than the recipients? E.g. a masochist wouldn't mind being attacked.
	- Problem 2: what if I would have desires that people treat me unreasonably? E.g. I would want others to always benefit me at the expense of others. 
- Moral Emotions: Treat others in the way that you would not blame someone for treating you
	Upshot: You can treat others in a way that you would dislike, so long as you wouldn't blame them for it.
- Rationalized: Treat others not based on counterfactual desires, but on our counterfactual reasons for blame.
	- Upshot: don't kill if they don't have reason to want to be killed (e.g. even if they're in an intoxicated state where they want to be killed).
	- Doesn't solve either problem. Just idealizes desires/blame.
- Inversed: Treat others in the way they want you to treat them or would not blame you for.
	- Upshot: don't attack if the person doesn't want to be attacked.
	- Solves Problem 1.
- Abstracted: Treat others in accord with principles any rational agent would endorse, independent of their actual circumstances, desires, interests, etc. (i.e. veil of ignorance), if the agent knew he had a chance of any combination of circumstances or desires.
	- Upshot: don't kill it would be forbidden by any principles that no one could rationally reject.
	- Solves Problem 1 and Problem 2.
	- Reasons from Ignorant self-interest =/= reasons from morality.
- Moralized: Treat others in accord with principles no rational agent could rationally reject, contingent upon that agent having a goal of finding such principles that others couldn't rationally reject.

#### Negotiation

- Normal negotions: 
	- Two parties are interested in trading goods. 
	- Each party has a ranked set of alternative systems of trade they would be willing to accept.
	- e.g. one party is willing to pay no more than $100 for some good X. The other is willing to sell X for no less than $50.
	- A good negotiation is one where X is sold for somewhere between $50 and $100.
	- The exact number to make the sell is indeterminate.
	- Agents may not have *reasons* to be good negotiators, i.e. if one party could coerce the other, that might be in their best interests.
- Morality features the following augmentations
	- Concerns alternative systems of principles to regulate society; not systems of trade.
	- Impartiality: Abstracts from any particular irrelevant circumstances, i.e. wealth, power, fame, race, etc. 

#### Comparisons

What kinds of reason are moral reasons?
Formal characterizations - make no reference to moral content
1. Standard prudential reasons. This defeats the purpose of morality. Morality is supposed to constraint action in some way.
2. Collective Reasons (Gauthier). Reasons for norms that would be rational for everyone to accept. E.g. norms whose general acceptance would benefit everyone. 
Substantive characterizations - make normative assumptions which are essential to morality
1. Reasons behind veil of ignorance (Rawls). Reasons for norms that would be rational for everyone to accept in ignorance of their particular circumstances.
2. Contractualist Reasons. Reasons for norms that would be reasonable to accept insofar as one had an interest in finding such norms. 

## Motivation

Both forms of morality explains why agents have reason to endorse certain moral principles. But neither explains why an agent has reason to abide by the duties prescribed by the moral principles. An agent would have such a reason insofar as they either (1) have natural sympathy with the welfare of others (meaning the reasons that others hold would be reasons that they also hold), or (2) judge that their behavior should be consistent with the norms they endorse.

## Objectivity

Morality is rationally optional, but this doesn't diminish its authority:

- Contingent on our interests:
	- Nearly universal: most people interested in impartial/social reasons, having a system of norms regulating blame.
	- Emphasizes the negotiation aspect: people cant just have independent that they claim are objective with no consideration of other person's reasons.
	- Other analogues: Scientific reasons are impartial/social reasons for belief (and thus evidentially optional), but that doesn't diminish its authority.
- Not externally necessarily justifiable, like all normative domains
	- Deduction/induction/abduction/evidence/science cannot be reasonable to someone who doesn't care for those forms of reasoning

There are no judgment-independent standards of moral truth, but that's a good thing:

- People cannot just come with arbitrary principles and claim them as the moral virtues.
- They are forced to take into account the interests of others.
- They are forced to make their demands reasonable to others. 
- Moral reasoning is a process of negotiation rather than of discovery.