<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.2.0">Jekyll</generator><link href="/feed.xml" rel="self" type="application/atom+xml" /><link href="/" rel="alternate" type="text/html" /><updated>2021-04-22T01:55:30-07:00</updated><id>/feed.xml</id><title type="html">Your Site Title</title><subtitle>Your Site Description
</subtitle><author><name>Your Name</name></author><entry><title type="html">Free Will</title><link href="/2019/06/19/Free-Will.html" rel="alternate" type="text/html" title="Free Will" /><published>2019-06-19T00:00:00-07:00</published><updated>2019-06-19T00:00:00-07:00</updated><id>/2019/06/19/Free%20Will</id><content type="html" xml:base="/2019/06/19/Free-Will.html">&lt;p&gt;I will be assuming determinism is true. So whether we have free will depends on whether compatibilism is true. My post here will argue for determinism. The first thing to settle when having these debates is meaning. We need to determine what we &lt;em&gt;mean&lt;/em&gt; by “free will”. &lt;em&gt;What beliefs are we expressing when we say someone has free will?&lt;/em&gt; After settling meaning, then we can determine whether people sometimes actually have free will or not. Obviously, if “free will” is &lt;em&gt;defined&lt;/em&gt; as some sort of incompatibilist free will, then incompatibilism is true; no argument needed. But it’s equally true that if “free will” is &lt;em&gt;defined&lt;/em&gt; as compatibilist free will, then compatibilism is true; no argument needed. Neither of these definitions illuminate the compatibilism/incompatibilism debate.&lt;/p&gt;

&lt;p&gt;I would say that there are two principles components behind the &lt;em&gt;meaning&lt;/em&gt; of free will, i.e. someone has free will if and only if these two components are met: (1) to say that someone had free will in performing an action is to say that they “could have done otherwise” in performing that action, and (2) to say that someone had free will in performing an action is to say that they could be morally responsible for performing that action. This isn’t exactly a definition per se, but I believe it serves as a useful enough analysis to help illuminate the meaning of an otherwise unclear concept; the hope is that the meaning behind &lt;em&gt;these&lt;/em&gt; two components is more clear and less controversial than the meaning behind “free will”. Now that the meaning of “free will” is somewhat illuminated, we can discuss whether people &lt;em&gt;actually&lt;/em&gt; have free will. We have to answer the following two questions: (1) Is it true that people could have done otherwise in a determined world? (2) Do people have moral responsibility in a determined world? People will have free will in performing a particular action whenever the answers to both of these questions are “yes”.&lt;/p&gt;

&lt;p&gt;Now, to answer the first question: &lt;strong&gt;Is it true that people could have done otherwise in a determined world?&lt;/strong&gt; The answer to this question depends on the meaning of “could have done otherwise”. I believe the only reasonable understanding of “could have done otherwise” is this: to say that someone &lt;em&gt;could&lt;/em&gt; have done otherwise is to say that they &lt;em&gt;would&lt;/em&gt; done otherwise &lt;em&gt;if they had different intentions&lt;/em&gt;. For example, if a student misses class because he woke up late, then he might say “I &lt;em&gt;could&lt;/em&gt; have made it to class”. We can make sense of this statement in a determined world because what he means is “I &lt;em&gt;would&lt;/em&gt; have made it to class &lt;em&gt;if I intended to wake up earlier&lt;/em&gt;”. On the other hand, if he misses class because he had an unexpected heart attack, then he might say “I could &lt;em&gt;not&lt;/em&gt; have made it to class”. Here, we can make sense of this statement because what he means is “I &lt;em&gt;would not&lt;/em&gt; have made it to class, &lt;em&gt;regardless&lt;/em&gt; of my intentions” (presumably, their heart attack would have occurred regardless of their intentions). It should be clear that this reasonable understanding of “could have done otherwise” is a compatibilist analysis: on this analysis, some people “could have” done other than they actually did, even in a determined world (as the above examples show).&lt;/p&gt;

&lt;p&gt;Incompatibilists try to claim that “could have done otherwise” deals with what a person would have done &lt;em&gt;if all the conditions were the same&lt;/em&gt; (including everyone’s intentions). But this is pretty much cheating - no one uses “could have done otherwise” in this manner. Under this analysis of “could have done otherwise”, we cannot make sense of the examples mentioned earlier. Under this analysis, if the student who woke up late says “I could have made it to class”, the incompatibilist would have to respond to the student with “Actually, no, you could not have made it to class, because that would require that you do other than what you &lt;em&gt;actually&lt;/em&gt; did. But, you see, the world has been determined from the Big Bang such that you &lt;em&gt;had&lt;/em&gt; to sleep late”. No competent English speaker would respond to the incompatibilist with “Oh, I hadn’t considered that. I was mistaken. I guess I couldn’t have made it to class”. Rather, any competent English speaker would conclude that the incompatibilist simply &lt;em&gt;misunderstood the language&lt;/em&gt; used by the late student; they &lt;em&gt;misunderstood the meaning&lt;/em&gt; of “could have done otherwise”. Let’s do away with the flawed incompatibilist analysis of “could have done otherwise” and return to the more reasonable compatibilist analysis given above. Again, on the more reasonable interpretation, some people “could have done otherwise” even in a determined world.&lt;/p&gt;

&lt;p&gt;For the second question: &lt;strong&gt;Do people have moral responsibility in a determined world?&lt;/strong&gt; First, again, we must settle what it means to say that someone is morally responsible for an action. To say that someone is morally responsible for an action is to say that they can be morally blamed/praised for that action. And moral blameworthiness/praiseworthiness is just one particular form of &lt;em&gt;evaluation&lt;/em&gt; - it’s an evaluation of one’s moral character. Now, you probably don’t think that evaluation &lt;em&gt;generally&lt;/em&gt; is impossible in a deterministic world. For example, we can evaluate the quality of a certain car based on the car’s attributes (e.g. fuel efficiency, safety, etc.), despite the fact that the car obviously did not &lt;em&gt;cause&lt;/em&gt; those attributes. It seems then that we can clearly perform evaluations of moral character &lt;em&gt;specifically&lt;/em&gt; in a determined world, just as we can perform evaluations &lt;em&gt;generally&lt;/em&gt;. We simply point to the relevant attributes of their moral character - i.e. their intentions. So to say that someone is morally responsible for an action is to say that that action was somehow the result of the agent’s intentions. Of course, this is perfectly coherent in a determined world.&lt;/p&gt;

&lt;p&gt;This actually matches up nicely with the compatibilist understanding of “could have done otherwise” given above. On this analysis, if someone “could have done otherwise” when performing an action, then they must have performed the action because of their intentions. And, as stated earlier, someone is morally responsible for an action if that action was the result of their intentions. Thus, it follows that if a person “could have done otherwise” in performing an action, then they can be morally responsible for their action. So the analysis of moral responsibility converges nicely with the analysis of “could have done otherwise”. For example, the student who wakes up late can be morally responsible for missing class, because he missed class &lt;em&gt;as a result of his intentions&lt;/em&gt;. On the other hand, he would not be morally responsible for missing class due to a heart attack, because he did not miss class as a result of his intentions. Again, this is all possible in a determined world. So people can be morally responsible in a determined world.&lt;/p&gt;

&lt;p&gt;This focus on intentions allows for a very convenient analysis of “free will” where someone had free will in doing X if and only if they performed X &lt;em&gt;because of their will&lt;/em&gt; (i.e. where I’m using “will” as a substitute for “intentions”). For example, the student (probably) did not have free will in missing class due to the heart attack, because the heart attack was (probably) independent of his will (his intentions). On the other hand, he (probably) did have free will in missing class due to waking up late, because he (probably) would have woke up earlier if his will (his intentions) were different.&lt;/p&gt;

&lt;p&gt;In conclusion, because a person can be morally responsible in a determined world, and people “could have done otherwise” in a determined world, it follows that people can have free will in a determined world. So you should accept a compatibilist conception of free will. Assuming you agree that the world is determined in the relevant respects, you should also accept that we have free will.&lt;/p&gt;

&lt;p&gt;Add three components:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Intuitions: the appeal of incompatibilism - it starts with an intuition that if people could not have done otherwise, then they don’t have free will (show examples). To best meet these intuitions, they say that free will means “could have done otherwise if all conditions were the same.” The appeal of this definition is that it &lt;em&gt;best captures our intuitions about usage.&lt;/em&gt; But there’s no reason to believe the latter qualifier is necessary. Indeed, metaphysical rewinding of time with all variables fixed is not something that the ordinary person thinks about. If we modify the qualifier, then we have a different definition that &lt;em&gt;best captures our intuitions about the usage&lt;/em&gt;.&lt;/li&gt;
  &lt;li&gt;Even if that was not true, to incompatibilists that say we have maintain moral responsibility &amp;amp; agency (and possibly morality, goodness, etc.), yet who think that I’m giving a new definition of free will: their argument would have to be something like: (P1) most people believe that free will requires indeterminism (not true but let’s assume it’s true); (P2) if most people believe that X is a feature of concept Y, then if your theory posits that X is not a feature of concept Y, then your theory must be a redefinition of Y (not true but let’s assume that it’s true); therefore, your theory, because it posits that free will does not require indeterminism, is a redefinition of free will. But this argument proves too much. If P2 is true, then I could say that you have redefined moral responsibility &amp;amp; agency, as most people have believed it to require libertarianism. They might object that, while this is true, even more people believe that something other than libertarianism is more tightly associated with moral responsibility &amp;amp; agency: that it warrants praiseworthiness/blameworthiness. But I could also say that praiseworthiness/blameworthiness is tightly associated with free will (as I have above). It’s important to keep tight the association between moral responsibility/agency and free will. It makes no sense to say that one is compatible with determinism (against common intuitions), while also saying that the other is incompatible with determinism (agreeing with common intuitions). If you’re going to be revisionist, then be consistently revisionist.&lt;/li&gt;
  &lt;li&gt;Terminological: (1) Already mentioned earlier somewhat. “Free” will literally means our will is free, i.e. unconstrained in the proper manner. This is compatible with determinism. When we think of other normative concepts with “free” in the phrase: freedom, free speech, we don’t think that determinism is detrimental to this. For example, if I were to say “The slaves were free”, does anyone honestly doubt this on the grounds of determinism? No, so why assume this is the case with free will. If I were to say “Free speech is good”, would anyone rebut with “But free will is impossible, because of determinism”? No, so why do so with free will? They would have to show that “Free will” is special in that we think of metaphysical determinism when thinking of free will, but this is false. Only philosophers think of free will (see 1).&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Qualiification to “intentions”. I.e. “x is free to z iff x would z if he had the appropriate intentions and the intentions are of type T”?&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Any intentions? E.g. We’re all free to be successful authors because we would be successful authors if we had the appropriate intentions, e.g. adopted the intentions involved in writing certain words on a piece of paper. But clearly there’s a sense in which some are free to be successful authors whereas others are not.&lt;/li&gt;
  &lt;li&gt;Intentions that we know of. E.g. we’re not free to be successful authors because we do not know which intentions to adopt to become successful, even though we would be successful if we adopted those intentions.&lt;/li&gt;
  &lt;li&gt;Intentions that we know of that are not coerced. E.g. if we would be killed if we did z (but there was no interference), then we are not free to do z. Less extremely, if there were severe penalties for doing z (e.g. social ostrasization) for doing z, then we are less free to do it.&lt;/li&gt;
  &lt;li&gt;Intentions devoid of any causal influence. E.g. libertarian free will. No.&lt;/li&gt;
&lt;/ul&gt;</content><author><name>JayMoss</name></author><summary type="html">I will be assuming determinism is true. So whether we have free will depends on whether compatibilism is true. My post here will argue for determinism. The first thing to settle when having these debates is meaning. We need to determine what we mean by “free will”. What beliefs are we expressing when we say someone has free will? After settling meaning, then we can determine whether people sometimes actually have free will or not. Obviously, if “free will” is defined as some sort of incompatibilist free will, then incompatibilism is true; no argument needed. But it’s equally true that if “free will” is defined as compatibilist free will, then compatibilism is true; no argument needed. Neither of these definitions illuminate the compatibilism/incompatibilism debate. I would say that there are two principles components behind the meaning of free will, i.e. someone has free will if and only if these two components are met: (1) to say that someone had free will in performing an action is to say that they “could have done otherwise” in performing that action, and (2) to say that someone had free will in performing an action is to say that they could be morally responsible for performing that action. This isn’t exactly a definition per se, but I believe it serves as a useful enough analysis to help illuminate the meaning of an otherwise unclear concept; the hope is that the meaning behind these two components is more clear and less controversial than the meaning behind “free will”. Now that the meaning of “free will” is somewhat illuminated, we can discuss whether people actually have free will. We have to answer the following two questions: (1) Is it true that people could have done otherwise in a determined world? (2) Do people have moral responsibility in a determined world? People will have free will in performing a particular action whenever the answers to both of these questions are “yes”. Now, to answer the first question: Is it true that people could have done otherwise in a determined world? The answer to this question depends on the meaning of “could have done otherwise”. I believe the only reasonable understanding of “could have done otherwise” is this: to say that someone could have done otherwise is to say that they would done otherwise if they had different intentions. For example, if a student misses class because he woke up late, then he might say “I could have made it to class”. We can make sense of this statement in a determined world because what he means is “I would have made it to class if I intended to wake up earlier”. On the other hand, if he misses class because he had an unexpected heart attack, then he might say “I could not have made it to class”. Here, we can make sense of this statement because what he means is “I would not have made it to class, regardless of my intentions” (presumably, their heart attack would have occurred regardless of their intentions). It should be clear that this reasonable understanding of “could have done otherwise” is a compatibilist analysis: on this analysis, some people “could have” done other than they actually did, even in a determined world (as the above examples show). Incompatibilists try to claim that “could have done otherwise” deals with what a person would have done if all the conditions were the same (including everyone’s intentions). But this is pretty much cheating - no one uses “could have done otherwise” in this manner. Under this analysis of “could have done otherwise”, we cannot make sense of the examples mentioned earlier. Under this analysis, if the student who woke up late says “I could have made it to class”, the incompatibilist would have to respond to the student with “Actually, no, you could not have made it to class, because that would require that you do other than what you actually did. But, you see, the world has been determined from the Big Bang such that you had to sleep late”. No competent English speaker would respond to the incompatibilist with “Oh, I hadn’t considered that. I was mistaken. I guess I couldn’t have made it to class”. Rather, any competent English speaker would conclude that the incompatibilist simply misunderstood the language used by the late student; they misunderstood the meaning of “could have done otherwise”. Let’s do away with the flawed incompatibilist analysis of “could have done otherwise” and return to the more reasonable compatibilist analysis given above. Again, on the more reasonable interpretation, some people “could have done otherwise” even in a determined world. For the second question: Do people have moral responsibility in a determined world? First, again, we must settle what it means to say that someone is morally responsible for an action. To say that someone is morally responsible for an action is to say that they can be morally blamed/praised for that action. And moral blameworthiness/praiseworthiness is just one particular form of evaluation - it’s an evaluation of one’s moral character. Now, you probably don’t think that evaluation generally is impossible in a deterministic world. For example, we can evaluate the quality of a certain car based on the car’s attributes (e.g. fuel efficiency, safety, etc.), despite the fact that the car obviously did not cause those attributes. It seems then that we can clearly perform evaluations of moral character specifically in a determined world, just as we can perform evaluations generally. We simply point to the relevant attributes of their moral character - i.e. their intentions. So to say that someone is morally responsible for an action is to say that that action was somehow the result of the agent’s intentions. Of course, this is perfectly coherent in a determined world. This actually matches up nicely with the compatibilist understanding of “could have done otherwise” given above. On this analysis, if someone “could have done otherwise” when performing an action, then they must have performed the action because of their intentions. And, as stated earlier, someone is morally responsible for an action if that action was the result of their intentions. Thus, it follows that if a person “could have done otherwise” in performing an action, then they can be morally responsible for their action. So the analysis of moral responsibility converges nicely with the analysis of “could have done otherwise”. For example, the student who wakes up late can be morally responsible for missing class, because he missed class as a result of his intentions. On the other hand, he would not be morally responsible for missing class due to a heart attack, because he did not miss class as a result of his intentions. Again, this is all possible in a determined world. So people can be morally responsible in a determined world. This focus on intentions allows for a very convenient analysis of “free will” where someone had free will in doing X if and only if they performed X because of their will (i.e. where I’m using “will” as a substitute for “intentions”). For example, the student (probably) did not have free will in missing class due to the heart attack, because the heart attack was (probably) independent of his will (his intentions). On the other hand, he (probably) did have free will in missing class due to waking up late, because he (probably) would have woke up earlier if his will (his intentions) were different. In conclusion, because a person can be morally responsible in a determined world, and people “could have done otherwise” in a determined world, it follows that people can have free will in a determined world. So you should accept a compatibilist conception of free will. Assuming you agree that the world is determined in the relevant respects, you should also accept that we have free will. Add three components: Intuitions: the appeal of incompatibilism - it starts with an intuition that if people could not have done otherwise, then they don’t have free will (show examples). To best meet these intuitions, they say that free will means “could have done otherwise if all conditions were the same.” The appeal of this definition is that it best captures our intuitions about usage. But there’s no reason to believe the latter qualifier is necessary. Indeed, metaphysical rewinding of time with all variables fixed is not something that the ordinary person thinks about. If we modify the qualifier, then we have a different definition that best captures our intuitions about the usage. Even if that was not true, to incompatibilists that say we have maintain moral responsibility &amp;amp; agency (and possibly morality, goodness, etc.), yet who think that I’m giving a new definition of free will: their argument would have to be something like: (P1) most people believe that free will requires indeterminism (not true but let’s assume it’s true); (P2) if most people believe that X is a feature of concept Y, then if your theory posits that X is not a feature of concept Y, then your theory must be a redefinition of Y (not true but let’s assume that it’s true); therefore, your theory, because it posits that free will does not require indeterminism, is a redefinition of free will. But this argument proves too much. If P2 is true, then I could say that you have redefined moral responsibility &amp;amp; agency, as most people have believed it to require libertarianism. They might object that, while this is true, even more people believe that something other than libertarianism is more tightly associated with moral responsibility &amp;amp; agency: that it warrants praiseworthiness/blameworthiness. But I could also say that praiseworthiness/blameworthiness is tightly associated with free will (as I have above). It’s important to keep tight the association between moral responsibility/agency and free will. It makes no sense to say that one is compatible with determinism (against common intuitions), while also saying that the other is incompatible with determinism (agreeing with common intuitions). If you’re going to be revisionist, then be consistently revisionist. Terminological: (1) Already mentioned earlier somewhat. “Free” will literally means our will is free, i.e. unconstrained in the proper manner. This is compatible with determinism. When we think of other normative concepts with “free” in the phrase: freedom, free speech, we don’t think that determinism is detrimental to this. For example, if I were to say “The slaves were free”, does anyone honestly doubt this on the grounds of determinism? No, so why assume this is the case with free will. If I were to say “Free speech is good”, would anyone rebut with “But free will is impossible, because of determinism”? No, so why do so with free will? They would have to show that “Free will” is special in that we think of metaphysical determinism when thinking of free will, but this is false. Only philosophers think of free will (see 1). Qualiification to “intentions”. I.e. “x is free to z iff x would z if he had the appropriate intentions and the intentions are of type T”? Any intentions? E.g. We’re all free to be successful authors because we would be successful authors if we had the appropriate intentions, e.g. adopted the intentions involved in writing certain words on a piece of paper. But clearly there’s a sense in which some are free to be successful authors whereas others are not. Intentions that we know of. E.g. we’re not free to be successful authors because we do not know which intentions to adopt to become successful, even though we would be successful if we adopted those intentions. Intentions that we know of that are not coerced. E.g. if we would be killed if we did z (but there was no interference), then we are not free to do z. Less extremely, if there were severe penalties for doing z (e.g. social ostrasization) for doing z, then we are less free to do it. Intentions devoid of any causal influence. E.g. libertarian free will. No.</summary></entry><entry><title type="html">Features of Normative Thought</title><link href="/2019/06/19/Normative-Thought.html" rel="alternate" type="text/html" title="Features of Normative Thought" /><published>2019-06-19T00:00:00-07:00</published><updated>2019-06-19T00:00:00-07:00</updated><id>/2019/06/19/Normative%20Thought</id><content type="html" xml:base="/2019/06/19/Normative-Thought.html">&lt;h2 id=&quot;introduction&quot;&gt;Introduction&lt;/h2&gt;

&lt;p&gt;Animals have desires and beliefs.
Both beliefs and desires are attitudes with proposition content.
“Belief” here is to be understood broadly as an attitude that is essentially representational.
Beliefs and similar attitudes are said to have a &lt;em&gt;mind-to-world&lt;/em&gt; direction of fit.
The contents of these kinds of attitudes are aimed at matching or corresponding to reality.
A “desire” is to be understood as an attitude that is essentially dispositional.
Desires and similar attitudes are said to have a &lt;em&gt;world-to-mind&lt;/em&gt; direction of fit.
These attitudes are such that the agent is disposed to modify the world to match the contents of the desire.
This characterization is just a rough sketch but it suffices for present purposes.&lt;/p&gt;

&lt;p&gt;Hume noted that belief and desire are both necessary to explain and motivate intentional action.
Belief alone can never explain or motivate intentional action.
E.g. A’s belief that it’s raining cannot explain A’s motivation to wear an umbrella.
However, A’s belief that it’s raining &lt;em&gt;and&lt;/em&gt; A’s desires to not be wet can explain A’s motivation to wear an umbrella.
In general, people with identical beliefs can have different action if they have different desires.
Likewise, desire alone can never explain or motivate intentional action.
E.g. A’s desire to not be wet cannot explain A’s motivation to wear an umbrella.
For example, if A believed it was not raining, A might not be motivated to wear the umbrella.
In general, people with identical desires can have different action if they have different beliefs.&lt;/p&gt;

&lt;p&gt;These attitudes are shared with other animals.
When a dog rushes to the door excitingly at the sound of the doorbell, this can be explained (1) by a belief (or a similar mind-to-world attitude) that its owner is at the door and (b) by a desire (or a smiilar mind-to-world attitude) to see its owner.
One capacity that seperates us seemingly from most other animals is our capacity for self-reflection.
Many animals believe whatever they perceive. 
And they act according to whatever they desire at the moment.
There are some exceptions to this rule in particular contexts but nothing that seems to match the essentially deliberative and reflective nature found in normal humans.&lt;/p&gt;

&lt;p&gt;This self-reflection allows us to have higher-order attitudes - attitudes about other attitudes.
We can form believes about our beliefs.
We can form desires about our desires.
We can form beliefs about our desires.
Perhaps, we can even have desires about our beliefs.
Some of these higher-order attitudes are normative judgments - judgments about what we ought to do or what we have reason to do.
More precisely, they are judgments about what attitudes we have reason to adopt.&lt;/p&gt;

&lt;p&gt;As humans, our perceptions do not &lt;em&gt;always&lt;/em&gt; produce corresponding beliefs.
We can step back from our perceptions and question whether we have reason to believe the appearances.
E.g. a person might experience certain perceptions due to a known optical illusion yet suspend belief in the information presented by their perception.
Nor do we always let desires produce action.
We can step back from our desires and question whether we have reason to act on a particular desire.
E.g. a person might have a strong desire to eat chocolate yet refrain from doing so if they know it isn’t good for them.
Unlike most animals whose base desires almost always drive their actions, humans are capable of &lt;em&gt;endorsing&lt;/em&gt; certain desires over others.
In general, when we are unreflectively presented with certain inputs (such as a perception or desire), we can reflect and deliberate over whether we actually endorse those inputs as guiding our decisions, i.e. we can question what attitudes we ought to hold given those inputs.
This faculty of &lt;em&gt;deliberative endorsement&lt;/em&gt; is what constitutes normative thinking and normative judgments.&lt;/p&gt;

&lt;p&gt;The task here is to characterize the thoughts and attitudes involved in deliberative endorsement. 
Is it more like a belief which represents some kind of normative reality?
Or is it more like a desire that disposes agents to behave in certain ways?
When one makes a normative judgment, is this judgment capable of being true or false?
If normative judgments are like beliefs, what are they attempting to represent?
If they are like desires, then what kind of motivational states are they?
Before answering these questions, it makes sense to consider certain features of the endorsement involved with normative judgments.
Once we better understand what is involved with this kind of attitude, we will be better suited to answer the above questions.
I will be reviewing what I take to be four key features of normative judgments that must be accounted for by any characterization of normative thoughts.&lt;/p&gt;

&lt;h2 id=&quot;1-ubiquity&quot;&gt;1. Ubiquity&lt;/h2&gt;

&lt;p&gt;The first feature is the ubiquity of normative thinking. 
We find normative thinking everywhere in human lives. 
As already mentioned, we regularly endorse or reject beliefs and desires. 
E.g. we question whether our current and past perception provides us with reason for a belief, and we question whether our desires (and other attitudes) provides us with reason for action.
Normative thinking is also ubiquitous in another sense, in that it takes a wide variety of attitudes as its object.
Normative thinking is present whenever we are determining whether an attitude is &lt;em&gt;warranted&lt;/em&gt;, &lt;em&gt;appropriate&lt;/em&gt;, &lt;em&gt;justified&lt;/em&gt;, &lt;em&gt;reasonable&lt;/em&gt;, etc.
E.g. we question whether we have &lt;em&gt;reason&lt;/em&gt; to have certain desires, whether fear is &lt;em&gt;justified&lt;/em&gt; in certain contexts, whether we &lt;em&gt;should&lt;/em&gt; admire certain people or certain acts, whether we &lt;em&gt;should&lt;/em&gt; appreciate certain pieces of art, whether hatred or anger is &lt;em&gt;appropriate&lt;/em&gt;, etc.&lt;/p&gt;

&lt;p&gt;The precise terminology is not important.
Whether a person has a normative thought does not depend on whether they happen to use a particular term to express that thought, e.g. it doesn’t depend on whether they use the word “should”, “reason”, “justified”, etc. 
So trying to tie normative &lt;em&gt;thinking&lt;/em&gt; to any necessarily normative &lt;em&gt;language&lt;/em&gt; is not likely to be fruitful.
Normative terms are used here because they commonly refer to what we already understand to be normative thoughts.
However, these thoughts can be understood without reference to any particular terms.
In fact, we could even use prescriptive or declarative language to express normative thoughts without &lt;em&gt;any&lt;/em&gt; normative terms. 
E.g. when a parent scolds their child and utters the prescriptive statement “Don’t hit people to settle disputes” or the declarative statement “We don’t hit each other to settle disputes!”, this can easily be understood as expressing the same thought as expressed by a normatively-laden statement such as “You &lt;em&gt;shouldn’t&lt;/em&gt; hit people to settle disputes” or “It’s &lt;em&gt;wrong&lt;/em&gt; to hit people to settle disputes”.&lt;/p&gt;

&lt;p&gt;I take the idea of a normative thought or attitude to be basic, a kind of attitude familiar to all normal humans which can be better understood upon reflection.
Any agent who is unfamiliar with normative thoughts is unlikely to understand them through any kind of communication. 
It is impossible to explain what a kind of thought is like to a creature that has never experienced those thoughts or anything related to those thoughts. 
Just as it is impossible to explain what it is like to perceive certain colors to a blind person, it is also impossible to explain what it is like to have normative thoughts to someone who doesn’t already have them.
Creatures that do not have normative attitudes (e.g. think of creatures without higher-order attitudes, such as animals, young children, developmentally disabled adults, etc.) cannot hope to understand them.
Thus, I will be assuming we all have a shared understanding of normative thoughts and attitudes.
My task here is merely to point out features of normative attitudes to clarify this shared understanding.&lt;/p&gt;

&lt;p&gt;All normative attitudes involve at least two entities: an agent A and some attitude X. 
All normative judgments can be reduced to: “A has reason to adopt attitude X”, “A ought to adopt attitude X”, “A is justified in adopting attitude X”, “it is appropriate for A to adopt attitude X”, etc.
Specific examples: we might judge that we have reason to go to a party (e.g. because it would make us happy), that we have reason to believe evolutionary theory over creationism, that we ought to admire generous people, that we have no reason to take our anger out the messenger, etc.
If we assumed that normative attitudes expressed truth-apt propositions (something which I do not assume at this point), then we can say they express that a relation holds between an agent and an attitude.&lt;/p&gt;

&lt;p&gt;Note that not all instances of attitudes which can be the object of normative attitudes involve normative judgments.
Sometimes we are prompted with attitudes without reasoning.
For examlpe, a fear of spiders might be biological or instilled from environment, not because someone reasoned that they should fear spiders.
Many of our desires are not produced by reason; rather, they are simply inputs that we take into account during reasoning by deciding how much weight they should have in determining our action (which sometimes results in the desire disappearing after we realize the desire is unreasonable).s&lt;/p&gt;

&lt;p&gt;I said before that all of normative thinking involves a judgment that an agent ought to adopt a certain attitude.
This implies that all normative concepts can be reduced to a relation involving an agent and an attitude. 
I believe this can be done with all actual normative concepts. 
Consider the following reductions of common normative concepts:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;“X is good” = “[some agent(s)] ought to &lt;em&gt;desire&lt;/em&gt; X”&lt;/li&gt;
  &lt;li&gt;“X is credible” = “[some agent(s)] ought to &lt;em&gt;believe&lt;/em&gt; X”&lt;/li&gt;
  &lt;li&gt;“X is morally wrong” = “[some agent(s)] ought not to &lt;em&gt;do&lt;/em&gt; X” and/or “[some agent(s)] ought to &lt;em&gt;blame&lt;/em&gt; those who do X”&lt;/li&gt;
  &lt;li&gt;“X is beautiful” = “[some agent(s)] ought to &lt;em&gt;admire&lt;/em&gt; or &lt;em&gt;appreciate&lt;/em&gt; X”
etc.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Again, the terminology is not what’s important. 
In place of “reason” or “ought”, we could use any term that allows us to refer to a relation involving an agent and the &lt;em&gt;appropriate&lt;/em&gt; or &lt;em&gt;justified&lt;/em&gt; attitude.&lt;/p&gt;

&lt;p&gt;There are two ways the normativity of belief can be misinterpreted.
Firstly, it should be noted that “X is credible” is not meant to be taken as “X is true”.
It is more akin to “X is justified”.
But we know there can be cases where a true belief is unjustified and cases where a false belief may be justified.
A belief is justified for a particular agent depending on whether that agent has evidence to support the belief.
A belief is true depending on whether it accurately corresponds to the world.
The former is a normative notion whereas the latter is a purely descriptive notion.
Secondly, the “ought” involved in the statement “X is credible” is not the same type of “ought” as in “X is morally obligatory”.
The former is concerned with epistemic justification, which is not identical to the justification involved with moral justification.&lt;/p&gt;

&lt;p&gt;All normative concepts and thoughts are similar in that they are all concerned with a special kind of &lt;em&gt;endorsement&lt;/em&gt; of a certain attitude.
They differ in terms of the attitude that the concept “calls for” or that the agent endorses.
There will be as many normative concepts as there are attitudes that can be subject to normative inquiry.
But what kind of attitudes can be subject to normative inquiry?&lt;/p&gt;

&lt;h2 id=&quot;2-motivation&quot;&gt;2. Motivation&lt;/h2&gt;

&lt;p&gt;I believe that the kinds of attitudes that can be subject to normative inquiry are what Thomas Scanlon calls &lt;em&gt;judgment-sensitive&lt;/em&gt; attitudes.
This includes all attitudes X such that one’s judgment that they ought to adopt attitude X can in principle influence whether they actually adopt attitude X.
In other words, this includes attitudes whose adoption by an agent is influenced by that agent’s endorsement of the attitude.
As already mentioned, this includes beliefs, desires, intentions, etc.
One’s beliefs, desires, intentions, etc. are regularly changed depending on whether one thinks the beliefs, desires, intentions, etc. are warranted.
In the case of belief, this almost always happens immediately and without struggle.
E.g. if one judges that they have reason to believe X, they will almost always believe X.
In the case of desire or intention, there is a possibility for weakness of will.
E.g. sometimes a person thinks they have reason to do X, but they fail to do X because their degenerate desires (i.e. desires which they judge themselves not to have reason to give weight to) overpower their normative judgments.
E.g. one might judge that they have reason to study, but their desire to surf the internet wins out and they never study.&lt;/p&gt;

&lt;p&gt;Other judgment-sensitive attitudes includes admiration, fear, anger, blame, pride, etc. 
All of these attitudes can in principle be motivated by judgments regarding their appropriateness.
Again, there are also regularly cases where one’s actual attitudes diverges from their normative judgments.
E.g. one might fear the dark even in contexts where they know they are safe and the fear is unjustified.
Insofar as one fails to adopt a judgment-sensitive attitude that they judge to be appropriate, they can be said to be &lt;em&gt;irrational&lt;/em&gt;.
E.g. procrastinating when you know you shouldn’t, fearing the dark when you know you shouldn’t, etc. are all instances of irrational behavior.&lt;/p&gt;

&lt;p&gt;Attitudes that cannot be the subject of normative inquiry are attitudes that are not judgment-sensitive. 
E.g. hunger, uncomfortableness, intoxicated, confused, having certain perceptions, etc.
These are attitudes or states of mind that one can adopt which are not influenced by one’s judgment of their appropriateness. 
E.g. it would not make sense to call someone irrational for &lt;em&gt;being&lt;/em&gt; hungry, uncomfortable, intoxicated, confused, having certain perceptions, etc.
Of course, they might be irrational for earlier intentional actions that they did to make themselves, hungry, intoxicated, confused, etc. but the final attitudes themselves cannot be irrational, precisely because they are not influenced by normative judgments.
Because of this, these attitudes cannot be attributed to agents in the same way that judgment-sensitive attitudes can be attributed to agents. 
Judgment-sensitive attitudes can be attributed to agents because one’s judgment-sensitive attitudes indicates something about either their normative judgments (if they adopt the attitudes that they take to be appropriate) or their rationality (if they don’t adopt the attitudes that they take to be appropriate).&lt;/p&gt;

&lt;p&gt;Because normative thinking only involves judgment-sensitive attitudes, this means that normative judgments must be intrinsically motivating.
Otherwise, no attitudes could in principle be influenced by one’s normative judgments, which means there would be no judgment-sensitive attitudes.
But if there are no judgment-sensitive attitudes, then normative thinking is not possible.
Since normative thinking clearly is possible, normative judgments must be intrinsically motivating.
An agent who comes to judge that they have reason to adopt attitude X must develop some motivation to adopt attitude X.
Note that this motivation is &lt;em&gt;defeasible&lt;/em&gt;. 
The normative faculty is not perfect, because the normative faculty is not the only motivational system in humans.
As mentioned above, humans are motivated by normative judgments, but they are also motivated by other degenerate desires as well (e.g. desires that we do not endorse).
This occurs in everyday human life, especially for more impulsive people such as children or the mentally handicapped.
This covers the second feature of normative thinking: normative judgments are intrinsically motivating yet defeasible.&lt;/p&gt;

&lt;p&gt;It might be questioned whether it makes sense to say that normative judgments must necessarily be intrinsically motivational if they are defeasible.
But we already accept this with other attitudes that are necessarily motivational.
E.g. desires are necessarily motivational states, but, for any particular desire, an agent might not act on that particular desire if they have a conflicting desire.
E.g. someone might desire to read a book, but a stronger desire to watch a movie might win out.
Likewise, a stronger desire might win out over a normative judgment.
Similar considerations apply to all attitudes like beliefs, fear, admiration, anger, etc. 
E.g. someone might judge that have no reason to be angry with someone, yet neverthless feel angry.
To endorse any of these attitudes entails some motivation, but it can be defeated by other base motivations.
Another way of putting it: normative judgments must be &lt;em&gt;capable&lt;/em&gt; of motivating an agent to adopt the relevant attitude on its own, without the need to posit an additional desire.
In other words, the normative judgment that attitude X is appropriate entails a disposition to adopt attitude X, the same as any other motivational state such as a desire.&lt;/p&gt;

&lt;h2 id=&quot;3-disagreement&quot;&gt;3. Disagreement&lt;/h2&gt;

&lt;p&gt;The third feature of normative judgments is the possibility for normative disagreements.
Perhaps the most prominent case of this kind of disagreement concerns (normative) reasons for belief.
Most disagreements about what is true involve disagreements about what (normative) reason we have for belief.
E.g. imagine an atheist and a theist who agree with certain facts, e.g. that the universe is complex.
That might not only disagree over whether God exists, but they also disagree over whether a certain set of facts or observations (facts which they agree with) &lt;em&gt;justify&lt;/em&gt; the belief in God, e.g. whether the complexity of the universe is a (normative) &lt;em&gt;reason&lt;/em&gt; to believe in God.
It is a disagreement about what the &lt;em&gt;evidence supports&lt;/em&gt;, which is a seperate question from what is true.
It is a question about what it is &lt;em&gt;appropriate&lt;/em&gt; to infer given observations that we all agree with.
This is a normative dispute.&lt;/p&gt;

&lt;p&gt;Similar disputes are had regarding the natural empirical world.
E.g. some pro gun-control advocates think that the &lt;em&gt;evidence indicates&lt;/em&gt; that gun control reduces violent crime whereas some opponents think the opposite is supported by the evidence.
Again, these are seperate questions from what is true.
Whether a belief is justified for an agent depends on the evidence available to that agent.
Whether a belief is true is a seperate question.
A justified belief might be false and a true belief might be unjustified.&lt;/p&gt;

&lt;p&gt;There are even arguments regarding more general principles for justifying beliefs.
There is agreement among most that certain methods of inference can justify beliefs. E.g. deduction, induction, abduction.
There is dispute about whether we are justified in relying on sense data, memories, inferring causation, etc. to form beliefs
There is dispute over various epistemic principles and how best to understand them: e.g. occam’s razor, whether falsifcation, verification, etc. are requirement of a scientific theory and what they consist in.
Most people accept these principles in at least some contexts.
The most extreme skeptics deny that they can ever justify a belief.
There are disagreements over general theories of justification. E.g. coherentism vs foundationalism.&lt;/p&gt;

&lt;p&gt;The next most prominent form of normative disagreement is moral disagreement.
There is widespread disagreement over what we should do, who ought to be blamed for what actions, what kinds of beings deserve moral consideration, etc.
There are moral disagreements about political issues, e.g. what the government’s stance ought to be regrading abortion, immigration, taxation, welfare, affirmative action, free speech, etc.
There are moral disagreements regarding personal behavior, e.g. how one ought to treat their friends, loved ones, children, the appropriate standards for behavior in polite society and the ramification for failing to meet those standards.
We disagree with our friends, strangers in our society, strangers of other societies and cultures, about how people ought to behave and what ought to be acceptable.&lt;/p&gt;

&lt;p&gt;There are moral disagreements about general ethical theories, often among philosophers. 
Consequentialists argue that actions are to be morally evaluated based on some relation to their consequent state of affairs.
Deontologists argue that actions are to be morally evaluated based on at least some features other than their consequent state of affairs.
Kantians argue that people are to never be treated as a mere means but always as an end.
Certain deontologists have certain rights that ought to never be violated for the sake of some overall good.
Certain anarchists argue that the initation of force is always wrong.
Hedonists argue that the only good thing is pleasure or happiness.
Pluralists argue that there are distinct and perhaps incomensurate types of value that cannot be reduced to any single good.
Generally speaking, when one person says “X is good” and another says “No, X is not good”, they have expressed &lt;em&gt;conflicting&lt;/em&gt; attitudes.
Similar points apply when “good” is replaced with other common moral terms, such as “right”, “bad”, etc.&lt;/p&gt;

&lt;p&gt;Similar disagreement (though often less heated) disagreement is found in other domains as well.
E.g. in aesthetics, people disagree over whether a piece of art is beautiful, whether someone is funny or not, whether a movie is good, etc. sAn analysis of normative terms must allow for and explain the conflict we regularly find in normative disagreements.&lt;/p&gt;

&lt;h2 id=&quot;4-non-empirical&quot;&gt;4. Non-empirical&lt;/h2&gt;

&lt;p&gt;Disagreement is so widespread in fact that two people can even agree that an object has certain physical properties while disagreeing on what attitudes are appropriate with regard to that object, without either person contradicting themselves.
This is due to the fourth and final feature of normative judgments: no set of empirical beliefs logically entail any set of normative judgments (or vice versa).
This relation is similar to the relation between beliefs and desire - no set of beliefs can logically entail any set of desires.
Just like any pair of beliefs and desire is possible, any pair of empirical beliefs and normative judgments is possible.
When a person judges that someone has reason to do something, we cannot infer that the judge also believes any particular &lt;em&gt;empirical&lt;/em&gt; relation holds between the agent and the attitude.
E.g. two people might agree on all the relevant empirical facts regarding abortion, but still disagree over whether women should be able to perform abortions.
Also unlike empirical beliefs, we seem to discover normative truths a priori.
We ordinarily do not perform observations in the world to determine a normative truth.
Rather, we think conceptual analysis and reason alone is enough to establish normative truths.&lt;/p&gt;

&lt;h2 id=&quot;the-problem&quot;&gt;The problem&lt;/h2&gt;

&lt;p&gt;Now that we have illustrated what I take to be the main features of normative judgments, we can now return to the original task.
We can now attempt to characterize the kind of attitude involved in &lt;em&gt;deliberative endorsement&lt;/em&gt;. 
The characterization has to be one that can be applied to the normative judgments of virtually all people.
This universal characterization is required because it is necessary to ground a shared concept, and a shared concept is necessary for the genuine disagreements we have with others. 
Otherwise, these “disagreements” wouldn’t really be disagreements, we would just be talking past each other with different concepts.
E.g. if “good” for Adam meant “approved by society” and “good” for Bob meant “approved by God”, then when Adam says “X is good” and Bob says “No, X is not good”, what is really happening is Adam is saying “X is approved by society” and Bob is saying “No, X is not approved by God”. 
But this characterization of normative judgment clearly does not allow for a disagreement (there is no contradiction with X being approved by society and X not be approved by God).
Since Adam and Bob clearly do disagreement when one says “X is good” and the other says “No, X is not good” (i.e. Adam and Bob both judge that the other person is &lt;em&gt;incorrect&lt;/em&gt;), this characterization does not suffice.&lt;/p&gt;

&lt;p&gt;Possible characterizations can be broadly seperated into two categories - world-to-mind states of mind and mind-to-world states of mind.
Both are states of mind that that have propositional content as their objects, i.e. agents have beliefs and desires with regard to p where p is some proposition. 
Mind-to-world states of mind are states whereby the propositional content of the attitude is meant to &lt;em&gt;correspond&lt;/em&gt; to an external reality. 
E.g. if one believes that p, then p is aimed at corresponding to reality. 
World-to-mind states of mind are states whereby the agent is disposed to modify the world so that the propositional content of the attitude is made true. 
E.g. if one desires that p, then they are disposed to try to make it the case that p is true. 
Whereas mind-to-world states have a &lt;em&gt;correspondence&lt;/em&gt; role, world-to-mind states have a &lt;em&gt;dispositional&lt;/em&gt; or &lt;em&gt;functional&lt;/em&gt; role regarding one’s motivations.&lt;/p&gt;

&lt;p&gt;How do we determine whether an attitude has a mind-to-world direction of fit or a world-to-mind direction of fit?
One test for the direction of fit of an attitude is to determine whether the attitude persists despite observing evidence against the propositional content of the attitude. 
For example, someone’s belief in p will tend to diminish upon observing evidence against p. 
E.g. if someone &lt;em&gt;believes&lt;/em&gt; that their home football team will win the game tonight, this will (usually) tend to diminish as they observe evidence that the team will lose, e.g. if the home team loses their best player, then this will diminish one’s belief they they will win. 
On the other hand, if one &lt;em&gt;desires&lt;/em&gt; that their home team win, then this attitude (usually) does not tend to diminish upon observing that the team will lose, e.g. if the home team loses their best player, then this will &lt;em&gt;not&lt;/em&gt; diminish one’s desire that they win.
Like most desires, the desire here persists despite evidence against the truth of the corresponding propositional content.&lt;/p&gt;

&lt;p&gt;It seems clear to me that normative attitudes have a world-to-mind direction of fit.
That is, when a person endorses A’s adoption of attitude X, this does not tend to diminish as one learns that A fails to adopt attitude X.
This to me lends evidence to a non-cognitive analysis of normative judgments.
This implies that normative judgments are not &lt;em&gt;beliefs&lt;/em&gt; or other cognitive states that represent a normative reality. 
Rather, they are sophisticated forms of desire-like states (or dispositions to have certain desire-like states).
However, other theories of normative talk purport to explain the appearances better. 
These theories are discussed in “Theories of Normative Talk”.
In the end, I believe that non-cognitivism is the best account of our normative thinking.&lt;/p&gt;</content><author><name>JayMoss</name></author><summary type="html">Introduction Animals have desires and beliefs. Both beliefs and desires are attitudes with proposition content. “Belief” here is to be understood broadly as an attitude that is essentially representational. Beliefs and similar attitudes are said to have a mind-to-world direction of fit. The contents of these kinds of attitudes are aimed at matching or corresponding to reality. A “desire” is to be understood as an attitude that is essentially dispositional. Desires and similar attitudes are said to have a world-to-mind direction of fit. These attitudes are such that the agent is disposed to modify the world to match the contents of the desire. This characterization is just a rough sketch but it suffices for present purposes. Hume noted that belief and desire are both necessary to explain and motivate intentional action. Belief alone can never explain or motivate intentional action. E.g. A’s belief that it’s raining cannot explain A’s motivation to wear an umbrella. However, A’s belief that it’s raining and A’s desires to not be wet can explain A’s motivation to wear an umbrella. In general, people with identical beliefs can have different action if they have different desires. Likewise, desire alone can never explain or motivate intentional action. E.g. A’s desire to not be wet cannot explain A’s motivation to wear an umbrella. For example, if A believed it was not raining, A might not be motivated to wear the umbrella. In general, people with identical desires can have different action if they have different beliefs. These attitudes are shared with other animals. When a dog rushes to the door excitingly at the sound of the doorbell, this can be explained (1) by a belief (or a similar mind-to-world attitude) that its owner is at the door and (b) by a desire (or a smiilar mind-to-world attitude) to see its owner. One capacity that seperates us seemingly from most other animals is our capacity for self-reflection. Many animals believe whatever they perceive. And they act according to whatever they desire at the moment. There are some exceptions to this rule in particular contexts but nothing that seems to match the essentially deliberative and reflective nature found in normal humans. This self-reflection allows us to have higher-order attitudes - attitudes about other attitudes. We can form believes about our beliefs. We can form desires about our desires. We can form beliefs about our desires. Perhaps, we can even have desires about our beliefs. Some of these higher-order attitudes are normative judgments - judgments about what we ought to do or what we have reason to do. More precisely, they are judgments about what attitudes we have reason to adopt. As humans, our perceptions do not always produce corresponding beliefs. We can step back from our perceptions and question whether we have reason to believe the appearances. E.g. a person might experience certain perceptions due to a known optical illusion yet suspend belief in the information presented by their perception. Nor do we always let desires produce action. We can step back from our desires and question whether we have reason to act on a particular desire. E.g. a person might have a strong desire to eat chocolate yet refrain from doing so if they know it isn’t good for them. Unlike most animals whose base desires almost always drive their actions, humans are capable of endorsing certain desires over others. In general, when we are unreflectively presented with certain inputs (such as a perception or desire), we can reflect and deliberate over whether we actually endorse those inputs as guiding our decisions, i.e. we can question what attitudes we ought to hold given those inputs. This faculty of deliberative endorsement is what constitutes normative thinking and normative judgments. The task here is to characterize the thoughts and attitudes involved in deliberative endorsement. Is it more like a belief which represents some kind of normative reality? Or is it more like a desire that disposes agents to behave in certain ways? When one makes a normative judgment, is this judgment capable of being true or false? If normative judgments are like beliefs, what are they attempting to represent? If they are like desires, then what kind of motivational states are they? Before answering these questions, it makes sense to consider certain features of the endorsement involved with normative judgments. Once we better understand what is involved with this kind of attitude, we will be better suited to answer the above questions. I will be reviewing what I take to be four key features of normative judgments that must be accounted for by any characterization of normative thoughts. 1. Ubiquity The first feature is the ubiquity of normative thinking. We find normative thinking everywhere in human lives. As already mentioned, we regularly endorse or reject beliefs and desires. E.g. we question whether our current and past perception provides us with reason for a belief, and we question whether our desires (and other attitudes) provides us with reason for action. Normative thinking is also ubiquitous in another sense, in that it takes a wide variety of attitudes as its object. Normative thinking is present whenever we are determining whether an attitude is warranted, appropriate, justified, reasonable, etc. E.g. we question whether we have reason to have certain desires, whether fear is justified in certain contexts, whether we should admire certain people or certain acts, whether we should appreciate certain pieces of art, whether hatred or anger is appropriate, etc. The precise terminology is not important. Whether a person has a normative thought does not depend on whether they happen to use a particular term to express that thought, e.g. it doesn’t depend on whether they use the word “should”, “reason”, “justified”, etc. So trying to tie normative thinking to any necessarily normative language is not likely to be fruitful. Normative terms are used here because they commonly refer to what we already understand to be normative thoughts. However, these thoughts can be understood without reference to any particular terms. In fact, we could even use prescriptive or declarative language to express normative thoughts without any normative terms. E.g. when a parent scolds their child and utters the prescriptive statement “Don’t hit people to settle disputes” or the declarative statement “We don’t hit each other to settle disputes!”, this can easily be understood as expressing the same thought as expressed by a normatively-laden statement such as “You shouldn’t hit people to settle disputes” or “It’s wrong to hit people to settle disputes”. I take the idea of a normative thought or attitude to be basic, a kind of attitude familiar to all normal humans which can be better understood upon reflection. Any agent who is unfamiliar with normative thoughts is unlikely to understand them through any kind of communication. It is impossible to explain what a kind of thought is like to a creature that has never experienced those thoughts or anything related to those thoughts. Just as it is impossible to explain what it is like to perceive certain colors to a blind person, it is also impossible to explain what it is like to have normative thoughts to someone who doesn’t already have them. Creatures that do not have normative attitudes (e.g. think of creatures without higher-order attitudes, such as animals, young children, developmentally disabled adults, etc.) cannot hope to understand them. Thus, I will be assuming we all have a shared understanding of normative thoughts and attitudes. My task here is merely to point out features of normative attitudes to clarify this shared understanding. All normative attitudes involve at least two entities: an agent A and some attitude X. All normative judgments can be reduced to: “A has reason to adopt attitude X”, “A ought to adopt attitude X”, “A is justified in adopting attitude X”, “it is appropriate for A to adopt attitude X”, etc. Specific examples: we might judge that we have reason to go to a party (e.g. because it would make us happy), that we have reason to believe evolutionary theory over creationism, that we ought to admire generous people, that we have no reason to take our anger out the messenger, etc. If we assumed that normative attitudes expressed truth-apt propositions (something which I do not assume at this point), then we can say they express that a relation holds between an agent and an attitude. Note that not all instances of attitudes which can be the object of normative attitudes involve normative judgments. Sometimes we are prompted with attitudes without reasoning. For examlpe, a fear of spiders might be biological or instilled from environment, not because someone reasoned that they should fear spiders. Many of our desires are not produced by reason; rather, they are simply inputs that we take into account during reasoning by deciding how much weight they should have in determining our action (which sometimes results in the desire disappearing after we realize the desire is unreasonable).s I said before that all of normative thinking involves a judgment that an agent ought to adopt a certain attitude. This implies that all normative concepts can be reduced to a relation involving an agent and an attitude. I believe this can be done with all actual normative concepts. Consider the following reductions of common normative concepts: “X is good” = “[some agent(s)] ought to desire X” “X is credible” = “[some agent(s)] ought to believe X” “X is morally wrong” = “[some agent(s)] ought not to do X” and/or “[some agent(s)] ought to blame those who do X” “X is beautiful” = “[some agent(s)] ought to admire or appreciate X” etc. Again, the terminology is not what’s important. In place of “reason” or “ought”, we could use any term that allows us to refer to a relation involving an agent and the appropriate or justified attitude. There are two ways the normativity of belief can be misinterpreted. Firstly, it should be noted that “X is credible” is not meant to be taken as “X is true”. It is more akin to “X is justified”. But we know there can be cases where a true belief is unjustified and cases where a false belief may be justified. A belief is justified for a particular agent depending on whether that agent has evidence to support the belief. A belief is true depending on whether it accurately corresponds to the world. The former is a normative notion whereas the latter is a purely descriptive notion. Secondly, the “ought” involved in the statement “X is credible” is not the same type of “ought” as in “X is morally obligatory”. The former is concerned with epistemic justification, which is not identical to the justification involved with moral justification. All normative concepts and thoughts are similar in that they are all concerned with a special kind of endorsement of a certain attitude. They differ in terms of the attitude that the concept “calls for” or that the agent endorses. There will be as many normative concepts as there are attitudes that can be subject to normative inquiry. But what kind of attitudes can be subject to normative inquiry? 2. Motivation I believe that the kinds of attitudes that can be subject to normative inquiry are what Thomas Scanlon calls judgment-sensitive attitudes. This includes all attitudes X such that one’s judgment that they ought to adopt attitude X can in principle influence whether they actually adopt attitude X. In other words, this includes attitudes whose adoption by an agent is influenced by that agent’s endorsement of the attitude. As already mentioned, this includes beliefs, desires, intentions, etc. One’s beliefs, desires, intentions, etc. are regularly changed depending on whether one thinks the beliefs, desires, intentions, etc. are warranted. In the case of belief, this almost always happens immediately and without struggle. E.g. if one judges that they have reason to believe X, they will almost always believe X. In the case of desire or intention, there is a possibility for weakness of will. E.g. sometimes a person thinks they have reason to do X, but they fail to do X because their degenerate desires (i.e. desires which they judge themselves not to have reason to give weight to) overpower their normative judgments. E.g. one might judge that they have reason to study, but their desire to surf the internet wins out and they never study. Other judgment-sensitive attitudes includes admiration, fear, anger, blame, pride, etc. All of these attitudes can in principle be motivated by judgments regarding their appropriateness. Again, there are also regularly cases where one’s actual attitudes diverges from their normative judgments. E.g. one might fear the dark even in contexts where they know they are safe and the fear is unjustified. Insofar as one fails to adopt a judgment-sensitive attitude that they judge to be appropriate, they can be said to be irrational. E.g. procrastinating when you know you shouldn’t, fearing the dark when you know you shouldn’t, etc. are all instances of irrational behavior. Attitudes that cannot be the subject of normative inquiry are attitudes that are not judgment-sensitive. E.g. hunger, uncomfortableness, intoxicated, confused, having certain perceptions, etc. These are attitudes or states of mind that one can adopt which are not influenced by one’s judgment of their appropriateness. E.g. it would not make sense to call someone irrational for being hungry, uncomfortable, intoxicated, confused, having certain perceptions, etc. Of course, they might be irrational for earlier intentional actions that they did to make themselves, hungry, intoxicated, confused, etc. but the final attitudes themselves cannot be irrational, precisely because they are not influenced by normative judgments. Because of this, these attitudes cannot be attributed to agents in the same way that judgment-sensitive attitudes can be attributed to agents. Judgment-sensitive attitudes can be attributed to agents because one’s judgment-sensitive attitudes indicates something about either their normative judgments (if they adopt the attitudes that they take to be appropriate) or their rationality (if they don’t adopt the attitudes that they take to be appropriate). Because normative thinking only involves judgment-sensitive attitudes, this means that normative judgments must be intrinsically motivating. Otherwise, no attitudes could in principle be influenced by one’s normative judgments, which means there would be no judgment-sensitive attitudes. But if there are no judgment-sensitive attitudes, then normative thinking is not possible. Since normative thinking clearly is possible, normative judgments must be intrinsically motivating. An agent who comes to judge that they have reason to adopt attitude X must develop some motivation to adopt attitude X. Note that this motivation is defeasible. The normative faculty is not perfect, because the normative faculty is not the only motivational system in humans. As mentioned above, humans are motivated by normative judgments, but they are also motivated by other degenerate desires as well (e.g. desires that we do not endorse). This occurs in everyday human life, especially for more impulsive people such as children or the mentally handicapped. This covers the second feature of normative thinking: normative judgments are intrinsically motivating yet defeasible. It might be questioned whether it makes sense to say that normative judgments must necessarily be intrinsically motivational if they are defeasible. But we already accept this with other attitudes that are necessarily motivational. E.g. desires are necessarily motivational states, but, for any particular desire, an agent might not act on that particular desire if they have a conflicting desire. E.g. someone might desire to read a book, but a stronger desire to watch a movie might win out. Likewise, a stronger desire might win out over a normative judgment. Similar considerations apply to all attitudes like beliefs, fear, admiration, anger, etc. E.g. someone might judge that have no reason to be angry with someone, yet neverthless feel angry. To endorse any of these attitudes entails some motivation, but it can be defeated by other base motivations. Another way of putting it: normative judgments must be capable of motivating an agent to adopt the relevant attitude on its own, without the need to posit an additional desire. In other words, the normative judgment that attitude X is appropriate entails a disposition to adopt attitude X, the same as any other motivational state such as a desire. 3. Disagreement The third feature of normative judgments is the possibility for normative disagreements. Perhaps the most prominent case of this kind of disagreement concerns (normative) reasons for belief. Most disagreements about what is true involve disagreements about what (normative) reason we have for belief. E.g. imagine an atheist and a theist who agree with certain facts, e.g. that the universe is complex. That might not only disagree over whether God exists, but they also disagree over whether a certain set of facts or observations (facts which they agree with) justify the belief in God, e.g. whether the complexity of the universe is a (normative) reason to believe in God. It is a disagreement about what the evidence supports, which is a seperate question from what is true. It is a question about what it is appropriate to infer given observations that we all agree with. This is a normative dispute. Similar disputes are had regarding the natural empirical world. E.g. some pro gun-control advocates think that the evidence indicates that gun control reduces violent crime whereas some opponents think the opposite is supported by the evidence. Again, these are seperate questions from what is true. Whether a belief is justified for an agent depends on the evidence available to that agent. Whether a belief is true is a seperate question. A justified belief might be false and a true belief might be unjustified. There are even arguments regarding more general principles for justifying beliefs. There is agreement among most that certain methods of inference can justify beliefs. E.g. deduction, induction, abduction. There is dispute about whether we are justified in relying on sense data, memories, inferring causation, etc. to form beliefs There is dispute over various epistemic principles and how best to understand them: e.g. occam’s razor, whether falsifcation, verification, etc. are requirement of a scientific theory and what they consist in. Most people accept these principles in at least some contexts. The most extreme skeptics deny that they can ever justify a belief. There are disagreements over general theories of justification. E.g. coherentism vs foundationalism. The next most prominent form of normative disagreement is moral disagreement. There is widespread disagreement over what we should do, who ought to be blamed for what actions, what kinds of beings deserve moral consideration, etc. There are moral disagreements about political issues, e.g. what the government’s stance ought to be regrading abortion, immigration, taxation, welfare, affirmative action, free speech, etc. There are moral disagreements regarding personal behavior, e.g. how one ought to treat their friends, loved ones, children, the appropriate standards for behavior in polite society and the ramification for failing to meet those standards. We disagree with our friends, strangers in our society, strangers of other societies and cultures, about how people ought to behave and what ought to be acceptable. There are moral disagreements about general ethical theories, often among philosophers. Consequentialists argue that actions are to be morally evaluated based on some relation to their consequent state of affairs. Deontologists argue that actions are to be morally evaluated based on at least some features other than their consequent state of affairs. Kantians argue that people are to never be treated as a mere means but always as an end. Certain deontologists have certain rights that ought to never be violated for the sake of some overall good. Certain anarchists argue that the initation of force is always wrong. Hedonists argue that the only good thing is pleasure or happiness. Pluralists argue that there are distinct and perhaps incomensurate types of value that cannot be reduced to any single good. Generally speaking, when one person says “X is good” and another says “No, X is not good”, they have expressed conflicting attitudes. Similar points apply when “good” is replaced with other common moral terms, such as “right”, “bad”, etc. Similar disagreement (though often less heated) disagreement is found in other domains as well. E.g. in aesthetics, people disagree over whether a piece of art is beautiful, whether someone is funny or not, whether a movie is good, etc. sAn analysis of normative terms must allow for and explain the conflict we regularly find in normative disagreements. 4. Non-empirical Disagreement is so widespread in fact that two people can even agree that an object has certain physical properties while disagreeing on what attitudes are appropriate with regard to that object, without either person contradicting themselves. This is due to the fourth and final feature of normative judgments: no set of empirical beliefs logically entail any set of normative judgments (or vice versa). This relation is similar to the relation between beliefs and desire - no set of beliefs can logically entail any set of desires. Just like any pair of beliefs and desire is possible, any pair of empirical beliefs and normative judgments is possible. When a person judges that someone has reason to do something, we cannot infer that the judge also believes any particular empirical relation holds between the agent and the attitude. E.g. two people might agree on all the relevant empirical facts regarding abortion, but still disagree over whether women should be able to perform abortions. Also unlike empirical beliefs, we seem to discover normative truths a priori. We ordinarily do not perform observations in the world to determine a normative truth. Rather, we think conceptual analysis and reason alone is enough to establish normative truths. The problem Now that we have illustrated what I take to be the main features of normative judgments, we can now return to the original task. We can now attempt to characterize the kind of attitude involved in deliberative endorsement. The characterization has to be one that can be applied to the normative judgments of virtually all people. This universal characterization is required because it is necessary to ground a shared concept, and a shared concept is necessary for the genuine disagreements we have with others. Otherwise, these “disagreements” wouldn’t really be disagreements, we would just be talking past each other with different concepts. E.g. if “good” for Adam meant “approved by society” and “good” for Bob meant “approved by God”, then when Adam says “X is good” and Bob says “No, X is not good”, what is really happening is Adam is saying “X is approved by society” and Bob is saying “No, X is not approved by God”. But this characterization of normative judgment clearly does not allow for a disagreement (there is no contradiction with X being approved by society and X not be approved by God). Since Adam and Bob clearly do disagreement when one says “X is good” and the other says “No, X is not good” (i.e. Adam and Bob both judge that the other person is incorrect), this characterization does not suffice. Possible characterizations can be broadly seperated into two categories - world-to-mind states of mind and mind-to-world states of mind. Both are states of mind that that have propositional content as their objects, i.e. agents have beliefs and desires with regard to p where p is some proposition. Mind-to-world states of mind are states whereby the propositional content of the attitude is meant to correspond to an external reality. E.g. if one believes that p, then p is aimed at corresponding to reality. World-to-mind states of mind are states whereby the agent is disposed to modify the world so that the propositional content of the attitude is made true. E.g. if one desires that p, then they are disposed to try to make it the case that p is true. Whereas mind-to-world states have a correspondence role, world-to-mind states have a dispositional or functional role regarding one’s motivations. How do we determine whether an attitude has a mind-to-world direction of fit or a world-to-mind direction of fit? One test for the direction of fit of an attitude is to determine whether the attitude persists despite observing evidence against the propositional content of the attitude. For example, someone’s belief in p will tend to diminish upon observing evidence against p. E.g. if someone believes that their home football team will win the game tonight, this will (usually) tend to diminish as they observe evidence that the team will lose, e.g. if the home team loses their best player, then this will diminish one’s belief they they will win. On the other hand, if one desires that their home team win, then this attitude (usually) does not tend to diminish upon observing that the team will lose, e.g. if the home team loses their best player, then this will not diminish one’s desire that they win. Like most desires, the desire here persists despite evidence against the truth of the corresponding propositional content. It seems clear to me that normative attitudes have a world-to-mind direction of fit. That is, when a person endorses A’s adoption of attitude X, this does not tend to diminish as one learns that A fails to adopt attitude X. This to me lends evidence to a non-cognitive analysis of normative judgments. This implies that normative judgments are not beliefs or other cognitive states that represent a normative reality. Rather, they are sophisticated forms of desire-like states (or dispositions to have certain desire-like states). However, other theories of normative talk purport to explain the appearances better. These theories are discussed in “Theories of Normative Talk”. In the end, I believe that non-cognitivism is the best account of our normative thinking.</summary></entry><entry><title type="html">Abortion</title><link href="/2019/06/19/Abortion.html" rel="alternate" type="text/html" title="Abortion" /><published>2019-06-19T00:00:00-07:00</published><updated>2019-06-19T00:00:00-07:00</updated><id>/2019/06/19/Abortion</id><content type="html" xml:base="/2019/06/19/Abortion.html">&lt;h2 id=&quot;pro-life-argument&quot;&gt;Pro-life argument&lt;/h2&gt;

&lt;ol&gt;
  &lt;li&gt;A fetus is a life
    &lt;ul&gt;
      &lt;li&gt;A. Arbitrariness argument
        &lt;ol&gt;
          &lt;li&gt;The line drawn to designate when life begins must be non-arbitrary.&lt;/li&gt;
          &lt;li&gt;The only non-arbitrary, non-repugnant line to draw for life before birth is conception.&lt;/li&gt;
          &lt;li&gt;[from 1 &amp;amp; 2] Life begins at conception.&lt;/li&gt;
        &lt;/ol&gt;
      &lt;/li&gt;
      &lt;li&gt;B. Potentiality argument
        &lt;ol&gt;
          &lt;li&gt;If X has the potential to develop into a being of type T, then X should be afforded all the same rights afforded to beings of type T.&lt;/li&gt;
          &lt;li&gt;Fetuses have potential develop into human life.&lt;/li&gt;
          &lt;li&gt;[from 1 &amp;amp; 2] Fetuses have a right to life.&lt;/li&gt;
        &lt;/ol&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;It is wrong to terminate a life&lt;/li&gt;
  &lt;li&gt;Abortion is wrong.&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;rebuttal&quot;&gt;Rebuttal&lt;/h2&gt;

&lt;p&gt;Rebuttal against 3:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;The pro-life argument works only if the fetus is understood as being a full life deserving of full rights to personhood. But if a fetus deserves full rights to personhood, then there are following two hugely unintuitive conclusions:
    &lt;ul&gt;
      &lt;li&gt;Abortion would be unjustified even when the pregnancy is due to rape: One cannot accept (1) a fetus deserves full rights to personhood, and (2) abortion is justified in the case of rape. Because (1) implies the falsity of (2). In other circumstances, when a person has full rights to personhood, another person cannot revoke those rights just because they were victimized. E.g. I cannot kill you to account for a crime that someone else committed.&lt;/li&gt;
      &lt;li&gt;Abortion would be unjustified even when the mother’s life is at risk: One cannot accept (1) a fetus deserves full rights to personhood, and (2) abortion is justified when the mother’s life is at risk. Because (1) implies the falsity of (2). In other circumstances, when a person has full rights to personhood, another person cannot revoke those rights just to save their life. E.g. I cannot kill you because I need a heart transplant.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;There are two options:
    &lt;ol&gt;
      &lt;li&gt;Bite the bullet and assert that abortion is unjutsified in the case of rape and danger to the mother.&lt;/li&gt;
      &lt;li&gt;Admit that fetus don’t really have full rights to personhood, but rather some weird form of pseudo-right to personhood. But what is the nature of the pseudo-rights and why should we believe that it encompasses protection of life only when the mother consented to pregnancy and/or is in danger. These are strange forms of rights not seen anywhere else. The only forms of rights either involve full rights to personhood (i.e. humans) or rights to not be subjected to pain but no rights to life (i.e. animals).&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Rebuttal against 1A1:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;General cases: we can say the same about plenty of things - age when one should be able to consent, vote, work, smoke, drink, run for office, etc. Why the discrepancy?&lt;/li&gt;
  &lt;li&gt;Abortion-specific case: assuming they believe that the mother can abort if her life is in danger. What non-arbitrary percentage of danger can you point to to say that the mother is justified in abortion?&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Rebuttal against 1B1:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;We don’t think chlidren should have the right to vote, run for office, drive vehicles, consent to sex, etc. even though they have the &lt;em&gt;potential&lt;/em&gt; to develop the capacities that would ordinarily generate these rights.&lt;/li&gt;
  &lt;li&gt;Furthermore, what is meant by “potential”? Some children don’t have the potential to develop these capacities. For example, let’s say that we know the child will die before adulthood because of a genetic disorder.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Rebuttal against 2:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Counter-examples:
    &lt;ul&gt;
      &lt;li&gt;Killing in self-defense. (2) is modified to: it is wrong to terminate an innocent life.&lt;/li&gt;
      &lt;li&gt;Killing with consent. (2) is modified to: it is wrong to terminate an innocent life without consent.&lt;/li&gt;
      &lt;li&gt;Killing to put someone out of misery who can’t consent. (2) is modified to: it is wrong to terminate an innocent life without indication of consent or misery.&lt;/li&gt;
      &lt;li&gt;Killing someone who would have died at that moment: (2) is modified to: it is wrong to terminate an innocent life without indication of consent, misery, or probable future death.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Blood transfusion case: people should not be forced to donate blood to others.
    &lt;ul&gt;
      &lt;li&gt;They respond by invoking responsibility. But, even if someone has put someone else’s life in danger through their own voluntary actions, we don’t force them to donate blood. Why the discrepancy?&lt;/li&gt;
      &lt;li&gt;They bite the bullet and say that we should force people to donate blood in these circumstances. Okay, but the impact of the responsibility is different. In the case of abortion, no being has their life deprived whereas in the case of the voluntary danger, someone’s life has been deprived. The initial voluntary action X produces a responsibility to Y only if X without Y deprives the person of a life that they would have otherwise had.&lt;/li&gt;
      &lt;li&gt;They bite the bullet and say that we should be forced to donate blood to people when we put them in circumstances where they need blood, even if they would not have been alive anyway.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Philosophical first principles: liberty&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;(1) There is no morally relevant difference between detaching in the Modified Blood Transfusion Hypothetical and and detaching in pregnancy.
(2) If there is no morally relevant difference between action X and Y, then X and Y must be given the same moral evaluation.
(3) It is morally permissible to detach in the Modified Blood Transfusion Hypothetical.
(4) (from 1 &amp;amp; 2) Detaching in the Modified Blood Transfusion Hypothetical must be given the same moral evaluation as detaching in pregnancy.
(5) (from 3 &amp;amp; 4) Detaching in pregnancy is morally permissible.&lt;/p&gt;

&lt;p&gt;Notes:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;The deprivation argument has no independent force. It is not meant to show that you are permitted to harm anyone you bring into existence. That’s absurd. E.g. giving a fetus FAS is also immoral.&lt;/li&gt;
  &lt;li&gt;It has force only in a very narrow context if other principles are adopted. I.e. it removes the relevance of responsibility caused by voluntary behavior, specifically when the produced state of affairs is the creation of a new life.&lt;/li&gt;
  &lt;li&gt;It is meant to show a conditional claim: IF it is permissible for the woman to abort due to rape THEN responsibility does not compel her to abort due to consensual sex. More generally: IF A is permitted to not sustain D because of bodily autonomy when they are not responsible for D’s dependence THEN A is also permitted to not sustain D because of bodily autonomy when they ARE responsible for D’s dependence if D would have never existed had A never performed the initial action that provided the responsibility.&lt;/li&gt;
  &lt;li&gt;This does not allow the woman to give the fetus FAS because it is not permissible to give the fetus FAS even in the cases of rape. It does not allow parents to kill children because it is not permissible to kill children even in cases of rape. It might even allow that mothers can be compelled to raise and care for children assuming that we think mothers can be compelled to raise and care for children due to rape (perhaps we do?).&lt;/li&gt;
  &lt;li&gt;Do not try to justify the deprivation point by saying conception + death is no worse off than never conceiving, therefore abortion is permissible. This could justify all sorts of bad stuff. I.e. birth + premature murder is no worse off than never being born, therefore premature murder to one’s offspring is permissible. The principle does not have wide scope. It’s scope only shows that responsibility does not cancel bodily autonomy if it is responsibility for one’s existence.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Objections:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Mentioned in Boonin’s paper - Langer, Tooley, etc.&lt;/li&gt;
  &lt;li&gt;Future like ours objection&lt;/li&gt;
  &lt;li&gt;“The Impairment Principle” argument:
    &lt;ul&gt;
      &lt;li&gt;If impairing an organism to the nth degree is immoral, then (all things else equal) impairing the organism to the nth+1 degree is also immoral.&lt;/li&gt;
      &lt;li&gt;Giving an infant FAS is immoral. Killing an infant causes more impairment than giving an infant FAS. Therefore, killing an infant is immoral.&lt;/li&gt;
      &lt;li&gt;Response: Giving an infant FAS in the case of rape is immoral. However, aborting an infant in the case of rape is not immoral.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Imagine a program is created which requests some stranger to donate their kidney to save someone. If you sign up, you have to stay signed up. This makes sense. Even though your intiial signing up did not deprive the victim of a previous state, it did deprive them of a life that they would have otherwise had (because otherwise someone else could have signed up).&lt;/li&gt;
&lt;/ul&gt;</content><author><name>JayMoss</name></author><summary type="html">Pro-life argument A fetus is a life A. Arbitrariness argument The line drawn to designate when life begins must be non-arbitrary. The only non-arbitrary, non-repugnant line to draw for life before birth is conception. [from 1 &amp;amp; 2] Life begins at conception. B. Potentiality argument If X has the potential to develop into a being of type T, then X should be afforded all the same rights afforded to beings of type T. Fetuses have potential develop into human life. [from 1 &amp;amp; 2] Fetuses have a right to life. It is wrong to terminate a life Abortion is wrong. Rebuttal Rebuttal against 3: The pro-life argument works only if the fetus is understood as being a full life deserving of full rights to personhood. But if a fetus deserves full rights to personhood, then there are following two hugely unintuitive conclusions: Abortion would be unjustified even when the pregnancy is due to rape: One cannot accept (1) a fetus deserves full rights to personhood, and (2) abortion is justified in the case of rape. Because (1) implies the falsity of (2). In other circumstances, when a person has full rights to personhood, another person cannot revoke those rights just because they were victimized. E.g. I cannot kill you to account for a crime that someone else committed. Abortion would be unjustified even when the mother’s life is at risk: One cannot accept (1) a fetus deserves full rights to personhood, and (2) abortion is justified when the mother’s life is at risk. Because (1) implies the falsity of (2). In other circumstances, when a person has full rights to personhood, another person cannot revoke those rights just to save their life. E.g. I cannot kill you because I need a heart transplant. There are two options: Bite the bullet and assert that abortion is unjutsified in the case of rape and danger to the mother. Admit that fetus don’t really have full rights to personhood, but rather some weird form of pseudo-right to personhood. But what is the nature of the pseudo-rights and why should we believe that it encompasses protection of life only when the mother consented to pregnancy and/or is in danger. These are strange forms of rights not seen anywhere else. The only forms of rights either involve full rights to personhood (i.e. humans) or rights to not be subjected to pain but no rights to life (i.e. animals). Rebuttal against 1A1: General cases: we can say the same about plenty of things - age when one should be able to consent, vote, work, smoke, drink, run for office, etc. Why the discrepancy? Abortion-specific case: assuming they believe that the mother can abort if her life is in danger. What non-arbitrary percentage of danger can you point to to say that the mother is justified in abortion? Rebuttal against 1B1: We don’t think chlidren should have the right to vote, run for office, drive vehicles, consent to sex, etc. even though they have the potential to develop the capacities that would ordinarily generate these rights. Furthermore, what is meant by “potential”? Some children don’t have the potential to develop these capacities. For example, let’s say that we know the child will die before adulthood because of a genetic disorder. Rebuttal against 2: Counter-examples: Killing in self-defense. (2) is modified to: it is wrong to terminate an innocent life. Killing with consent. (2) is modified to: it is wrong to terminate an innocent life without consent. Killing to put someone out of misery who can’t consent. (2) is modified to: it is wrong to terminate an innocent life without indication of consent or misery. Killing someone who would have died at that moment: (2) is modified to: it is wrong to terminate an innocent life without indication of consent, misery, or probable future death. Blood transfusion case: people should not be forced to donate blood to others. They respond by invoking responsibility. But, even if someone has put someone else’s life in danger through their own voluntary actions, we don’t force them to donate blood. Why the discrepancy? They bite the bullet and say that we should force people to donate blood in these circumstances. Okay, but the impact of the responsibility is different. In the case of abortion, no being has their life deprived whereas in the case of the voluntary danger, someone’s life has been deprived. The initial voluntary action X produces a responsibility to Y only if X without Y deprives the person of a life that they would have otherwise had. They bite the bullet and say that we should be forced to donate blood to people when we put them in circumstances where they need blood, even if they would not have been alive anyway. Philosophical first principles: liberty (1) There is no morally relevant difference between detaching in the Modified Blood Transfusion Hypothetical and and detaching in pregnancy. (2) If there is no morally relevant difference between action X and Y, then X and Y must be given the same moral evaluation. (3) It is morally permissible to detach in the Modified Blood Transfusion Hypothetical. (4) (from 1 &amp;amp; 2) Detaching in the Modified Blood Transfusion Hypothetical must be given the same moral evaluation as detaching in pregnancy. (5) (from 3 &amp;amp; 4) Detaching in pregnancy is morally permissible. Notes: The deprivation argument has no independent force. It is not meant to show that you are permitted to harm anyone you bring into existence. That’s absurd. E.g. giving a fetus FAS is also immoral. It has force only in a very narrow context if other principles are adopted. I.e. it removes the relevance of responsibility caused by voluntary behavior, specifically when the produced state of affairs is the creation of a new life. It is meant to show a conditional claim: IF it is permissible for the woman to abort due to rape THEN responsibility does not compel her to abort due to consensual sex. More generally: IF A is permitted to not sustain D because of bodily autonomy when they are not responsible for D’s dependence THEN A is also permitted to not sustain D because of bodily autonomy when they ARE responsible for D’s dependence if D would have never existed had A never performed the initial action that provided the responsibility. This does not allow the woman to give the fetus FAS because it is not permissible to give the fetus FAS even in the cases of rape. It does not allow parents to kill children because it is not permissible to kill children even in cases of rape. It might even allow that mothers can be compelled to raise and care for children assuming that we think mothers can be compelled to raise and care for children due to rape (perhaps we do?). Do not try to justify the deprivation point by saying conception + death is no worse off than never conceiving, therefore abortion is permissible. This could justify all sorts of bad stuff. I.e. birth + premature murder is no worse off than never being born, therefore premature murder to one’s offspring is permissible. The principle does not have wide scope. It’s scope only shows that responsibility does not cancel bodily autonomy if it is responsibility for one’s existence. Objections: Mentioned in Boonin’s paper - Langer, Tooley, etc. Future like ours objection “The Impairment Principle” argument: If impairing an organism to the nth degree is immoral, then (all things else equal) impairing the organism to the nth+1 degree is also immoral. Giving an infant FAS is immoral. Killing an infant causes more impairment than giving an infant FAS. Therefore, killing an infant is immoral. Response: Giving an infant FAS in the case of rape is immoral. However, aborting an infant in the case of rape is not immoral. Imagine a program is created which requests some stranger to donate their kidney to save someone. If you sign up, you have to stay signed up. This makes sense. Even though your intiial signing up did not deprive the victim of a previous state, it did deprive them of a life that they would have otherwise had (because otherwise someone else could have signed up).</summary></entry><entry><title type="html">Descriptivism</title><link href="/2019/06/19/Descriptivism.html" rel="alternate" type="text/html" title="Descriptivism" /><published>2019-06-19T00:00:00-07:00</published><updated>2019-06-19T00:00:00-07:00</updated><id>/2019/06/19/Descriptivism</id><content type="html" xml:base="/2019/06/19/Descriptivism.html">&lt;h2 id=&quot;key-features-of-normativitys&quot;&gt;Key features of Normativitys&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Ubiquitous -&lt;/li&gt;
  &lt;li&gt;Disagreement (especially with morality) regardless of empirical agreement or linguistic/societal differences&lt;/li&gt;
  &lt;li&gt;Rational/Deliberative - a priori&lt;/li&gt;
  &lt;li&gt;Motivational - world to mind fit that sometimes conflicts with other motivations&lt;/li&gt;
  &lt;li&gt;Supervenience - normative properties supervene on the natural properties&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;requirements-for-descriptivism&quot;&gt;Requirements for descriptivism&lt;/h2&gt;

&lt;ol&gt;
  &lt;li&gt;Must explain how the normative supervenes on the non-normative.&lt;/li&gt;
  &lt;li&gt;Must explain how a mind-to-world-fit state of mind can produce a mind-to-world fit sate of mind.&lt;/li&gt;
  &lt;li&gt;If there are normative facts, then either the normative facts need to somehow explain our normative judgments or else normative facts must consist in our (hypothetical or idealized) normative judgments. Otherwise, there would be no causal connection bewteen our normative judgments, on the one hand, and the normative facts, on the other. That would mean we could have no justification for any of our normative judgments, because in order to have justified belief in p, it must be the case that one’s belief in p is reliably explained by the fact that p (e.g. the perception that the Earth is not moving is not evidence that the Earth is not moving, because that perception is not better explained by the fact that the Earth is not moving).&lt;/li&gt;
  &lt;li&gt;Attitude-independent theories of normative facts would have to posit that the normative facts are ontologically prior to our normative judgments, but nevertheless explain our normative judgments. This seems impossible under non-naturalism. Under naturalism, it gets more complicated.&lt;/li&gt;
  &lt;li&gt;Attitude-dependent theories of normative facts must not reduce normative facts to our actual attitudes, as this would prevent disconnections between our actual attitudes and our normative judgments, and it would also preclude coherent questioning of one’s actual attitudes. Cannot be the basis of moral judgments because that would prevent coherent moral disagreement assuming all partiies were fully rational.&lt;/li&gt;
  &lt;li&gt;Must provide an explanation for how to translate our moral terms to/from cultures with other languages.&lt;/li&gt;
  &lt;li&gt;Under analytic naturalism, we must be able to replace our normative terms with non-normative terms without losing meaning.&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;general-problems&quot;&gt;General Problems&lt;/h2&gt;

&lt;p&gt;General problems with ignoring non-descriptive attitudes&lt;/p&gt;

&lt;h3 id=&quot;understanding-non-descriptivism&quot;&gt;Understanding non-descriptivism&lt;/h3&gt;

&lt;p&gt;&lt;em&gt;The dynamic meaning of judgments&lt;/em&gt;. Consider two uses of the same term with the same descriptive content but with different meaning, e.g. using “gay” purely descriptively versus derogatorily. Now consider two different terms with the same meaning but whereby one has the dynamic content implicitly associated with it, e.g. “skinny” versus “bony”.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Examples of other domains of non-descriptive judgments&lt;/em&gt;. E.g. aesthetics, tastes, etc.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Necessity of non-descriptive judgments.&lt;/em&gt; We would have needed to develop a system for expressing attitudes of approval, disapproval, and also for modifying the attitudes of others. It seems normative judgments definitely fulfill this role.&lt;/p&gt;

&lt;h3 id=&quot;normativity-doesnt-require-descriptivism&quot;&gt;Normativity doesn’t require descriptivism&lt;/h3&gt;

&lt;h4 id=&quot;normative-educationexpressions&quot;&gt;Normative education/expressions.&lt;/h4&gt;

&lt;p&gt;We teach children to form certain moral judgments by molding their non-descriptive attitudes. 
This is done by rewarding/punishing behavior with various non-descriptive attitudes.
This shows examples of appropriate attitudes in certain circumstances.&lt;/p&gt;

&lt;h4 id=&quot;flexibility-of-language&quot;&gt;Flexibility of language&lt;/h4&gt;

&lt;p&gt;A ought to X, A needs to X, A must X, X is crappy, X is disgusting, etc. can all mean the same thing. 
This is best explained as prescriptions and/or expressions, rather than reports/descriptions. 
It is unlikely that the referrents of the terms in each of these expressions are descriptive of the same entity.
if they were descriptive of the same entity, how would we know?&lt;/p&gt;

&lt;h4 id=&quot;descriptivism-unnecessary&quot;&gt;Descriptivism unnecessary.&lt;/h4&gt;

&lt;p&gt;All of our normative discourse can be explained without appeal to the existence of normative entities, or judgments about such properties.&lt;/p&gt;

&lt;h3 id=&quot;arguments-against-realism&quot;&gt;Arguments against Realism&lt;/h3&gt;

&lt;p&gt;&lt;em&gt;Motivation&lt;/em&gt;. One can infer that an agent has a world-to-mind fit state of mind with respect to X if they judge that they have normative reason to X. With moral judgments, this is particularly true if they &lt;em&gt;exclaim&lt;/em&gt; that a certain action is (im)moral. This is easy to explain if judgments of normative reasons are themselves world-to-mind fits. Otherwise, this is difficult to explain. Attributions of goodness to P have a conceptual link with the guidance of action towards promoting P (judgment internalism). For any (non-)naturalistic property R, we can imagine clear-headed beings who would fail to find appropriate reason or motive to action in the mere fact that R obtains regarding P. The fact that attributions of goodness are &lt;em&gt;necessarily&lt;/em&gt; action-guiding whereas attributions of R are only &lt;em&gt;contingently&lt;/em&gt; action-guiding suggests that goodness and R are not analytically equivalent.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Translation&lt;/em&gt; Imagine we are trying to translate words for descriptive concepts to another language. This involves picking an extension of the relevant concept that we can all agree with and finding the word from the other language that correlates with this extension. For example, if we want to find the translation for the word “red”, we would establish an extension of the concept RED - e.g. blood, stop signs, crayons, etc. Then we would find which word in the other language is often used to refer to the entities in that extension. On the other hand, we cannot do this for normative terms. Firstly, it is doubtful that we could establish an extension of any normative concept that we all agree on. But, more importantly, even if we could, it would not be enough to find the foreign word that corresponds to this extension in order to translate the term. We would also need to know the other society’s motivational and non-cognitive attitudes and dispositions with regard to the extension. For, it is conceivable that they could think that the extensions was either good or bad. This attacks all forms of non-naturalism and objectivist forms of naturalism.
-&amp;gt; Also imagine a culture with an identical nonverbal language of our own except that they didn’t speak verbally. They used sign language predominantly to communicate. Some analysis of their movements would be reducible to expressions of beliefs. How would we analyze the meaning of showing a middle finger? How would we analyze a parent who angrily points at a child’s bedroom (ordering him to go)? Imagine they needed to express more sophisticated thoughts using this language. Is it truly questionable whether they could express the entire range of human attitudes, including the attitudes themselves, dispositions to have the attitudes, endorsement of the attitudes? Is it questionable whether questionable whether they could use their language in a way to influence the behavior of others? Would we have any need to posit the existence of mind-independent action-guiding properties to explain the phenomenon? Would it change if they spoke verbally?&lt;/p&gt;

&lt;h3 id=&quot;arguments-against-all-descriptivism&quot;&gt;Arguments against all Descriptivism&lt;/h3&gt;

&lt;p&gt;&lt;em&gt;Non-predicating&lt;/em&gt;. Imagine someone asserts that some state of affairs or object has a certain normative property. What are they asserting is a property of that state of affairs or object? Nothing.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Role of attitude in Disagreement&lt;/em&gt;. Descriptivism cannot explain the role of attitude in ethical disagreements. There are two forms of disagreement, (1) disagreements in belief (both cannot be true) and (2) disagreement in attitudes (cannot be satisfied). Note that reducing ethical judgments to &lt;em&gt;beliefs about attitudes&lt;/em&gt; cannot account for this. If A believes he desires X and B believes he desires not-X, then these beliefs are not in disagreement because they can both be &lt;em&gt;correct&lt;/em&gt;. E.g. A saying “X is good” and B saying “X is not good” would not be a contradiction, since it would amount to “A desires X” and “B does not desire X”. In fact, they would both be &lt;em&gt;true&lt;/em&gt;. But it seems that ethical disagreement can persist despite accepting these truths.&lt;/p&gt;

&lt;p&gt;Ethical disagreements commonly feature disagreements in attitudes and in beliefs. But attitudes play the primary role because (1) The attitudes determine which beliefs are relevant, and (2) Ethical disagreement persist after agreement in belief. Perhaps this is actually a disagreement in beliefs about each agent’s idealized attitudes, where idealized attitudes are assumed to be convergent. Disagreement in idealized attitudes maybe can account for disagreements in certain normative domains, e.g. disagreements in desires, emotions, maybe even beliefs (i.e. we think other people would come to similar beliefs as us under idealized conditions, because our epistemic frameworks are assumed to be similar). But ethical disagreement can persist despite agreement about the beliefs of everyone’s fully rational, fully informed attitudes. This is not the case with something like think art, humor, taste, etc. This is because ethical judgments have a &lt;em&gt;prescriptive&lt;/em&gt; aspect in that they are meant to guide the behavior of other agents. Such prescriptions cannot &lt;em&gt;both&lt;/em&gt; be actualized when they conflict.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Beliefs and attitudes are logically independent&lt;/em&gt; Take a descriptivist theory of normative judgment which says that ascriptions of goodness to x express belief p to x. Take a non-descriptivist theory of normative judgment which says that such ascriptions express non-descriptivist attitude q to x. Imagine an agent held q with regard to x but they did not hold p with regard to x. It seems safe to say that they judge x to be good. Now imagine that they held p with regard to x but they did not hold q with regard to x. It seems safe to say that they don’t judge to be good.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Co-reference&lt;/em&gt; and &lt;em&gt;Expanded Twin Earth&lt;/em&gt;. What our terms refer is a contingent matter that depends upon our culture and history. It is a feature of our contingent culture that we happened to have hooked up the term “good” with any particular natural or non-natural property good. Imagine that a group of people whom you disagreed with merely stipulated that what they meant by “good” was not the (natural or non-natural) property that you refered to by “good” and they went on using their terms to regulate their behavior in their society. It still seems that you would disagree with them and think that they were incorrect. Even for people in our own societies, there is radical divergence on what things count as “good” or “right”. Yet we still believe that we can disagree. If descriptivism is true, then this is possible only if our terms pick out a common property and competent English speakers co-refer. But these seems implausible. What evidence do we have that all English speakers co-refer? How could we know speakers of different languages co-refer? Yet we know we disagree. Thus, descriptivism is false.&lt;/p&gt;

&lt;p&gt;Non-cognitivism objections:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Embedding&lt;/li&gt;
  &lt;li&gt;Amoralist&lt;/li&gt;
  &lt;li&gt;Realist appearance&lt;/li&gt;
&lt;/ul&gt;</content><author><name>JayMoss</name></author><summary type="html">Key features of Normativitys Ubiquitous - Disagreement (especially with morality) regardless of empirical agreement or linguistic/societal differences Rational/Deliberative - a priori Motivational - world to mind fit that sometimes conflicts with other motivations Supervenience - normative properties supervene on the natural properties Requirements for descriptivism Must explain how the normative supervenes on the non-normative. Must explain how a mind-to-world-fit state of mind can produce a mind-to-world fit sate of mind. If there are normative facts, then either the normative facts need to somehow explain our normative judgments or else normative facts must consist in our (hypothetical or idealized) normative judgments. Otherwise, there would be no causal connection bewteen our normative judgments, on the one hand, and the normative facts, on the other. That would mean we could have no justification for any of our normative judgments, because in order to have justified belief in p, it must be the case that one’s belief in p is reliably explained by the fact that p (e.g. the perception that the Earth is not moving is not evidence that the Earth is not moving, because that perception is not better explained by the fact that the Earth is not moving). Attitude-independent theories of normative facts would have to posit that the normative facts are ontologically prior to our normative judgments, but nevertheless explain our normative judgments. This seems impossible under non-naturalism. Under naturalism, it gets more complicated. Attitude-dependent theories of normative facts must not reduce normative facts to our actual attitudes, as this would prevent disconnections between our actual attitudes and our normative judgments, and it would also preclude coherent questioning of one’s actual attitudes. Cannot be the basis of moral judgments because that would prevent coherent moral disagreement assuming all partiies were fully rational. Must provide an explanation for how to translate our moral terms to/from cultures with other languages. Under analytic naturalism, we must be able to replace our normative terms with non-normative terms without losing meaning. General Problems General problems with ignoring non-descriptive attitudes Understanding non-descriptivism The dynamic meaning of judgments. Consider two uses of the same term with the same descriptive content but with different meaning, e.g. using “gay” purely descriptively versus derogatorily. Now consider two different terms with the same meaning but whereby one has the dynamic content implicitly associated with it, e.g. “skinny” versus “bony”. Examples of other domains of non-descriptive judgments. E.g. aesthetics, tastes, etc. Necessity of non-descriptive judgments. We would have needed to develop a system for expressing attitudes of approval, disapproval, and also for modifying the attitudes of others. It seems normative judgments definitely fulfill this role. Normativity doesn’t require descriptivism Normative education/expressions. We teach children to form certain moral judgments by molding their non-descriptive attitudes. This is done by rewarding/punishing behavior with various non-descriptive attitudes. This shows examples of appropriate attitudes in certain circumstances. Flexibility of language A ought to X, A needs to X, A must X, X is crappy, X is disgusting, etc. can all mean the same thing. This is best explained as prescriptions and/or expressions, rather than reports/descriptions. It is unlikely that the referrents of the terms in each of these expressions are descriptive of the same entity. if they were descriptive of the same entity, how would we know? Descriptivism unnecessary. All of our normative discourse can be explained without appeal to the existence of normative entities, or judgments about such properties. Arguments against Realism Motivation. One can infer that an agent has a world-to-mind fit state of mind with respect to X if they judge that they have normative reason to X. With moral judgments, this is particularly true if they exclaim that a certain action is (im)moral. This is easy to explain if judgments of normative reasons are themselves world-to-mind fits. Otherwise, this is difficult to explain. Attributions of goodness to P have a conceptual link with the guidance of action towards promoting P (judgment internalism). For any (non-)naturalistic property R, we can imagine clear-headed beings who would fail to find appropriate reason or motive to action in the mere fact that R obtains regarding P. The fact that attributions of goodness are necessarily action-guiding whereas attributions of R are only contingently action-guiding suggests that goodness and R are not analytically equivalent. Translation Imagine we are trying to translate words for descriptive concepts to another language. This involves picking an extension of the relevant concept that we can all agree with and finding the word from the other language that correlates with this extension. For example, if we want to find the translation for the word “red”, we would establish an extension of the concept RED - e.g. blood, stop signs, crayons, etc. Then we would find which word in the other language is often used to refer to the entities in that extension. On the other hand, we cannot do this for normative terms. Firstly, it is doubtful that we could establish an extension of any normative concept that we all agree on. But, more importantly, even if we could, it would not be enough to find the foreign word that corresponds to this extension in order to translate the term. We would also need to know the other society’s motivational and non-cognitive attitudes and dispositions with regard to the extension. For, it is conceivable that they could think that the extensions was either good or bad. This attacks all forms of non-naturalism and objectivist forms of naturalism. -&amp;gt; Also imagine a culture with an identical nonverbal language of our own except that they didn’t speak verbally. They used sign language predominantly to communicate. Some analysis of their movements would be reducible to expressions of beliefs. How would we analyze the meaning of showing a middle finger? How would we analyze a parent who angrily points at a child’s bedroom (ordering him to go)? Imagine they needed to express more sophisticated thoughts using this language. Is it truly questionable whether they could express the entire range of human attitudes, including the attitudes themselves, dispositions to have the attitudes, endorsement of the attitudes? Is it questionable whether questionable whether they could use their language in a way to influence the behavior of others? Would we have any need to posit the existence of mind-independent action-guiding properties to explain the phenomenon? Would it change if they spoke verbally? Arguments against all Descriptivism Non-predicating. Imagine someone asserts that some state of affairs or object has a certain normative property. What are they asserting is a property of that state of affairs or object? Nothing. Role of attitude in Disagreement. Descriptivism cannot explain the role of attitude in ethical disagreements. There are two forms of disagreement, (1) disagreements in belief (both cannot be true) and (2) disagreement in attitudes (cannot be satisfied). Note that reducing ethical judgments to beliefs about attitudes cannot account for this. If A believes he desires X and B believes he desires not-X, then these beliefs are not in disagreement because they can both be correct. E.g. A saying “X is good” and B saying “X is not good” would not be a contradiction, since it would amount to “A desires X” and “B does not desire X”. In fact, they would both be true. But it seems that ethical disagreement can persist despite accepting these truths. Ethical disagreements commonly feature disagreements in attitudes and in beliefs. But attitudes play the primary role because (1) The attitudes determine which beliefs are relevant, and (2) Ethical disagreement persist after agreement in belief. Perhaps this is actually a disagreement in beliefs about each agent’s idealized attitudes, where idealized attitudes are assumed to be convergent. Disagreement in idealized attitudes maybe can account for disagreements in certain normative domains, e.g. disagreements in desires, emotions, maybe even beliefs (i.e. we think other people would come to similar beliefs as us under idealized conditions, because our epistemic frameworks are assumed to be similar). But ethical disagreement can persist despite agreement about the beliefs of everyone’s fully rational, fully informed attitudes. This is not the case with something like think art, humor, taste, etc. This is because ethical judgments have a prescriptive aspect in that they are meant to guide the behavior of other agents. Such prescriptions cannot both be actualized when they conflict. Beliefs and attitudes are logically independent Take a descriptivist theory of normative judgment which says that ascriptions of goodness to x express belief p to x. Take a non-descriptivist theory of normative judgment which says that such ascriptions express non-descriptivist attitude q to x. Imagine an agent held q with regard to x but they did not hold p with regard to x. It seems safe to say that they judge x to be good. Now imagine that they held p with regard to x but they did not hold q with regard to x. It seems safe to say that they don’t judge to be good. Co-reference and Expanded Twin Earth. What our terms refer is a contingent matter that depends upon our culture and history. It is a feature of our contingent culture that we happened to have hooked up the term “good” with any particular natural or non-natural property good. Imagine that a group of people whom you disagreed with merely stipulated that what they meant by “good” was not the (natural or non-natural) property that you refered to by “good” and they went on using their terms to regulate their behavior in their society. It still seems that you would disagree with them and think that they were incorrect. Even for people in our own societies, there is radical divergence on what things count as “good” or “right”. Yet we still believe that we can disagree. If descriptivism is true, then this is possible only if our terms pick out a common property and competent English speakers co-refer. But these seems implausible. What evidence do we have that all English speakers co-refer? How could we know speakers of different languages co-refer? Yet we know we disagree. Thus, descriptivism is false. Non-cognitivism objections: Embedding Amoralist Realist appearance</summary></entry><entry><title type="html">Naturalism</title><link href="/2019/06/19/Naturalism.html" rel="alternate" type="text/html" title="Naturalism" /><published>2019-06-19T00:00:00-07:00</published><updated>2019-06-19T00:00:00-07:00</updated><id>/2019/06/19/Naturalism</id><content type="html" xml:base="/2019/06/19/Naturalism.html">&lt;p&gt;This concerns &lt;em&gt;reductive&lt;/em&gt; naturalism the view that contains the following components:&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;Normative concepts refer to normative properties (against non-cognitivism / constructivism).&lt;/li&gt;
  &lt;li&gt;Some normative propositions are true (against Error Theory).&lt;/li&gt;
  &lt;li&gt;Normative properties can be reduced to entities which are the subject matter of physics (synthetic naturalism).&lt;/li&gt;
  &lt;li&gt;Normative properties can be reduced to non-normative properties (reductive synthetic naturalism) (optional).&lt;/li&gt;
  &lt;li&gt;Normative concepts can be reduced to non-normative concepts (reductive analytic naturalism) (optional).&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Forms of non-reductive naturalism, which deny both 4 and 5 (e.g. David Brink and Nicholas Sturgeon), are edge cases not considered here.&lt;/p&gt;

&lt;p&gt;Also, analytic non-reductive naturalism (e.g. Michael Smith) is not considered here.&lt;/p&gt;

&lt;p&gt;It is not clear what the difference is between non-reductive naturalism (analytic and Synthetic) and metaphysically naturalist forms of non-naturalism. Perhaps one difference is that naturalistic theories appeal to explanation. Nor is it clear what the difference is bewteen Realism with non-ontologically committed conceptions of truth and constructivism/non-cognitivism. The difference seems to amount to difference in a conceptual scheme (e.g. like the differences between saying a statue is identical with its constituent marble versus being seperate). The difference must lie in the attitudinal nature of the judgments. Is motivation necessarily entailed or not?&lt;/p&gt;

&lt;h2 id=&quot;analytic-naturalism&quot;&gt;Analytic Naturalism&lt;/h2&gt;

&lt;p&gt;Note: some of the arguments here seem similar to the arguments shown in Descriptivism.md. The reason these arguments are also here is because they don’t defeat descriptivism broadly. Because, these arguments, by not mentioning the importance of attitudes, don’t generally defeat cognitive theories that ignore attitudes.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Open Question Argument&lt;/em&gt;. (1) Any proposed analytic reduction of a term must be uninformative and obvious. (2) Any analytic reduction of goodness would be informative and nonobvious. (3) Therefore, there can be no analytic reduction of moral terms. Consider the question “Is X good”. Now, imagine that a proposed complex analysis of goodness states that all questions of the form ‘Is X good’ are questions of the form ‘Does X have naturalistic property Y’. The problem with this is that, we can always further ask “Is it good that X has property Y”. This further question is clearly intelligible and coherent. But, if goodness that could be analyzed in terms of Y, then such a question would not be intelligible.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Descriptive beliefs don’t entail normative judgments&lt;/em&gt;. If M and N are &lt;em&gt;definitionally&lt;/em&gt; identical, then if A &lt;em&gt;believes&lt;/em&gt; that X has property M, then it logically follows that A also &lt;em&gt;believes&lt;/em&gt; X has property N (and vice-versa). Note that this is stronger than mere &lt;em&gt;property&lt;/em&gt; identity, e.g. H2O might be identical to water, but the fact that A believes water is H2O does not logically entail that A believes it is water (or vice-versa). However, this logical relation does not hold between and normative property and any natural property. If we know that A believes that X has natural property N and he later says that “X has moral property M”, then we have always learned something new about A.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Insistence on Normative Language&lt;/em&gt;. If normative term N really meant natural term M, then why not carry on making claims about M? If the thesis were true, this would be equivalent to making claims about N, so there should be no difference. The fact that one chooses not to do so implies either (1) he believes that there really is something about N not captured in M, or (2) he believes that society believes that there is something about N not captured in M. Either way, either he or society believes that N and M are not analytically equivalent.&lt;/p&gt;

&lt;p&gt;Response: deny that all analytic reductions must be trivial and uninformative. Counter: Explain why the normative instance of the paradox of analysis differs from other cases. Normative judgments are supposed to provide reasons for action. In other cases, we would be fine to abandon the terms being analyzed (i.e. no problem switching from “knowledge” to “justified true belief”). But this is not true in the normative case.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Normativity reduced to Tautology&lt;/em&gt;. While it may be appropriate for an analytic reduction to be nontrivial, it is not appropriate that an analytic reduction could ever provide one with a &lt;em&gt;reason&lt;/em&gt; for action. If normative concept M can be analytically reduced to natural concept N, then saying “N is M” would be a tautology, and thus could provide no reason for action. For example, if goodness could be analytically reduced to pleasure, then if someone said “pleasure is good”, then this would be equivalent to saying “pleasure is pleasure” or “goodness is goodness”. But presumably the claim “pleasure is good” is supposed to provide someone with reason for action. But no tautology such as “pleasure is pleasure” or “goodness is goodness” could ever provide a reason or motive for someone to promote pleasure.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Ethical disagreements reduced to disputed semantics or descriptions.&lt;/em&gt; If analytic naturalism is true, then two parties disagree ethically only if they disagree descriptively. But people can disagree ethically without disagreeing descriptively. There can be two people who represent reality identically without having similar ethical attitudes with regard to that representation. This can only be explained by positing that the two parties have different semantics, but then this wouldn’t even be a genuine disagreement. This means that two societies with ethical terms that had different semantic meaning (but were identical in that those terms guided the respective society’s behavior) would not really disagree with each other. They would be talking passed one another.&lt;/p&gt;

&lt;h2 id=&quot;reductive-synthetic-naturalism&quot;&gt;Reductive Synthetic Naturalism&lt;/h2&gt;

&lt;p&gt;&lt;em&gt;A Priori Argument&lt;/em&gt;. It seems we can come to learn about normative truths a priori. This is inexplicable if there is an a posteriori synthetic relationship between normative facts and non-normative facts. I.e. we cannot learn a priori that yellow is such and such wavelength, or that water is H2O. Yet how can it be the case that we can learn a priori that, e.g. some natural property &lt;em&gt;necessarily&lt;/em&gt; co-instantiates a normative property?&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Lack of Disagreement&lt;/em&gt;. Synthetic identities can be found in other domains because we can easily fix the referrents of terms like “water” or “yellow”, and then we can find that property that is always instantiated with that referrent. One strategy for doing this is to present a dispositional analysis: an entity is “yellow” just in case it causes sensation that we normally perceive as “yellow”. Such a dispositional analysis is not promising for moral terms. Imagine that two societies are lingustically identical except when one society used the word “good” they referred to pleasure and the other society referred to God’s will. On this reading, the two cultures wouldn’t even disagree with each other, since the content of “good” in these two societies are different - they are using the same word to track different phenomenon. But it seems that these cultures can coherently disagree with each other, especailly if they each act in accordance with what is good.&lt;/p&gt;

&lt;h3 id=&quot;cornell-realism&quot;&gt;Cornell Realism&lt;/h3&gt;

&lt;p&gt;These take a &lt;em&gt;causal reference theory&lt;/em&gt; for moral properties, because a causal reference theory is the standard theory of reference for natural kind terms. This rejects the &lt;em&gt;description theory of reference&lt;/em&gt;. What determines whether a natural property is good is not whether it has the attributes ascribed to it by the term “good”, but whether it causally regulates our use of the word “good”. We are looking not at the semantic attribution behind the term, but rather at the properties causally responsible for that word.&lt;/p&gt;

&lt;p&gt;This is similar to how we use the word “health”. When we say that someone is “healthy”, it’s unclear what the &lt;em&gt;meaning&lt;/em&gt; of that might be. “Healthiness” is a complex natural property that is not directly observable. Thus, “healthiness” cannot be &lt;em&gt;equated&lt;/em&gt; with any simpler set of properties that are directly observable. However, we can determine what property “healthy” &lt;em&gt;refers to&lt;/em&gt; by finding what causally regulates our use of the term “health”. This can be done by looking at the simpler set of properties that &lt;em&gt;are&lt;/em&gt; directly observable; these would be &lt;em&gt;indicators&lt;/em&gt; of “healthiness” rather than &lt;em&gt;equivalent&lt;/em&gt;. “Healthiness” thus has a robust causal profile, which means the property of being healthy can figure into causal explanations of our observations. Much the same is true of moral properties.&lt;/p&gt;</content><author><name>JayMoss</name></author><summary type="html">This concerns reductive naturalism the view that contains the following components: Normative concepts refer to normative properties (against non-cognitivism / constructivism). Some normative propositions are true (against Error Theory). Normative properties can be reduced to entities which are the subject matter of physics (synthetic naturalism). Normative properties can be reduced to non-normative properties (reductive synthetic naturalism) (optional). Normative concepts can be reduced to non-normative concepts (reductive analytic naturalism) (optional). Forms of non-reductive naturalism, which deny both 4 and 5 (e.g. David Brink and Nicholas Sturgeon), are edge cases not considered here. Also, analytic non-reductive naturalism (e.g. Michael Smith) is not considered here. It is not clear what the difference is between non-reductive naturalism (analytic and Synthetic) and metaphysically naturalist forms of non-naturalism. Perhaps one difference is that naturalistic theories appeal to explanation. Nor is it clear what the difference is bewteen Realism with non-ontologically committed conceptions of truth and constructivism/non-cognitivism. The difference seems to amount to difference in a conceptual scheme (e.g. like the differences between saying a statue is identical with its constituent marble versus being seperate). The difference must lie in the attitudinal nature of the judgments. Is motivation necessarily entailed or not? Analytic Naturalism Note: some of the arguments here seem similar to the arguments shown in Descriptivism.md. The reason these arguments are also here is because they don’t defeat descriptivism broadly. Because, these arguments, by not mentioning the importance of attitudes, don’t generally defeat cognitive theories that ignore attitudes. Open Question Argument. (1) Any proposed analytic reduction of a term must be uninformative and obvious. (2) Any analytic reduction of goodness would be informative and nonobvious. (3) Therefore, there can be no analytic reduction of moral terms. Consider the question “Is X good”. Now, imagine that a proposed complex analysis of goodness states that all questions of the form ‘Is X good’ are questions of the form ‘Does X have naturalistic property Y’. The problem with this is that, we can always further ask “Is it good that X has property Y”. This further question is clearly intelligible and coherent. But, if goodness that could be analyzed in terms of Y, then such a question would not be intelligible. Descriptive beliefs don’t entail normative judgments. If M and N are definitionally identical, then if A believes that X has property M, then it logically follows that A also believes X has property N (and vice-versa). Note that this is stronger than mere property identity, e.g. H2O might be identical to water, but the fact that A believes water is H2O does not logically entail that A believes it is water (or vice-versa). However, this logical relation does not hold between and normative property and any natural property. If we know that A believes that X has natural property N and he later says that “X has moral property M”, then we have always learned something new about A. Insistence on Normative Language. If normative term N really meant natural term M, then why not carry on making claims about M? If the thesis were true, this would be equivalent to making claims about N, so there should be no difference. The fact that one chooses not to do so implies either (1) he believes that there really is something about N not captured in M, or (2) he believes that society believes that there is something about N not captured in M. Either way, either he or society believes that N and M are not analytically equivalent. Response: deny that all analytic reductions must be trivial and uninformative. Counter: Explain why the normative instance of the paradox of analysis differs from other cases. Normative judgments are supposed to provide reasons for action. In other cases, we would be fine to abandon the terms being analyzed (i.e. no problem switching from “knowledge” to “justified true belief”). But this is not true in the normative case. Normativity reduced to Tautology. While it may be appropriate for an analytic reduction to be nontrivial, it is not appropriate that an analytic reduction could ever provide one with a reason for action. If normative concept M can be analytically reduced to natural concept N, then saying “N is M” would be a tautology, and thus could provide no reason for action. For example, if goodness could be analytically reduced to pleasure, then if someone said “pleasure is good”, then this would be equivalent to saying “pleasure is pleasure” or “goodness is goodness”. But presumably the claim “pleasure is good” is supposed to provide someone with reason for action. But no tautology such as “pleasure is pleasure” or “goodness is goodness” could ever provide a reason or motive for someone to promote pleasure. Ethical disagreements reduced to disputed semantics or descriptions. If analytic naturalism is true, then two parties disagree ethically only if they disagree descriptively. But people can disagree ethically without disagreeing descriptively. There can be two people who represent reality identically without having similar ethical attitudes with regard to that representation. This can only be explained by positing that the two parties have different semantics, but then this wouldn’t even be a genuine disagreement. This means that two societies with ethical terms that had different semantic meaning (but were identical in that those terms guided the respective society’s behavior) would not really disagree with each other. They would be talking passed one another. Reductive Synthetic Naturalism A Priori Argument. It seems we can come to learn about normative truths a priori. This is inexplicable if there is an a posteriori synthetic relationship between normative facts and non-normative facts. I.e. we cannot learn a priori that yellow is such and such wavelength, or that water is H2O. Yet how can it be the case that we can learn a priori that, e.g. some natural property necessarily co-instantiates a normative property? Lack of Disagreement. Synthetic identities can be found in other domains because we can easily fix the referrents of terms like “water” or “yellow”, and then we can find that property that is always instantiated with that referrent. One strategy for doing this is to present a dispositional analysis: an entity is “yellow” just in case it causes sensation that we normally perceive as “yellow”. Such a dispositional analysis is not promising for moral terms. Imagine that two societies are lingustically identical except when one society used the word “good” they referred to pleasure and the other society referred to God’s will. On this reading, the two cultures wouldn’t even disagree with each other, since the content of “good” in these two societies are different - they are using the same word to track different phenomenon. But it seems that these cultures can coherently disagree with each other, especailly if they each act in accordance with what is good. Cornell Realism These take a causal reference theory for moral properties, because a causal reference theory is the standard theory of reference for natural kind terms. This rejects the description theory of reference. What determines whether a natural property is good is not whether it has the attributes ascribed to it by the term “good”, but whether it causally regulates our use of the word “good”. We are looking not at the semantic attribution behind the term, but rather at the properties causally responsible for that word. This is similar to how we use the word “health”. When we say that someone is “healthy”, it’s unclear what the meaning of that might be. “Healthiness” is a complex natural property that is not directly observable. Thus, “healthiness” cannot be equated with any simpler set of properties that are directly observable. However, we can determine what property “healthy” refers to by finding what causally regulates our use of the term “health”. This can be done by looking at the simpler set of properties that are directly observable; these would be indicators of “healthiness” rather than equivalent. “Healthiness” thus has a robust causal profile, which means the property of being healthy can figure into causal explanations of our observations. Much the same is true of moral properties.</summary></entry><entry><title type="html">Non-Naturalism</title><link href="/2019/06/19/Non-naturalism.html" rel="alternate" type="text/html" title="Non-Naturalism" /><published>2019-06-19T00:00:00-07:00</published><updated>2019-06-19T00:00:00-07:00</updated><id>/2019/06/19/Non-naturalism</id><content type="html" xml:base="/2019/06/19/Non-naturalism.html">&lt;p&gt;This concerns &lt;em&gt;metaphysical&lt;/em&gt; non-naturalism which has the following components:&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;Normative concepts refer to normative properties (against non-cognitivism / constructivism).&lt;/li&gt;
  &lt;li&gt;Some normative propositions are true (against Error Theory).&lt;/li&gt;
  &lt;li&gt;Normative concepts cannot be reduced to non-normative concepts (against analytic naturalism).&lt;/li&gt;
  &lt;li&gt;Normative properties cannot be reduced to non-normative properties (against reductive synthetic naturalism).&lt;/li&gt;
  &lt;li&gt;Normative properties cannot be explained by the entities studied by physics (against non-reductive synthetic naturalism).&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Forms of metaphysically naturalistic ethical non-naturalism, which deny 5 (e.g. Landau, Scanlon, etc.), are edge cases not considered here.&lt;/p&gt;

&lt;p&gt;It is not clear what the difference is between non-reductive naturalism (analytic and Synthetic) and metaphysically naturalist forms of non-naturalism. Perhaps one difference is that naturalistic theories appeal to explanation. Nor is it clear what the difference is bewteen Realism with non-ontologically committed conceptions of truth and constructivism/non-cognitivism. The difference seems to amount to difference in a conceptual scheme (e.g. like the differences between saying a statue is identical with its constituent marble versus being seperate). The difference must lie in the attitudinal nature of the judgments. Is motivation necessarily entailed or not?&lt;/p&gt;

&lt;p&gt;These objections must not prove too much. Some or all of the above features are also true of counterfactual, probabilistic and causal properties, and many other a priori realms of knowledge (e.g. philosophy in general, mathematics, etc.). For each of these types of properties, either an explanation must be given as to how they can exist but not non-natural moral properties, or an explanation must be given as to why such properties do not really exist.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Counterfactual statements: do not really exist. They are constructs we use to aid in considering other possibilities. They are features we apply to propositions that are consistent with some proposition of the current set of known propositions.&lt;/li&gt;
  &lt;li&gt;Causal statements: causation cannot perceived. Moreover, causation is not even something that means anything. If there are two realities with all the same events that take place, except where one there is casuation and one where there is complete randomness, then the worlds are identical. Causation doesn’t exist. Causation is merely a useful heuristic tool that we attribute to events to plan for future scenarios.&lt;/li&gt;
  &lt;li&gt;Probabilistic statements: there are no genuine stochastic processes, not because our reality doesn’t have them, but because it wouldn’t mean anything for them to be true. Again, these are useful linguistic tools.&lt;/li&gt;
  &lt;li&gt;Predictive statements:&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Each of the above class of statements can be given a constructivist/anti-realist analysis.&lt;/p&gt;

&lt;p&gt;Noteably, Hume found that the following cannot be derived from statements about the way the world is:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Statements about the way the world will be.&lt;/li&gt;
  &lt;li&gt;Statements about the way the world ought to be.&lt;/li&gt;
  &lt;li&gt;Statements about what caused what.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;causal-inertness&quot;&gt;Causal Inertness&lt;/h2&gt;

&lt;p&gt;The lack of influence that normative properties place on the world pose the following three problems:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;Concept&lt;/strong&gt;: &lt;em&gt;There is no evolutionary benefit to developing a capacity to track these properties&lt;/em&gt;. In order for there to be a benefit in developing a perceptual faculty, that faculty must be useful at increasing an organism’s biological fitness. The only perceptual faculties useful in increasing an organism’s biological fitness are faculties that track relevant natural facts, as natural facts are the only facts that influence an organism’s chance at reproducing.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Epistemology&lt;/strong&gt;: &lt;em&gt;We have no epistemic access to non-natural facts&lt;/em&gt;. It is a necessary condition on justified belief that one’s belief be explained by the facts in question. Perceptions of natural facts are good evidence for natural properties not because of an intrinsic connection between &lt;em&gt;perceiving&lt;/em&gt; p and p being true. Rather, &lt;em&gt;perceiving&lt;/em&gt; p is good evidence for p only if p &lt;em&gt;being true&lt;/em&gt; causally exlpains why one perceives p. The reliable causal connection between &lt;em&gt;p being true&lt;/em&gt; and &lt;em&gt;perceiving p&lt;/em&gt; is required to treat &lt;em&gt;perceiving p&lt;/em&gt; as a relibable detection of p. There is no way that a non-natural fact p could ever causally explain how we perceive or judge p to be true. Thus, we cannot treat our judging that non-natural fact p as evidence that p is true. This means none of our normative beliefs are ever justified.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Ontology&lt;/strong&gt;: &lt;em&gt;Parsimony is preferrable to complexity with regard to ontology&lt;/em&gt;. When determining which entities exist in the world, we should use inference to the best explanation. Theories with fewer assumptions and better explanatory power are superior. Imagine a world without any non-natural properties but with all the same natural properties. These two worlds would have equal explanatory power, but the world without unneeded properties would have less assumptions and would therefore be superior. The reason is because non-natural properties must be causally inert. The existing of non-natural properties is not necessary to explain reality as we see it.&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;moral-supervenience&quot;&gt;Moral Supervenience&lt;/h2&gt;

&lt;p&gt;It seems to be an a priori conceptual truth that moral properties supervene on the non-moral properties, i.e. two circumstances which have identical non-moral properties must also have identical moral properties. This can be easily explained by naturalism, but it is difficult to see how this is explained by non-naturalism. There are two issues here, one epistemological and one ontological.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;Epistemology&lt;/strong&gt;: When we see an action that we judge to be wrong, we don’t just judge it to be wrong in that particular circumstance. We judge that a particular action with certain natural properties always coinstantiates normative properties. Non-naturalism purports that we perceive the non-natural moral facts as we perceive certain natural facts. But there is nothing about this perceptual model that &lt;em&gt;necessarily guarantees&lt;/em&gt; that we will perceive the same moral facts in circumstances where we perceive the same natural facts. Any perceived supervenience would be, at best, a posteriori; the supervenience relation couldn’t be perceived, for have only perceived the one circumstance Thus, the perceptual model of non-naturalism cannot explain the supervenience of the moral on the non-moral.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Ontology&lt;/strong&gt;: It is a &lt;em&gt;conceptual&lt;/em&gt; truth that the normative supervenes on the non-normative. No two worlds can have the same non-normative properties yet have different normative properties. Thus, normative properties and non-normative properties are not just coextensive, they are &lt;em&gt;necessarily&lt;/em&gt; coexstensive; they are coexstensive in all possible worlds. However, there are no distinct properties that are coextensive in all possible worlds. If two properties are distinct, then there must be &lt;em&gt;some&lt;/em&gt; possible worlds where only one of the properties obtain. Thus, normative properties, &lt;em&gt;if they are properties&lt;/em&gt;, must be natural.&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;motivation&quot;&gt;Motivation&lt;/h2&gt;

&lt;p&gt;Non-naturalism fails to account for the motivational feature of normative judgments for the very same reasons that mind-independent naturalism fails. The fact that moral properties move from the natural realm to the non-natural realm does not increase the motivational weight. Attributions of goodness to P appear to have a conceptual link with the guidance of action towards promoting P (judgment internalism). For any non-naturalistic property R, we can imagine clear-headed beings who would fail to find appropriate reason or motive to action in the mere fact that R obtains regarding P. The fact that attributions of goodness are necessarily action-guiding whereas attributions of R are only contingently action-guiding suggests that goodness and R are not analytically equivalent.&lt;/p&gt;

&lt;h2 id=&quot;others&quot;&gt;Others&lt;/h2&gt;

&lt;p&gt;How to know when our perceptions go astray? How to know if we’re suffering from an optical illusions? How to know what’s the best state of mind to be in when evaluating the reliability of intuitions?&lt;/p&gt;</content><author><name>JayMoss</name></author><summary type="html">This concerns metaphysical non-naturalism which has the following components: Normative concepts refer to normative properties (against non-cognitivism / constructivism). Some normative propositions are true (against Error Theory). Normative concepts cannot be reduced to non-normative concepts (against analytic naturalism). Normative properties cannot be reduced to non-normative properties (against reductive synthetic naturalism). Normative properties cannot be explained by the entities studied by physics (against non-reductive synthetic naturalism). Forms of metaphysically naturalistic ethical non-naturalism, which deny 5 (e.g. Landau, Scanlon, etc.), are edge cases not considered here. It is not clear what the difference is between non-reductive naturalism (analytic and Synthetic) and metaphysically naturalist forms of non-naturalism. Perhaps one difference is that naturalistic theories appeal to explanation. Nor is it clear what the difference is bewteen Realism with non-ontologically committed conceptions of truth and constructivism/non-cognitivism. The difference seems to amount to difference in a conceptual scheme (e.g. like the differences between saying a statue is identical with its constituent marble versus being seperate). The difference must lie in the attitudinal nature of the judgments. Is motivation necessarily entailed or not? These objections must not prove too much. Some or all of the above features are also true of counterfactual, probabilistic and causal properties, and many other a priori realms of knowledge (e.g. philosophy in general, mathematics, etc.). For each of these types of properties, either an explanation must be given as to how they can exist but not non-natural moral properties, or an explanation must be given as to why such properties do not really exist. Counterfactual statements: do not really exist. They are constructs we use to aid in considering other possibilities. They are features we apply to propositions that are consistent with some proposition of the current set of known propositions. Causal statements: causation cannot perceived. Moreover, causation is not even something that means anything. If there are two realities with all the same events that take place, except where one there is casuation and one where there is complete randomness, then the worlds are identical. Causation doesn’t exist. Causation is merely a useful heuristic tool that we attribute to events to plan for future scenarios. Probabilistic statements: there are no genuine stochastic processes, not because our reality doesn’t have them, but because it wouldn’t mean anything for them to be true. Again, these are useful linguistic tools. Predictive statements: Each of the above class of statements can be given a constructivist/anti-realist analysis. Noteably, Hume found that the following cannot be derived from statements about the way the world is: Statements about the way the world will be. Statements about the way the world ought to be. Statements about what caused what. Causal Inertness The lack of influence that normative properties place on the world pose the following three problems: Concept: There is no evolutionary benefit to developing a capacity to track these properties. In order for there to be a benefit in developing a perceptual faculty, that faculty must be useful at increasing an organism’s biological fitness. The only perceptual faculties useful in increasing an organism’s biological fitness are faculties that track relevant natural facts, as natural facts are the only facts that influence an organism’s chance at reproducing. Epistemology: We have no epistemic access to non-natural facts. It is a necessary condition on justified belief that one’s belief be explained by the facts in question. Perceptions of natural facts are good evidence for natural properties not because of an intrinsic connection between perceiving p and p being true. Rather, perceiving p is good evidence for p only if p being true causally exlpains why one perceives p. The reliable causal connection between p being true and perceiving p is required to treat perceiving p as a relibable detection of p. There is no way that a non-natural fact p could ever causally explain how we perceive or judge p to be true. Thus, we cannot treat our judging that non-natural fact p as evidence that p is true. This means none of our normative beliefs are ever justified. Ontology: Parsimony is preferrable to complexity with regard to ontology. When determining which entities exist in the world, we should use inference to the best explanation. Theories with fewer assumptions and better explanatory power are superior. Imagine a world without any non-natural properties but with all the same natural properties. These two worlds would have equal explanatory power, but the world without unneeded properties would have less assumptions and would therefore be superior. The reason is because non-natural properties must be causally inert. The existing of non-natural properties is not necessary to explain reality as we see it. Moral Supervenience It seems to be an a priori conceptual truth that moral properties supervene on the non-moral properties, i.e. two circumstances which have identical non-moral properties must also have identical moral properties. This can be easily explained by naturalism, but it is difficult to see how this is explained by non-naturalism. There are two issues here, one epistemological and one ontological. Epistemology: When we see an action that we judge to be wrong, we don’t just judge it to be wrong in that particular circumstance. We judge that a particular action with certain natural properties always coinstantiates normative properties. Non-naturalism purports that we perceive the non-natural moral facts as we perceive certain natural facts. But there is nothing about this perceptual model that necessarily guarantees that we will perceive the same moral facts in circumstances where we perceive the same natural facts. Any perceived supervenience would be, at best, a posteriori; the supervenience relation couldn’t be perceived, for have only perceived the one circumstance Thus, the perceptual model of non-naturalism cannot explain the supervenience of the moral on the non-moral. Ontology: It is a conceptual truth that the normative supervenes on the non-normative. No two worlds can have the same non-normative properties yet have different normative properties. Thus, normative properties and non-normative properties are not just coextensive, they are necessarily coexstensive; they are coexstensive in all possible worlds. However, there are no distinct properties that are coextensive in all possible worlds. If two properties are distinct, then there must be some possible worlds where only one of the properties obtain. Thus, normative properties, if they are properties, must be natural. Motivation Non-naturalism fails to account for the motivational feature of normative judgments for the very same reasons that mind-independent naturalism fails. The fact that moral properties move from the natural realm to the non-natural realm does not increase the motivational weight. Attributions of goodness to P appear to have a conceptual link with the guidance of action towards promoting P (judgment internalism). For any non-naturalistic property R, we can imagine clear-headed beings who would fail to find appropriate reason or motive to action in the mere fact that R obtains regarding P. The fact that attributions of goodness are necessarily action-guiding whereas attributions of R are only contingently action-guiding suggests that goodness and R are not analytically equivalent. Others How to know when our perceptions go astray? How to know if we’re suffering from an optical illusions? How to know what’s the best state of mind to be in when evaluating the reliability of intuitions?</summary></entry><entry><title type="html">Moral Reasons</title><link href="/2019/06/19/Moral-Reasons.html" rel="alternate" type="text/html" title="Moral Reasons" /><published>2019-06-19T00:00:00-07:00</published><updated>2019-06-19T00:00:00-07:00</updated><id>/2019/06/19/Moral%20Reasons</id><content type="html" xml:base="/2019/06/19/Moral-Reasons.html">&lt;p&gt;??? example “Readings”
	Derek Parfit
		- &lt;em&gt;Reasons and Persons&lt;/em&gt; (1984)
		- &lt;em&gt;On What Matters&lt;/em&gt; (2011)
		- “Justifiability to Each Person” (2003)
		- look up his discussion on “Kantian Contractualism”
	Thomas Scanlon
		- &lt;em&gt;What We Owe to Each Other&lt;/em&gt;
		- “Contractualism and What We Owe to Each Other”
		- “Contractualism and Utilitarianism”
		- &lt;em&gt;Moral Dimensions: Permissibility, Meaning, Blame&lt;/em&gt;
	T. Pogge, “What We Can Reasonably Reject” (2001)
	R. Kumar, “Reasonable reasons in contractualist moral argument” (2003)
	- Gilbert Harman, “Moral Relativism Defended”
	- Philippa Foot, “Morality as a System of Hypothetical Imperatives”
	- Essay: Nick Zangwill, “Externalist Moral Motivation”
	- Essay: David Brink, “Externalist Moral Realism”
	- David Gauthier, &lt;em&gt;Morals By Agreement&lt;/em&gt; (as in DGR)
	- Habermas,
	- Christine Kosgaard, “Kant’s Formulation of Universal Law”&lt;/p&gt;

&lt;p&gt;??? question “Some questions”
	- Contractualism rejects that the only relevant consideration for moral reasoning is well-being. It includes anything that people have reason to care about. Some questions:
		1. Can this “cares” be reduced to a common good? It doesn’t seem like it. It obviously wouldn’t be well-being. Maybe something like goals.
		2. If yes, can we ignore referring to specific kinds of goals? Instead use a language that just refers to intrinsic goals generally without losing importance? Doesn’t seem like it. E.g. imagine an agent had two goals: to be entertained and to provide food for his children. It you characterize this just as goal X and goal Y, you seem to lose just how much more important Y is compared to X. 
		3. If yes, can goals be compared numerically? Harms of qualitative differences don’t seem comparable, e.g. physical versus emotional harm. Also, significant quantitative differences in harm don’t seem comparable on a linear scale, e.g. being tortured versus a pinch can’t be compared on some numerical scale such that N instances of a pinch matches 1 instance of torture. Some kinds of harms:
			- Sensation
				- Physical pain
				- Emotional pain
			- Liberty limitation
				- In ability, e.g. losing a limb, mobility, etc.
				- In opportunity, e.g. discrimination, oppression, etc.
	- Establishing a method for establishing moral truth.
	- How can we use conceptual analysis to determine the role of moral norms but not all norms
		-&amp;gt; We can determine the role for norms, but not the role for attitudes.
		-&amp;gt; As for rational &lt;em&gt;norms&lt;/em&gt; (not the &lt;em&gt;attitudes&lt;/em&gt;), we can discover them (i.e. instrumental rationality as constituitive), but we must give a non-reductive analysis (i.e. constructivism).&lt;/p&gt;

&lt;p&gt;Some disputes:&lt;/p&gt;

&lt;p&gt;Epistemology:&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;Moral truths can be determined by reason alone&lt;/li&gt;
  &lt;li&gt;More truths can motivate intrinsically&lt;/li&gt;
  &lt;li&gt;Reason alone cannot motivate intrinsically&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Normativity&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;All rational agents have reason to be moral&lt;/li&gt;
  &lt;li&gt;Morality does not depend on any agent’s particular desires or interests&lt;/li&gt;
  &lt;li&gt;Reasons for action depend on an agent’s particular desires or interests&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Personal/Interpersonal&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;All rational agents have reason to be moral&lt;/li&gt;
  &lt;li&gt;Society has reason to socially coerce people into being moral&lt;/li&gt;
  &lt;li&gt;What society has reason to coerce people to do =/= what individuals have reason to do&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Substantive vs Formal characterizations - what kind of reasons are moral reasons?&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;Formal characterizations
    &lt;ul&gt;
      &lt;li&gt;Moral reasons are reasons in general.&lt;/li&gt;
      &lt;li&gt;Don’t seem to get at what morality is.&lt;/li&gt;
      &lt;li&gt;Prudential reasons =&amp;gt; Seem like a bribe, also not categorical&lt;/li&gt;
      &lt;li&gt;Categorical reasons =&amp;gt; Also seems like a bribe, seems inappropriate (e.g. rules of logic are not moral)&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Substantive characterizations
    &lt;ul&gt;
      &lt;li&gt;Particular kinds of reasons&lt;/li&gt;
      &lt;li&gt;Reasons toward a particular end&lt;/li&gt;
      &lt;li&gt;We can still sensibly ask, Why be moral?&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Thomas Scanlon distinctions on blame (from a YouTube series, similar to the one where he mentions the substantive vs formal characterizations above)&lt;/p&gt;

&lt;h2 id=&quot;moral-reasons&quot;&gt;Moral Reasons&lt;/h2&gt;

&lt;p&gt;Moral judgments are deeply tied to distinctly moral emotions and attitudes - blame and guilt. There are two ways that moral judgments are associated with these basic attitudes. Firstly, agents who make moral judgments directly express those attitudes, or a disposition to have those attitudes in certain situations. Secondly, agents who make moral judgments express a normative judgment that said attitudes are appropriate, i.e. they express their &lt;em&gt;endorsement&lt;/em&gt; of those attitudes in certain situations. First, let us discuss the motivational implications of moral judgments. When an agent makes a moral judgment, (1) the agent is disposed to regulate his behavior as prescribed by the judgment, (2) he is disposed to feel guilt himself for violating the standard, and (3) he is disposed to blame others for violating the perscribed standard. Oftentimes, the agent thinks others are &lt;em&gt;capable&lt;/em&gt; of being motivated to regulate their behavior in accord with the norm, i.e. they would be receptive to the reasons favoring the norm. E.g. while it might make sense for A to &lt;em&gt;dislike&lt;/em&gt; B’s preference for ice crean, it doesn’t make sense for A to &lt;em&gt;disapprove&lt;/em&gt; of B’s preference for ice cream, but it would make sense if B regarded A as his dietary adviser. This is true even when B’s actions might harm A. E.g. it doesn’t make sense for A to disapprove of B’s attack against him if B would be completely unreceptive (e.g. animal, child, evil person, aliens etc.), but it would make sense for someone who was receptive (i.e. normal rational agent).&lt;/p&gt;

&lt;p&gt;Moreover, like all normative judgments, moral judgments are also judgments about when certain attitudes are appropriate. That is, they express an agent’s endorsement of blame and guilt in certain situations. They state which attitudes agents ought to adopt. And like all ought-statements, these ought claims are to be explained by the &lt;em&gt;reasons&lt;/em&gt; agents have for acting as such. So morality consists of a system of moral reasons, and agents who act immorally are not receptive to the moral reasons that apply to them. The task is to characterize what is distinctive of moral reasons, explaining how they differ from normative reasons in general and (possibly) how they differ from practical reasons in general. To judge that an action X is morally wrong implies some variation of the following ought claims: (1) agents ought not to intend X, (2) agents ought to feel guilt for intending X, and (3) an agent does who X would be blameworthy if they were responsible for doing X (i.e. there were no extenuating circumstances that excuse their behavior). Someone who invokes any of these ought-claims judges that there are reasons explaining why agents ought to act as claimed.&lt;/p&gt;

&lt;p&gt;These features can be exposed by considering the implicit commitments of moral judgments. Consider an implicit commitment of &lt;em&gt;assertions&lt;/em&gt;: if someone says “X is P”, we would expect that they believe X is P, even though this belief does not actually &lt;em&gt;logically&lt;/em&gt; follow from their asserted proposition (nor is it an &lt;em&gt;analytic implication&lt;/em&gt;, s.t. if A believes “X is P” we can deduce that they also believe that they believe “X is P”). If someone said “X is P, but I don’t believe X is P”, we would have a difficult time interpreting the mental state of this person, even though they have expressed a proposition with coherent truth conditions. We can say that &lt;em&gt;beliefs&lt;/em&gt; are implications of &lt;em&gt;assertions&lt;/em&gt;. Likewise, if someone says “X is wrong”, we would expect that others have reason to refrain from doing X, even though this normative judgment does not actually follow from what they said. If someone said “X is wrong, but I don’t judge that anyone ought to refrain from X”, we would have a difficult time interpreting his mental state. Thus, we can say &lt;em&gt;reasons&lt;/em&gt; judgments are implications of &lt;em&gt;moral&lt;/em&gt; judgments. Similar remarks apply to how moral/normative judgments imply non-cognitive attitudes.&lt;/p&gt;

&lt;p&gt;Features (2) and (3) are necessary for any normative domain in any culture in order for it to qualify as a moral system. A hypothetical normative system in a hypothetical culture that did not make claims about the appropriateness of moral emotions would not count as a moral system. If someone made a judgment that only involved (1), this would seem more akin to a pure prudential or rational judgment, as opposed to a moral judgment. It also seems that (1) must also be necessary in any conceivable society’s morality. It does not seem sensible for someone to genuinely endorse shaming a certain behavior and endorse feeling guilt for performing that behavior, while simultaneously not prescribing agents to not perform the action. In fact, that seems to be what it is to shame a certain behavior, i.e. that you prescribe others to not do it. Therefore, if you endorse shaming a certain behavior, then you endorse prescribing others not to do it.&lt;/p&gt;

&lt;h3 id=&quot;blame-and-relationships&quot;&gt;Blame and Relationships&lt;/h3&gt;

&lt;p&gt;To understand what it is to judge that an action/person is &lt;em&gt;blameworthy&lt;/em&gt; (i.e. the appropriate object of blame), we need to understand what constitutes the attitude of blame. There are two (not necessarily conflicting) characterizations of the attitude of blame. Firstly, (1) to blame someone is just to make the the evaluative &lt;em&gt;judgment&lt;/em&gt; that he has done something wrong. This can be seen as a sober assessment of someone’s character. It is a grading of their sets of intentions, desires, goals, etc. against some preferred standard. Insofar an agent’s behavior falls short of that standard, we judge their actions to be morally wrong and thus blame them. Secondly, (2) to blame someone is to adopt more of a functional, dispositional or motivational role and is more akin to an emotion. Blaming someone involves several other non-cognitive attitudes. To blame someone is to hold some sort of disapproving attitude with regard to that person, i.e. it is to be adopt the attitude of anger, resentment, disgust, shame, hatred, etc. Blaming someone in this sense can be seen as a social tool to serve as a sanction that motivates others to behave in accordance with an individual’s preferred standard. It plays the role of modifying the attitudes of others, of both the person being blamed and other individuals in society.&lt;/p&gt;

&lt;p&gt;While these attitudes are commonly invoked when one engages in blaming someone, there is a more important aspect of blaming that is neither an evaluative judgment nor a social saction. To blame someone also involves a modification of one’s attitudes about the person. In particular, when A blames B for an action A judges that his relationship with B has been impaired in some way due to B’s actions. A judges that B violated certain expectations that were supposed to govern his actions by virtue of being in that relationship. It suggests that some reconciliation is needed by B to mend the relationship, if that is even possible. Because blame involves more than the judgment that someone or an action is wrong, it is possible to judge an action to be wrong without blaming them. This can happen (1) when an action is wrong but is not seen as bad enough to warrant a revision of attitudes. But it also occurs (2) when someone does something that &lt;em&gt;would&lt;/em&gt; violate a standard of a relationship if such one existed but such a relationship does not exist (thus they never violating any expectations).&lt;/p&gt;

&lt;p&gt;When (2) this happens and the agent can potentially be in relationships with others, we can still judge their actions to be &lt;em&gt;blameworthy&lt;/em&gt; (without actually blaming them), because we understand that it would be appropriate to someone to blame them if they were in the appropriate relationship. But when it happens to someone that we see as incapable of being in such relationships (i.e. completely cut off from our moral community, e.g. animals, aliens, sociopaths, enemies in war, etc. or people who are incapable of living up to such expectations, e.g. children, mentally disabled, etc.), we neither blame them nor judge them blameworthy. Similar remarks can be made about disapproval in general. If someone does not belong to our moral community, it does not make sense to &lt;em&gt;disapprove&lt;/em&gt; of their actions. It makes sense to &lt;em&gt;dislike&lt;/em&gt; their actions, but disapproval implies that they are receptive to our complaints in some way, i.e. that we stand in a certain relationship with them.&lt;/p&gt;

&lt;p&gt;This analysis of blame can account for many of the features of the standards for other kinds of interpersonal relationships we form. E.g. when two people are in a friendship, there are certain expectations and restrictions on how they behave that would not exist if it were not for the relationship. It is expected that one’s friends will be loyal, trustworthy, helpful, interested in their well-being, etc. When someone does something that violates these standards, their behavior can be said to be wrong &lt;em&gt;from a friendship perspective&lt;/em&gt;. However, this would not suffice to blame a person for this behavior, e.g. if a stranger did some of these things (e.g. failed to be loyal to you), you would not &lt;em&gt;blame&lt;/em&gt; him because you had no &lt;em&gt;expectation&lt;/em&gt; that he would do so (though you might judge him &lt;em&gt;blameworthy&lt;/em&gt;, i.e. that an person in the appropriate circumstances has reason to revise their attitudes regarding the person). Blame for being wrong in this way is only appropriate when one is expected to be a good friend; you would revise your attitudes with regard to that person because they have impaired the relationship, e.g. you would no longer trust them, confide in them, become less interested in their interests, etc. which is to stop treating them as a friend. Similar remarks can be said about romantic relationships, ettiquette, etc.&lt;/p&gt;

&lt;p&gt;All relationships can be defined as a system of expected attitudes and dispositions which specify standards for any person within that relationship. Moral wrongness is based on the standards of a &lt;em&gt;moral relationship&lt;/em&gt;. This is a general kind of relationship that consists of expectations that others’ behavior will be constrained by mutual recognition and respect, rather than specific expectations of other more “optional” relationships (e.g. loyalty, love, faithfulness, etc.). The nature of this relationship is characterized by common reasons that we all recognize &lt;em&gt;as reasons&lt;/em&gt;. The nature of these reasons is spelled by the contractualist formula. We only blame someone when we expected them to be in this relationship. This expectation is a “default” expectation that is only withdrawn in particular cases, e.g. children, mentally disabled, sociopaths, enemies in war, etc. Just as you wouldn’t blame a non-friend for being unfriendly to you, you wouldn’t blame an irredeemably moral non-participant person for being immoral to you. This is not to say that we wouldn’t be justified in being unfriendly, untrustworthy or combative against those people. However, this wouldn’t be a &lt;em&gt;revision&lt;/em&gt; (because we were never friendly, trustworthy, etc. to begin with).&lt;/p&gt;

&lt;p&gt;This analysis also determines when blame is appropriate. Blame is appropriate when we have reason to judge that a relationship has been impaired or to revise our attitudes with regard to a person in light of violated expectations. Likewise, judgments of blameworthiness are appropriate when we have reason to believe that anyone in the appropriate relationship would have reason to revise their attitudes as such. Note that this kind of reason is distinct from other consequentualistic kinds of reasons for blaming someone, i.e. the positive benefits of blaming someone (e.g. someone who did an action accidentally or because of non-culpable ignorance, while possibly beneficial to blame - e.g. if people were motivated to be more careful, more informed after seeing this blame - would not actually be blameworthy). While these may be reasons to blame someone, these are secondary reasons (i.e. the “Wrong” kind of reason). The primary reason to blame someone lies in our reason to revise our attitudes. Note also that &lt;em&gt;this&lt;/em&gt; reason (to revise our attitudes) is also evaluative in nature rather than consequentialist. E.g. if one of the expectations of a relationship is trustworthiness, and someone in the relationship reveals that they are no longer trustworthy because they are dishonest, then this provides the primary reason to revise our attitudes with this person (by no longer trusting them), regardless of the benefits of this revision.&lt;/p&gt;

&lt;p&gt;This analysis of blame also makes blame appropriate even in a deterministic world. There are two senses in which this is true: (1) in the secondary sense of “reasons” for blame which are based on consequences: we have reason to establish norms for blame if it produces good consequences, independent of their free will, and (2) in the primary sense of “reasons” for blame: we have reason to blame someone if someone has impaired a relationship that calls for revising our attitudes of that person. This impairment can occur independent of the consequences of blaming them and also independent of that person’s free will. Thus, the revision of our attitudes can be appropriate independently of their free will. For example, it is appropriate to be suspiscous of someone who is untrustworthy, defensive to someone who is insulting, etc. independent of their free will. Likewise, it is appropriate to revise our attitudes towards suspiscion or defensiveness toward someone insofar as they reveal themselves to be untrustworthy or abusive, independent of their free will. If this relevation violates an expected standard of a relationship, then this is enough to justify blaming them.&lt;/p&gt;

&lt;p&gt;Ordinarily, these standards apply to an individual only if a person agrees to the standards of the relationship, e.g. friendship, romantic, etc. But are there some that are not optional, e.g. being a parent to one’s offspring, moral relationships, etc.&lt;/p&gt;

&lt;p&gt;Ordinarily, when people fail to meet the standards of a relationship, we do not adopt the attitudes that constitutute the relationship (e.g. bad friends are not treated like friends anymore). Does the same apply to the moral relationship, e.g. murderers/rapists get no moral consideration.&lt;/p&gt;

&lt;p&gt;The task, now, is to specify the moral relationship that we take ourselves to stand in relation to for every other person. See below.&lt;/p&gt;

&lt;h3 id=&quot;possibilities&quot;&gt;Possibilities&lt;/h3&gt;

&lt;p&gt;How to get to various moral theories&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Rationality = Teleological =&amp;gt; Consequentialism
    &lt;ul&gt;
      &lt;li&gt;Morality = Rationality =&amp;gt;
        &lt;ul&gt;
          &lt;li&gt;Rationality = Self Interest =&amp;gt; Egoistic Consequentialism&lt;/li&gt;
          &lt;li&gt;Rationality = Impartial =&amp;gt; ~Impartial Consequentialism (e.g. Smith)&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Morality = Impartiality =&amp;gt; Impartial Consequentialism (e.g. Railton); strip away indexical reasons. Seems like because morality is built off of rationality, then if rationality is consequentialist then so must morality.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Rationality = Deontological =&amp;gt;
    &lt;ul&gt;
      &lt;li&gt;Morality = Rationality =&amp;gt; Deontology&lt;/li&gt;
      &lt;li&gt;Morality = Impartiality; strip away indexical reasons. Are the remaining reasons consequentialist? Do they respect the seperateness of persons?
        &lt;ul&gt;
          &lt;li&gt;Moral Reasons = Consequentialist Reasons =&amp;gt; Consequentialism&lt;/li&gt;
          &lt;li&gt;Moral Reasons = Some Deontological Reasons =&amp;gt;
            &lt;ul&gt;
              &lt;li&gt;Seperateness of Persons =&amp;gt; Deontology&lt;/li&gt;
              &lt;li&gt;Not Seperateness of Persons =&amp;gt; Impartial Consequentialism, ???&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;ol&gt;
  &lt;li&gt;Standard Personal reasons - I satisfy my interests
    &lt;ul&gt;
      &lt;li&gt;Not a moral theory. Doesn’t specify rules for everyone.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Speaker-personal reasons - everyone satisfy my interests
    &lt;ul&gt;
      &lt;li&gt;Indexical, so not a moral theory.&lt;/li&gt;
      &lt;li&gt;While not inconsistent, really doesn’t make sense. It violates a constraint implicit in normative judgments, that others have reason to accept your principle. E.g. “You are morally forbidden from stealing from me when it benefits you, but I am morally permitted to do so when it benefits me”. Strictly speaking, it is not a contradiction, but it does seem weird (like saying “X is true but I don’t believe X”). 
====&amp;gt; Below here are substantive questions. The above don’t qualify as moral theories. They don’t fulfill the role that moral discourse plays.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Interpersonal reasons - everyone satisfy their interests
    &lt;ul&gt;
      &lt;li&gt;While not inconsistent, violates the &lt;em&gt;interpersonal&lt;/em&gt; nature of moral judgments, i.e. that others make interpersonal demands on the actions of others (and that we are sometimes answerable the demands of others).&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Impartial interpersonal reasons - everyone satisfy everyone’s interests
    &lt;ul&gt;
      &lt;li&gt;Seems like there are sometimes cases where we can favor our own interests over others.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Reasons for action versus reasons for blame/shame&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Private vs Public reasons&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;See here: https://plato.stanford.edu/entries/reasons-agent/#RelDis&lt;/li&gt;
  &lt;li&gt;Agent-relative vs agent-neutral&lt;/li&gt;
  &lt;li&gt;Internal vs External:
    &lt;ul&gt;
      &lt;li&gt;Internalism -&amp;gt; AR&lt;/li&gt;
      &lt;li&gt;Externalism -&amp;gt; AR/AN&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Intersubjective vs Non-intersubjective (reasons A has s.t. we can communicate this to A)&lt;/li&gt;
  &lt;li&gt;Essentially-shared/Not-essentially-shared (reasons we all have)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The first feature (1) makes a claim about the reasons that individual agents have. It is the “agents ought not X” or “agents have reason to not do X” related to one’s judgment that X is immoral. This can be be most easily seen in cultures where &lt;em&gt;discussion&lt;/em&gt; and &lt;em&gt;argument&lt;/em&gt; play a key role in moral reasoning and communication. Moral argument involves an intention to motivate changes in the attitudes of other agents. We prescribe others to adopt other attitudes, whether these be intentions, dispositions of moral approval/disapproval, anger, guilt, etc. However, what is particular about moral &lt;em&gt;argument&lt;/em&gt; is that we don’t seem to be interested in &lt;em&gt;merely&lt;/em&gt; motivating such changes. Mere motivation can be achieved with emotional manipulation, rhetorical tricks, threats, force, etc. We seem to be trying to &lt;em&gt;rationally&lt;/em&gt; motivate a change in attitudes, i.e. we want to expose to them a reason that they have which they were not receptive to. In fact, it is difficult to imagine a society where moral judgments don’t play this same role; surely, someone who believed that X is wrong would believe that other agents had &lt;em&gt;reasons&lt;/em&gt; to not perform the action. It would seem incoherent for this to not be the case. One moral system that focuses on this aspect of the normativity of moral judgments is ethical egoism.&lt;/p&gt;

&lt;p&gt;The third feature (3) makes a claim about the reasons from an &lt;em&gt;interpersonal&lt;/em&gt; perspective rather than an individual or personal perspective. It is the “&lt;em&gt;others&lt;/em&gt; have reason to blame, disapprove or otherwise prohibit for X-ing” related to a judgment that X is immoral. Unlike personal reasons, interpersonal reasons often involve more than one agent. The question is whether there are grounds for one person (i.e. the judge) to disapprove of another person (i.e. the actor). One way of characterizing interpersonal reasons is by appealing to the personal reasons of society collectively. “Collectively” here must refer to some way of encapsulating the interests of people in general without merely reducing to the interests of &lt;em&gt;everyone&lt;/em&gt; (e.g. perhaps by looking at the interests of most people, by aggregating everyone’s interests, etc.). There are two explanations for why we can’t do that: firstly, if we sought agent-neutral principles (e.g. “all agents ought to X”, where X makes no reference to some feature of the acting agent), it doesn’t seem that there are any behaviors that would satisfy the personal reasons of &lt;em&gt;everyone&lt;/em&gt;; and, secondly, if we sought agent-relative principles (e.g. “all agents ought to X”, where X does no specific reference to some feature of the acting agent), then it would just reduce to (1). So these principles must be receptive to some encapsulated summary of the interests of all agents in society. This is the &lt;em&gt;impartial&lt;/em&gt; or &lt;em&gt;interpersonal&lt;/em&gt; feature of morality. One example of a moral system that focuses on the collective aspect of the normativity of moral judgments is utilitarianism (where the encapsulation function is an aggregation over the well-being of all involved creatures).&lt;/p&gt;

&lt;p&gt;The problem is that both of these features of moral judgments have detestable consequences if considered on their own. The first feature (1) only appeals to &lt;em&gt;personal&lt;/em&gt; reasons, i.e. goal-oriented, desire-based, prudential, etc. reasons. The issue is these reasons don’t seem to give the interests of others any intrinsic weight. One’s goal-oriented or prudential reasons can be in principle wholly independent of the interests of others. One would be morally obligated to take into account the interest of others only if they (a) happened to care about the interests of others intrinsically, or (b) doing so would promote their other intrinsic interests. This does seem to miss the force of moral judgments. It also implies that individuals can have incompatible moral obligations, which seems wrong. On the other hand, focusing on what is reasonable from the interpersonal perspective seems to risk subjugating the individual to the demands of the collective. Because it focuses on an encapsulation of everyone’s reasons, thus eliminating the seperateness of persons, it seems to allow for some principles to be moral even though they might grossly violate the rights of particular agents as a means to maximize the collective.&lt;/p&gt;

&lt;p&gt;The solution is to somehow strike a balance between the two features. The problem is that these two considerations pull in opposing directions. One way of doing this is to focus on individual personal reasons combined with some additional constraint that indirectly includes the interests of other agents. For example, you could consider the individual personal reasons a person has for selecting certain principles to govern society, while ignorant of their particular features in the society (Rawls). They would be placed behind a veil of ignorance where they don’t know what their race, gender, wealth, talent, etc. will be in society. In this circumstance, an individual would have personal reason to consider the interests of everyone because (for all they know) they might be in any of those positions. Another might be to consider the individual personal reasons a person has for selecting a principle, assuming everyone followed that principle (Contractarianism, Gauthier, etc.). This can handle cases where everyone has individual reason to X over Y, but if everyone collectively did X over Y, then everyone would be severely worse-off than if everyone did Y (prisoner’s dilemma). Kant is concerned with what you could rationally will &lt;em&gt;to be a universal law&lt;/em&gt; which all other agents would follow. Other similar strategies include Habermas, Hare, etc.&lt;/p&gt;

&lt;p&gt;??? question “Other interpretations of impartiality”
	Impartiality: Moral reasons can be distinguished from practical reasons in that the moral reasons are reasons for action with some impartiality constraint (e.g. science = interpsonal reasons for belief). Possible conceptions of moral norms
	- Individual practical reasons that everyone individual has.
		- Korsgaard: Valuing anything requires valuing the capacity to value.
		- Denial of Metaphysical Egoism: There is no valid distinction to make between different individuals.
	- Aggregation
		- Reasons that follow after considering everyone’s individual goodness. 
		- Maximizing the total utility of everyone (e.g. utilitarianism).
		- Technical problem with aggregate
			- The idea of there being a numerical assessment of well-being is dubious. What would the numbers mean?
		- Intuitive problems with aggregation
			- If we must choose between causing one person extreme harm and N people minor harm, then it the size of N doesn’t matter.
			- If we must choose between causing one person harm and N people comparable harm, then it the size of N does matter.
			- If we must choose between causing one person extreme harm and N people serious but not as extreme harm (e.g. paralysis versus loss of limb), then does the size of N matter? There may be no determinate answer to cases like this.
	- Veil of Ignorance
		- What is rational assuming an equal chance of being anyone
		- Note that “reasonable assuming equal chance of being anyone” =/= “reasonable for everyone”.
	- Contractualist:
		- Norms no one could reasonably reject as a basis for unenforced, informed cooperation given that one has such a desire.
		- This does suggest that all agents should be treated as ends in themselves? (maybe not as strong as in the Kantian sense). If agents are not ends, then why does it matter if they can reasonably reject a principle?
	- Universalization:
		- Maxims that A can rationally willed to be a maxim followed by agents. This requires:
			- It be conceivable for the maxim to be universalizable, and
			- It be possible for someone to rationally will the maxim to be universalizable. E.g. Kant says (1) for any agent A, A’s ends sometimes require help, (2) if all agents adopted a maxim whereby they never helped anyone, then this would frustrate A’s end, therefore (3) A cannot rationally will a maxim that prescribe agents to never help.
		- Necessary but not sufficient.
			- Provides some formal constraints on possible maxims.
			- May need to be supplanted (e.g. with Contractualism) to account for immoral ends which are conceivable and rational.
		- Cannot account for moral actions that are inconceivable as universal laws
			- e.g. Donate to charity more than the average
		- Cannot account for immoral actions that are conceivable/rational as universal laws
			- e.g. Ritualized bullying for newcomers.
		- Too stringent, e.g. Never Lie
		- Non-rational creatures have no moral consideration
	- Kantian Contractualism (from Parfit)
		- Everyone ought to follow the principles whose universal acceptance everyone could rationally will.
		- “An act is wrong unless such acts are permitted by some principle whose universal acceptance everyone could rationally will”
		- Different from standard Kantianism which says “follow principles whose universal acceptance YOU could rationally will.”&lt;/p&gt;

&lt;h3 id=&quot;contractualism&quot;&gt;Contractualism&lt;/h3&gt;

&lt;p&gt;The problem is that these strategies focus on reasons as such or rationality as such, and then try to indirectly draw a path toward moral reasons by incorporating non-moral considerations. It is true that morality is concerned with these impartial considerations. However, moral reasons cannot be reduced to non-moral reasons in some strange situations where agents have incentive to weigh the interests of others. Instead, moral reasons have to be identified by a particular &lt;em&gt;aim&lt;/em&gt; that agents have, namely a &lt;em&gt;moral&lt;/em&gt; aim. Some agents do not have the aim of being moral. Such positions also eliminate the separateness of persons.&lt;/p&gt;

&lt;p&gt;The other theories may be useful in that their conclusions may overlap with actual moral reasons, and considering their scenarios may fuel moral motivation. But (1) this overlap is only approximate. These theories can do a very good job at excluding morally irrelevant considerations from our reasoning (i.e. those that focus on an agent’s particular situation). However, the considerations that remain (i.e. our personal self-interest) may not be genuinely moral reasons. The strategy of excluding morally irrelevant features needs to go further into we focus precisely on the uniquely moral source of our reasoning. And (2) the motivation from considering these scenarios only makes sense &lt;em&gt;because&lt;/em&gt; of a prior &lt;em&gt;direct&lt;/em&gt; interest in moral reasons. If we did not have this &lt;em&gt;direct&lt;/em&gt; interest, then the above scenarios would have no motivational force. To illuminate the nature of morality, we need to &lt;em&gt;directly&lt;/em&gt; find the interest that characterizes moral agents.&lt;/p&gt;

&lt;p&gt;The aim is a &lt;em&gt;contractualist&lt;/em&gt; characterization of moral reasons that focuses on &lt;em&gt;intersubjective justifiability&lt;/em&gt;. We are aiming to find principles for regulating behavior that can be justified to others. But not principles that can be justified to &lt;em&gt;everyone&lt;/em&gt;. In particular, we are seeking principles that can be justified to everyone &lt;em&gt;who also has the aim&lt;/em&gt; of seeking such principles (i.e. everyone with the aim of seeking principles that could be justified to others). This satisfies the force of both (1) and (3). (1) is satisfied because we appeal to the personal reasons of certain agents, namely &lt;em&gt;moral&lt;/em&gt; agents, i.e. agents with the aim of finding principles with intersubjective justifiability. In fact, this interest is an implicit assumption in moral arguments; it wouldn’t make sense for someone to engage in a moral discussion if they had no interest in justifying themselves to others. It also satisfies the force of (3) because does not &lt;em&gt;just&lt;/em&gt; depend on an individual’s personal reasons. It addresses the interests of society at large, particular those members of society with an interest in intersubjective justifability. This also avoids the downsides of focusing solely on either of the two features. It avoids the downside of (1) because it doesn’t focus on reasons &lt;em&gt;as such&lt;/em&gt; but rather the reasons that relate to a particular &lt;em&gt;moral&lt;/em&gt; aim. It also avoids the downsides of (3) because it is concerned with what is reasonable from the perspective of &lt;em&gt;each individual&lt;/em&gt; with that aim.&lt;/p&gt;

&lt;p&gt;This characterization is only true for the moral system of societies where &lt;em&gt;argument&lt;/em&gt; and &lt;em&gt;discussion&lt;/em&gt; play a key role in moral reasoning, i.e. any society where &lt;em&gt;reasons&lt;/em&gt; are posited to explain why agents ought to follow moral duties. As stated earlier, this seems like it would cover any society that has anything resembling a moral system. However, conceivably there could be a moral system that didn’t involve judgments about what individuals ought to do (lacking feature (1) above), and just had a standard for shaming the behavior of people. It is difficult to imagine how this would work with rational creatures who have the capacity to ask &lt;em&gt;why&lt;/em&gt; they are commanded to perform certain actions (surely, &lt;em&gt;reasons&lt;/em&gt; would have to be provided?).&lt;/p&gt;

&lt;p&gt;Note that these standards are not motivating for (even ideal versions of) all individuals/societies, particularly those individuals/societies that don’t use discussion/argument/reasons (rather than rhetoric, emotions, threats, force, divinity, etc.) as a means to persuading others to adopt certain moral norms. Such norms would still be applicable to these parties (i.e. we could still call them morally wrong), but they could never appreciate these standards, nor would they have any personal reason to do so. This makes sense. We find that we really don’t think people are &lt;em&gt;irrational&lt;/em&gt; per se when they are immoral, i.e. we probably wouldn’t acuse Hitler, psychopaths, war enemies, etc. of being irrational when they do something we find immoral. And we don’t even acuse them of being irrational for believing that they’re morally justified (assuming their judgments are consistent with the judgments of their idealized selves). We acuse them of being irrational when they try to justify their actions to us in moral &lt;em&gt;argument&lt;/em&gt; and &lt;em&gt;discussion&lt;/em&gt;.&lt;/p&gt;

&lt;h2 id=&quot;content&quot;&gt;Content&lt;/h2&gt;

&lt;p&gt;The task is now to determine the substance or content of this characterization of moral reasons. We need to address some variation of the following questions:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Which intentions are morally wrong?&lt;/li&gt;
  &lt;li&gt;Which considerations are relavent when deliberating what is morally wrong?&lt;/li&gt;
  &lt;li&gt;How ought one deliberate about what is morally wrong?&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;??? questions “Questions”
	1. What is the object of inquiry? Idealized standards for behavior or idealized standards of societal (dis)approval?
	2. How to distinguish between the content of morality and ideal law? The former concerned with societal disapproval and the latter concerned with coercion.
	3. How to ground an account of wrongness and appropriateness of societal disapproval that does not just reduce to the benefits of societal disapproval? What’s the relation between what makes something appropriate to disapprove (as an assessment of historical behavior) and having reason to blame it (as a tool for promoting benefits)? Which is prior?&lt;/p&gt;

&lt;p&gt;This deals with the level of analysis between the meaning of normativity and substantive moral theories. It deals with the nature and motivational force of &lt;em&gt;moral&lt;/em&gt; reasons, i.e. their relation to normativity generally. Moral principles are principles that could be justified to everyone with the aim of finding such principles. In other words, these are principles that could be justified to everyone in group G, where group G is defined as the group interested in principles that can be justified to everyone in G. There are possibly objective standards of correctness for this form of moral judgments, as there is a fixed goal to which there are objectively (in)correct means for satisfying it. The standards of intersubjective justifiability extends beyond morality in the narrow sense of moral rightness and wrongness (e.g. it also sets standards of corrctness for ettiquette and justice).&lt;/p&gt;

&lt;p&gt;Moral discussion concerns what &lt;em&gt;norms&lt;/em&gt; to accept in society. Particular actions are assessed secondarily based on their conformity with those norms. This allows for some rule-consequential reasoning about the justification of norms, which is not possible when focusing strictly on actions. This is not to say that all justifications must be rule-consequentialist. There might also be deontological justification of certain rules. Note that the concern here is primarily on when certain actions are justified. These are standards for &lt;em&gt;actions&lt;/em&gt;, as opposed to standards for particular moral emotions, such as blame. The standards for these moral emotions are given below.&lt;/p&gt;

&lt;h3 id=&quot;relevant-considerations&quot;&gt;Relevant Considerations&lt;/h3&gt;

&lt;p&gt;The &lt;em&gt;justification&lt;/em&gt; of a norm is not based on it being reasonable to any &lt;em&gt;particular&lt;/em&gt; agent. Thus, a moral system is &lt;em&gt;completely&lt;/em&gt; unsupported if its justification reduces to “&lt;em&gt;I&lt;/em&gt; just prefer this system” (e.g. even a system with impartial &lt;em&gt;content&lt;/em&gt; like utilitarianism must be shown to be reasonable to all parties involved if it is to be &lt;em&gt;justified&lt;/em&gt;; it is a substantive question whether this can be done). Norms are justified because they can be reasonable from the “moral point of view”, i.e. reasonable from the perspective of an agent with the aim of finding principles with intersubjective justifiability. The structural nature of reasons allow for there to be reasons to discount the relevance of other considerations that would serve as reasons in other contexts. When considering the reasons that constitute the moral perspective, there are some constraints on the relevance of certain principles for moral reasoning:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Personal Reasons: only personal reasons can be reasons to reject a principle. Personal reasons relate to well-being, desires, goals, freedom, etc. They do not include impersonal reasons (e.g. someone who has a concern for the environment) or interpersonal reasons (e.g. someone who has a concern with the interests of others).&lt;/li&gt;
  &lt;li&gt;Impartiality: considerations that are indexical can be dismissed. This places an impartiality constraint on moral reasons in three ways: (1) the content - the nature of the duty, (2) the application - who the duty applies to, and (3) the justification of moral norms must not make reference to any proper nouns. E.g. (1) there can be no duties that say “benefit person A”.  (2) there can be no duties that vary depending on who someone happens to be (it depends on their circumstances). (3) that A in particular is harmed is not a reason against a principle if all alternative principles would result in a comparable or worse harm for others.&lt;/li&gt;
  &lt;li&gt;Degenerate Interests: Interests that either (a) neglect the interests of others or (2) are based upon a desire for the harm of others can be dismissed.&lt;/li&gt;
  &lt;li&gt;Responsibility: Harm to those who are responsible is more justifiable tham harm to those who are irresponsible. E.g. if a principle would impose a burden on people by virtue of negligence, poor intentions, etc.&lt;/li&gt;
  &lt;li&gt;Aggregation: aggregation in itself doesn’t matter. See T.M. Scanlon&lt;/li&gt;
  &lt;li&gt;Hard question: how to handle norms that harm some and help others.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Note that principles must be reasonable not to agents in some veil of ignorance, but rather to agents in the actual world. Behind a veil of ignorance, it might be reasonable for all to accept a princple that resulted in a state where well-being was 80 and 60 instead of 100 and 40 (imagine there are two people, A and B). However, in the actual world, if A=100 and B=40, it would be reasonable for A to reject a principle where force was used that resulted in A=60 and B=80, even though this end state is superior.&lt;/p&gt;

&lt;p&gt;One question is whether contractualism is committed to solely consequentialist reasons. A consequentualist method of justification first specifies a ranking of ideal states of affairs and then assess actions as right or wrong based on that ranking. Personal reasons would be consequentialist insofar as they are reasons for promoting some end state of affairs. But clearly contractualism is not committed to saying people only have these kinds of reasons. Contractualism allows that people can have reason to hold certain attitudes, attitudes which may be distinct from promoting some good with a positive weight which competes with other goods. However, even if we accept non-consequentialism for personal reasons. We might be consequentialist for moral reasons if we abandon the seperateness of persons. Contractualism is not committed to this either. There is no end state of affairs that is most desirable that we are trying to reach. The procedures matter for their own sake. Principles can be wrong if they permit wrong actions, even if that principle results in a better state of affairs. We do not lose the separateness of persons.&lt;/p&gt;

&lt;p&gt;These distinctions are similar to consequentialist systems which distinguish between ideal behaviors and decision theories. E.g. Even act-consequentialist say that it is a theory about what conditions makes actions &lt;em&gt;right&lt;/em&gt; or &lt;em&gt;wrong&lt;/em&gt;. This is distinct from whether those conditions should be taken into account for any particular agent when deciding what to do (e.g. if it is infeasible for an individual to weigh the consequences in any particular circumstances.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;So there are three levels of analysis for act-consequentialists: (1) the best state of affairs, (2) right/wrong actions, and (3) decisions about what we ought to do.&lt;/li&gt;
  &lt;li&gt;Rules consequentialism for norms for &lt;em&gt;behavior&lt;/em&gt; has the following levels of analysis: (1) the best state of affairs, (2) good/bad norms for behavior, (3) right/wrong actions - based on their adherence to the norms, (4) decisions about what we ought to do - probably just refers back to the norms.&lt;/li&gt;
  &lt;li&gt;Rule consequentialism for norms of &lt;em&gt;moral emotions&lt;/em&gt; has the following levels: (1) the best state of affairs, (2) good/bad norms for moral emotions, (3) right/wrong actions - whether it’s the appropriate object of blame given the norms, (4) decisions about whether we ought to blame - probably just refers back to the norm.&lt;/li&gt;
  &lt;li&gt;The contractualist analysis: (1) right/wrong actions - just depends on intersubjective justifiability, (2) good/bad norms for moral emotions - depends on whether it promotes/diminishes undesirable behavior.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;comparison-with-veil-of-ignorance-style-characterizations&quot;&gt;Comparison with Veil of Ignorance style characterizations&lt;/h3&gt;

&lt;p&gt;Two differences:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Veil of ignorance is concerned with rationality. Contractualism concerned with what is reasonable - i.e. what is reasonable contingent on the aim of finding principles that can be justified to others who are similarly motivated.&lt;/li&gt;
  &lt;li&gt;Veil of ignorance strips people of knowledge of their particular features. Contractualism does not?&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Possibilities:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Rationality + awareness of particular features: this can’t work because people would be biased towards irrelevant features.&lt;/li&gt;
  &lt;li&gt;Rationality + ignorance: Veil of ignorance. This is has bad implications because:
    &lt;ul&gt;
      &lt;li&gt;It strips away certain irrelevant features. But by only focusing on rationality simpliciter, it still includes some irrelevant features.&lt;/li&gt;
      &lt;li&gt;It only looks at the end distribution of well-being, ignoring the particular individuals who earned/deserve it.&lt;/li&gt;
      &lt;li&gt;If there is a fixed distribution of pleasure/pain to be distributed, it wouldn’t matter whether the larger bundles went to people who deserved/earned/virtuous it versus whether it went to the people who don’t deserve it or the vicious.&lt;/li&gt;
      &lt;li&gt;Degenerate interests are given just as much weight as everyone else.&lt;/li&gt;
      &lt;li&gt;It doesn’t care about whether people are personally responsible for their diminished well-being. E.g. someone who has diminished well-being because they are lazy.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Reasonableness + awareness: ???&lt;/li&gt;
  &lt;li&gt;Reasonableness + ignorance: ???&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;extensions-of-other-systems&quot;&gt;Extensions of other systems&lt;/h2&gt;

&lt;h3 id=&quot;constructed-normative-domains&quot;&gt;Constructed normative domains&lt;/h3&gt;

&lt;p&gt;Imagine social games with their own personal rules.
We can use those rules as standards of criticism without rationally criticizing an agent.&lt;/p&gt;

&lt;p&gt;Or consider the constructed standards of relationships&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;To stand in a certain relation to someone (e.g. friend, lover, partner, cooperator, self-respecting individuals, etc.) has certain expectations for behavior by the parties involved. To the extent that someone violates these expectations, it is appropriate to not extend those behaviors to them, since they would now stand outside of the relationship.&lt;/li&gt;
  &lt;li&gt;This might work for friends and ettiquette (i.e. to the extent that someone doesn’t uphold the standards of good friendship, ettiquette, it is appropriate to not treat them as a friend, or with ettiquette). Maybe it also works for aesthetic morality. But maybe this doesn’t work for forceful morality (maybe if someone is immoral, we still have moral obligations towards them, i.e. we can exclude them from society, but we cannot kill them).&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Other constructed normative domains&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Prudential Rationality: there are no independent standards for bodily movements. But insofar as one is deliberative and reflective and evaluates their own actions, i.e. one is a rational agent, there are standards for behavior.&lt;/li&gt;
  &lt;li&gt;Games: there are no independent standards for moving small pieces across a checkered board. But insofar as one is playing chess, there are constituitive standards of the activity that entail standards of correctness.&lt;/li&gt;
  &lt;li&gt;Relationships: there are no independent standards of kindness, respect, loyalty, etc. with regard to how to treat others. But insofar as one is being a friend, partner or other normatively-laden relationships, there are constituitive standards of the activity that entail standards of behavior.&lt;/li&gt;
  &lt;li&gt;Communication: there are no independent standards of speaking or language. But insofar as one is communicating as a means to transfer ideas to someone else, there are standards of correctness.&lt;/li&gt;
  &lt;li&gt;Conversation: To engage in a &lt;em&gt;discussion&lt;/em&gt; or &lt;em&gt;conversation&lt;/em&gt; with someone, one implies that they will listen to the other party, not cut them off, etc. even though there may be no independent reason to do thees things.&lt;/li&gt;
  &lt;li&gt;Negotiation: To engage in a &lt;em&gt;negotiation&lt;/em&gt; implies that people are willing to sacrifice or deviate from their most preferred plan to help satisfy the interests of others. Now, one might have no reason to do these things (i.e. if they had full power), but then they wouldn’t be negotiating. They would be bad negotiators.&lt;/li&gt;
  &lt;li&gt;Morality: there are no independent standards of behavior. But insofar as one is engaged in moral argument as a procedure for finding &lt;em&gt;impartial reasons&lt;/em&gt;, or reasons that all can accept, there are constituitive standards of correctness.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Communicative constraints regarding reasons for belief and/or conversations/arguments generally.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Burden of proof depends on the speaker who asserts a claim, not on the mere content of the proposition. That someone asserts a claim has a burden of proof cannot be entailed from the content of the propositions expressed. When Mike says “God Exists”, it follows that he has reason to follow the rule, even though this reason is not trivially included in the rational extension of his motivational set for beliefs.&lt;/li&gt;
  &lt;li&gt;Even though an anecdotal experience might provide one with a personal reason for belief, it would not provide everyone with a reason for belief (e.g. a scientific reason).&lt;/li&gt;
  &lt;li&gt;How to know what the standards are? We check what would happen if everyone accepted it. If no one accepted a burden of proof, the central goal of argument would be defeated.&lt;/li&gt;
  &lt;li&gt;Don’t interrupt others, cut them off, etc. Listen to them.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;intersubjective-justification&quot;&gt;Intersubjective Justification&lt;/h3&gt;

&lt;p&gt;Many normative domains are concerned with what can be justified to different agents, not any individual agent. E.g.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Personal experience / intuition / presuppositions might provide an individual agent with reasons for believe. But they cannot independently provide anyone else with a reason for belief (unless the other agent believes the other person’s experience/intuition/etc. are accurate). Science is a system that searches for intersubjective justification for beliefs. Thus, such instances are not scientifically justified.&lt;/li&gt;
  &lt;li&gt;That a principle benefits A at the expense of everyone else might be a reason for A to adopt the principle, but that is no reason for anyone else to accept it (e.g. a principle that said everyone has a moral obligation to maximize my pleasure). Thus, such a principle cannot be morally justified.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;golden-rule&quot;&gt;Golden Rule&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Golden Rule: Treat others in the way you would want to be treated.
    &lt;ul&gt;
      &lt;li&gt;Upshot: don’t kill if you wouldn’t want to be killed.&lt;/li&gt;
      &lt;li&gt;Problem 1: what if I would have different desires than the recipients? E.g. a masochist wouldn’t mind being attacked.&lt;/li&gt;
      &lt;li&gt;Problem 2: what if I would have desires that people treat me unreasonably? E.g. I would want others to always benefit me at the expense of others.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Moral Emotions: Treat others in the way that you would not blame someone for treating you
  Upshot: You can treat others in a way that you would dislike, so long as you wouldn’t blame them for it.&lt;/li&gt;
  &lt;li&gt;Rationalized: Treat others not based on counterfactual desires, but on our counterfactual reasons for blame.
    &lt;ul&gt;
      &lt;li&gt;Upshot: don’t kill if they don’t have reason to want to be killed (e.g. even if they’re in an intoxicated state where they want to be killed).&lt;/li&gt;
      &lt;li&gt;Doesn’t solve either problem. Just idealizes desires/blame.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Inversed: Treat others in the way they want you to treat them or would not blame you for.
    &lt;ul&gt;
      &lt;li&gt;Upshot: don’t attack if the person doesn’t want to be attacked.&lt;/li&gt;
      &lt;li&gt;Solves Problem 1.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Abstracted: Treat others in accord with principles any rational agent would endorse, independent of their actual circumstances, desires, interests, etc. (i.e. veil of ignorance), if the agent knew he had a chance of any combination of circumstances or desires.
    &lt;ul&gt;
      &lt;li&gt;Upshot: don’t kill it would be forbidden by any principles that no one could rationally reject.&lt;/li&gt;
      &lt;li&gt;Solves Problem 1 and Problem 2.&lt;/li&gt;
      &lt;li&gt;Reasons from Ignorant self-interest =/= reasons from morality.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Moralized: Treat others in accord with principles no rational agent could rationally reject, contingent upon that agent having a goal of finding such principles that others couldn’t rationally reject.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;negotiation&quot;&gt;Negotiation&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Normal negotions:
    &lt;ul&gt;
      &lt;li&gt;Two parties are interested in trading goods.&lt;/li&gt;
      &lt;li&gt;Each party has a ranked set of alternative systems of trade they would be willing to accept.&lt;/li&gt;
      &lt;li&gt;e.g. one party is willing to pay no more than $100 for some good X. The other is willing to sell X for no less than $50.&lt;/li&gt;
      &lt;li&gt;A good negotiation is one where X is sold for somewhere between $50 and $100.&lt;/li&gt;
      &lt;li&gt;The exact number to make the sell is indeterminate.&lt;/li&gt;
      &lt;li&gt;Agents may not have &lt;em&gt;reasons&lt;/em&gt; to be good negotiators, i.e. if one party could coerce the other, that might be in their best interests.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Morality features the following augmentations
    &lt;ul&gt;
      &lt;li&gt;Concerns alternative systems of principles to regulate society; not systems of trade.&lt;/li&gt;
      &lt;li&gt;Impartiality: Abstracts from any particular irrelevant circumstances, i.e. wealth, power, fame, race, etc.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;sentimentalism&quot;&gt;Sentimentalism&lt;/h2&gt;

&lt;p&gt;Even if one rejects the contractualist analysis, we can still give a general theory of truth for all moral systems, even those which do not adhere to the contractualist characterization given above. This can be done by treating moral judgments like aesthetic judgments.&lt;/p&gt;

&lt;p&gt;This concerns the attitudes or emotions (e.g. disgust, blame, shame, resentment, guilt, anger, etc.) involved in moral judgments and makes them akin to aesthetic attitudes. These would be any moral judgments we hold regarding a certain behavior despite not judging that they have any intersubjective justifiability. For example, we might mantain a disgust reaction to, e.g., a man has sex with a corpse, even if it isn’t unjustifiable given the aim of intersubjective justifiability (e.g. if we somehow know that this doesn’t affect the man’s relationship with others, that allowing this in society will not have negative effects, etc.). This is not to say that these judgments do not regularly figure in moral arguments. Sometimes they do. But when they do figure in, the argument merely concerns systemezing whatever morally optional sentiments we have (“optional” in the sense of not being necessary from the perspective of intersubjective justifiability).&lt;/p&gt;

&lt;p&gt;There are possibly two ways of establishing truth for these kinds of moral judgments: (1) dispositionalism and (2) rational sentimentalism. Dispositionalism focuses on the refined attitudes that an agent would have under certain idealized conditions, e.g. full information, full deliberation/reflection, full experienced, under a sound state of mind, etc. Rational sentimentalism focuses on what is &lt;em&gt;constituitive&lt;/em&gt; of moral emotions to determine the appropriate object of said emotions.&lt;/p&gt;

&lt;p&gt;Dispositionalism states the following: one has reason to feel attitude R with regard to X if and only if X is such as to elicit R in circumstances C. The circumstances C can be given several formulations such as, e.g., normal circumstances. This is similar to the truth conditions for when an entity is a certain color; i.e. X is red if and only if X is such as to elicit the perception of redness in normal humans under normal circumstances. However, moral judgments must be based on the attitudes in &lt;em&gt;idealized&lt;/em&gt; circumstance rather than “normal” circumstances because of the following problems with using “normal” circumstances: (1) It cannot be used to criticize conventional or one’s present - assuming they are normal 0 attitudes, (2) It doesn’t explain why one’s evaluative judgments influence their attitudes, whereas one’s judgments about color concepts don’t influence their color perceptions, and (3) It doesn’t explain why moral truth can be discovered a priori under reflection, whereas truth about color concepts cannot.&lt;/p&gt;

&lt;p&gt;Thus, moral truth depends on certain agent’s counterfactual attitudes under idealized conditions. Truth could either be specific to an individual’s idealized attitudes or the idealized attitudes of normal agents. If the latter, this may allow for some rigidifcation which creates a universal standard for truth common to all agents in the actual world. Regardless, because correctness depends on contingent psychological sensibilities, correctness is not mind-dependent in a way that allows for robust objectivity. This is similar to aesthetic judgments in general (think ettiquette) and perhaps secondary properties. Truth would be based on a refinement of one’s attitudes with experience, imagination, deliberation, etc. It doesn’t seem that there would standards for moral correctness independent of moral assumptions. Thus, reflective equilibrium seems to be the dominant method for seeking moral truth.&lt;/p&gt;

&lt;p&gt;Rational sentimentalism states: one has reason to feel R with regard to X if and only if X has the properties ascribed by R. For example, to fear X involves some sort of perception that it is dangerous. This is constitutive of fear, and there is clear evolutionary reason to develop such a psychological faculty. One has reason, then, to fear X if and only if X is dangerous. Moral emotions, e.g. blame, resentment, guilty, etc., are emotions like that. Unforunately, there may in fact be no constituitive standards of attitudes such as anger, resentment, etc. apart from moral judgments that something is morally wrong. That is, it may not be possible to describe the constituitive features of moral attitudes using non-moral terms.&lt;/p&gt;

&lt;h2 id=&quot;motivation&quot;&gt;Motivation&lt;/h2&gt;

&lt;p&gt;Both forms of morality (sentimentalism and contractualism) explains why agents have reason to endorse certain moral principles. But neither explains why an agent has reason to abide by the duties prescribed by the moral principles. An agent would have such a reason insofar as they either (1) have natural sympathy with the welfare of others (meaning the reasons that others hold would be reasons that they also hold), or (2) judge that their behavior should be consistent with the norms they endorse.&lt;/p&gt;

&lt;h2 id=&quot;methodologyobjectivity&quot;&gt;Methodology/Objectivity&lt;/h2&gt;

&lt;p&gt;Morality is rationally optional, but this doesn’t diminish its authority:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Contingent on our interests:
    &lt;ul&gt;
      &lt;li&gt;Nearly universal: most people interested in impartial/social reasons, having a system of norms regulating blame.&lt;/li&gt;
      &lt;li&gt;Emphasizes the negotiation aspect: people cant just have independent that they claim are objective with no consideration of other person’s reasons.&lt;/li&gt;
      &lt;li&gt;Other analogues: Scientific reasons are impartial/social reasons for belief (and thus evidentially optional), but that doesn’t diminish its authority.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Not externally necessarily justifiable, like all normative domains
    &lt;ul&gt;
      &lt;li&gt;Deduction/induction/abduction/evidence/science cannot be reasonable to someone who doesn’t care for those forms of reasoning&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Not ontologically independent
    &lt;ul&gt;
      &lt;li&gt;Who cares about ontology&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;No shared inputs
    &lt;ul&gt;
      &lt;li&gt;With science, we share the same perceptions/observations?&lt;/li&gt;
      &lt;li&gt;With morality, there is widespread disagreement. Might there be a general principle that all must agree to?&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;There are no judgment-independent standards of moral truth, but that’s a good thing:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;People cannot just come with arbitrary principles and claim them as the moral virtues.&lt;/li&gt;
  &lt;li&gt;They are forced to take into account the interests of others.&lt;/li&gt;
  &lt;li&gt;They are forced to make their demands reasonable to others.&lt;/li&gt;
  &lt;li&gt;Moral reasoning is a process of negotiation rather than of discovery.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Objectivity: imagine people have widely divergent beliefs. Objectivity is possible when there happens to be an intersection in the beliefs held by these people. More specifically, it’s possible when there is an intersection in what these people judge to be solid methods for establishing truth. E.g. think of science. People might have widely different beliefs. But everyone agrees that one’s beliefs should cohere with their other beliefs, and we happen to be beings with sensory inputs that automatically impress beliefs within us (which means our beliefs must cohere with our sensory inputs), and our sensory inputs happen to converge a lot of the time. There are other features we happen to agree with as well (or can be shown to agree with), e.g. repeated observations from different independent sources/experiments provide more evidence for a hypothesis than one-offs, etc. It is this convergence that grounds the objectivity of science. I.e. two people might disagree over whether theory X or Y is true, but they can agree on method for determining whether X or Y is true, e.g. by appealing to observation, abduction, induction. Without this, objectivity is impossible. Even if we disagree on method, we can ideally point to a meta-principle that we both agree with (or can be shown to agree with) that settles which method is valid (e.g. reflective equilibrium).&lt;/p&gt;

&lt;p&gt;Might there be a similar methodology for practical rationality or ethics? There is no reliable, impartial, etc. methodology for determining what a person has reason to do, so there is clearly no such methodology for ethics. So how can we determine the content of moral principles? (1) We determine the content of practical rationality (what is good for individuals, or what individuals have reason to do) and (2) We determine how morality relates to practical rationality. Once we agree on what makes an ordinary person’s life go well and determine how wellness relates to morality, we can determine moral content. We must determine what is good by appealing to intuitions we already agree with. If someone completely disagrees with what makes one’s life go good, then surely they will never agree with any moral principles. However, appealing to shared intuitions about goodness is useful: people are more likely to agree on what makes one’s life go best than they are to agree with what is morally right or wrong. E.g. at a minimum, people must agree that one’s life goes best when provided with positive liberty to do what they want. Note that we don’t need agreement in our moral views; we need agreement in what constitutes a good life.&lt;/p&gt;

&lt;p&gt;Disagreement&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;There is widespread moral disagreement. This is explained by intuitionist by the fact that we have different beliefs, different circumstances (circumstances which justify different moral positions, e.g. infanticide in food-sparse areas) or different levels of rationality. The basic moral perceptions, it is claimed are actually identical.&lt;/li&gt;
  &lt;li&gt;I agree that much disagreement can be reduced to these features and not disagerements in basic moral values (I don’t use perceptions). However, there is no reason to believe that all fully informed, fully rational beings would agree about that is morally appropriate in different circumstances.&lt;/li&gt;
  &lt;li&gt;I can agree that there would be near-unanimous agreement about what kinds of considerations are relevant and irrelevant (see above: well-being, liberty, autonomy, etc.) in fully informed, fully rational humans.&lt;/li&gt;
  &lt;li&gt;However, there will be widespread disagreement on what to do when these considerations conflict (e.g. harm one person to help another). In developed socities, for example, there is widespread disagremeent about using force against innocent to assist the disadvantaged. We need a procedure to determine which considerations are to trump others in which circumstances.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Some notes:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Reason is purely procedural. It is concerned with amelierating &lt;em&gt;conflicts&lt;/em&gt; and striving for &lt;em&gt;coherence&lt;/em&gt; of our aims.&lt;/li&gt;
  &lt;li&gt;Badness only occurs when one’s idealized aims are suppressed in some way.&lt;/li&gt;
  &lt;li&gt;Moral wrongness occurs only if it results in someone’s life being worse in some way.
    &lt;ul&gt;
      &lt;li&gt;If action X resulted in no one being worse-off or everyone better-off, then it cannot be morally wrong.&lt;/li&gt;
      &lt;li&gt;This is not to make a claim about consequentialism or deontology. One might say its morally wrong to make anyone worse off.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;</content><author><name>JayMoss</name></author><summary type="html">??? example “Readings” Derek Parfit - Reasons and Persons (1984) - On What Matters (2011) - “Justifiability to Each Person” (2003) - look up his discussion on “Kantian Contractualism” Thomas Scanlon - What We Owe to Each Other - “Contractualism and What We Owe to Each Other” - “Contractualism and Utilitarianism” - Moral Dimensions: Permissibility, Meaning, Blame T. Pogge, “What We Can Reasonably Reject” (2001) R. Kumar, “Reasonable reasons in contractualist moral argument” (2003) - Gilbert Harman, “Moral Relativism Defended” - Philippa Foot, “Morality as a System of Hypothetical Imperatives” - Essay: Nick Zangwill, “Externalist Moral Motivation” - Essay: David Brink, “Externalist Moral Realism” - David Gauthier, Morals By Agreement (as in DGR) - Habermas, - Christine Kosgaard, “Kant’s Formulation of Universal Law” ??? question “Some questions” - Contractualism rejects that the only relevant consideration for moral reasoning is well-being. It includes anything that people have reason to care about. Some questions: 1. Can this “cares” be reduced to a common good? It doesn’t seem like it. It obviously wouldn’t be well-being. Maybe something like goals. 2. If yes, can we ignore referring to specific kinds of goals? Instead use a language that just refers to intrinsic goals generally without losing importance? Doesn’t seem like it. E.g. imagine an agent had two goals: to be entertained and to provide food for his children. It you characterize this just as goal X and goal Y, you seem to lose just how much more important Y is compared to X. 3. If yes, can goals be compared numerically? Harms of qualitative differences don’t seem comparable, e.g. physical versus emotional harm. Also, significant quantitative differences in harm don’t seem comparable on a linear scale, e.g. being tortured versus a pinch can’t be compared on some numerical scale such that N instances of a pinch matches 1 instance of torture. Some kinds of harms: - Sensation - Physical pain - Emotional pain - Liberty limitation - In ability, e.g. losing a limb, mobility, etc. - In opportunity, e.g. discrimination, oppression, etc. - Establishing a method for establishing moral truth. - How can we use conceptual analysis to determine the role of moral norms but not all norms -&amp;gt; We can determine the role for norms, but not the role for attitudes. -&amp;gt; As for rational norms (not the attitudes), we can discover them (i.e. instrumental rationality as constituitive), but we must give a non-reductive analysis (i.e. constructivism). Some disputes: Epistemology: Moral truths can be determined by reason alone More truths can motivate intrinsically Reason alone cannot motivate intrinsically Normativity All rational agents have reason to be moral Morality does not depend on any agent’s particular desires or interests Reasons for action depend on an agent’s particular desires or interests Personal/Interpersonal All rational agents have reason to be moral Society has reason to socially coerce people into being moral What society has reason to coerce people to do =/= what individuals have reason to do Substantive vs Formal characterizations - what kind of reasons are moral reasons? Formal characterizations Moral reasons are reasons in general. Don’t seem to get at what morality is. Prudential reasons =&amp;gt; Seem like a bribe, also not categorical Categorical reasons =&amp;gt; Also seems like a bribe, seems inappropriate (e.g. rules of logic are not moral) Substantive characterizations Particular kinds of reasons Reasons toward a particular end We can still sensibly ask, Why be moral? Thomas Scanlon distinctions on blame (from a YouTube series, similar to the one where he mentions the substantive vs formal characterizations above) Moral Reasons Moral judgments are deeply tied to distinctly moral emotions and attitudes - blame and guilt. There are two ways that moral judgments are associated with these basic attitudes. Firstly, agents who make moral judgments directly express those attitudes, or a disposition to have those attitudes in certain situations. Secondly, agents who make moral judgments express a normative judgment that said attitudes are appropriate, i.e. they express their endorsement of those attitudes in certain situations. First, let us discuss the motivational implications of moral judgments. When an agent makes a moral judgment, (1) the agent is disposed to regulate his behavior as prescribed by the judgment, (2) he is disposed to feel guilt himself for violating the standard, and (3) he is disposed to blame others for violating the perscribed standard. Oftentimes, the agent thinks others are capable of being motivated to regulate their behavior in accord with the norm, i.e. they would be receptive to the reasons favoring the norm. E.g. while it might make sense for A to dislike B’s preference for ice crean, it doesn’t make sense for A to disapprove of B’s preference for ice cream, but it would make sense if B regarded A as his dietary adviser. This is true even when B’s actions might harm A. E.g. it doesn’t make sense for A to disapprove of B’s attack against him if B would be completely unreceptive (e.g. animal, child, evil person, aliens etc.), but it would make sense for someone who was receptive (i.e. normal rational agent). Moreover, like all normative judgments, moral judgments are also judgments about when certain attitudes are appropriate. That is, they express an agent’s endorsement of blame and guilt in certain situations. They state which attitudes agents ought to adopt. And like all ought-statements, these ought claims are to be explained by the reasons agents have for acting as such. So morality consists of a system of moral reasons, and agents who act immorally are not receptive to the moral reasons that apply to them. The task is to characterize what is distinctive of moral reasons, explaining how they differ from normative reasons in general and (possibly) how they differ from practical reasons in general. To judge that an action X is morally wrong implies some variation of the following ought claims: (1) agents ought not to intend X, (2) agents ought to feel guilt for intending X, and (3) an agent does who X would be blameworthy if they were responsible for doing X (i.e. there were no extenuating circumstances that excuse their behavior). Someone who invokes any of these ought-claims judges that there are reasons explaining why agents ought to act as claimed. These features can be exposed by considering the implicit commitments of moral judgments. Consider an implicit commitment of assertions: if someone says “X is P”, we would expect that they believe X is P, even though this belief does not actually logically follow from their asserted proposition (nor is it an analytic implication, s.t. if A believes “X is P” we can deduce that they also believe that they believe “X is P”). If someone said “X is P, but I don’t believe X is P”, we would have a difficult time interpreting the mental state of this person, even though they have expressed a proposition with coherent truth conditions. We can say that beliefs are implications of assertions. Likewise, if someone says “X is wrong”, we would expect that others have reason to refrain from doing X, even though this normative judgment does not actually follow from what they said. If someone said “X is wrong, but I don’t judge that anyone ought to refrain from X”, we would have a difficult time interpreting his mental state. Thus, we can say reasons judgments are implications of moral judgments. Similar remarks apply to how moral/normative judgments imply non-cognitive attitudes. Features (2) and (3) are necessary for any normative domain in any culture in order for it to qualify as a moral system. A hypothetical normative system in a hypothetical culture that did not make claims about the appropriateness of moral emotions would not count as a moral system. If someone made a judgment that only involved (1), this would seem more akin to a pure prudential or rational judgment, as opposed to a moral judgment. It also seems that (1) must also be necessary in any conceivable society’s morality. It does not seem sensible for someone to genuinely endorse shaming a certain behavior and endorse feeling guilt for performing that behavior, while simultaneously not prescribing agents to not perform the action. In fact, that seems to be what it is to shame a certain behavior, i.e. that you prescribe others to not do it. Therefore, if you endorse shaming a certain behavior, then you endorse prescribing others not to do it. Blame and Relationships To understand what it is to judge that an action/person is blameworthy (i.e. the appropriate object of blame), we need to understand what constitutes the attitude of blame. There are two (not necessarily conflicting) characterizations of the attitude of blame. Firstly, (1) to blame someone is just to make the the evaluative judgment that he has done something wrong. This can be seen as a sober assessment of someone’s character. It is a grading of their sets of intentions, desires, goals, etc. against some preferred standard. Insofar an agent’s behavior falls short of that standard, we judge their actions to be morally wrong and thus blame them. Secondly, (2) to blame someone is to adopt more of a functional, dispositional or motivational role and is more akin to an emotion. Blaming someone involves several other non-cognitive attitudes. To blame someone is to hold some sort of disapproving attitude with regard to that person, i.e. it is to be adopt the attitude of anger, resentment, disgust, shame, hatred, etc. Blaming someone in this sense can be seen as a social tool to serve as a sanction that motivates others to behave in accordance with an individual’s preferred standard. It plays the role of modifying the attitudes of others, of both the person being blamed and other individuals in society. While these attitudes are commonly invoked when one engages in blaming someone, there is a more important aspect of blaming that is neither an evaluative judgment nor a social saction. To blame someone also involves a modification of one’s attitudes about the person. In particular, when A blames B for an action A judges that his relationship with B has been impaired in some way due to B’s actions. A judges that B violated certain expectations that were supposed to govern his actions by virtue of being in that relationship. It suggests that some reconciliation is needed by B to mend the relationship, if that is even possible. Because blame involves more than the judgment that someone or an action is wrong, it is possible to judge an action to be wrong without blaming them. This can happen (1) when an action is wrong but is not seen as bad enough to warrant a revision of attitudes. But it also occurs (2) when someone does something that would violate a standard of a relationship if such one existed but such a relationship does not exist (thus they never violating any expectations). When (2) this happens and the agent can potentially be in relationships with others, we can still judge their actions to be blameworthy (without actually blaming them), because we understand that it would be appropriate to someone to blame them if they were in the appropriate relationship. But when it happens to someone that we see as incapable of being in such relationships (i.e. completely cut off from our moral community, e.g. animals, aliens, sociopaths, enemies in war, etc. or people who are incapable of living up to such expectations, e.g. children, mentally disabled, etc.), we neither blame them nor judge them blameworthy. Similar remarks can be made about disapproval in general. If someone does not belong to our moral community, it does not make sense to disapprove of their actions. It makes sense to dislike their actions, but disapproval implies that they are receptive to our complaints in some way, i.e. that we stand in a certain relationship with them. This analysis of blame can account for many of the features of the standards for other kinds of interpersonal relationships we form. E.g. when two people are in a friendship, there are certain expectations and restrictions on how they behave that would not exist if it were not for the relationship. It is expected that one’s friends will be loyal, trustworthy, helpful, interested in their well-being, etc. When someone does something that violates these standards, their behavior can be said to be wrong from a friendship perspective. However, this would not suffice to blame a person for this behavior, e.g. if a stranger did some of these things (e.g. failed to be loyal to you), you would not blame him because you had no expectation that he would do so (though you might judge him blameworthy, i.e. that an person in the appropriate circumstances has reason to revise their attitudes regarding the person). Blame for being wrong in this way is only appropriate when one is expected to be a good friend; you would revise your attitudes with regard to that person because they have impaired the relationship, e.g. you would no longer trust them, confide in them, become less interested in their interests, etc. which is to stop treating them as a friend. Similar remarks can be said about romantic relationships, ettiquette, etc. All relationships can be defined as a system of expected attitudes and dispositions which specify standards for any person within that relationship. Moral wrongness is based on the standards of a moral relationship. This is a general kind of relationship that consists of expectations that others’ behavior will be constrained by mutual recognition and respect, rather than specific expectations of other more “optional” relationships (e.g. loyalty, love, faithfulness, etc.). The nature of this relationship is characterized by common reasons that we all recognize as reasons. The nature of these reasons is spelled by the contractualist formula. We only blame someone when we expected them to be in this relationship. This expectation is a “default” expectation that is only withdrawn in particular cases, e.g. children, mentally disabled, sociopaths, enemies in war, etc. Just as you wouldn’t blame a non-friend for being unfriendly to you, you wouldn’t blame an irredeemably moral non-participant person for being immoral to you. This is not to say that we wouldn’t be justified in being unfriendly, untrustworthy or combative against those people. However, this wouldn’t be a revision (because we were never friendly, trustworthy, etc. to begin with). This analysis also determines when blame is appropriate. Blame is appropriate when we have reason to judge that a relationship has been impaired or to revise our attitudes with regard to a person in light of violated expectations. Likewise, judgments of blameworthiness are appropriate when we have reason to believe that anyone in the appropriate relationship would have reason to revise their attitudes as such. Note that this kind of reason is distinct from other consequentualistic kinds of reasons for blaming someone, i.e. the positive benefits of blaming someone (e.g. someone who did an action accidentally or because of non-culpable ignorance, while possibly beneficial to blame - e.g. if people were motivated to be more careful, more informed after seeing this blame - would not actually be blameworthy). While these may be reasons to blame someone, these are secondary reasons (i.e. the “Wrong” kind of reason). The primary reason to blame someone lies in our reason to revise our attitudes. Note also that this reason (to revise our attitudes) is also evaluative in nature rather than consequentialist. E.g. if one of the expectations of a relationship is trustworthiness, and someone in the relationship reveals that they are no longer trustworthy because they are dishonest, then this provides the primary reason to revise our attitudes with this person (by no longer trusting them), regardless of the benefits of this revision. This analysis of blame also makes blame appropriate even in a deterministic world. There are two senses in which this is true: (1) in the secondary sense of “reasons” for blame which are based on consequences: we have reason to establish norms for blame if it produces good consequences, independent of their free will, and (2) in the primary sense of “reasons” for blame: we have reason to blame someone if someone has impaired a relationship that calls for revising our attitudes of that person. This impairment can occur independent of the consequences of blaming them and also independent of that person’s free will. Thus, the revision of our attitudes can be appropriate independently of their free will. For example, it is appropriate to be suspiscous of someone who is untrustworthy, defensive to someone who is insulting, etc. independent of their free will. Likewise, it is appropriate to revise our attitudes towards suspiscion or defensiveness toward someone insofar as they reveal themselves to be untrustworthy or abusive, independent of their free will. If this relevation violates an expected standard of a relationship, then this is enough to justify blaming them. Ordinarily, these standards apply to an individual only if a person agrees to the standards of the relationship, e.g. friendship, romantic, etc. But are there some that are not optional, e.g. being a parent to one’s offspring, moral relationships, etc. Ordinarily, when people fail to meet the standards of a relationship, we do not adopt the attitudes that constitutute the relationship (e.g. bad friends are not treated like friends anymore). Does the same apply to the moral relationship, e.g. murderers/rapists get no moral consideration. The task, now, is to specify the moral relationship that we take ourselves to stand in relation to for every other person. See below. Possibilities How to get to various moral theories Rationality = Teleological =&amp;gt; Consequentialism Morality = Rationality =&amp;gt; Rationality = Self Interest =&amp;gt; Egoistic Consequentialism Rationality = Impartial =&amp;gt; ~Impartial Consequentialism (e.g. Smith) Morality = Impartiality =&amp;gt; Impartial Consequentialism (e.g. Railton); strip away indexical reasons. Seems like because morality is built off of rationality, then if rationality is consequentialist then so must morality. Rationality = Deontological =&amp;gt; Morality = Rationality =&amp;gt; Deontology Morality = Impartiality; strip away indexical reasons. Are the remaining reasons consequentialist? Do they respect the seperateness of persons? Moral Reasons = Consequentialist Reasons =&amp;gt; Consequentialism Moral Reasons = Some Deontological Reasons =&amp;gt; Seperateness of Persons =&amp;gt; Deontology Not Seperateness of Persons =&amp;gt; Impartial Consequentialism, ??? Standard Personal reasons - I satisfy my interests Not a moral theory. Doesn’t specify rules for everyone. Speaker-personal reasons - everyone satisfy my interests Indexical, so not a moral theory. While not inconsistent, really doesn’t make sense. It violates a constraint implicit in normative judgments, that others have reason to accept your principle. E.g. “You are morally forbidden from stealing from me when it benefits you, but I am morally permitted to do so when it benefits me”. Strictly speaking, it is not a contradiction, but it does seem weird (like saying “X is true but I don’t believe X”). ====&amp;gt; Below here are substantive questions. The above don’t qualify as moral theories. They don’t fulfill the role that moral discourse plays. Interpersonal reasons - everyone satisfy their interests While not inconsistent, violates the interpersonal nature of moral judgments, i.e. that others make interpersonal demands on the actions of others (and that we are sometimes answerable the demands of others). Impartial interpersonal reasons - everyone satisfy everyone’s interests Seems like there are sometimes cases where we can favor our own interests over others. Reasons for action versus reasons for blame/shame Private vs Public reasons See here: https://plato.stanford.edu/entries/reasons-agent/#RelDis Agent-relative vs agent-neutral Internal vs External: Internalism -&amp;gt; AR Externalism -&amp;gt; AR/AN Intersubjective vs Non-intersubjective (reasons A has s.t. we can communicate this to A) Essentially-shared/Not-essentially-shared (reasons we all have) The first feature (1) makes a claim about the reasons that individual agents have. It is the “agents ought not X” or “agents have reason to not do X” related to one’s judgment that X is immoral. This can be be most easily seen in cultures where discussion and argument play a key role in moral reasoning and communication. Moral argument involves an intention to motivate changes in the attitudes of other agents. We prescribe others to adopt other attitudes, whether these be intentions, dispositions of moral approval/disapproval, anger, guilt, etc. However, what is particular about moral argument is that we don’t seem to be interested in merely motivating such changes. Mere motivation can be achieved with emotional manipulation, rhetorical tricks, threats, force, etc. We seem to be trying to rationally motivate a change in attitudes, i.e. we want to expose to them a reason that they have which they were not receptive to. In fact, it is difficult to imagine a society where moral judgments don’t play this same role; surely, someone who believed that X is wrong would believe that other agents had reasons to not perform the action. It would seem incoherent for this to not be the case. One moral system that focuses on this aspect of the normativity of moral judgments is ethical egoism. The third feature (3) makes a claim about the reasons from an interpersonal perspective rather than an individual or personal perspective. It is the “others have reason to blame, disapprove or otherwise prohibit for X-ing” related to a judgment that X is immoral. Unlike personal reasons, interpersonal reasons often involve more than one agent. The question is whether there are grounds for one person (i.e. the judge) to disapprove of another person (i.e. the actor). One way of characterizing interpersonal reasons is by appealing to the personal reasons of society collectively. “Collectively” here must refer to some way of encapsulating the interests of people in general without merely reducing to the interests of everyone (e.g. perhaps by looking at the interests of most people, by aggregating everyone’s interests, etc.). There are two explanations for why we can’t do that: firstly, if we sought agent-neutral principles (e.g. “all agents ought to X”, where X makes no reference to some feature of the acting agent), it doesn’t seem that there are any behaviors that would satisfy the personal reasons of everyone; and, secondly, if we sought agent-relative principles (e.g. “all agents ought to X”, where X does no specific reference to some feature of the acting agent), then it would just reduce to (1). So these principles must be receptive to some encapsulated summary of the interests of all agents in society. This is the impartial or interpersonal feature of morality. One example of a moral system that focuses on the collective aspect of the normativity of moral judgments is utilitarianism (where the encapsulation function is an aggregation over the well-being of all involved creatures). The problem is that both of these features of moral judgments have detestable consequences if considered on their own. The first feature (1) only appeals to personal reasons, i.e. goal-oriented, desire-based, prudential, etc. reasons. The issue is these reasons don’t seem to give the interests of others any intrinsic weight. One’s goal-oriented or prudential reasons can be in principle wholly independent of the interests of others. One would be morally obligated to take into account the interest of others only if they (a) happened to care about the interests of others intrinsically, or (b) doing so would promote their other intrinsic interests. This does seem to miss the force of moral judgments. It also implies that individuals can have incompatible moral obligations, which seems wrong. On the other hand, focusing on what is reasonable from the interpersonal perspective seems to risk subjugating the individual to the demands of the collective. Because it focuses on an encapsulation of everyone’s reasons, thus eliminating the seperateness of persons, it seems to allow for some principles to be moral even though they might grossly violate the rights of particular agents as a means to maximize the collective. The solution is to somehow strike a balance between the two features. The problem is that these two considerations pull in opposing directions. One way of doing this is to focus on individual personal reasons combined with some additional constraint that indirectly includes the interests of other agents. For example, you could consider the individual personal reasons a person has for selecting certain principles to govern society, while ignorant of their particular features in the society (Rawls). They would be placed behind a veil of ignorance where they don’t know what their race, gender, wealth, talent, etc. will be in society. In this circumstance, an individual would have personal reason to consider the interests of everyone because (for all they know) they might be in any of those positions. Another might be to consider the individual personal reasons a person has for selecting a principle, assuming everyone followed that principle (Contractarianism, Gauthier, etc.). This can handle cases where everyone has individual reason to X over Y, but if everyone collectively did X over Y, then everyone would be severely worse-off than if everyone did Y (prisoner’s dilemma). Kant is concerned with what you could rationally will to be a universal law which all other agents would follow. Other similar strategies include Habermas, Hare, etc. ??? question “Other interpretations of impartiality” Impartiality: Moral reasons can be distinguished from practical reasons in that the moral reasons are reasons for action with some impartiality constraint (e.g. science = interpsonal reasons for belief). Possible conceptions of moral norms - Individual practical reasons that everyone individual has. - Korsgaard: Valuing anything requires valuing the capacity to value. - Denial of Metaphysical Egoism: There is no valid distinction to make between different individuals. - Aggregation - Reasons that follow after considering everyone’s individual goodness. - Maximizing the total utility of everyone (e.g. utilitarianism). - Technical problem with aggregate - The idea of there being a numerical assessment of well-being is dubious. What would the numbers mean? - Intuitive problems with aggregation - If we must choose between causing one person extreme harm and N people minor harm, then it the size of N doesn’t matter. - If we must choose between causing one person harm and N people comparable harm, then it the size of N does matter. - If we must choose between causing one person extreme harm and N people serious but not as extreme harm (e.g. paralysis versus loss of limb), then does the size of N matter? There may be no determinate answer to cases like this. - Veil of Ignorance - What is rational assuming an equal chance of being anyone - Note that “reasonable assuming equal chance of being anyone” =/= “reasonable for everyone”. - Contractualist: - Norms no one could reasonably reject as a basis for unenforced, informed cooperation given that one has such a desire. - This does suggest that all agents should be treated as ends in themselves? (maybe not as strong as in the Kantian sense). If agents are not ends, then why does it matter if they can reasonably reject a principle? - Universalization: - Maxims that A can rationally willed to be a maxim followed by agents. This requires: - It be conceivable for the maxim to be universalizable, and - It be possible for someone to rationally will the maxim to be universalizable. E.g. Kant says (1) for any agent A, A’s ends sometimes require help, (2) if all agents adopted a maxim whereby they never helped anyone, then this would frustrate A’s end, therefore (3) A cannot rationally will a maxim that prescribe agents to never help. - Necessary but not sufficient. - Provides some formal constraints on possible maxims. - May need to be supplanted (e.g. with Contractualism) to account for immoral ends which are conceivable and rational. - Cannot account for moral actions that are inconceivable as universal laws - e.g. Donate to charity more than the average - Cannot account for immoral actions that are conceivable/rational as universal laws - e.g. Ritualized bullying for newcomers. - Too stringent, e.g. Never Lie - Non-rational creatures have no moral consideration - Kantian Contractualism (from Parfit) - Everyone ought to follow the principles whose universal acceptance everyone could rationally will. - “An act is wrong unless such acts are permitted by some principle whose universal acceptance everyone could rationally will” - Different from standard Kantianism which says “follow principles whose universal acceptance YOU could rationally will.” Contractualism The problem is that these strategies focus on reasons as such or rationality as such, and then try to indirectly draw a path toward moral reasons by incorporating non-moral considerations. It is true that morality is concerned with these impartial considerations. However, moral reasons cannot be reduced to non-moral reasons in some strange situations where agents have incentive to weigh the interests of others. Instead, moral reasons have to be identified by a particular aim that agents have, namely a moral aim. Some agents do not have the aim of being moral. Such positions also eliminate the separateness of persons. The other theories may be useful in that their conclusions may overlap with actual moral reasons, and considering their scenarios may fuel moral motivation. But (1) this overlap is only approximate. These theories can do a very good job at excluding morally irrelevant considerations from our reasoning (i.e. those that focus on an agent’s particular situation). However, the considerations that remain (i.e. our personal self-interest) may not be genuinely moral reasons. The strategy of excluding morally irrelevant features needs to go further into we focus precisely on the uniquely moral source of our reasoning. And (2) the motivation from considering these scenarios only makes sense because of a prior direct interest in moral reasons. If we did not have this direct interest, then the above scenarios would have no motivational force. To illuminate the nature of morality, we need to directly find the interest that characterizes moral agents. The aim is a contractualist characterization of moral reasons that focuses on intersubjective justifiability. We are aiming to find principles for regulating behavior that can be justified to others. But not principles that can be justified to everyone. In particular, we are seeking principles that can be justified to everyone who also has the aim of seeking such principles (i.e. everyone with the aim of seeking principles that could be justified to others). This satisfies the force of both (1) and (3). (1) is satisfied because we appeal to the personal reasons of certain agents, namely moral agents, i.e. agents with the aim of finding principles with intersubjective justifiability. In fact, this interest is an implicit assumption in moral arguments; it wouldn’t make sense for someone to engage in a moral discussion if they had no interest in justifying themselves to others. It also satisfies the force of (3) because does not just depend on an individual’s personal reasons. It addresses the interests of society at large, particular those members of society with an interest in intersubjective justifability. This also avoids the downsides of focusing solely on either of the two features. It avoids the downside of (1) because it doesn’t focus on reasons as such but rather the reasons that relate to a particular moral aim. It also avoids the downsides of (3) because it is concerned with what is reasonable from the perspective of each individual with that aim. This characterization is only true for the moral system of societies where argument and discussion play a key role in moral reasoning, i.e. any society where reasons are posited to explain why agents ought to follow moral duties. As stated earlier, this seems like it would cover any society that has anything resembling a moral system. However, conceivably there could be a moral system that didn’t involve judgments about what individuals ought to do (lacking feature (1) above), and just had a standard for shaming the behavior of people. It is difficult to imagine how this would work with rational creatures who have the capacity to ask why they are commanded to perform certain actions (surely, reasons would have to be provided?). Note that these standards are not motivating for (even ideal versions of) all individuals/societies, particularly those individuals/societies that don’t use discussion/argument/reasons (rather than rhetoric, emotions, threats, force, divinity, etc.) as a means to persuading others to adopt certain moral norms. Such norms would still be applicable to these parties (i.e. we could still call them morally wrong), but they could never appreciate these standards, nor would they have any personal reason to do so. This makes sense. We find that we really don’t think people are irrational per se when they are immoral, i.e. we probably wouldn’t acuse Hitler, psychopaths, war enemies, etc. of being irrational when they do something we find immoral. And we don’t even acuse them of being irrational for believing that they’re morally justified (assuming their judgments are consistent with the judgments of their idealized selves). We acuse them of being irrational when they try to justify their actions to us in moral argument and discussion. Content The task is now to determine the substance or content of this characterization of moral reasons. We need to address some variation of the following questions: Which intentions are morally wrong? Which considerations are relavent when deliberating what is morally wrong? How ought one deliberate about what is morally wrong? ??? questions “Questions” 1. What is the object of inquiry? Idealized standards for behavior or idealized standards of societal (dis)approval? 2. How to distinguish between the content of morality and ideal law? The former concerned with societal disapproval and the latter concerned with coercion. 3. How to ground an account of wrongness and appropriateness of societal disapproval that does not just reduce to the benefits of societal disapproval? What’s the relation between what makes something appropriate to disapprove (as an assessment of historical behavior) and having reason to blame it (as a tool for promoting benefits)? Which is prior? This deals with the level of analysis between the meaning of normativity and substantive moral theories. It deals with the nature and motivational force of moral reasons, i.e. their relation to normativity generally. Moral principles are principles that could be justified to everyone with the aim of finding such principles. In other words, these are principles that could be justified to everyone in group G, where group G is defined as the group interested in principles that can be justified to everyone in G. There are possibly objective standards of correctness for this form of moral judgments, as there is a fixed goal to which there are objectively (in)correct means for satisfying it. The standards of intersubjective justifiability extends beyond morality in the narrow sense of moral rightness and wrongness (e.g. it also sets standards of corrctness for ettiquette and justice). Moral discussion concerns what norms to accept in society. Particular actions are assessed secondarily based on their conformity with those norms. This allows for some rule-consequential reasoning about the justification of norms, which is not possible when focusing strictly on actions. This is not to say that all justifications must be rule-consequentialist. There might also be deontological justification of certain rules. Note that the concern here is primarily on when certain actions are justified. These are standards for actions, as opposed to standards for particular moral emotions, such as blame. The standards for these moral emotions are given below. Relevant Considerations The justification of a norm is not based on it being reasonable to any particular agent. Thus, a moral system is completely unsupported if its justification reduces to “I just prefer this system” (e.g. even a system with impartial content like utilitarianism must be shown to be reasonable to all parties involved if it is to be justified; it is a substantive question whether this can be done). Norms are justified because they can be reasonable from the “moral point of view”, i.e. reasonable from the perspective of an agent with the aim of finding principles with intersubjective justifiability. The structural nature of reasons allow for there to be reasons to discount the relevance of other considerations that would serve as reasons in other contexts. When considering the reasons that constitute the moral perspective, there are some constraints on the relevance of certain principles for moral reasoning: Personal Reasons: only personal reasons can be reasons to reject a principle. Personal reasons relate to well-being, desires, goals, freedom, etc. They do not include impersonal reasons (e.g. someone who has a concern for the environment) or interpersonal reasons (e.g. someone who has a concern with the interests of others). Impartiality: considerations that are indexical can be dismissed. This places an impartiality constraint on moral reasons in three ways: (1) the content - the nature of the duty, (2) the application - who the duty applies to, and (3) the justification of moral norms must not make reference to any proper nouns. E.g. (1) there can be no duties that say “benefit person A”. (2) there can be no duties that vary depending on who someone happens to be (it depends on their circumstances). (3) that A in particular is harmed is not a reason against a principle if all alternative principles would result in a comparable or worse harm for others. Degenerate Interests: Interests that either (a) neglect the interests of others or (2) are based upon a desire for the harm of others can be dismissed. Responsibility: Harm to those who are responsible is more justifiable tham harm to those who are irresponsible. E.g. if a principle would impose a burden on people by virtue of negligence, poor intentions, etc. Aggregation: aggregation in itself doesn’t matter. See T.M. Scanlon Hard question: how to handle norms that harm some and help others. Note that principles must be reasonable not to agents in some veil of ignorance, but rather to agents in the actual world. Behind a veil of ignorance, it might be reasonable for all to accept a princple that resulted in a state where well-being was 80 and 60 instead of 100 and 40 (imagine there are two people, A and B). However, in the actual world, if A=100 and B=40, it would be reasonable for A to reject a principle where force was used that resulted in A=60 and B=80, even though this end state is superior. One question is whether contractualism is committed to solely consequentialist reasons. A consequentualist method of justification first specifies a ranking of ideal states of affairs and then assess actions as right or wrong based on that ranking. Personal reasons would be consequentialist insofar as they are reasons for promoting some end state of affairs. But clearly contractualism is not committed to saying people only have these kinds of reasons. Contractualism allows that people can have reason to hold certain attitudes, attitudes which may be distinct from promoting some good with a positive weight which competes with other goods. However, even if we accept non-consequentialism for personal reasons. We might be consequentialist for moral reasons if we abandon the seperateness of persons. Contractualism is not committed to this either. There is no end state of affairs that is most desirable that we are trying to reach. The procedures matter for their own sake. Principles can be wrong if they permit wrong actions, even if that principle results in a better state of affairs. We do not lose the separateness of persons. These distinctions are similar to consequentialist systems which distinguish between ideal behaviors and decision theories. E.g. Even act-consequentialist say that it is a theory about what conditions makes actions right or wrong. This is distinct from whether those conditions should be taken into account for any particular agent when deciding what to do (e.g. if it is infeasible for an individual to weigh the consequences in any particular circumstances. So there are three levels of analysis for act-consequentialists: (1) the best state of affairs, (2) right/wrong actions, and (3) decisions about what we ought to do. Rules consequentialism for norms for behavior has the following levels of analysis: (1) the best state of affairs, (2) good/bad norms for behavior, (3) right/wrong actions - based on their adherence to the norms, (4) decisions about what we ought to do - probably just refers back to the norms. Rule consequentialism for norms of moral emotions has the following levels: (1) the best state of affairs, (2) good/bad norms for moral emotions, (3) right/wrong actions - whether it’s the appropriate object of blame given the norms, (4) decisions about whether we ought to blame - probably just refers back to the norm. The contractualist analysis: (1) right/wrong actions - just depends on intersubjective justifiability, (2) good/bad norms for moral emotions - depends on whether it promotes/diminishes undesirable behavior. Comparison with Veil of Ignorance style characterizations Two differences: Veil of ignorance is concerned with rationality. Contractualism concerned with what is reasonable - i.e. what is reasonable contingent on the aim of finding principles that can be justified to others who are similarly motivated. Veil of ignorance strips people of knowledge of their particular features. Contractualism does not? Possibilities: Rationality + awareness of particular features: this can’t work because people would be biased towards irrelevant features. Rationality + ignorance: Veil of ignorance. This is has bad implications because: It strips away certain irrelevant features. But by only focusing on rationality simpliciter, it still includes some irrelevant features. It only looks at the end distribution of well-being, ignoring the particular individuals who earned/deserve it. If there is a fixed distribution of pleasure/pain to be distributed, it wouldn’t matter whether the larger bundles went to people who deserved/earned/virtuous it versus whether it went to the people who don’t deserve it or the vicious. Degenerate interests are given just as much weight as everyone else. It doesn’t care about whether people are personally responsible for their diminished well-being. E.g. someone who has diminished well-being because they are lazy. Reasonableness + awareness: ??? Reasonableness + ignorance: ??? Extensions of other systems Constructed normative domains Imagine social games with their own personal rules. We can use those rules as standards of criticism without rationally criticizing an agent. Or consider the constructed standards of relationships To stand in a certain relation to someone (e.g. friend, lover, partner, cooperator, self-respecting individuals, etc.) has certain expectations for behavior by the parties involved. To the extent that someone violates these expectations, it is appropriate to not extend those behaviors to them, since they would now stand outside of the relationship. This might work for friends and ettiquette (i.e. to the extent that someone doesn’t uphold the standards of good friendship, ettiquette, it is appropriate to not treat them as a friend, or with ettiquette). Maybe it also works for aesthetic morality. But maybe this doesn’t work for forceful morality (maybe if someone is immoral, we still have moral obligations towards them, i.e. we can exclude them from society, but we cannot kill them). Other constructed normative domains Prudential Rationality: there are no independent standards for bodily movements. But insofar as one is deliberative and reflective and evaluates their own actions, i.e. one is a rational agent, there are standards for behavior. Games: there are no independent standards for moving small pieces across a checkered board. But insofar as one is playing chess, there are constituitive standards of the activity that entail standards of correctness. Relationships: there are no independent standards of kindness, respect, loyalty, etc. with regard to how to treat others. But insofar as one is being a friend, partner or other normatively-laden relationships, there are constituitive standards of the activity that entail standards of behavior. Communication: there are no independent standards of speaking or language. But insofar as one is communicating as a means to transfer ideas to someone else, there are standards of correctness. Conversation: To engage in a discussion or conversation with someone, one implies that they will listen to the other party, not cut them off, etc. even though there may be no independent reason to do thees things. Negotiation: To engage in a negotiation implies that people are willing to sacrifice or deviate from their most preferred plan to help satisfy the interests of others. Now, one might have no reason to do these things (i.e. if they had full power), but then they wouldn’t be negotiating. They would be bad negotiators. Morality: there are no independent standards of behavior. But insofar as one is engaged in moral argument as a procedure for finding impartial reasons, or reasons that all can accept, there are constituitive standards of correctness. Communicative constraints regarding reasons for belief and/or conversations/arguments generally. Burden of proof depends on the speaker who asserts a claim, not on the mere content of the proposition. That someone asserts a claim has a burden of proof cannot be entailed from the content of the propositions expressed. When Mike says “God Exists”, it follows that he has reason to follow the rule, even though this reason is not trivially included in the rational extension of his motivational set for beliefs. Even though an anecdotal experience might provide one with a personal reason for belief, it would not provide everyone with a reason for belief (e.g. a scientific reason). How to know what the standards are? We check what would happen if everyone accepted it. If no one accepted a burden of proof, the central goal of argument would be defeated. Don’t interrupt others, cut them off, etc. Listen to them. Intersubjective Justification Many normative domains are concerned with what can be justified to different agents, not any individual agent. E.g. Personal experience / intuition / presuppositions might provide an individual agent with reasons for believe. But they cannot independently provide anyone else with a reason for belief (unless the other agent believes the other person’s experience/intuition/etc. are accurate). Science is a system that searches for intersubjective justification for beliefs. Thus, such instances are not scientifically justified. That a principle benefits A at the expense of everyone else might be a reason for A to adopt the principle, but that is no reason for anyone else to accept it (e.g. a principle that said everyone has a moral obligation to maximize my pleasure). Thus, such a principle cannot be morally justified. Golden Rule Golden Rule: Treat others in the way you would want to be treated. Upshot: don’t kill if you wouldn’t want to be killed. Problem 1: what if I would have different desires than the recipients? E.g. a masochist wouldn’t mind being attacked. Problem 2: what if I would have desires that people treat me unreasonably? E.g. I would want others to always benefit me at the expense of others. Moral Emotions: Treat others in the way that you would not blame someone for treating you Upshot: You can treat others in a way that you would dislike, so long as you wouldn’t blame them for it. Rationalized: Treat others not based on counterfactual desires, but on our counterfactual reasons for blame. Upshot: don’t kill if they don’t have reason to want to be killed (e.g. even if they’re in an intoxicated state where they want to be killed). Doesn’t solve either problem. Just idealizes desires/blame. Inversed: Treat others in the way they want you to treat them or would not blame you for. Upshot: don’t attack if the person doesn’t want to be attacked. Solves Problem 1. Abstracted: Treat others in accord with principles any rational agent would endorse, independent of their actual circumstances, desires, interests, etc. (i.e. veil of ignorance), if the agent knew he had a chance of any combination of circumstances or desires. Upshot: don’t kill it would be forbidden by any principles that no one could rationally reject. Solves Problem 1 and Problem 2. Reasons from Ignorant self-interest =/= reasons from morality. Moralized: Treat others in accord with principles no rational agent could rationally reject, contingent upon that agent having a goal of finding such principles that others couldn’t rationally reject. Negotiation Normal negotions: Two parties are interested in trading goods. Each party has a ranked set of alternative systems of trade they would be willing to accept. e.g. one party is willing to pay no more than $100 for some good X. The other is willing to sell X for no less than $50. A good negotiation is one where X is sold for somewhere between $50 and $100. The exact number to make the sell is indeterminate. Agents may not have reasons to be good negotiators, i.e. if one party could coerce the other, that might be in their best interests. Morality features the following augmentations Concerns alternative systems of principles to regulate society; not systems of trade. Impartiality: Abstracts from any particular irrelevant circumstances, i.e. wealth, power, fame, race, etc. Sentimentalism Even if one rejects the contractualist analysis, we can still give a general theory of truth for all moral systems, even those which do not adhere to the contractualist characterization given above. This can be done by treating moral judgments like aesthetic judgments. This concerns the attitudes or emotions (e.g. disgust, blame, shame, resentment, guilt, anger, etc.) involved in moral judgments and makes them akin to aesthetic attitudes. These would be any moral judgments we hold regarding a certain behavior despite not judging that they have any intersubjective justifiability. For example, we might mantain a disgust reaction to, e.g., a man has sex with a corpse, even if it isn’t unjustifiable given the aim of intersubjective justifiability (e.g. if we somehow know that this doesn’t affect the man’s relationship with others, that allowing this in society will not have negative effects, etc.). This is not to say that these judgments do not regularly figure in moral arguments. Sometimes they do. But when they do figure in, the argument merely concerns systemezing whatever morally optional sentiments we have (“optional” in the sense of not being necessary from the perspective of intersubjective justifiability). There are possibly two ways of establishing truth for these kinds of moral judgments: (1) dispositionalism and (2) rational sentimentalism. Dispositionalism focuses on the refined attitudes that an agent would have under certain idealized conditions, e.g. full information, full deliberation/reflection, full experienced, under a sound state of mind, etc. Rational sentimentalism focuses on what is constituitive of moral emotions to determine the appropriate object of said emotions. Dispositionalism states the following: one has reason to feel attitude R with regard to X if and only if X is such as to elicit R in circumstances C. The circumstances C can be given several formulations such as, e.g., normal circumstances. This is similar to the truth conditions for when an entity is a certain color; i.e. X is red if and only if X is such as to elicit the perception of redness in normal humans under normal circumstances. However, moral judgments must be based on the attitudes in idealized circumstance rather than “normal” circumstances because of the following problems with using “normal” circumstances: (1) It cannot be used to criticize conventional or one’s present - assuming they are normal 0 attitudes, (2) It doesn’t explain why one’s evaluative judgments influence their attitudes, whereas one’s judgments about color concepts don’t influence their color perceptions, and (3) It doesn’t explain why moral truth can be discovered a priori under reflection, whereas truth about color concepts cannot. Thus, moral truth depends on certain agent’s counterfactual attitudes under idealized conditions. Truth could either be specific to an individual’s idealized attitudes or the idealized attitudes of normal agents. If the latter, this may allow for some rigidifcation which creates a universal standard for truth common to all agents in the actual world. Regardless, because correctness depends on contingent psychological sensibilities, correctness is not mind-dependent in a way that allows for robust objectivity. This is similar to aesthetic judgments in general (think ettiquette) and perhaps secondary properties. Truth would be based on a refinement of one’s attitudes with experience, imagination, deliberation, etc. It doesn’t seem that there would standards for moral correctness independent of moral assumptions. Thus, reflective equilibrium seems to be the dominant method for seeking moral truth. Rational sentimentalism states: one has reason to feel R with regard to X if and only if X has the properties ascribed by R. For example, to fear X involves some sort of perception that it is dangerous. This is constitutive of fear, and there is clear evolutionary reason to develop such a psychological faculty. One has reason, then, to fear X if and only if X is dangerous. Moral emotions, e.g. blame, resentment, guilty, etc., are emotions like that. Unforunately, there may in fact be no constituitive standards of attitudes such as anger, resentment, etc. apart from moral judgments that something is morally wrong. That is, it may not be possible to describe the constituitive features of moral attitudes using non-moral terms. Motivation Both forms of morality (sentimentalism and contractualism) explains why agents have reason to endorse certain moral principles. But neither explains why an agent has reason to abide by the duties prescribed by the moral principles. An agent would have such a reason insofar as they either (1) have natural sympathy with the welfare of others (meaning the reasons that others hold would be reasons that they also hold), or (2) judge that their behavior should be consistent with the norms they endorse. Methodology/Objectivity Morality is rationally optional, but this doesn’t diminish its authority: Contingent on our interests: Nearly universal: most people interested in impartial/social reasons, having a system of norms regulating blame. Emphasizes the negotiation aspect: people cant just have independent that they claim are objective with no consideration of other person’s reasons. Other analogues: Scientific reasons are impartial/social reasons for belief (and thus evidentially optional), but that doesn’t diminish its authority. Not externally necessarily justifiable, like all normative domains Deduction/induction/abduction/evidence/science cannot be reasonable to someone who doesn’t care for those forms of reasoning Not ontologically independent Who cares about ontology No shared inputs With science, we share the same perceptions/observations? With morality, there is widespread disagreement. Might there be a general principle that all must agree to? There are no judgment-independent standards of moral truth, but that’s a good thing: People cannot just come with arbitrary principles and claim them as the moral virtues. They are forced to take into account the interests of others. They are forced to make their demands reasonable to others. Moral reasoning is a process of negotiation rather than of discovery. Objectivity: imagine people have widely divergent beliefs. Objectivity is possible when there happens to be an intersection in the beliefs held by these people. More specifically, it’s possible when there is an intersection in what these people judge to be solid methods for establishing truth. E.g. think of science. People might have widely different beliefs. But everyone agrees that one’s beliefs should cohere with their other beliefs, and we happen to be beings with sensory inputs that automatically impress beliefs within us (which means our beliefs must cohere with our sensory inputs), and our sensory inputs happen to converge a lot of the time. There are other features we happen to agree with as well (or can be shown to agree with), e.g. repeated observations from different independent sources/experiments provide more evidence for a hypothesis than one-offs, etc. It is this convergence that grounds the objectivity of science. I.e. two people might disagree over whether theory X or Y is true, but they can agree on method for determining whether X or Y is true, e.g. by appealing to observation, abduction, induction. Without this, objectivity is impossible. Even if we disagree on method, we can ideally point to a meta-principle that we both agree with (or can be shown to agree with) that settles which method is valid (e.g. reflective equilibrium). Might there be a similar methodology for practical rationality or ethics? There is no reliable, impartial, etc. methodology for determining what a person has reason to do, so there is clearly no such methodology for ethics. So how can we determine the content of moral principles? (1) We determine the content of practical rationality (what is good for individuals, or what individuals have reason to do) and (2) We determine how morality relates to practical rationality. Once we agree on what makes an ordinary person’s life go well and determine how wellness relates to morality, we can determine moral content. We must determine what is good by appealing to intuitions we already agree with. If someone completely disagrees with what makes one’s life go good, then surely they will never agree with any moral principles. However, appealing to shared intuitions about goodness is useful: people are more likely to agree on what makes one’s life go best than they are to agree with what is morally right or wrong. E.g. at a minimum, people must agree that one’s life goes best when provided with positive liberty to do what they want. Note that we don’t need agreement in our moral views; we need agreement in what constitutes a good life. Disagreement There is widespread moral disagreement. This is explained by intuitionist by the fact that we have different beliefs, different circumstances (circumstances which justify different moral positions, e.g. infanticide in food-sparse areas) or different levels of rationality. The basic moral perceptions, it is claimed are actually identical. I agree that much disagreement can be reduced to these features and not disagerements in basic moral values (I don’t use perceptions). However, there is no reason to believe that all fully informed, fully rational beings would agree about that is morally appropriate in different circumstances. I can agree that there would be near-unanimous agreement about what kinds of considerations are relevant and irrelevant (see above: well-being, liberty, autonomy, etc.) in fully informed, fully rational humans. However, there will be widespread disagreement on what to do when these considerations conflict (e.g. harm one person to help another). In developed socities, for example, there is widespread disagremeent about using force against innocent to assist the disadvantaged. We need a procedure to determine which considerations are to trump others in which circumstances. Some notes: Reason is purely procedural. It is concerned with amelierating conflicts and striving for coherence of our aims. Badness only occurs when one’s idealized aims are suppressed in some way. Moral wrongness occurs only if it results in someone’s life being worse in some way. If action X resulted in no one being worse-off or everyone better-off, then it cannot be morally wrong. This is not to make a claim about consequentialism or deontology. One might say its morally wrong to make anyone worse off.</summary></entry><entry><title type="html">Normative Talk</title><link href="/2019/06/19/Normative-Talk.html" rel="alternate" type="text/html" title="Normative Talk" /><published>2019-06-19T00:00:00-07:00</published><updated>2019-06-19T00:00:00-07:00</updated><id>/2019/06/19/Normative%20Talk</id><content type="html" xml:base="/2019/06/19/Normative-Talk.html">&lt;p&gt;New structure&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;Normative Talk - all normative concepts reduced to claims of reasons&lt;/li&gt;
  &lt;li&gt;Normative Truth - Internalism and Constructivism&lt;/li&gt;
  &lt;li&gt;Normative Thought - Non-cognitivism&lt;/li&gt;
  &lt;li&gt;Blame and Relationships&lt;/li&gt;
  &lt;li&gt;Moral Reasons and Relationships
    &lt;ul&gt;
      &lt;li&gt;Against narcisistic egoism - Neglects impartiality, what others have reason to accept/reject&lt;/li&gt;
      &lt;li&gt;Against Egoism - Certain people can have reason to reject egoism if it leads to their despair&lt;/li&gt;
      &lt;li&gt;Against certain forms of consequentialism - that reduce moral rightness to non-moral goodness. Not all rational interests are morally legitimate&lt;/li&gt;
      &lt;li&gt;Against Rawls/Consequentialism - “reasonable for everyone” (contractualism) =/= “reasonable given equal chance of being anyone” (Rawls, or some forms of consequentialism). Fauly interpretation of impartiality.&lt;/li&gt;
      &lt;li&gt;This still allows for people to prefer their own interests more than others. It is reasonable for everyone to accept a system of rules where they can give some weight to their interests. It would be unreasonable to accept being subjugated to some overall calculus (this doesn’t lead to egoism).&lt;/li&gt;
      &lt;li&gt;The end is somewhere between egoism and consequentialism with a discounting of particular &lt;em&gt;kinds&lt;/em&gt; of individual goodness. Rejects most conditions to count as consequentialism - hedomism and commensurability (both rejected from theory of rationality), aggregation and agent-neutrality (both rejected because they are not acceptable for all persons).&lt;/li&gt;
      &lt;li&gt;Under contractualism, the parties to the contract are as follows:&lt;/li&gt;
    &lt;/ul&gt;
    &lt;ul&gt;
      &lt;li&gt;They determine what the standards for blame/shame are to be (i.e. the moral norms), NOT what everyone’s behaviors will be. Just as Rawls is determining the principles of social institutions and not everyone’s behaviors. If we were determining everyone’s behaviors, everyone would be nice and charitable and there would be no need for morality/law.
        &lt;ul&gt;
          &lt;li&gt;Important: whether someone is blameworthy depends on whether they violated the standards of a relationship. So they will be determining the standards of the relationship. This will not just reduce to accepting the standards that promote the best consequences for everyone. One could only infer that if we already concluded that the standards of our relationship is to promote the best consequences. But that is the very thing to be decided. We don’t know beforehand if the parties of the constract are committed to promoting the best consequences. We need to determine what they are committed to by virtue of the fact that they are in the contracting position.&lt;/li&gt;
          &lt;li&gt;How to get different standards for different relationships?
            &lt;ul&gt;
              &lt;li&gt;Perhaps the parties have different aims depending on the kind of relationship. E.g. for standards of ettiquette, the parties are interested in determining how to maintain plesant interaction s with one another. For morality, the parties are interestsed in discovering how stand in a general relationship of mutual respect.&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;They are not behind a veil of ignorance. Individuals are concerned with what is reasonable for them &lt;em&gt;given&lt;/em&gt; their position in society.&lt;/li&gt;
      &lt;li&gt;They all share the same aim of finding principles that others (similarly motivated) can accept. This is what guarantees that there will be norms that all can accept.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Readings for analyzing normativity&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;A.C. Ewing, “A Suggested Non-Naturalistic Definition of Good”&lt;/li&gt;
  &lt;li&gt;Christine Kosgaard, “The Sources of Normativity”&lt;/li&gt;
  &lt;li&gt;Justin D’Arms, “Two Arguments for Sentimentalism”&lt;/li&gt;
  &lt;li&gt;Maybe
    &lt;ul&gt;
      &lt;li&gt;Henry Sidgwick, “Ethical Judgments”, from &lt;em&gt;The Methods of Ethics&lt;/em&gt;&lt;/li&gt;
      &lt;li&gt;H.A. Prichard, “Does Moral Philosophy Rest on a Mistake?”&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Outline:
Bold means seperate create a article for that section&lt;/p&gt;

&lt;p&gt;Copied in Topics.md&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;em&gt;Normativity&lt;/em&gt;
    &lt;ul&gt;
      &lt;li&gt;Examples&lt;/li&gt;
      &lt;li&gt;Contrast with descriptions&lt;/li&gt;
      &lt;li&gt;Plattitudes&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;em&gt;Analysis&lt;/em&gt; (the &lt;em&gt;content&lt;/em&gt; of normative judgments)
    &lt;ul&gt;
      &lt;li&gt;Domains
        &lt;ul&gt;
          &lt;li&gt;Rationality&lt;/li&gt;
          &lt;li&gt;Well-being versus reasons for action&lt;/li&gt;
          &lt;li&gt;Epistemology&lt;/li&gt;
          &lt;li&gt;Aesthetics&lt;/li&gt;
          &lt;li&gt;Morality&lt;/li&gt;
          &lt;li&gt;Ettiquette&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Flexibility of language&lt;/li&gt;
      &lt;li&gt;General: shoulds, justifications, warrant, etc. a relation involving an agent and an attitude. Grounds charges of criticism generally.&lt;/li&gt;
      &lt;li&gt;Narrow: Reasons. A relation that grounds charges of irrationality specifically.&lt;/li&gt;
      &lt;li&gt;Kinds of reasons concepts
        &lt;ul&gt;
          &lt;li&gt;Normative vs non-normative “should” (e.g. “he should arrive here soon”)&lt;/li&gt;
          &lt;li&gt;Explanatory vs Justificatory reasons&lt;/li&gt;
          &lt;li&gt;Objective vs Subjective reasons / Available vs Potential Reasons (e.g. reasons under lack of information)&lt;/li&gt;
          &lt;li&gt;Right/Wrong kinds of reasons&lt;/li&gt;
          &lt;li&gt;Internal vs External reasons
  —&amp;gt;
            &lt;ul&gt;
              &lt;li&gt;Available Reasons =&amp;gt; Rationality&lt;/li&gt;
              &lt;li&gt;Potential Reasons =&amp;gt; Counterfactual endorsements under rationally endorsed conditions&lt;/li&gt;
              &lt;li&gt;External Reasons&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Other different categories of reasons
        &lt;ul&gt;
          &lt;li&gt;Deontic vs Evaluative (proposition P should be true versus agent A ought to acquire attitude X)&lt;/li&gt;
          &lt;li&gt;Agent-Neutral / Agent-relative&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Intrinsic/Instrumental&lt;/li&gt;
      &lt;li&gt;Not all based in pleasure/happiness&lt;/li&gt;
      &lt;li&gt;Not all based in teleology&lt;/li&gt;
      &lt;li&gt;Hierarchical structure, pro-tanto &amp;amp; prima facie&lt;/li&gt;
      &lt;li&gt;Works: Moore, Ross, Ewing, Sidgwick, Wiggins, McDowell, D’arms/Jacobson, Parfit, Raz&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Psychology (the &lt;em&gt;psychology&lt;/em&gt; of normative judgments)
  &lt;em&gt;Introduction&lt;/em&gt;: the problem and possible solutions
  &lt;em&gt;Failure of descriptivism&lt;/em&gt; 
  &lt;em&gt;Characterization of non-descriptivism&lt;/em&gt;
      - World-to-mind fit that cannot be otherwise reduced
      - Expressive of deliberative endorsement and prescriptive
      - Possibility of an alternative standard of truth
      - Competing motivational faculties
  &lt;em&gt;Evolution&lt;/em&gt;: selections for descriptivism vs non-descriptivism
  &lt;em&gt;Observations&lt;/em&gt;: examples of other evaluative language, normative education, emphasizing the dynamic component of certain terms (e.g. no one admits to being “racist” despite meeting the criteria)
  &lt;em&gt;Objections&lt;/em&gt;
      - Seems intuitively false
      - Frege-Geach
      - Which attitude
    &lt;ul&gt;
      &lt;li&gt;Works: Stevenson, Ayer, Gibbard, Blackburn, Timmons/Horgan&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Correctness (the &lt;em&gt;correctness&lt;/em&gt; of normative judgments)
    &lt;ul&gt;
      &lt;li&gt;&lt;em&gt;Introduction&lt;/em&gt;: the problem and possible solutions&lt;/li&gt;
      &lt;li&gt;&lt;em&gt;Failure of externalism&lt;/em&gt;
        &lt;ul&gt;
          &lt;li&gt;Repeat many arguments from Williams’s article&lt;/li&gt;
          &lt;li&gt;Use analogy with theoretical reasons&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;em&gt;Failure of broad internalism&lt;/em&gt;
        &lt;ul&gt;
          &lt;li&gt;Critique Williams’s position&lt;/li&gt;
          &lt;li&gt;Use analogy with thoeretical reasons (e.g. desires don’t justify beliefs, even if they can explain them).&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;em&gt;Constructivism&lt;/em&gt;
        &lt;ul&gt;
          &lt;li&gt;Normative judgments, not desires/sensations, provide reasons&lt;/li&gt;
          &lt;li&gt;Analogy with other domains&lt;/li&gt;
          &lt;li&gt;Constituitive features&lt;/li&gt;
          &lt;li&gt;Explaining intuitive reasons versus broad internalism, externalism, etc.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;em&gt;Objections&lt;/em&gt;
        &lt;ul&gt;
          &lt;li&gt;Methodology
            &lt;ul&gt;
              &lt;li&gt;General Theory unlikely&lt;/li&gt;
              &lt;li&gt;Conflicting reasons&lt;/li&gt;
              &lt;li&gt;Deliberation/reflection&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Works: Koorsgard, Street, Scanlon, Parfit, Frankfurt, Nagel, Gauthier&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;em&gt;Morality&lt;/em&gt;
    &lt;ul&gt;
      &lt;li&gt;&lt;em&gt;Introduction&lt;/em&gt;: the problem of reasons and objectivity&lt;/li&gt;
      &lt;li&gt;Sentimentalism&lt;/li&gt;
      &lt;li&gt;Contractualism&lt;/li&gt;
      &lt;li&gt;Methodology
        &lt;ul&gt;
          &lt;li&gt;General Theory unlikely&lt;/li&gt;
          &lt;li&gt;Conflicting interests&lt;/li&gt;
          &lt;li&gt;Argumentation/Discussion&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Works: Scanlon, Kant&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Some insights that I haven’t seen explored elsewhere&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Individual rationality need not reduce to individual goodness. For example, individual goodness might reduce to desired states of consciousness, even though it might be rational to act to attain desired states of consciousness (e.g. experience machine). Can this relate to morality? How should goodness and rationality be analyzed? If this is true, then what does it mean to say that something ought to be desired/preferred/promoted (i.e. goodness) even though we ought not necessarily act to promote it (e.g. rationality). So not even individual rationality need be consequentialist.&lt;/li&gt;
  &lt;li&gt;Different irreducible domains of morality, e.g. ettiquette, aesthetic morality and justice morality. These distinctions are not necessarily a part of a linguistic culture.&lt;/li&gt;
  &lt;li&gt;We are not consequentialist about epistemology.&lt;/li&gt;
  &lt;li&gt;Formulating a revisionist cognitivist analysis of normative judgments from historical non-cognitive uses.&lt;/li&gt;
  &lt;li&gt;Normative judgments are all judgments of relations, not properties.&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;introduction&quot;&gt;Introduction&lt;/h2&gt;

&lt;h3 id=&quot;applies-ethics-normative-ethics-and-metaethics&quot;&gt;Applies Ethics, Normative Ethics and Metaethics&lt;/h3&gt;

&lt;h3 id=&quot;the-insufficiency-of-reflective-equilibrium-and-the-need-for-metaethics&quot;&gt;The insufficiency of reflective equilibrium and the need for metaethics&lt;/h3&gt;

&lt;p&gt;Can we recreate moral positions using non-moral terms?&lt;/p&gt;

&lt;p&gt;Reflective equilibrium with regard to normative ethical reasoning fails to settle disputes when two different parties reach different conclusions in their reflective equilibriums, either because of different foundational principles or different considered judgments. At this point, it may seem that the disagreements are irresolvable. To settle the dispute, we need to take a step back from answering the normative questions themselves. Instead of internally justifying our positions, we need to ask external questions about the normative questions. We need to determine what is actually at dispute among the parties.&lt;/p&gt;

&lt;p&gt;We need a strategy for communicating the meanings of our expressions to an agent unfamiliar with our language. This can work for descriptive concepts by merely presenting instances of the entity in question and associating it with certain words.&lt;/p&gt;

&lt;p&gt;The strategy for doing this is as follows. (1) list out all of the assertions from two parties in an ethical debate. (2) Replace the assertions that the parties make with different non-ethical statements about the parties in a manner that preserves the significant psychological and social commitments of all parties.&lt;/p&gt;

&lt;p&gt;For example, if given the following ethical dispute:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;A judges that X is morally wrong.&lt;/li&gt;
  &lt;li&gt;B judges that X is not morally wrong.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;There are a few ways to translate this:&lt;/p&gt;

&lt;h4 id=&quot;definitions&quot;&gt;Definitions&lt;/h4&gt;

&lt;p&gt;We might do this by substituting the normative terms with non-normative terms as if in a strict dictionary definition. The definition could be the agent’s subjective definition, societal definitions, etc. For example, the earlier dispute might be replaced as:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;A believes that X promotes suffering.&lt;/li&gt;
  &lt;li&gt;B believes that X does not promote suffering.&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;plattitudes&quot;&gt;Plattitudes&lt;/h4&gt;

&lt;p&gt;Maybe there can be no strict definition. Instead, we just encapsulate all the plattitudes that are necessary to come to have mastery of the concept, i.e. the inferential and judgmental dispositions of those who have mastery. This can be done by finding the role that these terms play in linguistic discourse.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;A judges that we have reason to disapprove of those who X.&lt;/li&gt;
  &lt;li&gt;A is disposed to disapprove of X.&lt;/li&gt;
  &lt;li&gt;A is disposed to not do X, all things else being equal.
…&lt;/li&gt;
  &lt;li&gt;B denies these.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;One issue with these is that they also use other normative terms, e.g. “reasons”. More work would need to be done to explain those.&lt;/p&gt;

&lt;p&gt;Another issue is that it may seem that some terms don’t have a clear role in language. For example, while the role of moral rightnes/wrongness might be clearly associated with motivation for and reasons for approval/disapproval, etc. but other normative terms like “rationality” might not have such a clear role in language. So it may be unclear how to settle disputes about “rationality”. Perhaps, what we can do is look for what roles we would need to be filled in, and argue that only certain interpretations of “rationality” can fill that void, and other interpretations don’t account for anything linguistically important.&lt;/p&gt;

&lt;h4 id=&quot;job-of-metaethics&quot;&gt;Job of metaethics&lt;/h4&gt;

&lt;p&gt;Explain the following&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Semantics: what we mean when making a moral statement.&lt;/li&gt;
  &lt;li&gt;Psychology: what state of mind characterized by moral judgment.&lt;/li&gt;
  &lt;li&gt;Ontology: what grounds moral properties, if they exist.&lt;/li&gt;
  &lt;li&gt;Epistemology: how we can learn/reason about moral truth.&lt;/li&gt;
  &lt;li&gt;Rationality: why we have reason to be moral.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The most important are accounting for semantics/psychology and giving a realistic account of epistemology/rationality, i.e. we need an objective methodology for handling moral disputes, as disputes are the most important feature of moral beliefs. The ontology doesn’t really matter.&lt;/p&gt;

&lt;h2 id=&quot;plattitudes-1&quot;&gt;Plattitudes&lt;/h2&gt;

&lt;p&gt;The role of normative thinking is to handle conflicts in our motivations.
Normative thinking requires the followings: (a) beings with motivations, which sometimes conflict, (b) beings capable of stepping back and acknowledging these motivations and assessing them, (c) beings capable of deciding on which motivation to will after normative reflection.
This explains why there cannot be inconsistent upshots of normative reasoning.
The very practice of normative thinking was created as a response to motivational conflicts.
Thus, a being who doesn’t care about such conflicts doesn’t count as a normative reasoning agent.
Or, a person who doesn’t have normative conflicts wouldn’t count as a normative reasoning agent. There would be no need for normativity to arise.
The basic goal is to move from disjointed conflict to unity.&lt;/p&gt;

&lt;p&gt;Normative “conflict” generally does not mean inconsistency specifically. 
Inconsistency refers to conflicts in beliefs, where there can be conflicts in desires, intentions, attitudes, etc.&lt;/p&gt;

&lt;h3 id=&quot;ubiquitous&quot;&gt;Ubiquitous&lt;/h3&gt;

&lt;p&gt;Normative judgments are found in all creatures who deliberate, insofar as those deliberations influence action.&lt;/p&gt;

&lt;p&gt;Perceptions and desires are pre-reflective cognitive elements that dispose us towards a certain behavior. A perception that p consists of a pre-reflective disposition towards believing p. A desire that p consists of a pre-reflective dispositions towards performing M whenever one believes M -&amp;gt; p. These pre-reflective elements can be identified as the animalistic motivational system.&lt;/p&gt;

&lt;p&gt;Non-human animals typically behave according to their pre-reflective cognitive dispositions. They believe whatever they perceive, and they act according to whatever desire happens to be strongest. The beliefs and actions of humans, on the other hand, are usually not strictly identical with our perceptions and desires. We deliberate and reflect about what to do, and this inevitably involves our perceptions and desires. However it involves much more than our perceptions and desires. (1) We decide which beliefs and actions are &lt;em&gt;justified&lt;/em&gt; from our perceptions/desires, which may not be identical with whatever the perceptions/desires indicate/favor. (2) We &lt;em&gt;reject&lt;/em&gt; some perceptions/desires as mistaken or irrational. (3) We &lt;em&gt;endorse&lt;/em&gt; certain perceptions/desires as rational or justified.&lt;/p&gt;

&lt;p&gt;When we deliberate and reflective, we try to determine the &lt;em&gt;reasons&lt;/em&gt; we have for a kind of behavior. Whenever we act, insofar as we are deliberative and reflective, we act according to what we have judged ourselves to have &lt;em&gt;reason&lt;/em&gt; to do. To the extent that we don’t act according to what we judge ourselves to have reason to do, we are acting &lt;em&gt;irrationally&lt;/em&gt;. The deliberation involved with the connection between are given pre-reflective &lt;em&gt;dispositions&lt;/em&gt; favoring a certain behavior (i.e. perceptions, desires, sensations, etc.) and are post-reflective conscious &lt;em&gt;endorsements&lt;/em&gt; of a certain behavior (i.e. what we determined ourselves to have reason to do) is &lt;em&gt;normative reasoning&lt;/em&gt;. The motivational system associated with normative reasoning is the &lt;em&gt;normative motivational system.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Supplement:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Korsgaard’s contrast of animals and humans&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;supervenience&quot;&gt;Supervenience&lt;/h3&gt;

&lt;p&gt;Normative judgments supervene on non-normative beliefs. If one has a competent grasp of normative concepts, then if they judge two things to be different normatively then this must be due to a judged difference in non-normative properties. Equivalently, once one’s beliefs about the non-normative properties of a thing is fixed, so too are his normative judgments about the thing.&lt;/p&gt;

&lt;h3 id=&quot;deliberative&quot;&gt;Deliberative&lt;/h3&gt;

&lt;p&gt;Argumentation/reasoning influences our normative judgments. Our judgments of normative reason are typically the upshots of deliberation, whereas our motivating reasons can be a given&lt;/p&gt;

&lt;p&gt;Supplement:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Smith’s elaboration on the deliberative and the intentional.&lt;/li&gt;
  &lt;li&gt;Koorsgard’s theory of normativity&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;motivational&quot;&gt;Motivational&lt;/h3&gt;

&lt;p&gt;Normative judgments influence action. Judging that one has normative reason to do x is typically associated with a motivating reason to do x. But this is not perfect: there are cases where one judges that they have normative reason to do x without having a corresponding motivating reason to do x, and there are cases where one has a motivating reason to do x without a corresponding judgment that they have normative reason to do x. Think of cases of psychological compulsion, physical addiction or emotional disturbances. Such cases are usually not the norm; an explanation of some such sort must be invoked to explain not intending what one judges to have reason to do.&lt;/p&gt;

&lt;p&gt;Supplement:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Supplement on Smith’s elaboration of the deliberative and the intentional&lt;/li&gt;
  &lt;li&gt;Gibbard’s evolutionary arguments for the value of motivational content&lt;/li&gt;
  &lt;li&gt;considerations about translations from other cultures&lt;/li&gt;
  &lt;li&gt;sincere inferences of normative judgments of others&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;disagreement&quot;&gt;Disagreement&lt;/h3&gt;

&lt;p&gt;People have normative disagreements.&lt;/p&gt;

&lt;p&gt;People have epistemic disagreements. Two parties can have identical perceptions and evidence in front of them, and yet disagree about what they have most &lt;em&gt;epistemic reason&lt;/em&gt; to believe given the evidence. They can disagree about what can be &lt;em&gt;rationally inferred&lt;/em&gt; given the evidence.&lt;/p&gt;

&lt;p&gt;People have moral disagreements. Two parties can have identical beliefs with regard to the empirical world, and yet disagree about what we have &lt;em&gt;moral reason&lt;/em&gt; to do. They can.&lt;/p&gt;

&lt;p&gt;People have prudential disagreements. Two parties can have identical beliefs about a hypothetical agent’s desires, interests, etc. and the empirical world, and yet have disagreements about what that agent has most reason to do. One parties might say he should satisfy his present desires, others say he should do what will in fact make him happiest, others that he should do what will result in the least regret, etc.&lt;/p&gt;

&lt;p&gt;People have aesthetic disagreements.&lt;/p&gt;

&lt;p&gt;While these disagreements sometimes stem from logical or semantic errors, they need not always. Rather, the disagreements are often the result of differing normative principles.&lt;/p&gt;

&lt;p&gt;We need a shared concept in order for disagreement to be possible.&lt;/p&gt;

&lt;p&gt;Supplement:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Stevenson’s article on disagreement.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;unification&quot;&gt;Unification&lt;/h2&gt;

&lt;p&gt;All normative judgments can be expressed in the form of a prescription that recommends a particular behavior X for an agent A in circumstances. There are often expressed in declarative form via some relation that involves entities A, X, C. The basic terms underlying this relation can be any term that supports this relation grammatically, i.e. “A ought to X in circumstances C”, “A has reason to X in circumstances C”, “A is justified in X-ing in circumstances C”, “It is fitting for A to X in circumstances C”, etc.&lt;/p&gt;

&lt;p&gt;They are also sometimes expressed without using strictly normative terms, e.g. “A must do X in C”, “A has to do X in C”, etc. Finally, they can also be expressed purely as imperatives, i.e. “A, do X in C”. All of these are ways of communicating a normative judgment to someone else.&lt;/p&gt;

&lt;p&gt;A normative system can be understood by the following components:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;T - The types of behavior regulated (actions, beliefs, driving, etc.) - this constraints genuine normative statements to be action guiding in some way. Normative propositions that cannot be expressed in this manner are not coherent normative propositions.&lt;/li&gt;
  &lt;li&gt;R - The considerations that serve as reasons for the norm. Different normative realms have different relavent considerations.
Then we can determine the content of the normative system:&lt;/li&gt;
  &lt;li&gt;S - The actual norms of the normative system. These are entailed from whatever the relevant considerations are plus any observational content.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Other considerations concerning the content of normative judgments&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Right/Wrong kinds of reason&lt;/li&gt;
  &lt;li&gt;Ought implies can &amp;amp; cannot&lt;/li&gt;
  &lt;li&gt;Is/Ought gap -&amp;gt; logical/analytic/synthetic&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;There are a few different classes of normative judgments:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Rational judgments - A has reason to do X&lt;/li&gt;
  &lt;li&gt;Aesthetic judgments - A expresses attitude with regard to X&lt;/li&gt;
  &lt;li&gt;Moral judgments - A encourages the attitudes of others&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;rational-psycholgoy&quot;&gt;Rational Psycholgoy&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;Rational Psychology.md&quot;&gt;Main Page&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&quot;intentional-and-deliberative&quot;&gt;Intentional and Deliberative&lt;/h3&gt;

&lt;p&gt;Intentional action can be explained from two perspectives, the &lt;em&gt;intentional&lt;/em&gt; and the &lt;em&gt;deliberative&lt;/em&gt;. From the intentional perspective, intentional action can be explained by citing &lt;em&gt;motivating reasons&lt;/em&gt;, i.e. by citing a belief-desire pair that fits into a pattern of teleological explanation. From the deliberative perspective, intentional action can be explained by citing &lt;em&gt;normative reasons&lt;/em&gt;, i.e. by citing a pattern of rational deliberation that either did, or could have, produced it. This involves citing the considerations that one reflects over in deciding what to do.&lt;/p&gt;

&lt;p&gt;The deliberative perspective must be explanatory to satisfy the judgment internalism thesis about normativity, i.e. when we decide what to do after deliberation, that often makes a difference in what we do. This would be impossible if the deliberative perspective were not explanatory, since the connection between deliberation and our action would be purely causally contingent. Thus, our attitudes towards the propositions that figure in our deliberations must be capable of figuring an explanation of our action.&lt;/p&gt;

&lt;p&gt;However, there must also be some slack between desires and values. An agent may desire to X without valuing to X (e.g. kleptomaniac, addicts, etc.). Likewise, an agent may value X without desiring to X (e.g. the depressed, weakness of will). In general, due to psychological compulsions, physical addictions, emotional disturbances, etc. there is an imperfect connection between what an agent judges to be a normative reasons for action and the agent’s motivating reasons for action.&lt;/p&gt;

&lt;p&gt;To judge that one has normative reason to X is to &lt;em&gt;endorse&lt;/em&gt; X under deliberation. Normative judgments then can be vaguely characterized as &lt;em&gt;deliberative endorsement&lt;/em&gt; of some propositional content. Contrast this with undeliberative or unreflective endorsement, which are the sources of one’s &lt;em&gt;motivating reasons&lt;/em&gt;, the explanation of their intentional behavior. Voluntary actions can be explained by a belief and desire; these actions are done on the basis of normative reasnoing insofar as deliberation and reflection play a role in how the belief and desire manifest into action, e.g. if deliberation influences what one desires, which desires are actualized, etc. The question is to determine what it is to form deliberative endorsement of an action. Is it a desire, belief of some sort, etc?&lt;/p&gt;

&lt;h3 id=&quot;world-to-mind&quot;&gt;World-to-mind&lt;/h3&gt;

&lt;p&gt;The question is whether deliberative endorsement is a world-to-mind fit (dispositional) or mind-to-world fit (representational). Good candidates for a representational analysis are counterfactual beliefs about an agent’s hypothetical attitudes under certain circumstances. Nevertheless, it seems that normative judgments and deliberative endorsement are best explained by a world-to-mind, dispositional fit. This best explains why people who judge that they have normative reason to X are disposed to X. If it was a mere mind-to-world state of mind (even if a counterfactual belief about one’s attitudes), then there would have to be some &lt;em&gt;additional&lt;/em&gt; world-to-mind state of mind that explained why one’s deliberation influences their motivation, and &lt;em&gt;this&lt;/em&gt; state of mind would be the core feature of normative judgments.&lt;/p&gt;

&lt;p&gt;However, normative judgments are not best characterized as desires. It seems clear that normative judgments and desires can sometimes diverge. Goals and preferences seem to be a distinctive form of world-to-mind fit. And we can clearly understand how one might not have a desire to achieve one of their goals. It seems like the distinction between desires and goals are similar to the distinction between desires and values. It seems like we can distinguish different world-to-mind fits based on their relationship to consciousness (thoughts) and deliberation (thoughts about thoughts).&lt;/p&gt;

&lt;h2 id=&quot;rational-correctness&quot;&gt;Rational Correctness&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;Rational Correctness.md&quot;&gt;Main Page&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&quot;existence-internalist&quot;&gt;Existence Internalist&lt;/h3&gt;

&lt;p&gt;R is a normative reason for A to X iff R would be a motivating reason for A to X insofar as A is rational and A was aware of R. Thus, R is a reason for agent A if and only if R is the upshot of sound rational deliberation. In other wrods, normative reasons are the rational extensions of one’s motivating reasons. A consideration C counts as a reason if and only if there is a sound deliberative route from an agent’s motivational reasons to C.&lt;/p&gt;

&lt;p&gt;The question is then how to account for what “rational extension” and “sound deliberative route” consists in. At the very least, this seems to require logical consistency. A constructivist account of normativity can explain what rational extension consists in generally.&lt;/p&gt;

&lt;h3 id=&quot;constructivist&quot;&gt;Constructivist&lt;/h3&gt;

&lt;p&gt;Truth for rationality is not correspondence. That is, the standard of correctness for a normative proposition is not an mind-independent entity or set of entities which the proposition is purported to correspond to. Rather, the standard of correctness is rules and requirements constructed by and internal to the agents who hold the proposition.&lt;/p&gt;

&lt;p&gt;The fact that X is a reason to Y for agent A is constituted by the fact that the judgment that X is a reason to Y (for A) withstands scrutiny from the standpoint of A’s other judgments about reasons. Note that X is never a reason in favor of Y, absolutely. X can only be in favor of Y for some particular agent, as determined by the standards set by the normative judgments of A himself.&lt;/p&gt;

&lt;p&gt;A normative judgment withstands scrutiny for an agent only if the agent could mantain the judgment in full awareness, which is determined by the constituitive standards of the attitude in question. For example, someone who judges that X is a reason to Y cannot also simultaneously and in full awareness judge that X is not a reason to Y (consistency is constitutive of normative judgments). Also, one cannot take oneself to have conclusive reason to Y without taking oneself to have reason to take the means to Y (means-end reasoning is constituitive of normative judgments). The force of &lt;em&gt;cannot&lt;/em&gt; is not rational, but what is &lt;em&gt;constituitive&lt;/em&gt; of the concept of forming normative judgments.&lt;/p&gt;

&lt;p&gt;These standards of correctness are legislated by the very person making the normative judgments. This allows that one can be genuinely mistaken about their normative judgments only insofar as they are not in full awareness of certain relevant features of their judgments.&lt;/p&gt;

&lt;h3 id=&quot;constituitive-features&quot;&gt;Constituitive Features&lt;/h3&gt;

&lt;p&gt;The central question is how to determine what requirements are constitutive of a type of behavior. One candidate is this: a requirement is constituitive of a behavior if no agent could consciously reject the requirement in full awareness.&lt;/p&gt;

&lt;p&gt;Logical Consistency. One basic constituitive feature of normative judgments (and thuoghts generally) is logical consistency. No person can consciously believe X and believe not-X in full awareness.&lt;/p&gt;

&lt;h4 id=&quot;epistemic&quot;&gt;Epistemic&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;Perceptions/memories: the reason that a perception that p provides one with reason to believe that p is because part of what it is to perceive p is to acquire an unreflective belief that p. If perceptions didn’t provide one with an unreflective belief that p, then perceiving that p would be like imagining that p, and this would not provide one with a reason to believe p. Similar considerations apply to memories.&lt;/li&gt;
  &lt;li&gt;Abduction:&lt;/li&gt;
  &lt;li&gt;Induction:&lt;/li&gt;
  &lt;li&gt;Causation:&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;prudential&quot;&gt;Prudential&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;Desires: the reason that a desire to X tends to provide one with reason to X is (1) people tend to judge that they have reason to X if they desire to X, and (2) all intentional actions are done because of some desire; if they are not done because of a desire, then they would be involuntary actions.&lt;/li&gt;
  &lt;li&gt;Instrumental Reasoning: one cannot take oneself to have conclusive reason to X without taking oneself to have reason to take the means to X. Part of what it is to judge one has a reason to X consists of judging one to have a reason to adopt the means.&lt;/li&gt;
  &lt;li&gt;Pain/Suffering: the reason that pain/suffering provides one with reason to avoid it is precisely because people judge that they have reason to avoid it (or they have an unreflective aversion towards it). If a person had no aversion toward pain and didn’t judge that they had reason to avoid it, then there would be no actual reason to avoid it. It is not the pure sensation of pain that provides us with reason to avoid it.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;competing-reasons&quot;&gt;Competing reasons&lt;/h3&gt;

&lt;p&gt;The most fundamental question is how to determine what one ought to do when there are some considerations that give one reason to X and some considerations that give one reason to not-X. This is especially important for moral considerations when weighing reasons from different agents.&lt;/p&gt;

&lt;h2 id=&quot;moral-psychology&quot;&gt;Moral Psychology&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;Moral Psychology.md&quot;&gt;Main Page&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Two puzzles that must be resolved by a moral psychology and ontology (or standard of correctness)&lt;/p&gt;

&lt;p&gt;Psychology&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Moral judgments are truth-apt.&lt;/li&gt;
  &lt;li&gt;Truth-apt judgments must be beliefs (i.e. descriptive).&lt;/li&gt;
  &lt;li&gt;Moral judgments are intrinsically motivating.&lt;/li&gt;
  &lt;li&gt;Beliefs are not sufficient for intrinsic motivation.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Truth&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Rational: Moral duties provide agents with reason for action.&lt;/li&gt;
  &lt;li&gt;Categorical: Moral duties apply to all agents (some infer an independence of any agent’s desires).&lt;/li&gt;
  &lt;li&gt;Internalism: Practical reasons are necessarily dependent on desires.&lt;/li&gt;
  &lt;li&gt;Contingency: There are no necessary desires in all rational agents&lt;/li&gt;
  &lt;li&gt;Success Theory: There are moral truths.&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;moral-reasons&quot;&gt;Moral Reasons&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;Moral Reasons.md&quot;&gt;Main Page&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&quot;aesthetic&quot;&gt;Aesthetic&lt;/h3&gt;

&lt;h3 id=&quot;constructivist-1&quot;&gt;Constructivist&lt;/h3&gt;

&lt;h3 id=&quot;objectivity&quot;&gt;Objectivity&lt;/h3&gt;

&lt;h4 id=&quot;game-only-exists-in-certain-cultures&quot;&gt;Game only exists in certain cultures&lt;/h4&gt;

&lt;p&gt;This constructed morality “game” only exist in cultures where moral discussion involves providing reasons for all persons to follow. But this need not necessarily be the case in certain authoritarian/hierarchical societies where moral discussion is a vehicle for the powerful to issue non-negotiable and enforced commands rather than a cooperative, negotiative role. E.g. if there is a king commanding peasants to act in a certain way. There are no objective moral standards that the kind has to follow; the best one can hope for is to destroy their opponents and/or try to manipulate their emotions.&lt;/p&gt;

&lt;p&gt;Did we really lose anything by being unable to say that they are unreasonable? We can still say that they are immoral, bad, evil, etc. So what have we lost? The only thing we’ve realize now is that they cannot be &lt;em&gt;rationally motivated&lt;/em&gt; to be moral. But this would be the case even if there was an independent ontology of moral facts. Do we really think that if such a realm existed, we could &lt;em&gt;rationally motivate&lt;/em&gt; all undesirable villians to behave. We have lost nothing.&lt;/p&gt;

&lt;h4 id=&quot;not-motivationally-necessary-constructivist&quot;&gt;Not motivationally necessary (constructivist)&lt;/h4&gt;

&lt;h4 id=&quot;contingent-upon-our-interests-aesthetic&quot;&gt;Contingent upon our interests (aesthetic)&lt;/h4&gt;

&lt;h4 id=&quot;not-rationally-necessary&quot;&gt;Not rationally necessary&lt;/h4&gt;

&lt;p&gt;One could say morality is not rationally necessary in the sense that one has no reason to be moral if they didn’t already have an interest in being moral. But a similar truth is found in other domains:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;One has no reason to accept logic if they didn’t already accept it (this wouldn’t really be an agent to begin with).&lt;/li&gt;
  &lt;li&gt;One has no reason to believe X if none of their perceptions indicated X.&lt;/li&gt;
  &lt;li&gt;One has no reason to accept science if they had no interest in science.&lt;/li&gt;
  &lt;li&gt;One has no reason to avoid pain if they had no interest in avoiding the sensation.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Standards of moral correctness only matter for people who are interested in settling moral arguments for moral reasons. For people who are uninterested, no objective moral ontology would have mattered to them anyway. For those who are interested, a standard of correctness that’s internal to contingent moral desires is motivating enough.&lt;/p&gt;

&lt;h4 id=&quot;objective-methodology&quot;&gt;Objective methodology&lt;/h4&gt;

&lt;p&gt;The importance of objectivity does not require an independent realm of moral facts, nor does it require rational reason for all agents. The importance of objectviity was:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Normative thinking is a rational enterprise.&lt;/li&gt;
  &lt;li&gt;Someone is incorrect in moral arguments.&lt;/li&gt;
  &lt;li&gt;There is an independent standard to determine who is incorrect.&lt;/li&gt;
&lt;/ul&gt;</content><author><name>JayMoss</name></author><summary type="html">New structure Normative Talk - all normative concepts reduced to claims of reasons Normative Truth - Internalism and Constructivism Normative Thought - Non-cognitivism Blame and Relationships Moral Reasons and Relationships Against narcisistic egoism - Neglects impartiality, what others have reason to accept/reject Against Egoism - Certain people can have reason to reject egoism if it leads to their despair Against certain forms of consequentialism - that reduce moral rightness to non-moral goodness. Not all rational interests are morally legitimate Against Rawls/Consequentialism - “reasonable for everyone” (contractualism) =/= “reasonable given equal chance of being anyone” (Rawls, or some forms of consequentialism). Fauly interpretation of impartiality. This still allows for people to prefer their own interests more than others. It is reasonable for everyone to accept a system of rules where they can give some weight to their interests. It would be unreasonable to accept being subjugated to some overall calculus (this doesn’t lead to egoism). The end is somewhere between egoism and consequentialism with a discounting of particular kinds of individual goodness. Rejects most conditions to count as consequentialism - hedomism and commensurability (both rejected from theory of rationality), aggregation and agent-neutrality (both rejected because they are not acceptable for all persons). Under contractualism, the parties to the contract are as follows: They determine what the standards for blame/shame are to be (i.e. the moral norms), NOT what everyone’s behaviors will be. Just as Rawls is determining the principles of social institutions and not everyone’s behaviors. If we were determining everyone’s behaviors, everyone would be nice and charitable and there would be no need for morality/law. Important: whether someone is blameworthy depends on whether they violated the standards of a relationship. So they will be determining the standards of the relationship. This will not just reduce to accepting the standards that promote the best consequences for everyone. One could only infer that if we already concluded that the standards of our relationship is to promote the best consequences. But that is the very thing to be decided. We don’t know beforehand if the parties of the constract are committed to promoting the best consequences. We need to determine what they are committed to by virtue of the fact that they are in the contracting position. How to get different standards for different relationships? Perhaps the parties have different aims depending on the kind of relationship. E.g. for standards of ettiquette, the parties are interested in determining how to maintain plesant interaction s with one another. For morality, the parties are interestsed in discovering how stand in a general relationship of mutual respect. They are not behind a veil of ignorance. Individuals are concerned with what is reasonable for them given their position in society. They all share the same aim of finding principles that others (similarly motivated) can accept. This is what guarantees that there will be norms that all can accept. Readings for analyzing normativity A.C. Ewing, “A Suggested Non-Naturalistic Definition of Good” Christine Kosgaard, “The Sources of Normativity” Justin D’Arms, “Two Arguments for Sentimentalism” Maybe Henry Sidgwick, “Ethical Judgments”, from The Methods of Ethics H.A. Prichard, “Does Moral Philosophy Rest on a Mistake?” Outline: Bold means seperate create a article for that section Copied in Topics.md Normativity Examples Contrast with descriptions Plattitudes Analysis (the content of normative judgments) Domains Rationality Well-being versus reasons for action Epistemology Aesthetics Morality Ettiquette Flexibility of language General: shoulds, justifications, warrant, etc. a relation involving an agent and an attitude. Grounds charges of criticism generally. Narrow: Reasons. A relation that grounds charges of irrationality specifically. Kinds of reasons concepts Normative vs non-normative “should” (e.g. “he should arrive here soon”) Explanatory vs Justificatory reasons Objective vs Subjective reasons / Available vs Potential Reasons (e.g. reasons under lack of information) Right/Wrong kinds of reasons Internal vs External reasons —&amp;gt; Available Reasons =&amp;gt; Rationality Potential Reasons =&amp;gt; Counterfactual endorsements under rationally endorsed conditions External Reasons Other different categories of reasons Deontic vs Evaluative (proposition P should be true versus agent A ought to acquire attitude X) Agent-Neutral / Agent-relative Intrinsic/Instrumental Not all based in pleasure/happiness Not all based in teleology Hierarchical structure, pro-tanto &amp;amp; prima facie Works: Moore, Ross, Ewing, Sidgwick, Wiggins, McDowell, D’arms/Jacobson, Parfit, Raz Psychology (the psychology of normative judgments) Introduction: the problem and possible solutions Failure of descriptivism Characterization of non-descriptivism - World-to-mind fit that cannot be otherwise reduced - Expressive of deliberative endorsement and prescriptive - Possibility of an alternative standard of truth - Competing motivational faculties Evolution: selections for descriptivism vs non-descriptivism Observations: examples of other evaluative language, normative education, emphasizing the dynamic component of certain terms (e.g. no one admits to being “racist” despite meeting the criteria) Objections - Seems intuitively false - Frege-Geach - Which attitude Works: Stevenson, Ayer, Gibbard, Blackburn, Timmons/Horgan Correctness (the correctness of normative judgments) Introduction: the problem and possible solutions Failure of externalism Repeat many arguments from Williams’s article Use analogy with theoretical reasons Failure of broad internalism Critique Williams’s position Use analogy with thoeretical reasons (e.g. desires don’t justify beliefs, even if they can explain them). Constructivism Normative judgments, not desires/sensations, provide reasons Analogy with other domains Constituitive features Explaining intuitive reasons versus broad internalism, externalism, etc. Objections Methodology General Theory unlikely Conflicting reasons Deliberation/reflection Works: Koorsgard, Street, Scanlon, Parfit, Frankfurt, Nagel, Gauthier Morality Introduction: the problem of reasons and objectivity Sentimentalism Contractualism Methodology General Theory unlikely Conflicting interests Argumentation/Discussion Works: Scanlon, Kant Some insights that I haven’t seen explored elsewhere Individual rationality need not reduce to individual goodness. For example, individual goodness might reduce to desired states of consciousness, even though it might be rational to act to attain desired states of consciousness (e.g. experience machine). Can this relate to morality? How should goodness and rationality be analyzed? If this is true, then what does it mean to say that something ought to be desired/preferred/promoted (i.e. goodness) even though we ought not necessarily act to promote it (e.g. rationality). So not even individual rationality need be consequentialist. Different irreducible domains of morality, e.g. ettiquette, aesthetic morality and justice morality. These distinctions are not necessarily a part of a linguistic culture. We are not consequentialist about epistemology. Formulating a revisionist cognitivist analysis of normative judgments from historical non-cognitive uses. Normative judgments are all judgments of relations, not properties. Introduction Applies Ethics, Normative Ethics and Metaethics The insufficiency of reflective equilibrium and the need for metaethics Can we recreate moral positions using non-moral terms? Reflective equilibrium with regard to normative ethical reasoning fails to settle disputes when two different parties reach different conclusions in their reflective equilibriums, either because of different foundational principles or different considered judgments. At this point, it may seem that the disagreements are irresolvable. To settle the dispute, we need to take a step back from answering the normative questions themselves. Instead of internally justifying our positions, we need to ask external questions about the normative questions. We need to determine what is actually at dispute among the parties. We need a strategy for communicating the meanings of our expressions to an agent unfamiliar with our language. This can work for descriptive concepts by merely presenting instances of the entity in question and associating it with certain words. The strategy for doing this is as follows. (1) list out all of the assertions from two parties in an ethical debate. (2) Replace the assertions that the parties make with different non-ethical statements about the parties in a manner that preserves the significant psychological and social commitments of all parties. For example, if given the following ethical dispute: A judges that X is morally wrong. B judges that X is not morally wrong. There are a few ways to translate this: Definitions We might do this by substituting the normative terms with non-normative terms as if in a strict dictionary definition. The definition could be the agent’s subjective definition, societal definitions, etc. For example, the earlier dispute might be replaced as: A believes that X promotes suffering. B believes that X does not promote suffering. Plattitudes Maybe there can be no strict definition. Instead, we just encapsulate all the plattitudes that are necessary to come to have mastery of the concept, i.e. the inferential and judgmental dispositions of those who have mastery. This can be done by finding the role that these terms play in linguistic discourse. A judges that we have reason to disapprove of those who X. A is disposed to disapprove of X. A is disposed to not do X, all things else being equal. … B denies these. One issue with these is that they also use other normative terms, e.g. “reasons”. More work would need to be done to explain those. Another issue is that it may seem that some terms don’t have a clear role in language. For example, while the role of moral rightnes/wrongness might be clearly associated with motivation for and reasons for approval/disapproval, etc. but other normative terms like “rationality” might not have such a clear role in language. So it may be unclear how to settle disputes about “rationality”. Perhaps, what we can do is look for what roles we would need to be filled in, and argue that only certain interpretations of “rationality” can fill that void, and other interpretations don’t account for anything linguistically important. Job of metaethics Explain the following Semantics: what we mean when making a moral statement. Psychology: what state of mind characterized by moral judgment. Ontology: what grounds moral properties, if they exist. Epistemology: how we can learn/reason about moral truth. Rationality: why we have reason to be moral. The most important are accounting for semantics/psychology and giving a realistic account of epistemology/rationality, i.e. we need an objective methodology for handling moral disputes, as disputes are the most important feature of moral beliefs. The ontology doesn’t really matter. Plattitudes The role of normative thinking is to handle conflicts in our motivations. Normative thinking requires the followings: (a) beings with motivations, which sometimes conflict, (b) beings capable of stepping back and acknowledging these motivations and assessing them, (c) beings capable of deciding on which motivation to will after normative reflection. This explains why there cannot be inconsistent upshots of normative reasoning. The very practice of normative thinking was created as a response to motivational conflicts. Thus, a being who doesn’t care about such conflicts doesn’t count as a normative reasoning agent. Or, a person who doesn’t have normative conflicts wouldn’t count as a normative reasoning agent. There would be no need for normativity to arise. The basic goal is to move from disjointed conflict to unity. Normative “conflict” generally does not mean inconsistency specifically. Inconsistency refers to conflicts in beliefs, where there can be conflicts in desires, intentions, attitudes, etc. Ubiquitous Normative judgments are found in all creatures who deliberate, insofar as those deliberations influence action. Perceptions and desires are pre-reflective cognitive elements that dispose us towards a certain behavior. A perception that p consists of a pre-reflective disposition towards believing p. A desire that p consists of a pre-reflective dispositions towards performing M whenever one believes M -&amp;gt; p. These pre-reflective elements can be identified as the animalistic motivational system. Non-human animals typically behave according to their pre-reflective cognitive dispositions. They believe whatever they perceive, and they act according to whatever desire happens to be strongest. The beliefs and actions of humans, on the other hand, are usually not strictly identical with our perceptions and desires. We deliberate and reflect about what to do, and this inevitably involves our perceptions and desires. However it involves much more than our perceptions and desires. (1) We decide which beliefs and actions are justified from our perceptions/desires, which may not be identical with whatever the perceptions/desires indicate/favor. (2) We reject some perceptions/desires as mistaken or irrational. (3) We endorse certain perceptions/desires as rational or justified. When we deliberate and reflective, we try to determine the reasons we have for a kind of behavior. Whenever we act, insofar as we are deliberative and reflective, we act according to what we have judged ourselves to have reason to do. To the extent that we don’t act according to what we judge ourselves to have reason to do, we are acting irrationally. The deliberation involved with the connection between are given pre-reflective dispositions favoring a certain behavior (i.e. perceptions, desires, sensations, etc.) and are post-reflective conscious endorsements of a certain behavior (i.e. what we determined ourselves to have reason to do) is normative reasoning. The motivational system associated with normative reasoning is the normative motivational system. Supplement: Korsgaard’s contrast of animals and humans Supervenience Normative judgments supervene on non-normative beliefs. If one has a competent grasp of normative concepts, then if they judge two things to be different normatively then this must be due to a judged difference in non-normative properties. Equivalently, once one’s beliefs about the non-normative properties of a thing is fixed, so too are his normative judgments about the thing. Deliberative Argumentation/reasoning influences our normative judgments. Our judgments of normative reason are typically the upshots of deliberation, whereas our motivating reasons can be a given Supplement: Smith’s elaboration on the deliberative and the intentional. Koorsgard’s theory of normativity Motivational Normative judgments influence action. Judging that one has normative reason to do x is typically associated with a motivating reason to do x. But this is not perfect: there are cases where one judges that they have normative reason to do x without having a corresponding motivating reason to do x, and there are cases where one has a motivating reason to do x without a corresponding judgment that they have normative reason to do x. Think of cases of psychological compulsion, physical addiction or emotional disturbances. Such cases are usually not the norm; an explanation of some such sort must be invoked to explain not intending what one judges to have reason to do. Supplement: Supplement on Smith’s elaboration of the deliberative and the intentional Gibbard’s evolutionary arguments for the value of motivational content considerations about translations from other cultures sincere inferences of normative judgments of others Disagreement People have normative disagreements. People have epistemic disagreements. Two parties can have identical perceptions and evidence in front of them, and yet disagree about what they have most epistemic reason to believe given the evidence. They can disagree about what can be rationally inferred given the evidence. People have moral disagreements. Two parties can have identical beliefs with regard to the empirical world, and yet disagree about what we have moral reason to do. They can. People have prudential disagreements. Two parties can have identical beliefs about a hypothetical agent’s desires, interests, etc. and the empirical world, and yet have disagreements about what that agent has most reason to do. One parties might say he should satisfy his present desires, others say he should do what will in fact make him happiest, others that he should do what will result in the least regret, etc. People have aesthetic disagreements. While these disagreements sometimes stem from logical or semantic errors, they need not always. Rather, the disagreements are often the result of differing normative principles. We need a shared concept in order for disagreement to be possible. Supplement: Stevenson’s article on disagreement. Unification All normative judgments can be expressed in the form of a prescription that recommends a particular behavior X for an agent A in circumstances. There are often expressed in declarative form via some relation that involves entities A, X, C. The basic terms underlying this relation can be any term that supports this relation grammatically, i.e. “A ought to X in circumstances C”, “A has reason to X in circumstances C”, “A is justified in X-ing in circumstances C”, “It is fitting for A to X in circumstances C”, etc. They are also sometimes expressed without using strictly normative terms, e.g. “A must do X in C”, “A has to do X in C”, etc. Finally, they can also be expressed purely as imperatives, i.e. “A, do X in C”. All of these are ways of communicating a normative judgment to someone else. A normative system can be understood by the following components: T - The types of behavior regulated (actions, beliefs, driving, etc.) - this constraints genuine normative statements to be action guiding in some way. Normative propositions that cannot be expressed in this manner are not coherent normative propositions. R - The considerations that serve as reasons for the norm. Different normative realms have different relavent considerations. Then we can determine the content of the normative system: S - The actual norms of the normative system. These are entailed from whatever the relevant considerations are plus any observational content. Other considerations concerning the content of normative judgments Right/Wrong kinds of reason Ought implies can &amp;amp; cannot Is/Ought gap -&amp;gt; logical/analytic/synthetic There are a few different classes of normative judgments: Rational judgments - A has reason to do X Aesthetic judgments - A expresses attitude with regard to X Moral judgments - A encourages the attitudes of others Rational Psycholgoy Main Page Intentional and Deliberative Intentional action can be explained from two perspectives, the intentional and the deliberative. From the intentional perspective, intentional action can be explained by citing motivating reasons, i.e. by citing a belief-desire pair that fits into a pattern of teleological explanation. From the deliberative perspective, intentional action can be explained by citing normative reasons, i.e. by citing a pattern of rational deliberation that either did, or could have, produced it. This involves citing the considerations that one reflects over in deciding what to do. The deliberative perspective must be explanatory to satisfy the judgment internalism thesis about normativity, i.e. when we decide what to do after deliberation, that often makes a difference in what we do. This would be impossible if the deliberative perspective were not explanatory, since the connection between deliberation and our action would be purely causally contingent. Thus, our attitudes towards the propositions that figure in our deliberations must be capable of figuring an explanation of our action. However, there must also be some slack between desires and values. An agent may desire to X without valuing to X (e.g. kleptomaniac, addicts, etc.). Likewise, an agent may value X without desiring to X (e.g. the depressed, weakness of will). In general, due to psychological compulsions, physical addictions, emotional disturbances, etc. there is an imperfect connection between what an agent judges to be a normative reasons for action and the agent’s motivating reasons for action. To judge that one has normative reason to X is to endorse X under deliberation. Normative judgments then can be vaguely characterized as deliberative endorsement of some propositional content. Contrast this with undeliberative or unreflective endorsement, which are the sources of one’s motivating reasons, the explanation of their intentional behavior. Voluntary actions can be explained by a belief and desire; these actions are done on the basis of normative reasnoing insofar as deliberation and reflection play a role in how the belief and desire manifest into action, e.g. if deliberation influences what one desires, which desires are actualized, etc. The question is to determine what it is to form deliberative endorsement of an action. Is it a desire, belief of some sort, etc? World-to-mind The question is whether deliberative endorsement is a world-to-mind fit (dispositional) or mind-to-world fit (representational). Good candidates for a representational analysis are counterfactual beliefs about an agent’s hypothetical attitudes under certain circumstances. Nevertheless, it seems that normative judgments and deliberative endorsement are best explained by a world-to-mind, dispositional fit. This best explains why people who judge that they have normative reason to X are disposed to X. If it was a mere mind-to-world state of mind (even if a counterfactual belief about one’s attitudes), then there would have to be some additional world-to-mind state of mind that explained why one’s deliberation influences their motivation, and this state of mind would be the core feature of normative judgments. However, normative judgments are not best characterized as desires. It seems clear that normative judgments and desires can sometimes diverge. Goals and preferences seem to be a distinctive form of world-to-mind fit. And we can clearly understand how one might not have a desire to achieve one of their goals. It seems like the distinction between desires and goals are similar to the distinction between desires and values. It seems like we can distinguish different world-to-mind fits based on their relationship to consciousness (thoughts) and deliberation (thoughts about thoughts). Rational Correctness Main Page Existence Internalist R is a normative reason for A to X iff R would be a motivating reason for A to X insofar as A is rational and A was aware of R. Thus, R is a reason for agent A if and only if R is the upshot of sound rational deliberation. In other wrods, normative reasons are the rational extensions of one’s motivating reasons. A consideration C counts as a reason if and only if there is a sound deliberative route from an agent’s motivational reasons to C. The question is then how to account for what “rational extension” and “sound deliberative route” consists in. At the very least, this seems to require logical consistency. A constructivist account of normativity can explain what rational extension consists in generally. Constructivist Truth for rationality is not correspondence. That is, the standard of correctness for a normative proposition is not an mind-independent entity or set of entities which the proposition is purported to correspond to. Rather, the standard of correctness is rules and requirements constructed by and internal to the agents who hold the proposition. The fact that X is a reason to Y for agent A is constituted by the fact that the judgment that X is a reason to Y (for A) withstands scrutiny from the standpoint of A’s other judgments about reasons. Note that X is never a reason in favor of Y, absolutely. X can only be in favor of Y for some particular agent, as determined by the standards set by the normative judgments of A himself. A normative judgment withstands scrutiny for an agent only if the agent could mantain the judgment in full awareness, which is determined by the constituitive standards of the attitude in question. For example, someone who judges that X is a reason to Y cannot also simultaneously and in full awareness judge that X is not a reason to Y (consistency is constitutive of normative judgments). Also, one cannot take oneself to have conclusive reason to Y without taking oneself to have reason to take the means to Y (means-end reasoning is constituitive of normative judgments). The force of cannot is not rational, but what is constituitive of the concept of forming normative judgments. These standards of correctness are legislated by the very person making the normative judgments. This allows that one can be genuinely mistaken about their normative judgments only insofar as they are not in full awareness of certain relevant features of their judgments. Constituitive Features The central question is how to determine what requirements are constitutive of a type of behavior. One candidate is this: a requirement is constituitive of a behavior if no agent could consciously reject the requirement in full awareness. Logical Consistency. One basic constituitive feature of normative judgments (and thuoghts generally) is logical consistency. No person can consciously believe X and believe not-X in full awareness. Epistemic Perceptions/memories: the reason that a perception that p provides one with reason to believe that p is because part of what it is to perceive p is to acquire an unreflective belief that p. If perceptions didn’t provide one with an unreflective belief that p, then perceiving that p would be like imagining that p, and this would not provide one with a reason to believe p. Similar considerations apply to memories. Abduction: Induction: Causation: Prudential Desires: the reason that a desire to X tends to provide one with reason to X is (1) people tend to judge that they have reason to X if they desire to X, and (2) all intentional actions are done because of some desire; if they are not done because of a desire, then they would be involuntary actions. Instrumental Reasoning: one cannot take oneself to have conclusive reason to X without taking oneself to have reason to take the means to X. Part of what it is to judge one has a reason to X consists of judging one to have a reason to adopt the means. Pain/Suffering: the reason that pain/suffering provides one with reason to avoid it is precisely because people judge that they have reason to avoid it (or they have an unreflective aversion towards it). If a person had no aversion toward pain and didn’t judge that they had reason to avoid it, then there would be no actual reason to avoid it. It is not the pure sensation of pain that provides us with reason to avoid it. Competing reasons The most fundamental question is how to determine what one ought to do when there are some considerations that give one reason to X and some considerations that give one reason to not-X. This is especially important for moral considerations when weighing reasons from different agents. Moral Psychology Main Page Two puzzles that must be resolved by a moral psychology and ontology (or standard of correctness) Psychology Moral judgments are truth-apt. Truth-apt judgments must be beliefs (i.e. descriptive). Moral judgments are intrinsically motivating. Beliefs are not sufficient for intrinsic motivation. Truth Rational: Moral duties provide agents with reason for action. Categorical: Moral duties apply to all agents (some infer an independence of any agent’s desires). Internalism: Practical reasons are necessarily dependent on desires. Contingency: There are no necessary desires in all rational agents Success Theory: There are moral truths. Moral Reasons Main Page Aesthetic Constructivist Objectivity Game only exists in certain cultures This constructed morality “game” only exist in cultures where moral discussion involves providing reasons for all persons to follow. But this need not necessarily be the case in certain authoritarian/hierarchical societies where moral discussion is a vehicle for the powerful to issue non-negotiable and enforced commands rather than a cooperative, negotiative role. E.g. if there is a king commanding peasants to act in a certain way. There are no objective moral standards that the kind has to follow; the best one can hope for is to destroy their opponents and/or try to manipulate their emotions. Did we really lose anything by being unable to say that they are unreasonable? We can still say that they are immoral, bad, evil, etc. So what have we lost? The only thing we’ve realize now is that they cannot be rationally motivated to be moral. But this would be the case even if there was an independent ontology of moral facts. Do we really think that if such a realm existed, we could rationally motivate all undesirable villians to behave. We have lost nothing. Not motivationally necessary (constructivist) Contingent upon our interests (aesthetic) Not rationally necessary One could say morality is not rationally necessary in the sense that one has no reason to be moral if they didn’t already have an interest in being moral. But a similar truth is found in other domains: One has no reason to accept logic if they didn’t already accept it (this wouldn’t really be an agent to begin with). One has no reason to believe X if none of their perceptions indicated X. One has no reason to accept science if they had no interest in science. One has no reason to avoid pain if they had no interest in avoiding the sensation. Standards of moral correctness only matter for people who are interested in settling moral arguments for moral reasons. For people who are uninterested, no objective moral ontology would have mattered to them anyway. For those who are interested, a standard of correctness that’s internal to contingent moral desires is motivating enough. Objective methodology The importance of objectivity does not require an independent realm of moral facts, nor does it require rational reason for all agents. The importance of objectviity was: Normative thinking is a rational enterprise. Someone is incorrect in moral arguments. There is an independent standard to determine who is incorrect.</summary></entry><entry><title type="html">Affirmative Action</title><link href="/2019/06/19/Affirmative-Action.html" rel="alternate" type="text/html" title="Affirmative Action" /><published>2019-06-19T00:00:00-07:00</published><updated>2019-06-19T00:00:00-07:00</updated><id>/2019/06/19/Affirmative%20Action</id><content type="html" xml:base="/2019/06/19/Affirmative-Action.html">&lt;h2 id=&quot;justification-of-the-intentions&quot;&gt;Justification of the intentions&lt;/h2&gt;

&lt;p&gt;We don’t think discrimination should be illegal on an individual small scale level (i.e. individuals agreeing to make a transaction) but we do think it should be illegal for larger companies. What’s the difference?&lt;/p&gt;

&lt;h3 id=&quot;private-universities&quot;&gt;Private Universities&lt;/h3&gt;

&lt;p&gt;For simplicity, I’ll limit my post to affirmative action among private universities, since public institutions runs into many complications. I would agree that affirmative action is mistaken insofar as it results in underqualified students being admitted. Admitting students who don’t have the qualifications to succeed is setting them up for failure, and we should not be setting students up for failure. But I don’t see anything wrong with racial affirmative action among private universities where only qualified students are accepted, i.e. giving preference to a member of a certain race when choosing between two qualified applicants of different races. This is what I wish to defend.&lt;/p&gt;

&lt;p&gt;You are correct that race-based affirmative action is discriminatory. The question that remains, however, is whether it’s immoral. The fact that a policy is discriminatory, in itself, doesn’t imply that it’s immoral. If that were the case, then &lt;em&gt;all&lt;/em&gt; employers would be immoral, since all employers discriminate between applicants based on their skills, knowledge, traits, etc. or even appearance. So it can’t be discrimination alone that makes race-based affirmative action immoral.&lt;/p&gt;

&lt;h3 id=&quot;arbitrary&quot;&gt;Arbitrary&lt;/h3&gt;

&lt;p&gt;You might instead say it’s immoral because it’s specifically &lt;em&gt;racial discrimination&lt;/em&gt;. But that can’t be right either. There are also cases of morally permissible racial discrimination. For example, casting directors for movies and plays discriminate based on race all the time. Why is this morally permissible? It must have something to do with the fact that race might be a &lt;em&gt;relevant feature&lt;/em&gt; of the actors and actresses of the given movie, play, etc. In other words, racial discrimination by casting directors might not be &lt;em&gt;arbitrary discrimination&lt;/em&gt;, and this is why it’s not immoral. Race just so happens to be an essential component of the product that movie/play creators are trying to sell.&lt;/p&gt;

&lt;p&gt;This seems right to me. Discrimination by itself can’t wrong, even if it’s racial discrimination. What’s also necessary to be wrong is &lt;em&gt;arbitrary discrimination&lt;/em&gt;. This explains why racial discrimination seems almost always wrong. The reason is that racial discrimination is almost always arbitrary. Most jobs require you to apply manual labor or process information or something that has nothing to do with race. But if we imagine cases where race &lt;em&gt;is&lt;/em&gt; a relevant characteristic, we see that racial discrimination is actually morally permissible. This also can explain why discrimination seems morally wrong when it has nothing to do with race. For example, let’s say that an applicant is denied a job as a programmer because the employer didn’t like his/her eye color. This sort of discrimination seems wrong not because it’s racial discrimination, but because it’s arbitrary discrimination.&lt;/p&gt;

&lt;p&gt;So the arbitrariness of discrimination is what determines whether discrimination is morally wrong. Now, the question is whether affirmative action (of the kind I mentioned earlier) by private universities is arbitrary. In other words, is race a &lt;em&gt;relevant feature&lt;/em&gt; of the students of a university? It seems clear to me that it almost always is. Universities aren’t just selling library usage and lectures to students. They also purport to offer a college campus of a certain kind. That is, the makeup and “atmosphere” of the college campus is a part of the overall product that universities wish to sell. Therefore, students are not just &lt;em&gt;customers&lt;/em&gt; of a university; they are also a part of &lt;em&gt;the product&lt;/em&gt; (just like actors/actresses are a part of the product of movies/plays). Thus, race &lt;em&gt;is&lt;/em&gt; an essential component of the product/service of all universities that wish to advertise a college campus with a certain racial makeup (whether that be a racially diverse campus or a racially homogenous campus). Because of this, affirmative action among private universities is not an arbitrary form of racial discrimination, and is therefore not immoral.&lt;/p&gt;

&lt;p&gt;If this still seems unintuitive, consider the fact that many universities already practice a similar form of discrimination in the form of sex-based discrimination. The most extreme form of discrimination of this kind comes from women’s colleges and men’s colleges, universities that only allow students of a certain sex. Most do not intuit that sex-based discrimination from these colleges is immoral. The reason is that the sexual makeup of the student campus is clearly an essential part of the product that these colleges wish to sell; thus, sex-based discrimination would not be arbitrary. No doubt there are also colleges out there that perform sex-based discrimination for the opposite goal, to maintain a roughly even male:female on campus. People don’t intuit that sex-based discrimination from such universities is morally wrong (I would argue) because it’s not &lt;em&gt;arbitrary&lt;/em&gt; discrimination. I see no reason to treat race-based discrimination any differently.&lt;/p&gt;

&lt;h3 id=&quot;balancing-versus-exclusion&quot;&gt;Balancing versus Exclusion&lt;/h3&gt;

&lt;p&gt;It’s important to distinguish between two kinds of discrimination - racial balancing and racial exclusion. Racial balancing is what might be committed by universities with regard to affirmative action. Racial exclusion is the strict exclusion of people from certain racial groups from participating. Racial balancing is to include race in the application process as a way to shift the racial demographics towards that which is more representative of the general population. It seems to me that racial exclusion is what’s wrong here, not racial balancing.&lt;/p&gt;

&lt;p&gt;Consider a Night Club, for example. Many night clubs have their own quotas in place for the proportion of male/females at a given time. I think most people would agree that there’s nothing wrong with this. Now imagine that they also had quotas for racial demographics. They don’t want the club to be too far skewed towards one particular race, for whatever reason. I would also say that there really is nothing wrong with this. At the very least, it seems far less wrong than flat out exclusions. Racial balancing at universities could play a similar role.&lt;/p&gt;

&lt;p&gt;As another example, imagine if the NBA put in quotas for certain races to balance the demographics to be more representative of the country. You might think this is morally wrong in some way, but I don’t many would say it’s &lt;em&gt;racist&lt;/em&gt;.&lt;/p&gt;

&lt;h3 id=&quot;public-versus-private&quot;&gt;Public versus Private&lt;/h3&gt;

&lt;p&gt;Another reason we might be upset with discrimination is if it allows for public embarassment or humiliation.
E.g. imagine a restaurant refuses to serve Black people
This seems wrong because (1) a person who doesn’t know this might mistakenly enter the restauarant and be humiliated
and (2) we can see the establishment and people moving freely in and out, giving the impression of a public place.
This wrongness does not apply with “private” groups or organizations
Which are (1) hidden from public view,
and (2) require some sort of registration process for joining the club (e.g. you don’t just walk in be served)
E.g. consider sex-segregated gyms, night clubs, golf clubs, etc.
These don’t seem wrong at all&lt;/p&gt;

&lt;h3 id=&quot;subjugation&quot;&gt;Subjugation&lt;/h3&gt;

&lt;p&gt;Why are these properties important? Why are arbitrariness and balancing versus exclusion relevant considerations that determine whether discrimination is bad? Well, we have to discuss why discrimination is ever bad. We cannot just assume that discrimination is bad sometimes without understanding &lt;em&gt;why&lt;/em&gt;? In order for anything to be bad, it has to be considerably bad for someone somewhere. Now, note that there’s nothing inherent to discrimination that implies that it is considerably bad for someone somewhere, i.e. their life would have to be relevantly damanged (I don’t consider upset feelings as relevantly bad, because if that were the case then all discrimination would be bad). So what is it about discrimination that sometimes makes it significantly bad in the relevant manner? The answer has to be that discrimination has historically been used as a tool for racial oppression and subjugation, something that destroyed the lives of many minorities. Thus, we implicitly associate discrimination (which isn’t inherently bad) with oppression/subjugation (which is inherently bad, as people’s lives are destroyed). That is what makes arbitrariness and balancing versus exclusion relevant factors: in order for discrimination to actually ruin a group’s lives, it must be arbitrary and it must be exclusionary. Otherwise, there’s no way that it can be harmful.&lt;/p&gt;

&lt;p&gt;Now, racial discrimination would definitely be deemed immoral by most people. But I contend that the intuitions of most people are wrong here. Such a school would &lt;em&gt;not&lt;/em&gt; be immoral. The intuition that it is immoral can be explained by the deep connection we have between racial &lt;em&gt;discrimination&lt;/em&gt; and racial &lt;em&gt;oppression&lt;/em&gt;. We have an immediate disapproving reaction to racial discrimination in schools because this was used as a tool for racial oppression in the past. If we could magically disassociate racial discrimination from racial oppression, then I think our intuitions regarding race-based discrimination would be more in line with our intuitions regarding socially accepted forms of discrimination (e.g. sex-based discrimination at all-male/all-female schools, sexual/racial discrimination by casting directors, sexual balancing at night clubs).&lt;/p&gt;

&lt;p&gt;I think the laws enacted during the civil rights era chased morality in the sense that they corrected for the wrongs and damages resulting from governmental systematic racial oppression and they gave racial minorities a fair chance at integrating into society. Therefore, civil rights laws had a deeply moral motivation. However, it doesn’t follow from this that all policies prohibited by these laws were themselves immoral. The reason it doesn’t follow is that prohibiting some otherwise moral activities might be necessary to accomplish some broader moral goal. For example, I don’t think hard drug usage or prostitution is inherently immoral, but outlawing them might be necessary to accomplish a broader moral goal - i.e. to prevent violence and harms that would inevitably occur when these acts are legal. Likewise, I would say racial discrimination by private companies is not inherently immoral, but outlawing them might have been necessary to accomplish a broader moral goal - i.e. to correct for systematic racial injustice and integrate racial minorities into society.&lt;/p&gt;

&lt;h3 id=&quot;public-universities&quot;&gt;Public Universities&lt;/h3&gt;

&lt;p&gt;TBD&lt;/p&gt;

&lt;h2 id=&quot;consequences&quot;&gt;Consequences&lt;/h2&gt;

&lt;p&gt;The problem &lt;em&gt;with certain implementations of affirmative action&lt;/em&gt; (this qualifier is important) is that it leads to &lt;em&gt;under&lt;/em&gt;qualified students. This is a problem because admitting underqualified applicants actually hurts the students that it tries to help. Admitting students who don’t have the qualifications to succeed is setting them up for failure, and we should not be setting students up for failure. For example, &lt;a href=&quot;https://www.youtube.com/watch?v=VVvnTByzTmA&quot;&gt;here’s an interview&lt;/a&gt; where economist Thomas Sowell shares that the black students at MIT were in the top 10% of the country in terms of mathematics, but they were in the bottom 10% at MIT. The result was that many were on academic probation and one-fourth never graduated. That’s absurd. Students who would have otherwise excelled in their environment were struggling just to pass. This is not helping anyone.&lt;/p&gt;

&lt;p&gt;For a somewhat more modern example, look at &lt;a href=&quot;http://www.foxnews.com/us/2014/11/18/rejected-asian-students-sue-harvard-over-admissions-that-favor-other-minorities.html&quot;&gt;Harvard University&lt;/a&gt;. The 2009 study cited notes that “the average Asian American applicant needed a much higher 1460 SAT score to be admitted, a white student with similar GPA and other qualifications only needed a score of 1320, while blacks needed 1010 and Hispanics 1190.” Combining that with &lt;a href=&quot;http://www.collegeboard.com/prod_downloads/about/news_info/cbsenior/yr2005/02_v&amp;amp;m_composite_percentile_ranks_0506.pdf&quot;&gt;these percentile charts&lt;/a&gt;, Asians were in the 98th percentile, Whites were in the 92nd percentile, Hispanics were in the 77th percentile, and Blacks were in the 48th percentile. These are huge differences and it would be naive to assume that this was the best environment for the underrepresented students to thrive academically.&lt;/p&gt;

&lt;p&gt;If a kid from a disadvantaged background is in the 80th percentile of students, then the most &lt;em&gt;effective&lt;/em&gt; way for this kid to succeed is to attend an institution that teaches to kids roughly in the 80th percentile. Sending him to an institution that teaches to, say, the 99th percentile will increase the probability that he will switch to a “soft” major and/or drop out. That puts the kid in an even &lt;em&gt;more&lt;/em&gt; disadvantaged position, all in the ironic pursuit of equality. You might think that academics are not the only valuable attribute of college applicants, and you might be right. But it must be granted that there is a &lt;em&gt;base threshold&lt;/em&gt; of college readiness that all students should have to meet before being accepted (you seem to grant this in your first paragraph). No doubt this threshold varies from college to college depending on the abilities of each school’s student body. Accepting students who do not meet this threshold hurts them more than it helps them. My central claim is that affirmative action is wrong at least insofar as it allows for the acceptance of students that do not meet this threshold of college readiness.&lt;/p&gt;

&lt;p&gt;It is not sufficient that the &lt;em&gt;intentions&lt;/em&gt; of affirmative action are morally justifiable (that’s a different concern that I bypass here). It is also necessary to consider the practical &lt;em&gt;consequences&lt;/em&gt; of affirmative action. Often, discussions of affirmative action focus entirely on the former and none at all on the latter, but both concerns are necessary for good policy. We can’t evaluate policy purely from a philosophical normative position. Normative evaluation is only valuable insofar as it guides what our &lt;em&gt;goal&lt;/em&gt; should be. Once we agree on our &lt;em&gt;goal&lt;/em&gt;, we have to empirically investigate the consequences of various policies to determine effective methods of achieving that goal. I would like to believe that most agree that our &lt;em&gt;goal&lt;/em&gt; is to help underrepresented minorities thrive. However, affirmative action (of the kind mentioned here) is not the proper &lt;em&gt;policy&lt;/em&gt; to accomplish that goal precisely because the consequences are ineffective. College readiness &lt;em&gt;matters&lt;/em&gt;, and this fact cannot be ignored just because our intentions are good, because the consequences will come to hurt the students in the end.&lt;/p&gt;

&lt;p&gt;You might say that certain groups tend to experience pre-university disadvantages that unfairly reduce their performance on traditional measurements of scholarly assessment (e.g. grades, test scores, writing ability, etc.). Okay, I can grant all of that. However, insofar as these disadvantages exist, the fact is that these disadvantages also (albeit unfairly) reduce their college &lt;em&gt;readiness&lt;/em&gt;. The fact is, accepting unprepared students is not going to erase the lifetime of disadvantages that they have already endured. I grant the disadvantages, but the solution cannot be to add &lt;em&gt;more&lt;/em&gt; disadvantages by mismatching students to institutions that don’t cater to their abilities. The solution must be to remove disadvantages for the next generation and to help disadvantaged students by sending them to institutions that cater to their abilities (whether that be less prestigious universities, community colleges, trade schools, etc.).&lt;/p&gt;</content><author><name>JayMoss</name></author><summary type="html">Justification of the intentions We don’t think discrimination should be illegal on an individual small scale level (i.e. individuals agreeing to make a transaction) but we do think it should be illegal for larger companies. What’s the difference? Private Universities For simplicity, I’ll limit my post to affirmative action among private universities, since public institutions runs into many complications. I would agree that affirmative action is mistaken insofar as it results in underqualified students being admitted. Admitting students who don’t have the qualifications to succeed is setting them up for failure, and we should not be setting students up for failure. But I don’t see anything wrong with racial affirmative action among private universities where only qualified students are accepted, i.e. giving preference to a member of a certain race when choosing between two qualified applicants of different races. This is what I wish to defend. You are correct that race-based affirmative action is discriminatory. The question that remains, however, is whether it’s immoral. The fact that a policy is discriminatory, in itself, doesn’t imply that it’s immoral. If that were the case, then all employers would be immoral, since all employers discriminate between applicants based on their skills, knowledge, traits, etc. or even appearance. So it can’t be discrimination alone that makes race-based affirmative action immoral. Arbitrary You might instead say it’s immoral because it’s specifically racial discrimination. But that can’t be right either. There are also cases of morally permissible racial discrimination. For example, casting directors for movies and plays discriminate based on race all the time. Why is this morally permissible? It must have something to do with the fact that race might be a relevant feature of the actors and actresses of the given movie, play, etc. In other words, racial discrimination by casting directors might not be arbitrary discrimination, and this is why it’s not immoral. Race just so happens to be an essential component of the product that movie/play creators are trying to sell. This seems right to me. Discrimination by itself can’t wrong, even if it’s racial discrimination. What’s also necessary to be wrong is arbitrary discrimination. This explains why racial discrimination seems almost always wrong. The reason is that racial discrimination is almost always arbitrary. Most jobs require you to apply manual labor or process information or something that has nothing to do with race. But if we imagine cases where race is a relevant characteristic, we see that racial discrimination is actually morally permissible. This also can explain why discrimination seems morally wrong when it has nothing to do with race. For example, let’s say that an applicant is denied a job as a programmer because the employer didn’t like his/her eye color. This sort of discrimination seems wrong not because it’s racial discrimination, but because it’s arbitrary discrimination. So the arbitrariness of discrimination is what determines whether discrimination is morally wrong. Now, the question is whether affirmative action (of the kind I mentioned earlier) by private universities is arbitrary. In other words, is race a relevant feature of the students of a university? It seems clear to me that it almost always is. Universities aren’t just selling library usage and lectures to students. They also purport to offer a college campus of a certain kind. That is, the makeup and “atmosphere” of the college campus is a part of the overall product that universities wish to sell. Therefore, students are not just customers of a university; they are also a part of the product (just like actors/actresses are a part of the product of movies/plays). Thus, race is an essential component of the product/service of all universities that wish to advertise a college campus with a certain racial makeup (whether that be a racially diverse campus or a racially homogenous campus). Because of this, affirmative action among private universities is not an arbitrary form of racial discrimination, and is therefore not immoral. If this still seems unintuitive, consider the fact that many universities already practice a similar form of discrimination in the form of sex-based discrimination. The most extreme form of discrimination of this kind comes from women’s colleges and men’s colleges, universities that only allow students of a certain sex. Most do not intuit that sex-based discrimination from these colleges is immoral. The reason is that the sexual makeup of the student campus is clearly an essential part of the product that these colleges wish to sell; thus, sex-based discrimination would not be arbitrary. No doubt there are also colleges out there that perform sex-based discrimination for the opposite goal, to maintain a roughly even male:female on campus. People don’t intuit that sex-based discrimination from such universities is morally wrong (I would argue) because it’s not arbitrary discrimination. I see no reason to treat race-based discrimination any differently. Balancing versus Exclusion It’s important to distinguish between two kinds of discrimination - racial balancing and racial exclusion. Racial balancing is what might be committed by universities with regard to affirmative action. Racial exclusion is the strict exclusion of people from certain racial groups from participating. Racial balancing is to include race in the application process as a way to shift the racial demographics towards that which is more representative of the general population. It seems to me that racial exclusion is what’s wrong here, not racial balancing. Consider a Night Club, for example. Many night clubs have their own quotas in place for the proportion of male/females at a given time. I think most people would agree that there’s nothing wrong with this. Now imagine that they also had quotas for racial demographics. They don’t want the club to be too far skewed towards one particular race, for whatever reason. I would also say that there really is nothing wrong with this. At the very least, it seems far less wrong than flat out exclusions. Racial balancing at universities could play a similar role. As another example, imagine if the NBA put in quotas for certain races to balance the demographics to be more representative of the country. You might think this is morally wrong in some way, but I don’t many would say it’s racist. Public versus Private Another reason we might be upset with discrimination is if it allows for public embarassment or humiliation. E.g. imagine a restaurant refuses to serve Black people This seems wrong because (1) a person who doesn’t know this might mistakenly enter the restauarant and be humiliated and (2) we can see the establishment and people moving freely in and out, giving the impression of a public place. This wrongness does not apply with “private” groups or organizations Which are (1) hidden from public view, and (2) require some sort of registration process for joining the club (e.g. you don’t just walk in be served) E.g. consider sex-segregated gyms, night clubs, golf clubs, etc. These don’t seem wrong at all Subjugation Why are these properties important? Why are arbitrariness and balancing versus exclusion relevant considerations that determine whether discrimination is bad? Well, we have to discuss why discrimination is ever bad. We cannot just assume that discrimination is bad sometimes without understanding why? In order for anything to be bad, it has to be considerably bad for someone somewhere. Now, note that there’s nothing inherent to discrimination that implies that it is considerably bad for someone somewhere, i.e. their life would have to be relevantly damanged (I don’t consider upset feelings as relevantly bad, because if that were the case then all discrimination would be bad). So what is it about discrimination that sometimes makes it significantly bad in the relevant manner? The answer has to be that discrimination has historically been used as a tool for racial oppression and subjugation, something that destroyed the lives of many minorities. Thus, we implicitly associate discrimination (which isn’t inherently bad) with oppression/subjugation (which is inherently bad, as people’s lives are destroyed). That is what makes arbitrariness and balancing versus exclusion relevant factors: in order for discrimination to actually ruin a group’s lives, it must be arbitrary and it must be exclusionary. Otherwise, there’s no way that it can be harmful. Now, racial discrimination would definitely be deemed immoral by most people. But I contend that the intuitions of most people are wrong here. Such a school would not be immoral. The intuition that it is immoral can be explained by the deep connection we have between racial discrimination and racial oppression. We have an immediate disapproving reaction to racial discrimination in schools because this was used as a tool for racial oppression in the past. If we could magically disassociate racial discrimination from racial oppression, then I think our intuitions regarding race-based discrimination would be more in line with our intuitions regarding socially accepted forms of discrimination (e.g. sex-based discrimination at all-male/all-female schools, sexual/racial discrimination by casting directors, sexual balancing at night clubs). I think the laws enacted during the civil rights era chased morality in the sense that they corrected for the wrongs and damages resulting from governmental systematic racial oppression and they gave racial minorities a fair chance at integrating into society. Therefore, civil rights laws had a deeply moral motivation. However, it doesn’t follow from this that all policies prohibited by these laws were themselves immoral. The reason it doesn’t follow is that prohibiting some otherwise moral activities might be necessary to accomplish some broader moral goal. For example, I don’t think hard drug usage or prostitution is inherently immoral, but outlawing them might be necessary to accomplish a broader moral goal - i.e. to prevent violence and harms that would inevitably occur when these acts are legal. Likewise, I would say racial discrimination by private companies is not inherently immoral, but outlawing them might have been necessary to accomplish a broader moral goal - i.e. to correct for systematic racial injustice and integrate racial minorities into society. Public Universities TBD Consequences The problem with certain implementations of affirmative action (this qualifier is important) is that it leads to underqualified students. This is a problem because admitting underqualified applicants actually hurts the students that it tries to help. Admitting students who don’t have the qualifications to succeed is setting them up for failure, and we should not be setting students up for failure. For example, here’s an interview where economist Thomas Sowell shares that the black students at MIT were in the top 10% of the country in terms of mathematics, but they were in the bottom 10% at MIT. The result was that many were on academic probation and one-fourth never graduated. That’s absurd. Students who would have otherwise excelled in their environment were struggling just to pass. This is not helping anyone. For a somewhat more modern example, look at Harvard University. The 2009 study cited notes that “the average Asian American applicant needed a much higher 1460 SAT score to be admitted, a white student with similar GPA and other qualifications only needed a score of 1320, while blacks needed 1010 and Hispanics 1190.” Combining that with these percentile charts, Asians were in the 98th percentile, Whites were in the 92nd percentile, Hispanics were in the 77th percentile, and Blacks were in the 48th percentile. These are huge differences and it would be naive to assume that this was the best environment for the underrepresented students to thrive academically. If a kid from a disadvantaged background is in the 80th percentile of students, then the most effective way for this kid to succeed is to attend an institution that teaches to kids roughly in the 80th percentile. Sending him to an institution that teaches to, say, the 99th percentile will increase the probability that he will switch to a “soft” major and/or drop out. That puts the kid in an even more disadvantaged position, all in the ironic pursuit of equality. You might think that academics are not the only valuable attribute of college applicants, and you might be right. But it must be granted that there is a base threshold of college readiness that all students should have to meet before being accepted (you seem to grant this in your first paragraph). No doubt this threshold varies from college to college depending on the abilities of each school’s student body. Accepting students who do not meet this threshold hurts them more than it helps them. My central claim is that affirmative action is wrong at least insofar as it allows for the acceptance of students that do not meet this threshold of college readiness. It is not sufficient that the intentions of affirmative action are morally justifiable (that’s a different concern that I bypass here). It is also necessary to consider the practical consequences of affirmative action. Often, discussions of affirmative action focus entirely on the former and none at all on the latter, but both concerns are necessary for good policy. We can’t evaluate policy purely from a philosophical normative position. Normative evaluation is only valuable insofar as it guides what our goal should be. Once we agree on our goal, we have to empirically investigate the consequences of various policies to determine effective methods of achieving that goal. I would like to believe that most agree that our goal is to help underrepresented minorities thrive. However, affirmative action (of the kind mentioned here) is not the proper policy to accomplish that goal precisely because the consequences are ineffective. College readiness matters, and this fact cannot be ignored just because our intentions are good, because the consequences will come to hurt the students in the end. You might say that certain groups tend to experience pre-university disadvantages that unfairly reduce their performance on traditional measurements of scholarly assessment (e.g. grades, test scores, writing ability, etc.). Okay, I can grant all of that. However, insofar as these disadvantages exist, the fact is that these disadvantages also (albeit unfairly) reduce their college readiness. The fact is, accepting unprepared students is not going to erase the lifetime of disadvantages that they have already endured. I grant the disadvantages, but the solution cannot be to add more disadvantages by mismatching students to institutions that don’t cater to their abilities. The solution must be to remove disadvantages for the next generation and to help disadvantaged students by sending them to institutions that cater to their abilities (whether that be less prestigious universities, community colleges, trade schools, etc.).</summary></entry><entry><title type="html">Normative Truth</title><link href="/2019/06/19/Normative-Truth.html" rel="alternate" type="text/html" title="Normative Truth" /><published>2019-06-19T00:00:00-07:00</published><updated>2019-06-19T00:00:00-07:00</updated><id>/2019/06/19/Normative%20Truth</id><content type="html" xml:base="/2019/06/19/Normative-Truth.html">&lt;p&gt;Existence internalism characterizes rationality without explicitly requiring any particular motivations. Note that this does not reduce internalism to an Actual Motivational view whereby an agent needs to be actually motivated to perform the action. Usually, rationality is specified by some form of &lt;em&gt;ideal&lt;/em&gt; deliberation, i.e. R is a reason for agent A if and only if R is the upshot of &lt;em&gt;sound, valid, fully imaginative&lt;/em&gt; (from Williams) deliberation. Other forms of internalism might require being in a sound state of mind, having full experience, etc. In other words, normative reasons are the rational extension of one’s motivating reasons. A consideration C counts as a reason if and only if there is some rational procedure from an agent’s motivational reasons to C (without presupposing any new motivational states along the way).&lt;/p&gt;

&lt;p&gt;[x] Forms of internalism: state/motivational, actual/counterfactual, Humeanism
[x] Analogy with theoretical reasons
[ ] Construcivism as an improvement over broad internalism. Plus, Intuition check
[ ] Conceptual arguments for/against internalism. Theories of rationality
[ ] Conceptual arguments for/against constructivism.
[ ] Semantics&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Reconciling judgment internalism with existence internalism, or non-cognitivism with constructivism.&lt;/li&gt;
  &lt;li&gt;External Reasons judgments and Internal Reasons judgments are often used by competent English speakers. How to account for this?&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Readings:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Collections
    &lt;ul&gt;
      &lt;li&gt;Reasons, Motives, and the Demands of Morality: An Introduction&lt;/li&gt;
      &lt;li&gt;Essays: &lt;em&gt;The Oxford Handbook of Reasons and Normativity&lt;/em&gt; (OHRN)&lt;/li&gt;
      &lt;li&gt;Essays: &lt;em&gt;Internal Reasons: Contemporary Readings (MIT Readers in Contemporary Philosophy)&lt;/em&gt;&lt;/li&gt;
      &lt;li&gt;Essays: &lt;em&gt;Constructivism in Practical Philosophy&lt;/em&gt;&lt;/li&gt;
      &lt;li&gt;Essays: Bagnoli, &lt;em&gt;Constructivism in Ethics&lt;/em&gt;&lt;/li&gt;
      &lt;li&gt;Also see Philosophy of mind/action syllabus&lt;/li&gt;
      &lt;li&gt;&lt;em&gt;Routledge Handbook of Metaethics&lt;/em&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Books
    &lt;ul&gt;
      &lt;li&gt;R. Brandt, &lt;em&gt;A Theory of the Good and the Right&lt;/em&gt; (1979)&lt;/li&gt;
      &lt;li&gt;Bond &lt;em&gt;Reason and Value&lt;/em&gt; (1983)&lt;/li&gt;
      &lt;li&gt;Milgram &lt;em&gt;Practical Induction&lt;/em&gt; (1997)&lt;/li&gt;
      &lt;li&gt;S. Darwall, &lt;em&gt;Impartial Reason&lt;/em&gt; (1983)&lt;/li&gt;
      &lt;li&gt;J. Dancy, &lt;em&gt;Practical Reality&lt;/em&gt; (2000)&lt;/li&gt;
      &lt;li&gt;K. Setiya, &lt;em&gt;Reasons without Rationalism&lt;/em&gt; (2007),&lt;/li&gt;
      &lt;li&gt;Derek Parfit, &lt;em&gt;Reasons and Persons&lt;/em&gt;&lt;/li&gt;
      &lt;li&gt;Mark Schroeder, &lt;em&gt;Slaves of the Passions&lt;/em&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Conceptual
    &lt;ul&gt;
      &lt;li&gt;Ralph Wedgwood, “The Unity of Normativity”&lt;/li&gt;
      &lt;li&gt;Mark Schroeder,
        &lt;ul&gt;
          &lt;li&gt;“The Unity of Reasons”&lt;/li&gt;
          &lt;li&gt;“The Ubiquity of State-Given Reasons”&lt;/li&gt;
          &lt;li&gt;“Value and the right kind of reason”&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Shyam Nair and John Horty, “The Logic of Reasons”&lt;/li&gt;
      &lt;li&gt;Aaron Bronfman and J. L. Dowell, “The Language of Ought, and Reasons”&lt;/li&gt;
      &lt;li&gt;John Hawthorne and Ofra Magidor, “Reflections on the Ideology of Reasons”
  =&amp;gt; From section 1 of OHRN&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Substantive
    &lt;ul&gt;
      &lt;li&gt;Donald Davidson, “Actions, Reasons, and Causes” (1963)&lt;/li&gt;
      &lt;li&gt;Ulrike Heuer, “Reasons for actions and desires”&lt;/li&gt;
      &lt;li&gt;Peter Railton, “Toward a Unified Account of Rationality in Belief, Desire, and Action”&lt;/li&gt;
      &lt;li&gt;Stephen Darwall, “Making the ‘Hard’ Problem of Normativity Easier”&lt;/li&gt;
      &lt;li&gt;Stephen Finlay
        &lt;ul&gt;
          &lt;li&gt;“The Reasons that Matter” (2006)&lt;/li&gt;
          &lt;li&gt;“Responding to Normativity” (2007)&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;David Velleman,
        &lt;ul&gt;
          &lt;li&gt;“On the Aim of Belief” (2000)&lt;/li&gt;
          &lt;li&gt;“The Possibility of Practical Reason”&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Kelly, “Epistemic Rationality as Instrumental Rationality: A Critique” (2003)&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Desires
    &lt;ul&gt;
      &lt;li&gt;Thomas Nagel, “The Possibility of Altruism” (1970)&lt;/li&gt;
      &lt;li&gt;W. Quinn, “Putting Rationality in its Place” (1993)&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Deliberation
    &lt;ul&gt;
      &lt;li&gt;Antti Kauppinen, “Practical Reasoning”&lt;/li&gt;
      &lt;li&gt;Garrett Cullity, “Weighing Reasons”&lt;/li&gt;
      &lt;li&gt;Joshua Gert, “Underdetermination by Reasons”&lt;/li&gt;
      &lt;li&gt;Stephen Kearns, “Reasons, Choices, and Responsibility”
  =&amp;gt; From section 5 of OHRN&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Internalism/Externalism
    &lt;ul&gt;
      &lt;li&gt;Kieran Setiya, “Internal Reasons” (2012) (Introduction to &lt;em&gt;Internal Reasons: Contemporary Readings&lt;/em&gt; )&lt;/li&gt;
      &lt;li&gt;Bernard Williams
        &lt;ul&gt;
          &lt;li&gt;“Internal and External Reasons” from &lt;em&gt;Moral Luck&lt;/em&gt; (1979)&lt;/li&gt;
          &lt;li&gt;“Internal Reasons and the Obscurity of Blame” (1989)&lt;/li&gt;
          &lt;li&gt;“Replies” (1995)&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Stephen Finlay, “The Obscurity of Internal Reasons” (2009)&lt;/li&gt;
      &lt;li&gt;Christine Korsgard, “Skepticism About Practical Reasons” (1986)&lt;/li&gt;
      &lt;li&gt;John McDowell, “Might There Be External Reasons?” (1995)&lt;/li&gt;
      &lt;li&gt;Michael Smith, “Internal Reasons” (1995)
  =&amp;gt; Above are from &lt;em&gt;Internal Reasons: Contemporary Readings&lt;/em&gt;&lt;/li&gt;
      &lt;li&gt;T. M. Scanlon - “On Williams’ Internal and External Reasons” (from &lt;em&gt;What We Owe to Each Other&lt;/em&gt;)&lt;/li&gt;
      &lt;li&gt;Kieran Setiya, “Against Internalism” (2004)&lt;/li&gt;
      &lt;li&gt;Philip Pettit &amp;amp; Michael Smith “External Reasons” (2006)&lt;/li&gt;
      &lt;li&gt;Julia Markovits,
        &lt;ul&gt;
          &lt;li&gt;“Why Be an Internalist about Reasons?” (2011)&lt;/li&gt;
          &lt;li&gt;“Kantian Internalism” in &lt;em&gt;Moral Reason&lt;/em&gt; (2014)&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Elijah Millgram, “Williams’ Argument Against External Reasons” (1996)&lt;/li&gt;
      &lt;li&gt;Michael Smith
        &lt;ul&gt;
          &lt;li&gt;“The Humean Theory of Motivation” (1995)&lt;/li&gt;
          &lt;li&gt;“The Anti-Humean Theory of Normative Reasons” (1995)&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;“Reasons Internalism” in Routledge Handbook mentions many articles&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Constructivism
    &lt;ul&gt;
      &lt;li&gt;Christine Korsgard:
        &lt;ul&gt;
          &lt;li&gt;“The Sources of Normativity”&lt;/li&gt;
          &lt;li&gt;“Realism and Constructivism in Twentieth-Century Moral Philosophy”&lt;/li&gt;
          &lt;li&gt;&lt;em&gt;Self-Constitution. Agency, Identity and Integrity&lt;/em&gt;.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Essays: Sharon Street
        &lt;ul&gt;
          &lt;li&gt;“What is Constructivism in Ethics and Metaethics”&lt;/li&gt;
          &lt;li&gt;“Constructivism about Reasons”&lt;/li&gt;
          &lt;li&gt;“A Darwinian Dilemma for Realist Theories of Value”&lt;/li&gt;
          &lt;li&gt;“Evolution and the Normativity of Epistemic Reasons”&lt;/li&gt;
          &lt;li&gt;“Coming to Terms with Contingency : Humean Constructivism About Practical Reason”&lt;/li&gt;
          &lt;li&gt;“In Defense of Future Tuesday Indifference”&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Harry Frankfurt, “Freedom of the Will and the Concept of a Person”&lt;/li&gt;
      &lt;li&gt;Michael Smith, “A Constituvist theory of reasons”&lt;/li&gt;
      &lt;li&gt;Critics
        &lt;ul&gt;
          &lt;li&gt;“A Problem for Ambitious Metanormative Constructivism” by Nadeem J. Z. Hussain&lt;/li&gt;
          &lt;li&gt;“The Appeal and Limits of Constructivism” by T. M. Scanlon&lt;/li&gt;
          &lt;li&gt;David Enoch - “Can There Be a Global, Interesting, Coherent Constructivism About Practical Reason?”&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Constructivism and Expressivism:
    &lt;ul&gt;
      &lt;li&gt;Some say that constructivism is best understood as a form ‘expressivism,’ which holds that normative terms function to guide action rather than represent matters of fact and are used to express states of mind that differ from belief (Chrisman 2010; Lenman 2012; Lenman &amp;amp; Shemmer 2012b; Meyers 2012). Furthermore, Lenman argues that embracing expressivism would promise to solve a basic problem for constructivism, specifically, the problem of identifying the kinds of mental state that normative judgments are (Lenman 2012). This suggestion is not shared. Humean constructivist Street has forcefully argued that expressivism fails to fully explain the normative function of normative discourse, which cannot be reduced to expressing normative states (Korsgaard 2003, 2008: 312, 325 n. 49, 2009: 309; Bagnoli 2002: 130–132; Magri 2002; Street 2010: 239–242).&lt;/li&gt;
      &lt;li&gt;https://plato.stanford.edu/entries/constructivism-metaethics/#ConsRealAntiDeba&lt;/li&gt;
      &lt;li&gt;Lenman, James (2012): “Expressivism and Constructivism”&lt;/li&gt;
      &lt;li&gt;Chrisman, Matthew (2010): Constructivism, Expressivism and Ethical Knowledge&lt;/li&gt;
      &lt;li&gt;Meyers, Chris (2012): “Expressivism, Constructivism, and the Supervenience of Moral Properties”&lt;/li&gt;
      &lt;li&gt;Magri, Tito, 2002, “Frères Ennemis. The Common Root of Expressivism and Constructivism”&lt;/li&gt;
      &lt;li&gt;Bagnoli, Carla, 2002, “Moral Constructivism: A Phenomenological Argument”&lt;/li&gt;
      &lt;li&gt;Street, Sharon (2010): “What is Constructivism in Ethics and Metaethics?”&lt;/li&gt;
      &lt;li&gt;Korsgaard, Christine M., 2003, “Realism and Constructivism in Twentieth-Century Moral Philosophy”&lt;/li&gt;
      &lt;li&gt;Korsgaard, Christine M.,2008, The Constitution of Agency: Essays on Practical Reason and Moral Psychology,&lt;/li&gt;
      &lt;li&gt;Korsgaard, Christine M.,2009, Self-Constitution: Action, Identity, and Integrity,&lt;/li&gt;
      &lt;li&gt;Richardson, “Revising Moral Norms: Pragmatism and the Problem of Perspicuous Description” (2013) from Bagnli’s &lt;em&gt;Consructivism in Ethics&lt;/em&gt;&lt;/li&gt;
      &lt;li&gt;Richardson, “Truth and Ends in Dewey’s Pragmatism” (1998)&lt;/li&gt;
      &lt;li&gt;Richardson, “Beyond Good and Right: toward a Constructive Ethical Pragmatism” (1995)&lt;/li&gt;
      &lt;li&gt;Misak, &lt;em&gt;Truth, Politics, Morality: Pragmatism and Deliberation&lt;/em&gt;&lt;/li&gt;
      &lt;li&gt;See GIbbard&lt;/li&gt;
      &lt;li&gt;Dorsey, “A Puzzle for Constructivism and How to Solve It”&lt;/li&gt;
      &lt;li&gt;Schwartz, Velasco (2018), “Towards a semantics for metanormative constructivism”&lt;/li&gt;
      &lt;li&gt;Kirun Kumar Sankaran (2014), “Two Essays on Constructivism: Lessons from Semantic Theory”&lt;/li&gt;
      &lt;li&gt;van Roojen, Mark. 2015. Metaethics: A Contemporary Introduction -&amp;gt; contention between judgment internalism and existence internalism&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;??? question “Some questions left unanswered”
	- Conception of rationality that doesn’t beg the question against externalism.
	- How constructivism and expressivism can be reconciled. Two kinds of judgments. Constructivists claim that the truth of a normative claim is consituted by the normative judgments of the given agent. The normative judgments of the given agent are analyzed under expressivism. How are we to analyze the normative claim which constructivists state can be true? 
	- How to distinguish well-being (what makes a life go best) from reasons for action/desires? 
		- Some differences:
			1. X might provide high well-being without an agent having reason to X, e.g. experience machine, animals, etc.
			2. It is sensible to ask whether an agent has reason to do something that promotes their well-being due to some other end.
		- Reasons for action/desire = considerations in favor of an action, whether the agent knows it or not.
		- Well-being = how an agent assesses their own life to be going from their first-personal perspective, possibly under idealized conditions.
	- I understand the argument that there is no normative truth independent of normative judgments (i.e. the metaphysical/epistemological/motivational problems with realism).. But how do we establish that normative truth for a given agent’s depends on &lt;em&gt;that&lt;/em&gt; agent’s normative judgments? E.g. why not the normative judgments of the agent’s community? Or the normative judgments of the speaker? Why not understood “reasons” broadly as a standard by which to criticize someone, e.g. because people are subject to criticism for being cruel, and because reasons are standards of criticism, why not say cruel people are unreasonable? There are infinitely many possible theories of normative truth that don’t reduce normative truth for A to A’s normative judgments, without also having the metaphysical/epistemological problems of realism. 
		- We can understand “should” claims as general standards to ground criticism, e.g. people “should” not act immorally, even though they may have no reason not to do so.
		- “Reasons” may be sometimes used in this broad sense, but for clarity this concept will be identified with the narrow sense (connected with an agent’s normative judgments) leaving “should” the job of handling general grounds for criticism. 
		- A motivational argument can be given perhaps. 
		- Kosgaard’s states that such an account is the only thing that can explain the normative authority of deliberation for agents. What does this mean?
		- Why focus on reasons in the internal sense? Similar considerations can be used to explain why reasons for belief are internal rather than external (i.e. rather than simply beliefs that are true).
		- The internal sense is what we use not just for charges of criticism but for charges of irrationality.
		- The internal sense is the kind of reason we acknowledge when we judge that something is a reason from a first-person perspective rather thana third-person perspective.
	- What is the general strategy for determining what is constitutive of a given activity?&lt;/p&gt;

&lt;p&gt;Conceptual constraints on reasons agreed to by internalists and externalists:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Everyone agrees: A’s judgment that he has reason to X will motivate A to X insofar as he is rational&lt;/li&gt;
  &lt;li&gt;Controverial: if proposition C is a reason for A to X, then A’s awareness of C will motivate A to X insofar as he is rational and fully informed.
    &lt;ul&gt;
      &lt;li&gt;This is true only if the fact that (1) C is a reason for A to X, (2) A’s full rationality and full descriptive information, and (3) A’s awareness of C entails that he will judge that C is a reason to X. Is this true? If this is true, then it will entail motivation to C.&lt;/li&gt;
      &lt;li&gt;This seems true only if a fully rational/informed awareness of C (assuming C is a reason to X) will necessarily entail a judgment that C is a reason to X. This judgment is required for the above because the judgment is sufficient to produce motivation, and there doesn’t seem to be any other connection between something being a reason and it motivating an agent (otherwise, why would a consdieration motivate an agent if the agent did not recognize the consideration AS a reason).&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Externalists account for this:
    &lt;ul&gt;
      &lt;li&gt;Externalists have to posit that rationality has substantive requirements, i.e. a desire to do what is kind, generous, etc. or whatever they posit people have reason to do.&lt;/li&gt;
      &lt;li&gt;Or externalists have to posit that rational agents have an &lt;em&gt;additional desire&lt;/em&gt; to do what they judge themselves to do.&lt;/li&gt;
      &lt;li&gt;The question is still what is the &lt;em&gt;content&lt;/em&gt; of the judgment that something is a reason, and how can this motivate anyone to do anything?&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Some thoughts:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;But the question isn’t even about the &lt;em&gt;content&lt;/em&gt; of reasons judgments. For a non-cognitivist, there is no content. For constructivists, truth is not based on the contents (i.e. one has reason to X only if they judge that they have reason to X, but clearly the judgment that one has reason to X cannot just reduce to this). But if the &lt;em&gt;content&lt;/em&gt; of reasons judgment does not determine what counts as a reason, then what does? What is the job description of a theory of reasons. When one says A has reason to X iff p (e.g. p = internalism, some form of externalism, etc.), what are the requirements on p?&lt;/li&gt;
  &lt;li&gt;Perhaps, the requirement is this: if it is true that A has reason to X iff P, then A’s recognition of P must entail a judgment that they have reason to P. This will satisfy constructivism and internalism. The only way that recognition of P could entail a judgment that A has reason to X (which is itself a motivation; normative judgments are motivating) is if P was intimately tied to A’s motiation to begin with (the internalism thesis). Likewise, under constructivism, P just is the fact that A judges that they have reason to X (or that it follows from their normative judgments that they have reason to X). Anyone who recognizes this must neessarily recognize that they have reason to X.&lt;/li&gt;
  &lt;li&gt;But why accept this job description? This job description may be true for conceptual analysis where you say reasons judgments MEAN a certain thing (even then, such a job description would be controversial), but asserting necessary/sufficient conditions is not conceptual analysis. So why accept this? E.g. X is yellow iff X reflects light of a certain wavelength, but this does not imply anyone who judges X has a certain wavelength has to judge that it has a certain color (or vice-versa). There are a few responses
    &lt;ul&gt;
      &lt;li&gt;Perhaps reasons are different because there are no actual reasons properties or relations, unlike color&lt;/li&gt;
      &lt;li&gt;Perhaps we are actually doing conceptual analysis by positing this job description. But I thought non-cognitivism was the conceptual analysis and there is no content of reasons judgments.
        &lt;ul&gt;
          &lt;li&gt;Perhaps the analysis of normative claims can be different than base normative judgments. Of course normative claims often express our normative judgments, but perhaps they also do something else sometimes, i.e. express what we think follows from someone’s evaluative standpoint.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Perhaps when positing this job description, we are just expressing attitudes as predicted by non-cognitivism&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;What ARE we doing when we say that a certain job description is true? There seems to be a disinction between (1) ordinary judgments that one has reason to do something and (2) reasons judgments involved in asserting internalism, constructivism, job descriptions for a theory of truth, etc.? Are these the same kind of judgments? Are they both just expressions of a non-cognitive sentiment?&lt;/li&gt;
  &lt;li&gt;Assuming non-cognitivism is true, why assume there is a theory of truth? Why assume there &lt;em&gt;are&lt;/em&gt; reasons instead of just &lt;em&gt;judgments&lt;/em&gt; about reasons? E.g. we agree that people judge things to be scary/funny. But that doesn’t imply that some things actually ARE scary/funny in a sense above/beyond judging them to be scary/funny. Perhaps constructivism does not claim that the existence of &lt;em&gt;reasons&lt;/em&gt; are anything above/beyond &lt;em&gt;judgments&lt;/em&gt; about reasons. Perhaps, when one a constructivist says “you have reason to X” this is just a convenient way of saying “your normative judgments commit you to X, whether you know it or not”. Perhaps the job description for a theory of truth is to satisfy certain grammatical/linguistic requirements along with the following minimum requirements:
    &lt;ul&gt;
      &lt;li&gt;People can be wrong about what they have reason to do.&lt;/li&gt;
      &lt;li&gt;We can improve toward “truth” when our judgments change&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;A seperate theory of truth is needed&lt;/li&gt;
  &lt;li&gt;What status are we giving to a consideration when we say “I might have a reason to do X, but I don’t believe I do”. What are we doing during deliberation, as we seemingly “figure out” what to do?&lt;/li&gt;
  &lt;li&gt;The answer is to look at the standards that we are committed to in our normative judgments: consistency, coherence, reflection, etc. Insofar as we deliberate, we are committed to the upshots of these standards. But we can be mistaken about the upshot of these standards. Thus, the truth of normative judgments is whatever the upshot of these standards are because we are aiming at these standards. Thus, normative truth is related to normative judgments not in an attributional sense (i.e. in the sense of looking at the properties that we ascribe to things when we make normative judgments) but in a regulative sense (i.e. by looking at the standards that are implicitly guiding our judgments). It is by looking at rules that are implicit in our deliberations. Thus, this is truth not in a correspondence sense. Deliberation is an activity the standards of which we construct and impose on ourselves.&lt;/li&gt;
  &lt;li&gt;We might not even be aware of what the standards are. But they regulate our judgments nevertheless (i.e. those who are unaware of the rules of consistency).&lt;/li&gt;
  &lt;li&gt;Why are these the standards?
    &lt;ul&gt;
      &lt;li&gt;They guide our thinking whether we know it or not.&lt;/li&gt;
      &lt;li&gt;They cannot in full awareness be rejected. CANNOT here means conceptually not rationally. E.g. if someone in full awareness endorsed inconsistent judgments, then they wouldn’t legitimately count as making a judgment in the first place. They’re not irrational, but they are not even an agent, so terms like rationality/irrationality do not apply. They would be irrational if they accepted an inconsitency but was NOT aware of the inconsistency.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Note that this DOES not imply that deliberation is an activity that attempts to figure out the upshots of deliberation while adhering to the implicit standards (which would be a kind of naturalism). We are not trying to answer theoretical questions to represent reality or counterfactuals. We are trying to answer practical questions, determining what to do. Rather, the implicit standards are regulating our deliberation (and thus determine success for the activity) independently of whether we are aware.&lt;/li&gt;
  &lt;li&gt;Why this constructivism is compatible with non-cognitivism
    &lt;ul&gt;
      &lt;li&gt;Deliberation does not aim to answer theoretical questions. It does not aim to represent the way the world is. Against cognitivism&lt;/li&gt;
      &lt;li&gt;The upshots of deliberation are inherently motivating insofar as one is rational. Note, however, that they differ from ordinary motivating states such as desires because of the standards that are constituitive of normative judgments - e.g. instrumental reasoning CANNOT in full awareness be denied if one is to count as a deliberating agent. CANNOT here means conceptually not rationally. I.e. it is not that one is being irrational by failing to follow instrumental rationality in full awareness; rather, they aren’t attempting to deliberate rationally. Someone IS being irrational when they fail to follow instrumental rationality NOT in full awareness.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Normative Truth consists in what follows from an agent’s evaluative standpoint.
    &lt;ul&gt;
      &lt;li&gt;This is not what we &lt;em&gt;mean&lt;/em&gt; when we form a normative judgment. When we’re form a normative judgment, we are just settling the practical question of what to do, rather than the theoretical question of what the upshots of our commitments are. Abandon a semantic theory of truth (whereby the truth of a proposition occurs when the state of affairs &lt;em&gt;meant&lt;/em&gt; by the proposition are obtained)&lt;/li&gt;
      &lt;li&gt;Rather, this is a question that we are aimed to answer (whether we know it or not), when in the process of settling practical questions.&lt;/li&gt;
      &lt;li&gt;Final question: why should normative truth be construed as relative to the evaluative standpoint of the agent in question rather than the speaker? The reasoning here has all taken a person characterization; i.e. we are considering the standpoint and perspective of the agent. But why not instead focus on the judge? This analysis might capture what agents are attempting to do when answering normative questions, but it need not be what judges are doing when they are answering normative questions for others. Two possibilities:
        &lt;ol&gt;
          &lt;li&gt;Posit that there is some special semantic/psychological difference between speakers endorsing actions for others, and endorsing actions for themselves. In the former case, truth is not relative to their (the speaker’s) motivations; it is somehow relative to the subject’s motivations. I.e. the speaker commits themselves to judging what follows from the agent’s evaluative standpoint whether they know it or not. In the latter case, the judge is only committed to judging what follows from their own evaluative standpoint. The former seems difficult to explain if the function of the judgments is merely to express plans/sentiments.
            &lt;ul&gt;
              &lt;li&gt;Perhaps it has to do with the fact that we expect that if the agent accepts our claim that they have reason to X, this will instill in them a motivation to X insofar as they are rational. But this only makes sense if X is connected to their evaluative standpoint.
  -&amp;gt; But this doesn’t necessarily work to show that truth is relative to the agent. Because if “accept our claim that they have reason to X” just means “agree that they have reason to X” which just means adopting a motivation to X, then the speaker cannot expect that without believing that X is connected to their evaluattive standpoint. It would be equivalent to a speaker believing: if the agent becomes motivated to X, then they will be motivated to X insofar as they are rational. But clearly this doesn’t require X be connected to their present evaluative standpoint.
  -&amp;gt; Perhaps instead it should be: when we judge that Y (a proposition) &lt;em&gt;is&lt;/em&gt; a reason to X (a behavior), then we expect that agents aware of Y will become motivated to X (because of their awareness of Y) insofar as they are rational [or perhaps, that agents aware of Y will judge that they have reason to X insofar as they are rational; or that a rational agent’s awareness of Y could &lt;em&gt;explain&lt;/em&gt; why they judge themselves to have reason to X]. So the constructivist/internalist conceptual component is only about judgments about what &lt;em&gt;constitute&lt;/em&gt; reasons rather than all reasons judgments. Now we need an analysis of what fully rational means without begging the question. 
  -&amp;gt; So we need to explain the conceptual connection between explanation/motivation and third-personal normative judgments, and how this can be reconciled with non-cognitivism which denies that there is any essential content to normative judgments.&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
          &lt;li&gt;Don’t divorse semantics/psychology of third-person and first-person normative judgments. Rather, adopt a theory of truth that is not tied to the judgments themselves. It’s not clear how this can secure speaker’s being committed to an agent’s evaluative perspective.&lt;/li&gt;
        &lt;/ol&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Constructivist theories of the meaning of truth, semantics, compatibility with expressivism:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Street, “What is Constructivism in Ethics and Metaethics”, See section on Expressivism. She outlines three strategies for explaining semantics of moral terms (1) state that its impossible because normative attitudes cannot be reduced, (2) argue for an inferentialist semantics, whereby the truth of claim consists in what inferences one needs to make to be competent with the concept, (3) argue for a reforming definition, or (4) adopt the expressivist theory.&lt;/li&gt;
  &lt;li&gt;Street, “Constructivism about Reasons”, 237-241. Here, Street argues for (1) from above.&lt;/li&gt;
  &lt;li&gt;See above section under “Expressivism and Constructivism” for more
Strategies:&lt;/li&gt;
  &lt;li&gt;Normative judgments can be explained by an expressivist theory, possibly the judgments cannot be reduced to non-normative judgments.&lt;/li&gt;
  &lt;li&gt;Normative assertions and normative truth can be explained by either (1) an inferentialist theory as described above or (2) a pragmatic theory. (1) may be acceptable but (a) it needs to be fleshed out more and (b) why is it concerned with the agent rather than the speaker. (2) requires more investigation.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;existence-internalism&quot;&gt;Existence Internalism&lt;/h2&gt;

&lt;p&gt;Some twists&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;Externalism too broad, move to internalism.&lt;/li&gt;
  &lt;li&gt;Actual motivations too narrow, require idealized conditions.&lt;/li&gt;
  &lt;li&gt;Not all actual states provide reasons, move to constructivism.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Consider analogy with theoretical reasons along the way.&lt;/p&gt;

&lt;p&gt;Varieties of internalism:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Actual Motivation: A has reason to X only if A is motivated to X.&lt;/li&gt;
  &lt;li&gt;Actual State: A has reason to X only if A has some motivational attitude that supports doing X.&lt;/li&gt;
  &lt;li&gt;Counterfactual Motivation: A has reason to X only if A would be motivated to X under circumstances C.&lt;/li&gt;
  &lt;li&gt;Counterfactual State: A has reason to X only if A would have some motivational attitude that supports doing X under circumstances C.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;For Motivation views, “is motivated” and “can be motivated” don’t just mean some motivation that may be overridden by other motivations. It means the source of an agent’s volition that drives them to act intentionally. For State views, a Motivational attitude is a certain kind of psychological state which plays a role in motivation. These states are often taken to be desires, but can include other attitudes such as emotions, intentions, and aversions. Motivation views do not, by themselves, require the presence of any particular kind of psychological state which does the motivating, and State views do not, by themselves, require that the motivating state which is present actually does any motivating.&lt;/p&gt;

&lt;p&gt;It is a platitude about reasons and rationality that: R is a normative reason for A to X iff R would be a motivating reason for A to X if A were rational and A was aware of R. In other words, reasons are the upshot of full rationality and full information. The question is how to characterize rationality. Internalism gives a &lt;em&gt;procedural&lt;/em&gt; characterization of rationality. It usually specifies a form of ideal &lt;em&gt;deliberation&lt;/em&gt;, i.e. of moving from certain motivations to action and other motivations. Externalism specifies an &lt;em&gt;substantive&lt;/em&gt; characterization of rationality that specifies certain substantive elements like “a motivation to help others”. i.e. being rational might require being converted rather than sound reasoning.&lt;/p&gt;

&lt;p&gt;The above is a true platitude only if we use a fairly broad definition of rationality. But Scanlon narrows rationality to just doing that which you judge yourself to have reason to do. Which means to be irrational is to fail to adopt the attitudes that one judges themselves to have reason to adopt. This makes sense to me. I wouldn’t call someone irrational if they failed to do what they would do if they reflected more or were more experienced. “Rationality” as used above seems to simply mean “idealized person”.&lt;/p&gt;

&lt;p&gt;Existence internalism characterizes rationality without explicitly requiring any particular motivations. Note that this does not reduce internalism to an Actual Motivational view whereby an agent needs to be actually motivated to perform the action. Usually, rationality is specified by some form of &lt;em&gt;ideal&lt;/em&gt; deliberation, i.e. R is a reason for agent A if and only if R is the upshot of &lt;em&gt;sound, valid, fully imaginative&lt;/em&gt; (from Williams) deliberation. Other forms of internalism might require being in a sound state of mind, having full experience, etc. In other words, normative reasons are the rational extension of one’s motivating reasons. A consideration C counts as a reason if and only if there is some rational procedure from an agent’s motivational reasons to C (without presupposing any new motivational states along the way).&lt;/p&gt;

&lt;p&gt;??? warning “Todo”
	Include the categories mentioned in the sep article. I.e.
		- state versus motivational forms of internalism
		- actual versus counterfactual forms
		- different ways to characterize the counterfactual conditions&lt;/p&gt;

&lt;h3 id=&quot;motivational-argument-1&quot;&gt;Motivational Argument 1&lt;/h3&gt;

&lt;p&gt;One argument for internal reasons states that reasons must be capable of motivating action.&lt;/p&gt;

&lt;p&gt;The argument:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;R is a reason for A to X only if A would be motivated to X by believing R insofar as A were fully rational.&lt;/li&gt;
  &lt;li&gt;A, if fully rational, would be motivated to X by believing R only if A is disposed to X by believing R.&lt;/li&gt;
  &lt;li&gt;If R is an external reason for A to X, then A is not disposed to X by believing R.&lt;/li&gt;
  &lt;li&gt;Therefore there are no external reasons.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;The central question here is (2). (1) and (3) are both a priori, conceptual truths. (2) depends on whether we take rationality to have substantive or procedural requirements, so may seem to be question-begging. We need to give an independent argument for (2), in a way that explains how to pick out which dispositions provide reasons.&lt;/p&gt;

&lt;p&gt;Modifications:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;“Fully Rational” may need to be explicitly characterized in terms of “ideal sound deliberation” or something more specific, so that (2) is not seen as question-begging against the (rare) externalist who says that full rationality might endorse behaviors for A that A has no dispositions to do.&lt;/li&gt;
  &lt;li&gt;From Scanlon: One option is to characterize “rationality” just in terms of consistency. So that one is irrational only if they fail to adopt an attitude that they do not judge themselves to have reason to have.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Procedural rationality&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;This is to support (2) of the explanatory argument: A, if fully rational, would be motivated to X by believing R only if A is disposed to X by believing R. (2) depends on whether we take rationality to have substantive or procedural requirements. We need an independent argument for procedural rationality to support (2). And we also need to explain why it’s not just any ol’ dispositions that are needed to supply an agent with reasons for action, i.e. an agent might have a disposition to overvalue short-term gains at the expense of long-term losses, but this &lt;em&gt;mere&lt;/em&gt; disposition is not what grounds any reasons to value short-term gains as one might think from (2). Instead, what matters is what dispositions that agent actually endorses under deliberation. But now we seem to be making the deliberative argument below:&lt;/p&gt;

&lt;h3 id=&quot;motivational-argument-2&quot;&gt;Motivational Argument 2&lt;/h3&gt;

&lt;ol&gt;
  &lt;li&gt;R is a reason for A to X only if A would be motivated to X by believing R insofar as A deliberated soundly.&lt;/li&gt;
  &lt;li&gt;A would be motivated to X by believing R under sound deliberation only if A is disposed to X by believing R.&lt;/li&gt;
  &lt;li&gt;If R is an external reason for A to X, then A is not disposed to X by believing R.&lt;/li&gt;
  &lt;li&gt;Therefore there are no external reasons.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Now, (1) needs to be argued for, as it is no longer merely a plattitude. It almost may seem to be question-begging against the externalist. We might be able to accept (1) if we accepted constructivism. Normative truth derives from the normative judgments an agent makes, and it is constituitive of agency to value one’s motivations under deliberation. So we just need to argue for constructivism.&lt;/p&gt;

&lt;h3 id=&quot;rational-argument&quot;&gt;Rational Argument&lt;/h3&gt;

&lt;p&gt;Motivation is too strong. Recognition of p (where p is a reason to X) need not create motivation to X. This happens when only two things happen (1) A recognizes p as a reason and (2) A is motivated to act on his reasons. (2) is a seperate claim that makes the first premise unnecessarily strong, so lets remove it and focus on (1).&lt;/p&gt;

&lt;p&gt;This also implies two forms of rational defect: (1) failure to recognize one’s reasons as reasons, and (2) failure to be motivated by what one recognizes to be a reason.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;R is a reason for A to X only if A could recognize R as a reason to X upon believing R.&lt;/li&gt;
  &lt;li&gt;A could recognize R as a reason to X upon believing R only if R follows from A’s current normative judgments&lt;/li&gt;
  &lt;li&gt;R is a reason for A to X only if R follows from A’s current normative judgments&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Defend (2): Beliefs have a mind-to-world fit. Normative judgments have a world-to-mind fit. Mind-to-world fits cannot influence world-to-mind fits. Thus, a belief alone cannot cause a normative judgment. But this doesn’t show (2) is true. Perhaps R must follow from A’s current normative judgments + his other desires?&lt;/p&gt;

&lt;h3 id=&quot;explanatory-argument&quot;&gt;Explanatory Argument&lt;/h3&gt;

&lt;p&gt;Normative reasons are counterfactual explanatory reasons (Michael Smith w/out ideal observer).&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;R is a reason for A to X only if R could explain why A would X under sound, ideal deliberation.&lt;/li&gt;
  &lt;li&gt;That A is motivated to X by believing R can be explained only by something in A’s desires, goals, etc. favoring doing X by believing R.&lt;/li&gt;
  &lt;li&gt;If R is an external reason for A to X, then there is nothing in A’s desires, goals, etc. that motivate a sound, deliberative A to X by believing R.&lt;/li&gt;
  &lt;li&gt;Therefore there are no external reasons.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Note we have (1) which is not a plattitude which one might object to. However an argument for (1) might be: (1) should be accepted by considering the cases where we perform actions because of normative reasons. The times where there is a disconnect between our motivating and normative reasons, we can point to some sort of problem, either we aren’t aware of the reasons, we have false information, we suffer from addiction, etc.&lt;/p&gt;

&lt;p&gt;Note that (1) is a weaker claim than in earlier arguments. To say that R could explain why A X-ed is weaker than saying R could motivate A to X. The former says that, if A were motivated to X (which might not be possible), this could be explained by R. The latter says that it is possible for A to be motivated to X (because of R).&lt;/p&gt;

&lt;p&gt;The reason that reasons statements are not based on the hypothetical motivational sets of e.g. a fully moral A, i.e. A+, is because it is important that reasons statements apply directly to A. Note, however, that we can still focus on the somewhat idealized A who has deliberated, because we can infer that A already values the motivations of himself after he has deliberated. We can infer this from the fact that he is in fact deliberating. So he already values his deliberation.&lt;/p&gt;

&lt;p&gt;But why should reasons statements for A be based on what he actually values in any present moment? This seems question-begging against the externalist. Two reasons (1) We make claims about reasons for the purpose of influencing, motivating, or guiding agents. But the only thing that can guide agents (assuming they don’t suffer from addictions, false beliefs, etc.) are elements from their motivational set. And (2) this is a basic premise of constructivism (see below).&lt;/p&gt;

&lt;h3 id=&quot;focus-on-theoretical-reasons&quot;&gt;Focus on Theoretical Reasons&lt;/h3&gt;

&lt;p&gt;(not a different argument from above; perhaps an elaboration of the explanatory argument).&lt;/p&gt;

&lt;p&gt;Points to be learned:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Existence internalism may seem to be disproven by theoretical reasons because beliefs are justified by features other than one’s motivational set (i.e. one’s desires).&lt;/li&gt;
  &lt;li&gt;However, the motivational set for beliefs wouldn’t just be desires; it would be other beliefs, perceptions, judgments, intuitions, etc. And these DO justify beliefs.&lt;/li&gt;
  &lt;li&gt;Not all elements from one’s motivational set are relevant. E.g. desires don’t justify beliefs.&lt;/li&gt;
  &lt;li&gt;Which elements are relevant?&lt;/li&gt;
  &lt;li&gt;Why are those elements relevant?&lt;/li&gt;
  &lt;li&gt;The relevant elements are the agent’s normative judgments.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;As mentioned before, there is a narrow and broad sense of normative judgments. The broad sense refers to general “should” statements that could simply serve as standards by which we can criticize and evaluate the behavior of others - this includes internal and external reasons. There is also a narrow sense that refers to internal “reasons” statements. The question is why this distinction is important and what is special/important about internal reasons statements.&lt;/p&gt;

&lt;p&gt;Consider reasons for belief. One could say that one has reason to believe just whatever is true. In a sense, this could be true. But it seems that there is another, independent role played by reasons statements about belief. Reasons in this more narrow sense are conferred to considerations that guide our deliberation as we decide what to believe. The fact that something is an external reason for belief - the fact that it’s true, for example - cannot be a consideration that one takes to be reason to decide their belief. I.e. if you asked someone why they believed X and they responded with “because X is true”, this would do nothing to explain their belief. We expect them to respond with an accessible feature of their motivational set - e.g. their other beliefs, their intuitions, their normative judgments, etc. Likewise, external reasons for action cannot be a consideration that someone takes to be a reason for action, unless we assume it’s already connected with their motivational set. E.g. if you asked someone why they did X, and they responded with “because X is kind” (yet they had no care for kindness), this wouldn’t really explain why they did X.&lt;/p&gt;

&lt;h3 id=&quot;procedural-rationality&quot;&gt;Procedural Rationality&lt;/h3&gt;

&lt;p&gt;There are two types of reasons:&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;Internal: What could be entailed from the appropriate elements of an agent’s motivational set via some idealized procedure or set of conditions. The rational extension of one’s motivational set.&lt;/li&gt;
  &lt;li&gt;External: general grounds for criticizing an agent, i.e. broad use of “should”. A general positive status that we confer to behaviors that we approve of.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Why is the distinction important and what is special/important about internal reasons statements?&lt;/p&gt;

&lt;p&gt;Consider the earlier discussion of theoretical reasons. That is, reasons for beliefs must be internal to an agent’s perceptions, intuitions, etc. even though there is a sense in which it is appropriate to confer a positive status to certain beliefs on the basis of external reasons i.e. their truth. The reason is because, regardless of the appropriateness a attitude on externalist grounds, we &lt;em&gt;need&lt;/em&gt; a system to confer status to attitudes on internalist grounds. There are times when we don’t have access to considerations that warrant approval of certain attitudes. In those circumstances, we still need to make a choice. Thus, we need a procedure that determines which attitudes are worth adopting. And we need an element of language to play this role in explaining this status. Internal reasons statements play this role.&lt;/p&gt;

&lt;p&gt;When we deliberate, we are trying to answer the question of which attitudes to adopt. During theoretical reasoning, we are determining what beliefs to adopt. During practical reasoning, we are determining what intentinos to adopt. Because theoretical reasoning involves determining whether a given proposition, say, P is true, the &lt;em&gt;mere fact that P is true&lt;/em&gt; cannot possibly serve as a reason to believe P; at least not when “reason” is understood as the status we confer to beliefs during deliberation about what to believe. From the agent’s perspective, s/he begins unsure as to whether or not P is true and is trying to answer that question. He thus cannot use &lt;em&gt;the fact that P is true&lt;/em&gt; as a reason to believe P. Similar considerations apply to practical reasoning. Practical reasoning involves determining whether a given intention X is to be adopted. Therefore, the &lt;em&gt;mere fact that X is virtuous or kind or fair&lt;/em&gt; cannot serve as a reason to do X. Again, the agent begins unsure as to whether virtue or kindness or fairness is a reason to intend to something. Thus, the mere fact that an action has these properties cannot be taken as a reason for an intention. In general when deliberating, the only considerations that we can appeal to as reasons for action are considerations that we already accept to be reasons for action. There is no normative truth outside of what we take to be normative.&lt;/p&gt;

&lt;p&gt;The very activity of normative reasoning is to address conflicts in motivations. The problem to which normative thinking is designed to address is conflicts in our motivations. This means that normative thinking is not designed to track any mind-independent truth. Evenif it can be said that there is some mind-independent truth external to the world of the relevant kind, there is no way that this could relate to normative reasoning. Normative thinking is only answerable to our given motivations and normative judgments.&lt;/p&gt;

&lt;h3 id=&quot;constructivist-argument&quot;&gt;Constructivist Argument&lt;/h3&gt;

&lt;p&gt;Constructivism + Judgment Internalism = Existence Internalism&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Constructivism: A has a reason to X only if A’s normative judgments in some sense endorse X-ing.&lt;/li&gt;
  &lt;li&gt;Judgment Internalism: A’s normative judgments endorse X-ing only if A has some motivation to X.&lt;/li&gt;
  &lt;li&gt;Existence Internalism: A has a reason to X only if A has some motivation to X.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Constructivism is actually a narrow form of existence internalism if we accept judgment internalism and if we believe one can have motivating reasons without judging them to be normative reasons. In that case, the motivating reasons corresponding to one’s normative judgments would be a strict subset of their motivational set. Of course, there is still the question of why we should accept constructivism in the first place.&lt;/p&gt;

&lt;h2 id=&quot;constructivism&quot;&gt;Constructivism&lt;/h2&gt;

&lt;p&gt;Three categories of normative judgments&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Constituitive: normative judgments held by all agents insofar as they are rational&lt;/li&gt;
  &lt;li&gt;Internal: normative judgments held by a particular agent, i.e. narrow use of “reason”. Or what is entailed from an agent’s normative judgments.&lt;/li&gt;
  &lt;li&gt;External: grounds for criticizing an agent, i.e. broad use of “should”&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;The question is why does the internal/external divide matter and why do internal reasons count as real reasons?&lt;/p&gt;

&lt;p&gt;The answer is this: There is a sense of reasons such that if an agent fails to do what &lt;em&gt;he judges&lt;/em&gt; to be a reason R, then he is irrational. But this can be true only if the agent judges R to be an internal reason. I.e. if an agent fails to do what he &lt;em&gt;endorses&lt;/em&gt; (i.e. an internal reason judgment), then he is irrational. But if he fails to do what he judges to be endorsed from some other perspective (which would be an external reason judgment), e.g. the moral perspective, then he is not being irrational. So reasons in the sense of being connected with rationality or irrationality must be internal. The property of &lt;em&gt;being a reason&lt;/em&gt; is a status we confer give to considerations that we endorse upon deliberation.&lt;/p&gt;

&lt;p&gt;The question now is why assume rationality cannot be broadened to include substantive normative judgments, so that someone who fails to respond to e.g. moral reasons are irrational beause rationality requires being moral?&lt;/p&gt;

&lt;p&gt;Some Arguments&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Little ontological baggage.&lt;/li&gt;
  &lt;li&gt;Allows for a credible epistemology.&lt;/li&gt;
  &lt;li&gt;Explains many constituitive properties of certain normative domains.&lt;/li&gt;
  &lt;li&gt;Explains existence internalism (assuming we accept judgment internalism).&lt;/li&gt;
  &lt;li&gt;Doesn’t seem like reasons can be discarded as meaningless. One can’t ask “why be rational”.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;See: Christine Korsgaard, Sharon Street, (Bernard Williams?)&lt;/p&gt;

&lt;p&gt;The fact that X is a reason to Y for agent A is constituted by the fact that the judgment that X is a reason to Y (for A) withstands scrutiny from the standpoint of A’s other judgments about reasons. Note that X is never a reason in favor of Y, absolutely. X can only be in favor of Y for some particular agent, as determined by the standards set by the normative judgments of A himself.&lt;/p&gt;

&lt;p&gt;A normative judgment withstands scrutiny for an agent only if the agent could mantain the judgment in full awareness, which is determined by the constituitive standards of the attitude in question. For example, someone who judges that X is a reason to Y cannot also simultaneously and in full awareness judge that X is not a reason to Y (consistency is constitutive of normative judgments). Also, one cannot take oneself to have conclusive reason to Y without taking oneself to have reason to take the means to Y (means-end reasoning is constituitive of normative judgments). The force of &lt;em&gt;cannot&lt;/em&gt; is not rational, but what is &lt;em&gt;constituitive&lt;/em&gt; of the concept of forming normative judgments. These standards of correctness are legislated by the very person making the normative judgments. This allows that one can be genuinely mistaken about their normative judgments only insofar as they are not in full awareness of certain relevant features of their judgments.&lt;/p&gt;

&lt;h3 id=&quot;disallowing-brute-error&quot;&gt;Disallowing Brute Error&lt;/h3&gt;

&lt;p&gt;See “Constructing Ortagorean Objectivity.md”&lt;/p&gt;

&lt;h3 id=&quot;theory-of-error&quot;&gt;Theory of Error&lt;/h3&gt;

&lt;p&gt;The basic idea is that we have reason to adopt attitude X if adopting attitude can be entailed from our current set of judgments.
But how to account for agents who have false normative judgments?
After all, such judgments are a part of their judgments, so it can be said to be “entailed” from their current set of judgments.&lt;/p&gt;

&lt;p&gt;The answer is that some normative judgments are strictly of higher priority than others. 
There are a few reasons for this:&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;Judgment A sets the context for when judgment B is relavent. E.g. the difference between endorsing what you would endorse if unemotional, fully reflective, etc. versus what one endorses in the heat of the moment. The former is an endorsement about the kinds of conditions that determine when one’s actual endorsements are valid.&lt;/li&gt;
  &lt;li&gt;Judgment A is constituitive of the very activity. Thus, it cannot be discarded in favor of A. E.g. judging that one has reason to adopt the means to meet an end is constitutive of adopting the end.&lt;/li&gt;
  &lt;li&gt;Judgment A is extremely difficult to get rid of. E.g. relying on induction, memories, perceptions, caring about our future selves, etc. In fact, insofar as someone were able to not rely on these features, they would have psychological states completely unlike anything of our own.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Part of the practice of establishing normative attitudes is establishing attitudes that regulate other attitudes.
There is a hierarchy of normative judgments abound.
Other considerations for favoring one judgment over another:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;It is more likely to acccomplish
If there is no significant difference in any of the points mentioned above between two potential normative judgment, there is not necessarily a more “correct” position to adopt.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;alternative-conceptions-of-truth&quot;&gt;Alternative conceptions of truth&lt;/h3&gt;

&lt;p&gt;There are plenty of other domains of propositions whereby truth is based on something other than correspondence. The general structure is that one takes an attitude with regard to a proposition p, and then finds standards of correctness constituitive of the attitude. Consider the following examples:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Descriptive judgments: Judgment S expresses a relation involving a description D and reality R, namely that D represents R. S is true if and only if D represents reality.&lt;/li&gt;
  &lt;li&gt;Logical judgments: Judgment S expresses a relation involving a set of propositions P1 and another set of propositions P2, namely that P1 entails P2, i.e. the truth values constitutive of P1 are also constitutive of P2. S is true if and only if P1 entails P2.&lt;/li&gt;
  &lt;li&gt;Modal judgments:&lt;/li&gt;
  &lt;li&gt;Probabilistic judgments:&lt;/li&gt;
  &lt;li&gt;Causal judgments:&lt;/li&gt;
  &lt;li&gt;Counterfactual judgments:&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Rational Judgments&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Epistemic Rationality:&lt;/li&gt;
  &lt;li&gt;Prudential Rationality:&lt;/li&gt;
  &lt;li&gt;Moral Rationality:&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Under constructivism, for normative judgments, truth is not based on some correspondence to some mind-independent normative reality. There is no standard of correctness for normative judgments independent of what we ourselves decide to be valuable. There is no sense in determining that someone has a reason to do something if it cannot be inferred from what they actually judge themselves to have reason to do.&lt;/p&gt;

&lt;p&gt;If we remain committed to the correspondence theory of truth, we can abandon truth-aptness. Normative judgments are rationalility-apt. Normative propositions have the property of being rational or irrational, whereas descriptive propositions have the property of being true or false. Ascriptions of rationality can be siblings to ascriptions of truth, while not being reduced in those terms. This can be considered a form of quasi-truth. All the purported values of cognitivism can be withheld:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Normative thinking is a rational enterprise.&lt;/li&gt;
  &lt;li&gt;Certain normative judgments are better than others.&lt;/li&gt;
  &lt;li&gt;The better normative judgments are independent of our actual judgments.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;constituitive-features&quot;&gt;Constituitive Features&lt;/h3&gt;

&lt;p&gt;The central question is how to determine what requirements are constitutive of a type of behavior. One candidate is this: a requirement is constituitive of a behavior if no agent could consciously reject the requirement in full awareness.&lt;/p&gt;

&lt;p&gt;Logical Consistency. One basic constituitive feature of normative judgments (and thuoghts generally) is logical consistency. No person can consciously believe X and believe not-X in full awareness.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;General&lt;/strong&gt;&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Consistency: Consistent/Coherent norms trump inconsistent/incoherent norms (This is required for all other constituive features to have force). Without a concern for consistency, an agent could not count as a normative reasoning agent. The very activity of normative reasoning is to address conflicts in motivations.&lt;/li&gt;
  &lt;li&gt;Soundness: Norms endorsed under a sound state of mind trump norms endorsed under psychological compulsions, physical addictions, emotional disturbances, etc.&lt;/li&gt;
  &lt;li&gt;Deliberation: Norms endorsed under deliberation trump unreflective dispositions that we discard under deliberation.&lt;/li&gt;
  &lt;li&gt;Experience: Norms that maintain endorsement upon experiencing their outcome trump ends which are not.&lt;/li&gt;
  &lt;li&gt;Full Information: Norms endorsed with full information trump norms based on false beliefs?&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Stability?
Commonality?&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Epistemic&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;The normativity of beliefs (against people who think the normativity of beliefs just reduce to their truth, so normativity is descriptive):&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;We are all familiar with the idea of justifying beliefs. I.e. people who believe in Santa Clause who are exposed to the appropriate evidence have unjustified beliefs, people who believe in God (or lack belief if you’re religious), people with opposing beliefs about the efficacy of gun control, etc.&lt;/li&gt;
  &lt;li&gt;Justification and truth are separate concepts, i.e. a belief can be justified yet false or unjustified yet true. So justification cannot be descriptive, as it is not concerned with truth.&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Normative principles come prior to descriptive beliefs. We need normative principles to establish descriptive beliefs. We need a procedure to proceed from evidential input - i.e. sensory perceptions, memories, intuitions, etc. - to belief outputs. We must establish what counts as evidence to make this inference. Deductive reasoning is required at a minimum. But this is not sufficient, we need induction, abduction, etc.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;Deductive:
    &lt;ul&gt;
      &lt;li&gt;Basic constistency: we cannot believe P and ~P.&lt;/li&gt;
      &lt;li&gt;Logical rules of inference: if P-&amp;gt;Q and P, then Q.&lt;/li&gt;
      &lt;li&gt;Constraints on thought. We cannot help but follow logical constraints in our thinking.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Subjective:
    &lt;ul&gt;
      &lt;li&gt;Perceptions/memories: the reason that a perception that p provides one with reason to believe that p is because part of what it is to perceive p is to acquire an unreflective belief that p. If perceptions didn’t provide one with an unreflective belief that p, then perceiving that p would be like imagining that p, and this would not provide one with a reason to believe p. Similar considerations apply to memories.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Abduction:
    &lt;ul&gt;
      &lt;li&gt;Falsifiability&lt;/li&gt;
      &lt;li&gt;Generality&lt;/li&gt;
      &lt;li&gt;Parisomony (Occam’s Razor)&lt;/li&gt;
      &lt;li&gt;Explanatory&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Induction:
    &lt;ul&gt;
      &lt;li&gt;Past -&amp;gt; Future&lt;/li&gt;
      &lt;li&gt;Observed -&amp;gt; Unobserved&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;All of these are either:
	- Constraints on our thoughts. We cannot help but believe them. Or,
	- Things we don’t &lt;em&gt;have&lt;/em&gt; to trust, but which we just so happen to do. This isn’t just something that individuals happen to trust, but that everyone happens to trust. If there were beings that didn’t abide by induction or abduction, then we wouldn’t call them irrational; they just wouldn’t have cognitive structures like our own. Normativity only deals with resolving conflicts. Thus, if induction, abduction, etc. are already adopted by most people, then we don’t need to justify them.&lt;/p&gt;

&lt;p&gt;This seems to be too low of a standard. It seems we can still question the validity of a belief system that is internally coherent and held by everyone else. E.g. think about beliefs about God back when everyone was religious. Why is this unjustified? Appeal to a more foundational principle that we all intuitive adopt, which is abduction. How do we know that abduction is more foundational than beliefs about God? (1) abduction is not a belief in that it is representation; it is a framework for establishing representations. (2) God is something we come to believe after engaging in abduction. (3) everyone participates in abduction, not everyone participates in believing God. Someone might say that they specifically place God on a more foundational level than abduction, but then their position wouldn’t be reasonable for other people. And usually, when we say X provides a reason to believe Y in circumstances C, we take that to be a universal claim, i.e. &lt;em&gt;every&lt;/em&gt; agent has reason to take X to provide reason to believe Y in circumstances C.&lt;/p&gt;

&lt;p&gt;Reason is purely procedural. It is concerned with amelierating &lt;em&gt;conflicts&lt;/em&gt; and striving for &lt;em&gt;coherence&lt;/em&gt; of our aims. Beliefs are not justified in isolation. Rather they are justified based on their coherence with other beliefs. It may seem that all propositions must be justified in a non-circular non-infinite regress, and any beliefs that cannot be justified are irrational. This is the case only because of the context of ordinary uses of “rational” or “irrational”. When we talk of “rational” in the context of a debate, it usually applied to propositions that can be justified to all parties involved. However, even though propositions may not be justifiable in this sense (in the sense of collective support), they can justifiable to an individual (based on their coherence with the individual’s other beliefs). The “rational” sense as used in collective support is not constituitive of rationality itself (i.e. agents can be rational without jutsifying themselves to others), but having debates with others implicitly commits oneself to a constructed “game” where the rules are intersubjective justifiability.&lt;/p&gt;

&lt;p&gt;Objectivity: imagine people have widely divergent beliefs. Objectivity is possible when there happens to be an intersection in the beliefs held by these people. More specifically, it’s possible when there is an intersection in what these people judge to be solid methods for establishing truth. E.g. think of science. People might have widely different beliefs. But everyone agrees that one’s beliefs should cohere with their other beliefs, and we happen to be beings with sensory inputs that automatically impress beliefs within us (which means our beliefs must cohere with our sensory inputs), and our sensory inputs happen to converge a lot of the time. There are other features we happen to agree with as well (or can be shown to agree with), e.g. repeated observations from different independent sources/experiments provide more evidence for a hypothesis than one-offs, etc. It is this convergence that grounds the objectivity of science. I.e. two people might disagree over whether theory X or Y is true, but they can agree on method for determining whether X or Y is true, e.g. by appealing to observation, abduction, induction. Without this, objectivity is impossible. Even if we disagree on method, we can ideally point to a meta-principle that we both agree with (or can be shown to agree with) that settles which method is valid (e.g. reflective equilibrium).&lt;/p&gt;

&lt;p&gt;Methodology:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;There are no exhaustive general principles. There are only procedures for establishing principles and truths. Procedure -&amp;gt; Principles -&amp;gt; Truth.&lt;/li&gt;
  &lt;li&gt;Conflicts must be handled by (1) reflective equilibrium - checking coherence with other beliefs/truths, and (2) by appeal to higher level principles that are agreed upon. Applies to individual beliefs and interpersonal disagreement.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Prudential&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Constructivism provides an easy explanation of the following norms of practical reasoning.&lt;/p&gt;

&lt;p&gt;Constitutive Features&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;End-Satisfaction: agents have reason to satisfy their ends.&lt;/li&gt;
  &lt;li&gt;Instrumental: agents have reason to adopt the means to satisfy their ends.&lt;/li&gt;
  &lt;li&gt;Time: agents have reason to satisfy the goals of their future self. 
 Agents justified in criticizing the goals of our past selves.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Other Features. May not be constitutive (?), but depend on features implicit in most people&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Conflict: how to deal with conflicting goals? 
 Is there a goal hierarchy? 
 Ends constitutive of one’s identity (i.e. valuing reflection) trump conflicting ends.&lt;/li&gt;
  &lt;li&gt;Feasibility: goals which are more likely to be satisfied trump equivalent goals that cannot be satisfied.&lt;/li&gt;
  &lt;li&gt;Pain/Suffering: pain/suffering provides one with reason to avoid it is precisely because people judge that they have reason to avoid it (or they have an unreflective aversion towards it). 
 If a person had no (un)reflective aversion toward pain, then there would be no actual reason to avoid it. 
 It is not the pure sensation of pain that provides us with reason to avoid it.&lt;/li&gt;
  &lt;li&gt;Desires: a desire to X tends to provide one with reason to X because
    &lt;ul&gt;
      &lt;li&gt;people tend to judge that they have reason to X if they desire to X, and&lt;/li&gt;
      &lt;li&gt;all intentional actions are done because of some desire; otherwise, they would be involuntary actions.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;against-consequentialism&quot;&gt;Against consequentialism&lt;/h3&gt;

&lt;p&gt;For a particular agent, their reasons need not be consequentialist. For example, this is true insofar as the agent accepts that they have reason to hold certain attitudes, attitudes that cannot be reduced to merely promoting some desired state of affairs. For example, an agent might value friendship, meaning they think they have reason to be loyal to their friends, care about their interests, etc. These reasons are not reasons to promote some state of affairs. This would imply that there could be some end state of affairs that would justify them betraying these current reasons to reach that desired state, but this need not be what an agent has reason to do.&lt;/p&gt;

&lt;p&gt;In sum, not all reasons are teleological, i.e. all states of affairs are given some amount of weight which can be theoretically quantified which competes against are conflicting states of affairs. Instead, there reasons can be structural, where some features are given zero weight due to higher order reasons.&lt;/p&gt;

&lt;p&gt;Kinds of consequentialism:&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;Maximizing - Define some good which can be quantified, we have most reason to act so as to promote that quantity. This can be disproven above.&lt;/li&gt;
  &lt;li&gt;Trivial - Rank possible states of affairs according to how you judge yourself to have most reason to act. Have a complete ranking of all the states. Because constructivism is true, we have most reason to promote that state of affairs. This seems trivially true.&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;methodology&quot;&gt;Methodology&lt;/h3&gt;

&lt;p&gt;Objectivity:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;There is no objectivity in the mind-independence sense. But there is a kind of objectivity in terms of what is constituitive of agency itself. E.g. in order to count as an agent who values anything, they must take themselves to have reason to adopt the means to fulfill their ends, they must value their capacity for agency, etc.&lt;/li&gt;
  &lt;li&gt;One might doubt whether this is a important kind of objectivity. They might say: you are cheating by talking about what is valuable after presupposing someone is an agent. This isn’t really interesting.
–&amp;gt; Response: this is the same kind of objectivity that we get with deductive reasoning. I.e. the only reason P -&amp;gt; P, ~(P ^ ~P), (P-&amp;gt;Q ^ P) -&amp;gt; Q, etc. is because of what it is to believe a proposition to be true. It is constituitive of belief that one not believe contradictions. Indeed, for “agents” without these tendencies, we wouldn’t be able to rationally persuade them otherwise. But it’s not clear that the concept of “rationality” even applies to them. They’re neither rational nor irrational. No one questions the objectivity here:
—&amp;gt; One might still question its objectivity because it doesn’t have the mind-independence. In that case, I question if this usage of “objectivity” is interesting or important. What does it take to call something “objectivity”? I look to the role that “objectivity” plays in discourse. When we call something objectivity, we apply this to domains of propositions that (1) people can be mistaken about, (2) we can criticize others/ourselves about, (3) we can have improve about, (4) we can disagree about, etc. The characterization given thus far fulfills that role. 
—&amp;gt; Speaking of roles, think of normative “truth”. When we attribute the predicate TRUE to a normative judgment about what one ought to do, this implies something above and beyond typical desires:
—&amp;gt; That that judgment will be more &lt;em&gt;stable&lt;/em&gt; than other desires upon reflection. So reflective stability under ideal deliberation is a test for rationality among agents. Reflective stability under idealized &lt;em&gt;conditions&lt;/em&gt; can be a test for the &lt;em&gt;reasons&lt;/em&gt; of an agent (where the idealized conditions are the conditions that an agent endorses under ideal deliberation, i.e. full information, full experience, fully imaginative, etc.). Might stability under idealized social negotiation be a test &lt;em&gt;moral reasons&lt;/em&gt;. Stability is one of the reasons why our value of reflection has normative authority over any conflicting unreflective judgments we might have.&lt;/li&gt;
  &lt;li&gt;Another “kind” of objectivity. It may not be constituitive of agency per se, but it is nearly universal among humans:
—&amp;gt; Standing in mutual recognition with other agents (i.e. being a moral agent). As an agent, one doesn’t &lt;em&gt;have&lt;/em&gt; to care about this. But almost all agents do. Because for the ones who did not, they would have had a difficult time spreading their genes. Of course, evolutionarily, the circle of mutual recognition was often small, limited to one’s tribe or in-group. But we have the rational capacity to question whether differences between tribes are actually relevant, and most will conclude that they are not. This is not only evolutionarily necessary, it is also neurologically necessary for all current humans. Humans who are not touched and played with as infants either die or grow to have developmental disorders.
—&amp;gt; A similar non-constituitive “tendency” that agents have is to value the values of their future self. This need not be constituitive of agency. However, it is near-universal among humans for very similar reasons as being a moral agent. For those who did not, they would have had a difficult time spreading their genes. Of course, our tendency to plan for the future is often limited based on certain factors (i.e. impulsivity, excitement, etc.), but we can question whether those considerations are rationally relevant, and most will conclude that they are not. [there is a further question as to whether caring for future selves commits one to care about other persons. This is a question I will not answer].&lt;/li&gt;
  &lt;li&gt;Different kinds of constituitive features:
—&amp;gt; Constituitive of psychological attitudes: Fear -&amp;gt; Attributions of danger
—&amp;gt; Constituitive of linguistic concepts: thick ethical concepts, coward -&amp;gt; attribution of fear
—&amp;gt; Constructed social norms: moral norms -&amp;gt; impartial concern with others. Based on the role or function that the norms plays in our lives. Find the job description of morality. E.g. compare with ettiquette, science, etc. Morality is like thick ethical concepts in that sense. For that reason, they can sometimes be used non-motivationally, e.g. someone who sincerely (i.e. not in the “inverted comma” sense) says “X is a generous” might not have any motivation by focusing on the descriptive component of the thick ethical concept “generous” - i.e. that he give to others, etc. Likewise, someone can sincerely judge “X is wrong” without any motivational by focusing on the thick component of wrongness - i.e. that others have reason to blame one for this, that people motivated to stand in mutual recognition have reason to accept the norm, etc. The thick component here is also normative (i.e. it uses the concept of a reason), but it need not be motivational, because it relates to reasons for other people. So it may just express a disposition for motivation of the speaker in certain counterfactual circumstances.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;desire-theories&quot;&gt;Desire Theories&lt;/h2&gt;

&lt;p&gt;!!! danger “Deprecate”
	Delete this section. Consider the pros and cons of desire theories when discussing the merits of various forms of internalism.&lt;/p&gt;

&lt;p&gt;This examines theories for normative correctness that reduce in some way to an agents desires, whether first-order or higher-order, actual or hypothetical, etc.&lt;/p&gt;

&lt;h3 id=&quot;humean-model&quot;&gt;Humean Model&lt;/h3&gt;

&lt;p&gt;The Humean theory of rationality states the following&lt;/p&gt;

&lt;p&gt;A has a reason to X if and only if (1) X promotes A’s desire d and (2) d is not based on any false beliefs. This can be simplified to: A has a reason to X if and only if X promotes a foundational (rather than derivative) desire in A. Desires are then the upshot of the following&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Full information&lt;/li&gt;
  &lt;li&gt;Correct means-end deliberation (generation of a desire to X as a result of combining a desire to Y and a belief that X -&amp;gt; Y).&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Desires can be given three components:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;A certain positive or negative sensation&lt;/li&gt;
  &lt;li&gt;A disposition to promote some state of affairs&lt;/li&gt;
  &lt;li&gt;An unreflective normative judgment that one has reason to promote a state of affairs&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Not clear if an “urge” can be reduced to a sensation/disposition pair.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Problems&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;These are problems insofar as desires are divorced from normative judgments (e.g. plans, goals, etc.).&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Normativity of desires: Why would a desire, in terms of just sensations and dispositions, provide someone with reasons for action? Imagine someone had a disposition where they just felt the urge to turn on radios whenever they saw one but they didn’t think they had any reason to do so. Imagine A is injected with a drug that makes him crave the drug much more, and this is his strongest desire by far. Does he have most reason to take the drug?&lt;/li&gt;
  &lt;li&gt;Disconnects: Assume the normativity of desires are accounted for. How to account for disconnects between an agent’s reasons and their desires? These disconnects can happen under physical addiction, emotional disturbances, psychological compulsions, etc.
    &lt;ul&gt;
      &lt;li&gt;We sometimes have reasons without corresponding desires - e.g. weakness of will&lt;/li&gt;
      &lt;li&gt;We sometimes have desires without corresponding reasons - e.g. addictions&lt;/li&gt;
      &lt;li&gt;These cannot be accounted for with full information. There can be degenerate desires that are produced from, or persist despite, full information. Imagine that if a person became fully informed about all the germs on one’s hands, this would trigger a natural underived disgust reaction in the person, causing them to never touch anything directly and to constantly wash their hands everyday. Imagine that they are aware that the germs cause no actual danger or harm. They would be against coming into contact with germs because of an intrinsic disgust reaction, and they would think, all things else considered, satisfying their desire to reduce germs is more important than the sacrifice that doing so requires. The fact that full information would produce certain responses in people doesn’t make those responses rational.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Priority: Assume the disconnect between reasons and desires is accounted for (perhaps by looking at a mode of desires). On this model, the authority of desires are simply based on their “strength”.
    &lt;ul&gt;
      &lt;li&gt;How does this account for the authority we want to give to categorically superior desires? E.g. the priority of higher-order desires or desires under full experience, reflection, sound state of mind, etc. which may have low strength?&lt;/li&gt;
      &lt;li&gt;How can we ground criticisms of fully informed desires that are based on inexperience, lack of reflection, unsound, etc.?&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Prudence: Why agents have reason to satisfy the desires of their future self?&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;dispositionalism--sophisticated-humean-model&quot;&gt;Dispositionalism / Sophisticated Humean Model&lt;/h3&gt;

&lt;p&gt;The idealization for discovering reasons requires, at a minimum, full information and correct means-end-deliberation. Some other possibilities include. We can supplement the Humean model by incorportating other requirements:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Fully Informed&lt;/li&gt;
  &lt;li&gt;Correct means-end deliberation.&lt;/li&gt;
  &lt;li&gt;Reflection - desires endorsed under reflection have priority over others
    &lt;ul&gt;
      &lt;li&gt;Using imagination to determine how a desire would be satisfied.&lt;/li&gt;
      &lt;li&gt;Deciding which desires one places most weight.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Soundness - free of psychological compulsions, physical addictions, emotional disturbances.&lt;/li&gt;
  &lt;li&gt;Fully Experienced - not merely knowledge of a proposition p, but exposure to a stimuli (i.e. a perception, an argument, etc.) that provokes the attitude.&lt;/li&gt;
  &lt;li&gt;Systematically unified desires.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Reasons = Full Experience + Full Information + Full Reflection + Sound mental state + …&lt;/p&gt;

&lt;p&gt;At bottom, the concern is that we are starting with an agent’s given motivational set and find a sound deliberative route or procedure with the aforemention properties to discover reasons.&lt;/p&gt;

&lt;p&gt;Some theories allow the creation/destruction of underived desires. Williams and Smith think this allows for the creation and destruction of underived desires via imagination and, for Smith, the focus on unification. Smith takes a more radical approach in that he believes certain seemingly arational desires (e.g. desiring value only one’s interests at the expense of others) are irrational. This is because some theories are “fully rational”, not merely fully informed, where “fully rational” extends beyond correct ends-means deliberation. This is necessary to handle irrational desires.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Problems&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Hasn’t solved the following problems from above:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Normativity of desires: why do mere sensations/dispositions even under idealized circumstances, in the absence of a normative judgment, provide a reason for action? It doesn’t seem that they do. Instead, we should focus on the normative judgments an agent would make (e.g. their plans, goals), under these idealized conditions.&lt;/li&gt;
  &lt;li&gt;Unification: what do these conditions all have in common? It cannot just be that we all desire to satisfy the desires that we would have under these conditions because not everyone has this desire.&lt;/li&gt;
  &lt;li&gt;Priority: assume everyone does actually desire the desires they would have under idealized conditions. What gives these desires the priority that they have? On desire-based theories, priority must be determined purely by “strength” and very often we can have desires that are stronger than our desire to satisfy the desires we would have under idealized conditions.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;??? example “Ideal Observer”&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;See: Peter Railton, Michael Smith

Ideal agent vs Ideal Observer: *Ideal agent*: an agent A has reason to X in circumstances C if and only if an ideal version of themselves, A+, would desire to X in C. *Ideal Observer*: an ideal agent A has reason to X in circumstances C if and only if an ideal version of the agent, A+, would desire that A desires to X in C. 

*Observer-based not agent-based.* The reasons that X has reduces to whether A+ would desire A to desire X, not whether A+ would desire X. This is because doing otherwise cannot account for reasons under uncertainty. Consider the case when one has reason to seek new information. A fully informed being would have no desire to seek information, even though they have reason to do so.

It's not clear why this means we should focus on observers rather than agents. For example, imagine the case where someone drinks a glass of soda that they believe to be water and they desire to drink water. We can easily say that they have reason to not drink from the glass, even though they do have reason to drink from the glass given the information that they have. In this case, there is no problem with saying someone has most reason to do something which they have no rational way of endorsing given their currently held beliefs. Likewise, it seems we can say that people don't actually have reason to seek information, but rather they have reason to seek information given their currently held beliefs. There is no problem with saying, for example, that someone lost in the woods has most reason to take route X, even though this is not something which they have a rational way of endorsing given their currently held beliefs.

**Problems** 

- They cannot account for degenerate idealized counterparts. What if a fully idealized counterpart, A+, desired that his less idealized counterpart, A, do something that he didn't have reason to do? What if A+ was viscious? The only way to avoid this conclusion is by assuming that some desire or concern for the sake of others is somehow constitutive of a fully rational agent. But this seems dubious. This is especially dubious for theories that allow any non-self-defeating desire in principle to be rational (unlike, e.g. Smith who thinks that something like this might be constitutive of a fully rational agent). But these seem like poor candidates for an analysis as they are assuming substantive desires as being rational in their analysis... This, combined with the earlier notes on ideal observer, might be enough to ignore the observer aspect and focus on the agent. We can distinguish what to do under uncertainty versus full information by distinguishing rationality and reasons.
- ~~~They cannot account for rationality in general. Take an analysis of reasons for belief. A world-to-mind fit analysis might say &quot;A has reason to believe X in C iff an idealized version of himself, A+, would desire that A believed X in C&quot;. But this certainly does not seem to be true. Let's assume A+ is concerned ultimately with the welfare of A above all else (which is a dubious assumption as mentioned earlier). Then this certainly makes it possible for there to be cases where A+ desires that A believes X even though A has normative reason to not believe X, e.g. if believing X made A's life worse, even though it was justified. Theories about the direct beliefs of A+ (i.e. &quot;A has reason to believe X iff an idealized version of himself, A+, would believe X in those circumstances&quot;) fail because (1) insofar as the idealization involves full information, this is flawed because the reasons to hold a belief are not determined by the truth of that belief, and (2) insofar as the idealization involves full rationality, it is circular.~~~ Actually, this can account for rationality in general. The full information requirement is not to account for *rationality*, but to account for *reasons*. It is full information + rationality that provides reasons. The account of rationality is independent from full information, and this account can be extended to other domains.
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;general-problems&quot;&gt;General Problems&lt;/h3&gt;

&lt;p&gt;General problems with desire accounts and counterfactual attitude accounts.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;The elements posited as providing reasons (desires, informed desires, motivations, ideal desires, ideal observer’s desires, etc.) don’t necessarily provide reasons, i.e. when they disconnect with an agent’s normative judgments. Consider a case where dispositionalism (but not constructivism) would say someone has reason. On what grounds can the person be said to have that reason if they are not in some way committed to the action?&lt;/li&gt;
  &lt;li&gt;Insofar as they do provide reasons, constructivism explains why they provide reasons, why they matter and a unifying theme explaining the authority of the elements that do matter. E.g. if certain features are constituitive of agency, caring about desires under experience, future desires, etc.&lt;/li&gt;
  &lt;li&gt;Constructivism can give a clean general account of all reasons.
    &lt;ul&gt;
      &lt;li&gt;How to give a metaphysical account of reasons for belief? One response is that one has reason to believe P only if they would believe P in circumstance P. How to account for a reason to believe &lt;em&gt;that&lt;/em&gt; counterfactual? The response is that one has reason to believe that they would believe P in circumstances C iff they would believe that “they would believe P in circumstances C” in circumstances C. This is circular… This may not actually be an issue on the metaphysical/epistemic level. It may still be an issue on the linguistic/psychological level, however.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;</content><author><name>JayMoss</name></author><summary type="html">Existence internalism characterizes rationality without explicitly requiring any particular motivations. Note that this does not reduce internalism to an Actual Motivational view whereby an agent needs to be actually motivated to perform the action. Usually, rationality is specified by some form of ideal deliberation, i.e. R is a reason for agent A if and only if R is the upshot of sound, valid, fully imaginative (from Williams) deliberation. Other forms of internalism might require being in a sound state of mind, having full experience, etc. In other words, normative reasons are the rational extension of one’s motivating reasons. A consideration C counts as a reason if and only if there is some rational procedure from an agent’s motivational reasons to C (without presupposing any new motivational states along the way). [x] Forms of internalism: state/motivational, actual/counterfactual, Humeanism [x] Analogy with theoretical reasons [ ] Construcivism as an improvement over broad internalism. Plus, Intuition check [ ] Conceptual arguments for/against internalism. Theories of rationality [ ] Conceptual arguments for/against constructivism. [ ] Semantics Reconciling judgment internalism with existence internalism, or non-cognitivism with constructivism. External Reasons judgments and Internal Reasons judgments are often used by competent English speakers. How to account for this? Readings: Collections Reasons, Motives, and the Demands of Morality: An Introduction Essays: The Oxford Handbook of Reasons and Normativity (OHRN) Essays: Internal Reasons: Contemporary Readings (MIT Readers in Contemporary Philosophy) Essays: Constructivism in Practical Philosophy Essays: Bagnoli, Constructivism in Ethics Also see Philosophy of mind/action syllabus Routledge Handbook of Metaethics Books R. Brandt, A Theory of the Good and the Right (1979) Bond Reason and Value (1983) Milgram Practical Induction (1997) S. Darwall, Impartial Reason (1983) J. Dancy, Practical Reality (2000) K. Setiya, Reasons without Rationalism (2007), Derek Parfit, Reasons and Persons Mark Schroeder, Slaves of the Passions Conceptual Ralph Wedgwood, “The Unity of Normativity” Mark Schroeder, “The Unity of Reasons” “The Ubiquity of State-Given Reasons” “Value and the right kind of reason” Shyam Nair and John Horty, “The Logic of Reasons” Aaron Bronfman and J. L. Dowell, “The Language of Ought, and Reasons” John Hawthorne and Ofra Magidor, “Reflections on the Ideology of Reasons” =&amp;gt; From section 1 of OHRN Substantive Donald Davidson, “Actions, Reasons, and Causes” (1963) Ulrike Heuer, “Reasons for actions and desires” Peter Railton, “Toward a Unified Account of Rationality in Belief, Desire, and Action” Stephen Darwall, “Making the ‘Hard’ Problem of Normativity Easier” Stephen Finlay “The Reasons that Matter” (2006) “Responding to Normativity” (2007) David Velleman, “On the Aim of Belief” (2000) “The Possibility of Practical Reason” Kelly, “Epistemic Rationality as Instrumental Rationality: A Critique” (2003) Desires Thomas Nagel, “The Possibility of Altruism” (1970) W. Quinn, “Putting Rationality in its Place” (1993) Deliberation Antti Kauppinen, “Practical Reasoning” Garrett Cullity, “Weighing Reasons” Joshua Gert, “Underdetermination by Reasons” Stephen Kearns, “Reasons, Choices, and Responsibility” =&amp;gt; From section 5 of OHRN Internalism/Externalism Kieran Setiya, “Internal Reasons” (2012) (Introduction to Internal Reasons: Contemporary Readings ) Bernard Williams “Internal and External Reasons” from Moral Luck (1979) “Internal Reasons and the Obscurity of Blame” (1989) “Replies” (1995) Stephen Finlay, “The Obscurity of Internal Reasons” (2009) Christine Korsgard, “Skepticism About Practical Reasons” (1986) John McDowell, “Might There Be External Reasons?” (1995) Michael Smith, “Internal Reasons” (1995) =&amp;gt; Above are from Internal Reasons: Contemporary Readings T. M. Scanlon - “On Williams’ Internal and External Reasons” (from What We Owe to Each Other) Kieran Setiya, “Against Internalism” (2004) Philip Pettit &amp;amp; Michael Smith “External Reasons” (2006) Julia Markovits, “Why Be an Internalist about Reasons?” (2011) “Kantian Internalism” in Moral Reason (2014) Elijah Millgram, “Williams’ Argument Against External Reasons” (1996) Michael Smith “The Humean Theory of Motivation” (1995) “The Anti-Humean Theory of Normative Reasons” (1995) “Reasons Internalism” in Routledge Handbook mentions many articles Constructivism Christine Korsgard: “The Sources of Normativity” “Realism and Constructivism in Twentieth-Century Moral Philosophy” Self-Constitution. Agency, Identity and Integrity. Essays: Sharon Street “What is Constructivism in Ethics and Metaethics” “Constructivism about Reasons” “A Darwinian Dilemma for Realist Theories of Value” “Evolution and the Normativity of Epistemic Reasons” “Coming to Terms with Contingency : Humean Constructivism About Practical Reason” “In Defense of Future Tuesday Indifference” Harry Frankfurt, “Freedom of the Will and the Concept of a Person” Michael Smith, “A Constituvist theory of reasons” Critics “A Problem for Ambitious Metanormative Constructivism” by Nadeem J. Z. Hussain “The Appeal and Limits of Constructivism” by T. M. Scanlon David Enoch - “Can There Be a Global, Interesting, Coherent Constructivism About Practical Reason?” Constructivism and Expressivism: Some say that constructivism is best understood as a form ‘expressivism,’ which holds that normative terms function to guide action rather than represent matters of fact and are used to express states of mind that differ from belief (Chrisman 2010; Lenman 2012; Lenman &amp;amp; Shemmer 2012b; Meyers 2012). Furthermore, Lenman argues that embracing expressivism would promise to solve a basic problem for constructivism, specifically, the problem of identifying the kinds of mental state that normative judgments are (Lenman 2012). This suggestion is not shared. Humean constructivist Street has forcefully argued that expressivism fails to fully explain the normative function of normative discourse, which cannot be reduced to expressing normative states (Korsgaard 2003, 2008: 312, 325 n. 49, 2009: 309; Bagnoli 2002: 130–132; Magri 2002; Street 2010: 239–242). https://plato.stanford.edu/entries/constructivism-metaethics/#ConsRealAntiDeba Lenman, James (2012): “Expressivism and Constructivism” Chrisman, Matthew (2010): Constructivism, Expressivism and Ethical Knowledge Meyers, Chris (2012): “Expressivism, Constructivism, and the Supervenience of Moral Properties” Magri, Tito, 2002, “Frères Ennemis. The Common Root of Expressivism and Constructivism” Bagnoli, Carla, 2002, “Moral Constructivism: A Phenomenological Argument” Street, Sharon (2010): “What is Constructivism in Ethics and Metaethics?” Korsgaard, Christine M., 2003, “Realism and Constructivism in Twentieth-Century Moral Philosophy” Korsgaard, Christine M.,2008, The Constitution of Agency: Essays on Practical Reason and Moral Psychology, Korsgaard, Christine M.,2009, Self-Constitution: Action, Identity, and Integrity, Richardson, “Revising Moral Norms: Pragmatism and the Problem of Perspicuous Description” (2013) from Bagnli’s Consructivism in Ethics Richardson, “Truth and Ends in Dewey’s Pragmatism” (1998) Richardson, “Beyond Good and Right: toward a Constructive Ethical Pragmatism” (1995) Misak, Truth, Politics, Morality: Pragmatism and Deliberation See GIbbard Dorsey, “A Puzzle for Constructivism and How to Solve It” Schwartz, Velasco (2018), “Towards a semantics for metanormative constructivism” Kirun Kumar Sankaran (2014), “Two Essays on Constructivism: Lessons from Semantic Theory” van Roojen, Mark. 2015. Metaethics: A Contemporary Introduction -&amp;gt; contention between judgment internalism and existence internalism ??? question “Some questions left unanswered” - Conception of rationality that doesn’t beg the question against externalism. - How constructivism and expressivism can be reconciled. Two kinds of judgments. Constructivists claim that the truth of a normative claim is consituted by the normative judgments of the given agent. The normative judgments of the given agent are analyzed under expressivism. How are we to analyze the normative claim which constructivists state can be true? - How to distinguish well-being (what makes a life go best) from reasons for action/desires? - Some differences: 1. X might provide high well-being without an agent having reason to X, e.g. experience machine, animals, etc. 2. It is sensible to ask whether an agent has reason to do something that promotes their well-being due to some other end. - Reasons for action/desire = considerations in favor of an action, whether the agent knows it or not. - Well-being = how an agent assesses their own life to be going from their first-personal perspective, possibly under idealized conditions. - I understand the argument that there is no normative truth independent of normative judgments (i.e. the metaphysical/epistemological/motivational problems with realism).. But how do we establish that normative truth for a given agent’s depends on that agent’s normative judgments? E.g. why not the normative judgments of the agent’s community? Or the normative judgments of the speaker? Why not understood “reasons” broadly as a standard by which to criticize someone, e.g. because people are subject to criticism for being cruel, and because reasons are standards of criticism, why not say cruel people are unreasonable? There are infinitely many possible theories of normative truth that don’t reduce normative truth for A to A’s normative judgments, without also having the metaphysical/epistemological problems of realism. - We can understand “should” claims as general standards to ground criticism, e.g. people “should” not act immorally, even though they may have no reason not to do so. - “Reasons” may be sometimes used in this broad sense, but for clarity this concept will be identified with the narrow sense (connected with an agent’s normative judgments) leaving “should” the job of handling general grounds for criticism. - A motivational argument can be given perhaps. - Kosgaard’s states that such an account is the only thing that can explain the normative authority of deliberation for agents. What does this mean? - Why focus on reasons in the internal sense? Similar considerations can be used to explain why reasons for belief are internal rather than external (i.e. rather than simply beliefs that are true). - The internal sense is what we use not just for charges of criticism but for charges of irrationality. - The internal sense is the kind of reason we acknowledge when we judge that something is a reason from a first-person perspective rather thana third-person perspective. - What is the general strategy for determining what is constitutive of a given activity? Conceptual constraints on reasons agreed to by internalists and externalists: Everyone agrees: A’s judgment that he has reason to X will motivate A to X insofar as he is rational Controverial: if proposition C is a reason for A to X, then A’s awareness of C will motivate A to X insofar as he is rational and fully informed. This is true only if the fact that (1) C is a reason for A to X, (2) A’s full rationality and full descriptive information, and (3) A’s awareness of C entails that he will judge that C is a reason to X. Is this true? If this is true, then it will entail motivation to C. This seems true only if a fully rational/informed awareness of C (assuming C is a reason to X) will necessarily entail a judgment that C is a reason to X. This judgment is required for the above because the judgment is sufficient to produce motivation, and there doesn’t seem to be any other connection between something being a reason and it motivating an agent (otherwise, why would a consdieration motivate an agent if the agent did not recognize the consideration AS a reason). Externalists account for this: Externalists have to posit that rationality has substantive requirements, i.e. a desire to do what is kind, generous, etc. or whatever they posit people have reason to do. Or externalists have to posit that rational agents have an additional desire to do what they judge themselves to do. The question is still what is the content of the judgment that something is a reason, and how can this motivate anyone to do anything? Some thoughts: But the question isn’t even about the content of reasons judgments. For a non-cognitivist, there is no content. For constructivists, truth is not based on the contents (i.e. one has reason to X only if they judge that they have reason to X, but clearly the judgment that one has reason to X cannot just reduce to this). But if the content of reasons judgment does not determine what counts as a reason, then what does? What is the job description of a theory of reasons. When one says A has reason to X iff p (e.g. p = internalism, some form of externalism, etc.), what are the requirements on p? Perhaps, the requirement is this: if it is true that A has reason to X iff P, then A’s recognition of P must entail a judgment that they have reason to P. This will satisfy constructivism and internalism. The only way that recognition of P could entail a judgment that A has reason to X (which is itself a motivation; normative judgments are motivating) is if P was intimately tied to A’s motiation to begin with (the internalism thesis). Likewise, under constructivism, P just is the fact that A judges that they have reason to X (or that it follows from their normative judgments that they have reason to X). Anyone who recognizes this must neessarily recognize that they have reason to X. But why accept this job description? This job description may be true for conceptual analysis where you say reasons judgments MEAN a certain thing (even then, such a job description would be controversial), but asserting necessary/sufficient conditions is not conceptual analysis. So why accept this? E.g. X is yellow iff X reflects light of a certain wavelength, but this does not imply anyone who judges X has a certain wavelength has to judge that it has a certain color (or vice-versa). There are a few responses Perhaps reasons are different because there are no actual reasons properties or relations, unlike color Perhaps we are actually doing conceptual analysis by positing this job description. But I thought non-cognitivism was the conceptual analysis and there is no content of reasons judgments. Perhaps the analysis of normative claims can be different than base normative judgments. Of course normative claims often express our normative judgments, but perhaps they also do something else sometimes, i.e. express what we think follows from someone’s evaluative standpoint. Perhaps when positing this job description, we are just expressing attitudes as predicted by non-cognitivism What ARE we doing when we say that a certain job description is true? There seems to be a disinction between (1) ordinary judgments that one has reason to do something and (2) reasons judgments involved in asserting internalism, constructivism, job descriptions for a theory of truth, etc.? Are these the same kind of judgments? Are they both just expressions of a non-cognitive sentiment? Assuming non-cognitivism is true, why assume there is a theory of truth? Why assume there are reasons instead of just judgments about reasons? E.g. we agree that people judge things to be scary/funny. But that doesn’t imply that some things actually ARE scary/funny in a sense above/beyond judging them to be scary/funny. Perhaps constructivism does not claim that the existence of reasons are anything above/beyond judgments about reasons. Perhaps, when one a constructivist says “you have reason to X” this is just a convenient way of saying “your normative judgments commit you to X, whether you know it or not”. Perhaps the job description for a theory of truth is to satisfy certain grammatical/linguistic requirements along with the following minimum requirements: People can be wrong about what they have reason to do. We can improve toward “truth” when our judgments change A seperate theory of truth is needed What status are we giving to a consideration when we say “I might have a reason to do X, but I don’t believe I do”. What are we doing during deliberation, as we seemingly “figure out” what to do? The answer is to look at the standards that we are committed to in our normative judgments: consistency, coherence, reflection, etc. Insofar as we deliberate, we are committed to the upshots of these standards. But we can be mistaken about the upshot of these standards. Thus, the truth of normative judgments is whatever the upshot of these standards are because we are aiming at these standards. Thus, normative truth is related to normative judgments not in an attributional sense (i.e. in the sense of looking at the properties that we ascribe to things when we make normative judgments) but in a regulative sense (i.e. by looking at the standards that are implicitly guiding our judgments). It is by looking at rules that are implicit in our deliberations. Thus, this is truth not in a correspondence sense. Deliberation is an activity the standards of which we construct and impose on ourselves. We might not even be aware of what the standards are. But they regulate our judgments nevertheless (i.e. those who are unaware of the rules of consistency). Why are these the standards? They guide our thinking whether we know it or not. They cannot in full awareness be rejected. CANNOT here means conceptually not rationally. E.g. if someone in full awareness endorsed inconsistent judgments, then they wouldn’t legitimately count as making a judgment in the first place. They’re not irrational, but they are not even an agent, so terms like rationality/irrationality do not apply. They would be irrational if they accepted an inconsitency but was NOT aware of the inconsistency. Note that this DOES not imply that deliberation is an activity that attempts to figure out the upshots of deliberation while adhering to the implicit standards (which would be a kind of naturalism). We are not trying to answer theoretical questions to represent reality or counterfactuals. We are trying to answer practical questions, determining what to do. Rather, the implicit standards are regulating our deliberation (and thus determine success for the activity) independently of whether we are aware. Why this constructivism is compatible with non-cognitivism Deliberation does not aim to answer theoretical questions. It does not aim to represent the way the world is. Against cognitivism The upshots of deliberation are inherently motivating insofar as one is rational. Note, however, that they differ from ordinary motivating states such as desires because of the standards that are constituitive of normative judgments - e.g. instrumental reasoning CANNOT in full awareness be denied if one is to count as a deliberating agent. CANNOT here means conceptually not rationally. I.e. it is not that one is being irrational by failing to follow instrumental rationality in full awareness; rather, they aren’t attempting to deliberate rationally. Someone IS being irrational when they fail to follow instrumental rationality NOT in full awareness. Normative Truth consists in what follows from an agent’s evaluative standpoint. This is not what we mean when we form a normative judgment. When we’re form a normative judgment, we are just settling the practical question of what to do, rather than the theoretical question of what the upshots of our commitments are. Abandon a semantic theory of truth (whereby the truth of a proposition occurs when the state of affairs meant by the proposition are obtained) Rather, this is a question that we are aimed to answer (whether we know it or not), when in the process of settling practical questions. Final question: why should normative truth be construed as relative to the evaluative standpoint of the agent in question rather than the speaker? The reasoning here has all taken a person characterization; i.e. we are considering the standpoint and perspective of the agent. But why not instead focus on the judge? This analysis might capture what agents are attempting to do when answering normative questions, but it need not be what judges are doing when they are answering normative questions for others. Two possibilities: Posit that there is some special semantic/psychological difference between speakers endorsing actions for others, and endorsing actions for themselves. In the former case, truth is not relative to their (the speaker’s) motivations; it is somehow relative to the subject’s motivations. I.e. the speaker commits themselves to judging what follows from the agent’s evaluative standpoint whether they know it or not. In the latter case, the judge is only committed to judging what follows from their own evaluative standpoint. The former seems difficult to explain if the function of the judgments is merely to express plans/sentiments. Perhaps it has to do with the fact that we expect that if the agent accepts our claim that they have reason to X, this will instill in them a motivation to X insofar as they are rational. But this only makes sense if X is connected to their evaluative standpoint. -&amp;gt; But this doesn’t necessarily work to show that truth is relative to the agent. Because if “accept our claim that they have reason to X” just means “agree that they have reason to X” which just means adopting a motivation to X, then the speaker cannot expect that without believing that X is connected to their evaluattive standpoint. It would be equivalent to a speaker believing: if the agent becomes motivated to X, then they will be motivated to X insofar as they are rational. But clearly this doesn’t require X be connected to their present evaluative standpoint. -&amp;gt; Perhaps instead it should be: when we judge that Y (a proposition) is a reason to X (a behavior), then we expect that agents aware of Y will become motivated to X (because of their awareness of Y) insofar as they are rational [or perhaps, that agents aware of Y will judge that they have reason to X insofar as they are rational; or that a rational agent’s awareness of Y could explain why they judge themselves to have reason to X]. So the constructivist/internalist conceptual component is only about judgments about what constitute reasons rather than all reasons judgments. Now we need an analysis of what fully rational means without begging the question. -&amp;gt; So we need to explain the conceptual connection between explanation/motivation and third-personal normative judgments, and how this can be reconciled with non-cognitivism which denies that there is any essential content to normative judgments. Don’t divorse semantics/psychology of third-person and first-person normative judgments. Rather, adopt a theory of truth that is not tied to the judgments themselves. It’s not clear how this can secure speaker’s being committed to an agent’s evaluative perspective. Constructivist theories of the meaning of truth, semantics, compatibility with expressivism: Street, “What is Constructivism in Ethics and Metaethics”, See section on Expressivism. She outlines three strategies for explaining semantics of moral terms (1) state that its impossible because normative attitudes cannot be reduced, (2) argue for an inferentialist semantics, whereby the truth of claim consists in what inferences one needs to make to be competent with the concept, (3) argue for a reforming definition, or (4) adopt the expressivist theory. Street, “Constructivism about Reasons”, 237-241. Here, Street argues for (1) from above. See above section under “Expressivism and Constructivism” for more Strategies: Normative judgments can be explained by an expressivist theory, possibly the judgments cannot be reduced to non-normative judgments. Normative assertions and normative truth can be explained by either (1) an inferentialist theory as described above or (2) a pragmatic theory. (1) may be acceptable but (a) it needs to be fleshed out more and (b) why is it concerned with the agent rather than the speaker. (2) requires more investigation. Existence Internalism Some twists Externalism too broad, move to internalism. Actual motivations too narrow, require idealized conditions. Not all actual states provide reasons, move to constructivism. Consider analogy with theoretical reasons along the way. Varieties of internalism: Actual Motivation: A has reason to X only if A is motivated to X. Actual State: A has reason to X only if A has some motivational attitude that supports doing X. Counterfactual Motivation: A has reason to X only if A would be motivated to X under circumstances C. Counterfactual State: A has reason to X only if A would have some motivational attitude that supports doing X under circumstances C. For Motivation views, “is motivated” and “can be motivated” don’t just mean some motivation that may be overridden by other motivations. It means the source of an agent’s volition that drives them to act intentionally. For State views, a Motivational attitude is a certain kind of psychological state which plays a role in motivation. These states are often taken to be desires, but can include other attitudes such as emotions, intentions, and aversions. Motivation views do not, by themselves, require the presence of any particular kind of psychological state which does the motivating, and State views do not, by themselves, require that the motivating state which is present actually does any motivating. It is a platitude about reasons and rationality that: R is a normative reason for A to X iff R would be a motivating reason for A to X if A were rational and A was aware of R. In other words, reasons are the upshot of full rationality and full information. The question is how to characterize rationality. Internalism gives a procedural characterization of rationality. It usually specifies a form of ideal deliberation, i.e. of moving from certain motivations to action and other motivations. Externalism specifies an substantive characterization of rationality that specifies certain substantive elements like “a motivation to help others”. i.e. being rational might require being converted rather than sound reasoning. The above is a true platitude only if we use a fairly broad definition of rationality. But Scanlon narrows rationality to just doing that which you judge yourself to have reason to do. Which means to be irrational is to fail to adopt the attitudes that one judges themselves to have reason to adopt. This makes sense to me. I wouldn’t call someone irrational if they failed to do what they would do if they reflected more or were more experienced. “Rationality” as used above seems to simply mean “idealized person”. Existence internalism characterizes rationality without explicitly requiring any particular motivations. Note that this does not reduce internalism to an Actual Motivational view whereby an agent needs to be actually motivated to perform the action. Usually, rationality is specified by some form of ideal deliberation, i.e. R is a reason for agent A if and only if R is the upshot of sound, valid, fully imaginative (from Williams) deliberation. Other forms of internalism might require being in a sound state of mind, having full experience, etc. In other words, normative reasons are the rational extension of one’s motivating reasons. A consideration C counts as a reason if and only if there is some rational procedure from an agent’s motivational reasons to C (without presupposing any new motivational states along the way). ??? warning “Todo” Include the categories mentioned in the sep article. I.e. - state versus motivational forms of internalism - actual versus counterfactual forms - different ways to characterize the counterfactual conditions Motivational Argument 1 One argument for internal reasons states that reasons must be capable of motivating action. The argument: R is a reason for A to X only if A would be motivated to X by believing R insofar as A were fully rational. A, if fully rational, would be motivated to X by believing R only if A is disposed to X by believing R. If R is an external reason for A to X, then A is not disposed to X by believing R. Therefore there are no external reasons. The central question here is (2). (1) and (3) are both a priori, conceptual truths. (2) depends on whether we take rationality to have substantive or procedural requirements, so may seem to be question-begging. We need to give an independent argument for (2), in a way that explains how to pick out which dispositions provide reasons. Modifications: “Fully Rational” may need to be explicitly characterized in terms of “ideal sound deliberation” or something more specific, so that (2) is not seen as question-begging against the (rare) externalist who says that full rationality might endorse behaviors for A that A has no dispositions to do. From Scanlon: One option is to characterize “rationality” just in terms of consistency. So that one is irrational only if they fail to adopt an attitude that they do not judge themselves to have reason to have. Procedural rationality This is to support (2) of the explanatory argument: A, if fully rational, would be motivated to X by believing R only if A is disposed to X by believing R. (2) depends on whether we take rationality to have substantive or procedural requirements. We need an independent argument for procedural rationality to support (2). And we also need to explain why it’s not just any ol’ dispositions that are needed to supply an agent with reasons for action, i.e. an agent might have a disposition to overvalue short-term gains at the expense of long-term losses, but this mere disposition is not what grounds any reasons to value short-term gains as one might think from (2). Instead, what matters is what dispositions that agent actually endorses under deliberation. But now we seem to be making the deliberative argument below: Motivational Argument 2 R is a reason for A to X only if A would be motivated to X by believing R insofar as A deliberated soundly. A would be motivated to X by believing R under sound deliberation only if A is disposed to X by believing R. If R is an external reason for A to X, then A is not disposed to X by believing R. Therefore there are no external reasons. Now, (1) needs to be argued for, as it is no longer merely a plattitude. It almost may seem to be question-begging against the externalist. We might be able to accept (1) if we accepted constructivism. Normative truth derives from the normative judgments an agent makes, and it is constituitive of agency to value one’s motivations under deliberation. So we just need to argue for constructivism. Rational Argument Motivation is too strong. Recognition of p (where p is a reason to X) need not create motivation to X. This happens when only two things happen (1) A recognizes p as a reason and (2) A is motivated to act on his reasons. (2) is a seperate claim that makes the first premise unnecessarily strong, so lets remove it and focus on (1). This also implies two forms of rational defect: (1) failure to recognize one’s reasons as reasons, and (2) failure to be motivated by what one recognizes to be a reason. R is a reason for A to X only if A could recognize R as a reason to X upon believing R. A could recognize R as a reason to X upon believing R only if R follows from A’s current normative judgments R is a reason for A to X only if R follows from A’s current normative judgments Defend (2): Beliefs have a mind-to-world fit. Normative judgments have a world-to-mind fit. Mind-to-world fits cannot influence world-to-mind fits. Thus, a belief alone cannot cause a normative judgment. But this doesn’t show (2) is true. Perhaps R must follow from A’s current normative judgments + his other desires? Explanatory Argument Normative reasons are counterfactual explanatory reasons (Michael Smith w/out ideal observer). R is a reason for A to X only if R could explain why A would X under sound, ideal deliberation. That A is motivated to X by believing R can be explained only by something in A’s desires, goals, etc. favoring doing X by believing R. If R is an external reason for A to X, then there is nothing in A’s desires, goals, etc. that motivate a sound, deliberative A to X by believing R. Therefore there are no external reasons. Note we have (1) which is not a plattitude which one might object to. However an argument for (1) might be: (1) should be accepted by considering the cases where we perform actions because of normative reasons. The times where there is a disconnect between our motivating and normative reasons, we can point to some sort of problem, either we aren’t aware of the reasons, we have false information, we suffer from addiction, etc. Note that (1) is a weaker claim than in earlier arguments. To say that R could explain why A X-ed is weaker than saying R could motivate A to X. The former says that, if A were motivated to X (which might not be possible), this could be explained by R. The latter says that it is possible for A to be motivated to X (because of R). The reason that reasons statements are not based on the hypothetical motivational sets of e.g. a fully moral A, i.e. A+, is because it is important that reasons statements apply directly to A. Note, however, that we can still focus on the somewhat idealized A who has deliberated, because we can infer that A already values the motivations of himself after he has deliberated. We can infer this from the fact that he is in fact deliberating. So he already values his deliberation. But why should reasons statements for A be based on what he actually values in any present moment? This seems question-begging against the externalist. Two reasons (1) We make claims about reasons for the purpose of influencing, motivating, or guiding agents. But the only thing that can guide agents (assuming they don’t suffer from addictions, false beliefs, etc.) are elements from their motivational set. And (2) this is a basic premise of constructivism (see below). Focus on Theoretical Reasons (not a different argument from above; perhaps an elaboration of the explanatory argument). Points to be learned: Existence internalism may seem to be disproven by theoretical reasons because beliefs are justified by features other than one’s motivational set (i.e. one’s desires). However, the motivational set for beliefs wouldn’t just be desires; it would be other beliefs, perceptions, judgments, intuitions, etc. And these DO justify beliefs. Not all elements from one’s motivational set are relevant. E.g. desires don’t justify beliefs. Which elements are relevant? Why are those elements relevant? The relevant elements are the agent’s normative judgments. As mentioned before, there is a narrow and broad sense of normative judgments. The broad sense refers to general “should” statements that could simply serve as standards by which we can criticize and evaluate the behavior of others - this includes internal and external reasons. There is also a narrow sense that refers to internal “reasons” statements. The question is why this distinction is important and what is special/important about internal reasons statements. Consider reasons for belief. One could say that one has reason to believe just whatever is true. In a sense, this could be true. But it seems that there is another, independent role played by reasons statements about belief. Reasons in this more narrow sense are conferred to considerations that guide our deliberation as we decide what to believe. The fact that something is an external reason for belief - the fact that it’s true, for example - cannot be a consideration that one takes to be reason to decide their belief. I.e. if you asked someone why they believed X and they responded with “because X is true”, this would do nothing to explain their belief. We expect them to respond with an accessible feature of their motivational set - e.g. their other beliefs, their intuitions, their normative judgments, etc. Likewise, external reasons for action cannot be a consideration that someone takes to be a reason for action, unless we assume it’s already connected with their motivational set. E.g. if you asked someone why they did X, and they responded with “because X is kind” (yet they had no care for kindness), this wouldn’t really explain why they did X. Procedural Rationality There are two types of reasons: Internal: What could be entailed from the appropriate elements of an agent’s motivational set via some idealized procedure or set of conditions. The rational extension of one’s motivational set. External: general grounds for criticizing an agent, i.e. broad use of “should”. A general positive status that we confer to behaviors that we approve of. Why is the distinction important and what is special/important about internal reasons statements? Consider the earlier discussion of theoretical reasons. That is, reasons for beliefs must be internal to an agent’s perceptions, intuitions, etc. even though there is a sense in which it is appropriate to confer a positive status to certain beliefs on the basis of external reasons i.e. their truth. The reason is because, regardless of the appropriateness a attitude on externalist grounds, we need a system to confer status to attitudes on internalist grounds. There are times when we don’t have access to considerations that warrant approval of certain attitudes. In those circumstances, we still need to make a choice. Thus, we need a procedure that determines which attitudes are worth adopting. And we need an element of language to play this role in explaining this status. Internal reasons statements play this role. When we deliberate, we are trying to answer the question of which attitudes to adopt. During theoretical reasoning, we are determining what beliefs to adopt. During practical reasoning, we are determining what intentinos to adopt. Because theoretical reasoning involves determining whether a given proposition, say, P is true, the mere fact that P is true cannot possibly serve as a reason to believe P; at least not when “reason” is understood as the status we confer to beliefs during deliberation about what to believe. From the agent’s perspective, s/he begins unsure as to whether or not P is true and is trying to answer that question. He thus cannot use the fact that P is true as a reason to believe P. Similar considerations apply to practical reasoning. Practical reasoning involves determining whether a given intention X is to be adopted. Therefore, the mere fact that X is virtuous or kind or fair cannot serve as a reason to do X. Again, the agent begins unsure as to whether virtue or kindness or fairness is a reason to intend to something. Thus, the mere fact that an action has these properties cannot be taken as a reason for an intention. In general when deliberating, the only considerations that we can appeal to as reasons for action are considerations that we already accept to be reasons for action. There is no normative truth outside of what we take to be normative. The very activity of normative reasoning is to address conflicts in motivations. The problem to which normative thinking is designed to address is conflicts in our motivations. This means that normative thinking is not designed to track any mind-independent truth. Evenif it can be said that there is some mind-independent truth external to the world of the relevant kind, there is no way that this could relate to normative reasoning. Normative thinking is only answerable to our given motivations and normative judgments. Constructivist Argument Constructivism + Judgment Internalism = Existence Internalism Constructivism: A has a reason to X only if A’s normative judgments in some sense endorse X-ing. Judgment Internalism: A’s normative judgments endorse X-ing only if A has some motivation to X. Existence Internalism: A has a reason to X only if A has some motivation to X. Constructivism is actually a narrow form of existence internalism if we accept judgment internalism and if we believe one can have motivating reasons without judging them to be normative reasons. In that case, the motivating reasons corresponding to one’s normative judgments would be a strict subset of their motivational set. Of course, there is still the question of why we should accept constructivism in the first place. Constructivism Three categories of normative judgments Constituitive: normative judgments held by all agents insofar as they are rational Internal: normative judgments held by a particular agent, i.e. narrow use of “reason”. Or what is entailed from an agent’s normative judgments. External: grounds for criticizing an agent, i.e. broad use of “should” The question is why does the internal/external divide matter and why do internal reasons count as real reasons? The answer is this: There is a sense of reasons such that if an agent fails to do what he judges to be a reason R, then he is irrational. But this can be true only if the agent judges R to be an internal reason. I.e. if an agent fails to do what he endorses (i.e. an internal reason judgment), then he is irrational. But if he fails to do what he judges to be endorsed from some other perspective (which would be an external reason judgment), e.g. the moral perspective, then he is not being irrational. So reasons in the sense of being connected with rationality or irrationality must be internal. The property of being a reason is a status we confer give to considerations that we endorse upon deliberation. The question now is why assume rationality cannot be broadened to include substantive normative judgments, so that someone who fails to respond to e.g. moral reasons are irrational beause rationality requires being moral? Some Arguments Little ontological baggage. Allows for a credible epistemology. Explains many constituitive properties of certain normative domains. Explains existence internalism (assuming we accept judgment internalism). Doesn’t seem like reasons can be discarded as meaningless. One can’t ask “why be rational”. See: Christine Korsgaard, Sharon Street, (Bernard Williams?) The fact that X is a reason to Y for agent A is constituted by the fact that the judgment that X is a reason to Y (for A) withstands scrutiny from the standpoint of A’s other judgments about reasons. Note that X is never a reason in favor of Y, absolutely. X can only be in favor of Y for some particular agent, as determined by the standards set by the normative judgments of A himself. A normative judgment withstands scrutiny for an agent only if the agent could mantain the judgment in full awareness, which is determined by the constituitive standards of the attitude in question. For example, someone who judges that X is a reason to Y cannot also simultaneously and in full awareness judge that X is not a reason to Y (consistency is constitutive of normative judgments). Also, one cannot take oneself to have conclusive reason to Y without taking oneself to have reason to take the means to Y (means-end reasoning is constituitive of normative judgments). The force of cannot is not rational, but what is constituitive of the concept of forming normative judgments. These standards of correctness are legislated by the very person making the normative judgments. This allows that one can be genuinely mistaken about their normative judgments only insofar as they are not in full awareness of certain relevant features of their judgments. Disallowing Brute Error See “Constructing Ortagorean Objectivity.md” Theory of Error The basic idea is that we have reason to adopt attitude X if adopting attitude can be entailed from our current set of judgments. But how to account for agents who have false normative judgments? After all, such judgments are a part of their judgments, so it can be said to be “entailed” from their current set of judgments. The answer is that some normative judgments are strictly of higher priority than others. There are a few reasons for this: Judgment A sets the context for when judgment B is relavent. E.g. the difference between endorsing what you would endorse if unemotional, fully reflective, etc. versus what one endorses in the heat of the moment. The former is an endorsement about the kinds of conditions that determine when one’s actual endorsements are valid. Judgment A is constituitive of the very activity. Thus, it cannot be discarded in favor of A. E.g. judging that one has reason to adopt the means to meet an end is constitutive of adopting the end. Judgment A is extremely difficult to get rid of. E.g. relying on induction, memories, perceptions, caring about our future selves, etc. In fact, insofar as someone were able to not rely on these features, they would have psychological states completely unlike anything of our own. Part of the practice of establishing normative attitudes is establishing attitudes that regulate other attitudes. There is a hierarchy of normative judgments abound. Other considerations for favoring one judgment over another: It is more likely to acccomplish If there is no significant difference in any of the points mentioned above between two potential normative judgment, there is not necessarily a more “correct” position to adopt. Alternative conceptions of truth There are plenty of other domains of propositions whereby truth is based on something other than correspondence. The general structure is that one takes an attitude with regard to a proposition p, and then finds standards of correctness constituitive of the attitude. Consider the following examples: Descriptive judgments: Judgment S expresses a relation involving a description D and reality R, namely that D represents R. S is true if and only if D represents reality. Logical judgments: Judgment S expresses a relation involving a set of propositions P1 and another set of propositions P2, namely that P1 entails P2, i.e. the truth values constitutive of P1 are also constitutive of P2. S is true if and only if P1 entails P2. Modal judgments: Probabilistic judgments: Causal judgments: Counterfactual judgments: Rational Judgments Epistemic Rationality: Prudential Rationality: Moral Rationality: Under constructivism, for normative judgments, truth is not based on some correspondence to some mind-independent normative reality. There is no standard of correctness for normative judgments independent of what we ourselves decide to be valuable. There is no sense in determining that someone has a reason to do something if it cannot be inferred from what they actually judge themselves to have reason to do. If we remain committed to the correspondence theory of truth, we can abandon truth-aptness. Normative judgments are rationalility-apt. Normative propositions have the property of being rational or irrational, whereas descriptive propositions have the property of being true or false. Ascriptions of rationality can be siblings to ascriptions of truth, while not being reduced in those terms. This can be considered a form of quasi-truth. All the purported values of cognitivism can be withheld: Normative thinking is a rational enterprise. Certain normative judgments are better than others. The better normative judgments are independent of our actual judgments. Constituitive Features The central question is how to determine what requirements are constitutive of a type of behavior. One candidate is this: a requirement is constituitive of a behavior if no agent could consciously reject the requirement in full awareness. Logical Consistency. One basic constituitive feature of normative judgments (and thuoghts generally) is logical consistency. No person can consciously believe X and believe not-X in full awareness. General Consistency: Consistent/Coherent norms trump inconsistent/incoherent norms (This is required for all other constituive features to have force). Without a concern for consistency, an agent could not count as a normative reasoning agent. The very activity of normative reasoning is to address conflicts in motivations. Soundness: Norms endorsed under a sound state of mind trump norms endorsed under psychological compulsions, physical addictions, emotional disturbances, etc. Deliberation: Norms endorsed under deliberation trump unreflective dispositions that we discard under deliberation. Experience: Norms that maintain endorsement upon experiencing their outcome trump ends which are not. Full Information: Norms endorsed with full information trump norms based on false beliefs? Stability? Commonality? Epistemic The normativity of beliefs (against people who think the normativity of beliefs just reduce to their truth, so normativity is descriptive): We are all familiar with the idea of justifying beliefs. I.e. people who believe in Santa Clause who are exposed to the appropriate evidence have unjustified beliefs, people who believe in God (or lack belief if you’re religious), people with opposing beliefs about the efficacy of gun control, etc. Justification and truth are separate concepts, i.e. a belief can be justified yet false or unjustified yet true. So justification cannot be descriptive, as it is not concerned with truth. Normative principles come prior to descriptive beliefs. We need normative principles to establish descriptive beliefs. We need a procedure to proceed from evidential input - i.e. sensory perceptions, memories, intuitions, etc. - to belief outputs. We must establish what counts as evidence to make this inference. Deductive reasoning is required at a minimum. But this is not sufficient, we need induction, abduction, etc. Deductive: Basic constistency: we cannot believe P and ~P. Logical rules of inference: if P-&amp;gt;Q and P, then Q. Constraints on thought. We cannot help but follow logical constraints in our thinking. Subjective: Perceptions/memories: the reason that a perception that p provides one with reason to believe that p is because part of what it is to perceive p is to acquire an unreflective belief that p. If perceptions didn’t provide one with an unreflective belief that p, then perceiving that p would be like imagining that p, and this would not provide one with a reason to believe p. Similar considerations apply to memories. Abduction: Falsifiability Generality Parisomony (Occam’s Razor) Explanatory Induction: Past -&amp;gt; Future Observed -&amp;gt; Unobserved All of these are either: - Constraints on our thoughts. We cannot help but believe them. Or, - Things we don’t have to trust, but which we just so happen to do. This isn’t just something that individuals happen to trust, but that everyone happens to trust. If there were beings that didn’t abide by induction or abduction, then we wouldn’t call them irrational; they just wouldn’t have cognitive structures like our own. Normativity only deals with resolving conflicts. Thus, if induction, abduction, etc. are already adopted by most people, then we don’t need to justify them. This seems to be too low of a standard. It seems we can still question the validity of a belief system that is internally coherent and held by everyone else. E.g. think about beliefs about God back when everyone was religious. Why is this unjustified? Appeal to a more foundational principle that we all intuitive adopt, which is abduction. How do we know that abduction is more foundational than beliefs about God? (1) abduction is not a belief in that it is representation; it is a framework for establishing representations. (2) God is something we come to believe after engaging in abduction. (3) everyone participates in abduction, not everyone participates in believing God. Someone might say that they specifically place God on a more foundational level than abduction, but then their position wouldn’t be reasonable for other people. And usually, when we say X provides a reason to believe Y in circumstances C, we take that to be a universal claim, i.e. every agent has reason to take X to provide reason to believe Y in circumstances C. Reason is purely procedural. It is concerned with amelierating conflicts and striving for coherence of our aims. Beliefs are not justified in isolation. Rather they are justified based on their coherence with other beliefs. It may seem that all propositions must be justified in a non-circular non-infinite regress, and any beliefs that cannot be justified are irrational. This is the case only because of the context of ordinary uses of “rational” or “irrational”. When we talk of “rational” in the context of a debate, it usually applied to propositions that can be justified to all parties involved. However, even though propositions may not be justifiable in this sense (in the sense of collective support), they can justifiable to an individual (based on their coherence with the individual’s other beliefs). The “rational” sense as used in collective support is not constituitive of rationality itself (i.e. agents can be rational without jutsifying themselves to others), but having debates with others implicitly commits oneself to a constructed “game” where the rules are intersubjective justifiability. Objectivity: imagine people have widely divergent beliefs. Objectivity is possible when there happens to be an intersection in the beliefs held by these people. More specifically, it’s possible when there is an intersection in what these people judge to be solid methods for establishing truth. E.g. think of science. People might have widely different beliefs. But everyone agrees that one’s beliefs should cohere with their other beliefs, and we happen to be beings with sensory inputs that automatically impress beliefs within us (which means our beliefs must cohere with our sensory inputs), and our sensory inputs happen to converge a lot of the time. There are other features we happen to agree with as well (or can be shown to agree with), e.g. repeated observations from different independent sources/experiments provide more evidence for a hypothesis than one-offs, etc. It is this convergence that grounds the objectivity of science. I.e. two people might disagree over whether theory X or Y is true, but they can agree on method for determining whether X or Y is true, e.g. by appealing to observation, abduction, induction. Without this, objectivity is impossible. Even if we disagree on method, we can ideally point to a meta-principle that we both agree with (or can be shown to agree with) that settles which method is valid (e.g. reflective equilibrium). Methodology: There are no exhaustive general principles. There are only procedures for establishing principles and truths. Procedure -&amp;gt; Principles -&amp;gt; Truth. Conflicts must be handled by (1) reflective equilibrium - checking coherence with other beliefs/truths, and (2) by appeal to higher level principles that are agreed upon. Applies to individual beliefs and interpersonal disagreement. Prudential Constructivism provides an easy explanation of the following norms of practical reasoning. Constitutive Features End-Satisfaction: agents have reason to satisfy their ends. Instrumental: agents have reason to adopt the means to satisfy their ends. Time: agents have reason to satisfy the goals of their future self. Agents justified in criticizing the goals of our past selves. Other Features. May not be constitutive (?), but depend on features implicit in most people Conflict: how to deal with conflicting goals? Is there a goal hierarchy? Ends constitutive of one’s identity (i.e. valuing reflection) trump conflicting ends. Feasibility: goals which are more likely to be satisfied trump equivalent goals that cannot be satisfied. Pain/Suffering: pain/suffering provides one with reason to avoid it is precisely because people judge that they have reason to avoid it (or they have an unreflective aversion towards it). If a person had no (un)reflective aversion toward pain, then there would be no actual reason to avoid it. It is not the pure sensation of pain that provides us with reason to avoid it. Desires: a desire to X tends to provide one with reason to X because people tend to judge that they have reason to X if they desire to X, and all intentional actions are done because of some desire; otherwise, they would be involuntary actions. Against consequentialism For a particular agent, their reasons need not be consequentialist. For example, this is true insofar as the agent accepts that they have reason to hold certain attitudes, attitudes that cannot be reduced to merely promoting some desired state of affairs. For example, an agent might value friendship, meaning they think they have reason to be loyal to their friends, care about their interests, etc. These reasons are not reasons to promote some state of affairs. This would imply that there could be some end state of affairs that would justify them betraying these current reasons to reach that desired state, but this need not be what an agent has reason to do. In sum, not all reasons are teleological, i.e. all states of affairs are given some amount of weight which can be theoretically quantified which competes against are conflicting states of affairs. Instead, there reasons can be structural, where some features are given zero weight due to higher order reasons. Kinds of consequentialism: Maximizing - Define some good which can be quantified, we have most reason to act so as to promote that quantity. This can be disproven above. Trivial - Rank possible states of affairs according to how you judge yourself to have most reason to act. Have a complete ranking of all the states. Because constructivism is true, we have most reason to promote that state of affairs. This seems trivially true. Methodology Objectivity: There is no objectivity in the mind-independence sense. But there is a kind of objectivity in terms of what is constituitive of agency itself. E.g. in order to count as an agent who values anything, they must take themselves to have reason to adopt the means to fulfill their ends, they must value their capacity for agency, etc. One might doubt whether this is a important kind of objectivity. They might say: you are cheating by talking about what is valuable after presupposing someone is an agent. This isn’t really interesting. –&amp;gt; Response: this is the same kind of objectivity that we get with deductive reasoning. I.e. the only reason P -&amp;gt; P, ~(P ^ ~P), (P-&amp;gt;Q ^ P) -&amp;gt; Q, etc. is because of what it is to believe a proposition to be true. It is constituitive of belief that one not believe contradictions. Indeed, for “agents” without these tendencies, we wouldn’t be able to rationally persuade them otherwise. But it’s not clear that the concept of “rationality” even applies to them. They’re neither rational nor irrational. No one questions the objectivity here: —&amp;gt; One might still question its objectivity because it doesn’t have the mind-independence. In that case, I question if this usage of “objectivity” is interesting or important. What does it take to call something “objectivity”? I look to the role that “objectivity” plays in discourse. When we call something objectivity, we apply this to domains of propositions that (1) people can be mistaken about, (2) we can criticize others/ourselves about, (3) we can have improve about, (4) we can disagree about, etc. The characterization given thus far fulfills that role. —&amp;gt; Speaking of roles, think of normative “truth”. When we attribute the predicate TRUE to a normative judgment about what one ought to do, this implies something above and beyond typical desires: —&amp;gt; That that judgment will be more stable than other desires upon reflection. So reflective stability under ideal deliberation is a test for rationality among agents. Reflective stability under idealized conditions can be a test for the reasons of an agent (where the idealized conditions are the conditions that an agent endorses under ideal deliberation, i.e. full information, full experience, fully imaginative, etc.). Might stability under idealized social negotiation be a test moral reasons. Stability is one of the reasons why our value of reflection has normative authority over any conflicting unreflective judgments we might have. Another “kind” of objectivity. It may not be constituitive of agency per se, but it is nearly universal among humans: —&amp;gt; Standing in mutual recognition with other agents (i.e. being a moral agent). As an agent, one doesn’t have to care about this. But almost all agents do. Because for the ones who did not, they would have had a difficult time spreading their genes. Of course, evolutionarily, the circle of mutual recognition was often small, limited to one’s tribe or in-group. But we have the rational capacity to question whether differences between tribes are actually relevant, and most will conclude that they are not. This is not only evolutionarily necessary, it is also neurologically necessary for all current humans. Humans who are not touched and played with as infants either die or grow to have developmental disorders. —&amp;gt; A similar non-constituitive “tendency” that agents have is to value the values of their future self. This need not be constituitive of agency. However, it is near-universal among humans for very similar reasons as being a moral agent. For those who did not, they would have had a difficult time spreading their genes. Of course, our tendency to plan for the future is often limited based on certain factors (i.e. impulsivity, excitement, etc.), but we can question whether those considerations are rationally relevant, and most will conclude that they are not. [there is a further question as to whether caring for future selves commits one to care about other persons. This is a question I will not answer]. Different kinds of constituitive features: —&amp;gt; Constituitive of psychological attitudes: Fear -&amp;gt; Attributions of danger —&amp;gt; Constituitive of linguistic concepts: thick ethical concepts, coward -&amp;gt; attribution of fear —&amp;gt; Constructed social norms: moral norms -&amp;gt; impartial concern with others. Based on the role or function that the norms plays in our lives. Find the job description of morality. E.g. compare with ettiquette, science, etc. Morality is like thick ethical concepts in that sense. For that reason, they can sometimes be used non-motivationally, e.g. someone who sincerely (i.e. not in the “inverted comma” sense) says “X is a generous” might not have any motivation by focusing on the descriptive component of the thick ethical concept “generous” - i.e. that he give to others, etc. Likewise, someone can sincerely judge “X is wrong” without any motivational by focusing on the thick component of wrongness - i.e. that others have reason to blame one for this, that people motivated to stand in mutual recognition have reason to accept the norm, etc. The thick component here is also normative (i.e. it uses the concept of a reason), but it need not be motivational, because it relates to reasons for other people. So it may just express a disposition for motivation of the speaker in certain counterfactual circumstances. Desire Theories !!! danger “Deprecate” Delete this section. Consider the pros and cons of desire theories when discussing the merits of various forms of internalism. This examines theories for normative correctness that reduce in some way to an agents desires, whether first-order or higher-order, actual or hypothetical, etc. Humean Model The Humean theory of rationality states the following A has a reason to X if and only if (1) X promotes A’s desire d and (2) d is not based on any false beliefs. This can be simplified to: A has a reason to X if and only if X promotes a foundational (rather than derivative) desire in A. Desires are then the upshot of the following Full information Correct means-end deliberation (generation of a desire to X as a result of combining a desire to Y and a belief that X -&amp;gt; Y). Desires can be given three components: A certain positive or negative sensation A disposition to promote some state of affairs An unreflective normative judgment that one has reason to promote a state of affairs Not clear if an “urge” can be reduced to a sensation/disposition pair. Problems These are problems insofar as desires are divorced from normative judgments (e.g. plans, goals, etc.). Normativity of desires: Why would a desire, in terms of just sensations and dispositions, provide someone with reasons for action? Imagine someone had a disposition where they just felt the urge to turn on radios whenever they saw one but they didn’t think they had any reason to do so. Imagine A is injected with a drug that makes him crave the drug much more, and this is his strongest desire by far. Does he have most reason to take the drug? Disconnects: Assume the normativity of desires are accounted for. How to account for disconnects between an agent’s reasons and their desires? These disconnects can happen under physical addiction, emotional disturbances, psychological compulsions, etc. We sometimes have reasons without corresponding desires - e.g. weakness of will We sometimes have desires without corresponding reasons - e.g. addictions These cannot be accounted for with full information. There can be degenerate desires that are produced from, or persist despite, full information. Imagine that if a person became fully informed about all the germs on one’s hands, this would trigger a natural underived disgust reaction in the person, causing them to never touch anything directly and to constantly wash their hands everyday. Imagine that they are aware that the germs cause no actual danger or harm. They would be against coming into contact with germs because of an intrinsic disgust reaction, and they would think, all things else considered, satisfying their desire to reduce germs is more important than the sacrifice that doing so requires. The fact that full information would produce certain responses in people doesn’t make those responses rational. Priority: Assume the disconnect between reasons and desires is accounted for (perhaps by looking at a mode of desires). On this model, the authority of desires are simply based on their “strength”. How does this account for the authority we want to give to categorically superior desires? E.g. the priority of higher-order desires or desires under full experience, reflection, sound state of mind, etc. which may have low strength? How can we ground criticisms of fully informed desires that are based on inexperience, lack of reflection, unsound, etc.? Prudence: Why agents have reason to satisfy the desires of their future self? Dispositionalism / Sophisticated Humean Model The idealization for discovering reasons requires, at a minimum, full information and correct means-end-deliberation. Some other possibilities include. We can supplement the Humean model by incorportating other requirements: Fully Informed Correct means-end deliberation. Reflection - desires endorsed under reflection have priority over others Using imagination to determine how a desire would be satisfied. Deciding which desires one places most weight. Soundness - free of psychological compulsions, physical addictions, emotional disturbances. Fully Experienced - not merely knowledge of a proposition p, but exposure to a stimuli (i.e. a perception, an argument, etc.) that provokes the attitude. Systematically unified desires. Reasons = Full Experience + Full Information + Full Reflection + Sound mental state + … At bottom, the concern is that we are starting with an agent’s given motivational set and find a sound deliberative route or procedure with the aforemention properties to discover reasons. Some theories allow the creation/destruction of underived desires. Williams and Smith think this allows for the creation and destruction of underived desires via imagination and, for Smith, the focus on unification. Smith takes a more radical approach in that he believes certain seemingly arational desires (e.g. desiring value only one’s interests at the expense of others) are irrational. This is because some theories are “fully rational”, not merely fully informed, where “fully rational” extends beyond correct ends-means deliberation. This is necessary to handle irrational desires. Problems Hasn’t solved the following problems from above: Normativity of desires: why do mere sensations/dispositions even under idealized circumstances, in the absence of a normative judgment, provide a reason for action? It doesn’t seem that they do. Instead, we should focus on the normative judgments an agent would make (e.g. their plans, goals), under these idealized conditions. Unification: what do these conditions all have in common? It cannot just be that we all desire to satisfy the desires that we would have under these conditions because not everyone has this desire. Priority: assume everyone does actually desire the desires they would have under idealized conditions. What gives these desires the priority that they have? On desire-based theories, priority must be determined purely by “strength” and very often we can have desires that are stronger than our desire to satisfy the desires we would have under idealized conditions. ??? example “Ideal Observer” See: Peter Railton, Michael Smith Ideal agent vs Ideal Observer: *Ideal agent*: an agent A has reason to X in circumstances C if and only if an ideal version of themselves, A+, would desire to X in C. *Ideal Observer*: an ideal agent A has reason to X in circumstances C if and only if an ideal version of the agent, A+, would desire that A desires to X in C. *Observer-based not agent-based.* The reasons that X has reduces to whether A+ would desire A to desire X, not whether A+ would desire X. This is because doing otherwise cannot account for reasons under uncertainty. Consider the case when one has reason to seek new information. A fully informed being would have no desire to seek information, even though they have reason to do so. It's not clear why this means we should focus on observers rather than agents. For example, imagine the case where someone drinks a glass of soda that they believe to be water and they desire to drink water. We can easily say that they have reason to not drink from the glass, even though they do have reason to drink from the glass given the information that they have. In this case, there is no problem with saying someone has most reason to do something which they have no rational way of endorsing given their currently held beliefs. Likewise, it seems we can say that people don't actually have reason to seek information, but rather they have reason to seek information given their currently held beliefs. There is no problem with saying, for example, that someone lost in the woods has most reason to take route X, even though this is not something which they have a rational way of endorsing given their currently held beliefs. **Problems** - They cannot account for degenerate idealized counterparts. What if a fully idealized counterpart, A+, desired that his less idealized counterpart, A, do something that he didn't have reason to do? What if A+ was viscious? The only way to avoid this conclusion is by assuming that some desire or concern for the sake of others is somehow constitutive of a fully rational agent. But this seems dubious. This is especially dubious for theories that allow any non-self-defeating desire in principle to be rational (unlike, e.g. Smith who thinks that something like this might be constitutive of a fully rational agent). But these seem like poor candidates for an analysis as they are assuming substantive desires as being rational in their analysis... This, combined with the earlier notes on ideal observer, might be enough to ignore the observer aspect and focus on the agent. We can distinguish what to do under uncertainty versus full information by distinguishing rationality and reasons. - ~~~They cannot account for rationality in general. Take an analysis of reasons for belief. A world-to-mind fit analysis might say &quot;A has reason to believe X in C iff an idealized version of himself, A+, would desire that A believed X in C&quot;. But this certainly does not seem to be true. Let's assume A+ is concerned ultimately with the welfare of A above all else (which is a dubious assumption as mentioned earlier). Then this certainly makes it possible for there to be cases where A+ desires that A believes X even though A has normative reason to not believe X, e.g. if believing X made A's life worse, even though it was justified. Theories about the direct beliefs of A+ (i.e. &quot;A has reason to believe X iff an idealized version of himself, A+, would believe X in those circumstances&quot;) fail because (1) insofar as the idealization involves full information, this is flawed because the reasons to hold a belief are not determined by the truth of that belief, and (2) insofar as the idealization involves full rationality, it is circular.~~~ Actually, this can account for rationality in general. The full information requirement is not to account for *rationality*, but to account for *reasons*. It is full information + rationality that provides reasons. The account of rationality is independent from full information, and this account can be extended to other domains. General Problems General problems with desire accounts and counterfactual attitude accounts. The elements posited as providing reasons (desires, informed desires, motivations, ideal desires, ideal observer’s desires, etc.) don’t necessarily provide reasons, i.e. when they disconnect with an agent’s normative judgments. Consider a case where dispositionalism (but not constructivism) would say someone has reason. On what grounds can the person be said to have that reason if they are not in some way committed to the action? Insofar as they do provide reasons, constructivism explains why they provide reasons, why they matter and a unifying theme explaining the authority of the elements that do matter. E.g. if certain features are constituitive of agency, caring about desires under experience, future desires, etc. Constructivism can give a clean general account of all reasons. How to give a metaphysical account of reasons for belief? One response is that one has reason to believe P only if they would believe P in circumstance P. How to account for a reason to believe that counterfactual? The response is that one has reason to believe that they would believe P in circumstances C iff they would believe that “they would believe P in circumstances C” in circumstances C. This is circular… This may not actually be an issue on the metaphysical/epistemic level. It may still be an issue on the linguistic/psychological level, however.</summary></entry></feed>