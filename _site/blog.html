<!DOCTYPE html><html lang="en">
  <head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no"><title>Blog - Your Site Title</title>

<meta name="description" content="Your Site Description
">
<link rel="canonical" href="http://localhost:4000/blog.html"><link rel="alternate" type="application/rss+xml" title="Your Site Title" href="/feed.xml"><!-- start favicons snippet, use https://realfavicongenerator.net/ --><link rel="apple-touch-icon" sizes="180x180" href="/assets/apple-touch-icon.png"><link rel="icon" type="image/png" sizes="32x32" href="/assets/favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="/assets/favicon-16x16.png"><link rel="manifest" href="/assets/site.webmanifest"><link rel="mask-icon" href="/assets/safari-pinned-tab.svg" color="#fc4d50"><link rel="shortcut icon" href="/assets/favicon.ico">

<meta name="msapplication-TileColor" content="#ffc40d"><meta name="msapplication-config" content="/assets/browserconfig.xml">

<meta name="theme-color" content="#ffffff">
<!-- end favicons snippet --><link rel="stylesheet" href="/assets/css/main.css"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.0.13/css/all.css" ><!-- start custom head snippets -->

<!-- end custom head snippets --><script>(function() {
  window.isArray = function(val) {
    return Object.prototype.toString.call(val) === '[object Array]';
  };
  window.isString = function(val) {
    return typeof val === 'string';
  };

  window.hasEvent = function(event) {
    return 'on'.concat(event) in window.document;
  };

  window.isOverallScroller = function(node) {
    return node === document.documentElement || node === document.body || node === window;
  };

  window.isFormElement = function(node) {
    var tagName = node.tagName;
    return tagName === 'INPUT' || tagName === 'SELECT' || tagName === 'TEXTAREA';
  };

  window.pageLoad = (function () {
    var loaded = false, cbs = [];
    window.addEventListener('load', function () {
      var i;
      loaded = true;
      if (cbs.length > 0) {
        for (i = 0; i < cbs.length; i++) {
          cbs[i]();
        }
      }
    });
    return {
      then: function(cb) {
        cb && (loaded ? cb() : (cbs.push(cb)));
      }
    };
  })();
})();
(function() {
  window.throttle = function(func, wait) {
    var args, result, thisArg, timeoutId, lastCalled = 0;

    function trailingCall() {
      lastCalled = new Date;
      timeoutId = null;
      result = func.apply(thisArg, args);
    }
    return function() {
      var now = new Date,
        remaining = wait - (now - lastCalled);

      args = arguments;
      thisArg = this;

      if (remaining <= 0) {
        clearTimeout(timeoutId);
        timeoutId = null;
        lastCalled = now;
        result = func.apply(thisArg, args);
      } else if (!timeoutId) {
        timeoutId = setTimeout(trailingCall, remaining);
      }
      return result;
    };
  };
})();
(function() {
  var Set = (function() {
    var add = function(item) {
      var i, data = this._data;
      for (i = 0; i < data.length; i++) {
        if (data[i] === item) {
          return;
        }
      }
      this.size ++;
      data.push(item);
      return data;
    };

    var Set = function(data) {
      this.size = 0;
      this._data = [];
      var i;
      if (data.length > 0) {
        for (i = 0; i < data.length; i++) {
          add.call(this, data[i]);
        }
      }
    };
    Set.prototype.add = add;
    Set.prototype.get = function(index) { return this._data[index]; };
    Set.prototype.has = function(item) {
      var i, data = this._data;
      for (i = 0; i < data.length; i++) {
        if (this.get(i) === item) {
          return true;
        }
      }
      return false;
    };
    Set.prototype.is = function(map) {
      if (map._data.length !== this._data.length) { return false; }
      var i, j, flag, tData = this._data, mData = map._data;
      for (i = 0; i < tData.length; i++) {
        for (flag = false, j = 0; j < mData.length; j++) {
          if (tData[i] === mData[j]) {
            flag = true;
            break;
          }
        }
        if (!flag) { return false; }
      }
      return true;
    };
    Set.prototype.values = function() {
      return this._data;
    };
    return Set;
  })();

  window.Lazyload = (function(doc) {
    var queue = {js: [], css: []}, sources = {js: {}, css: {}}, context = this;
    var createNode = function(name, attrs) {
      var node = doc.createElement(name), attr;
      for (attr in attrs) {
        if (attrs.hasOwnProperty(attr)) {
          node.setAttribute(attr, attrs[attr]);
        }
      }
      return node;
    };
    var end = function(type, url) {
      var s, q, qi, cbs, i, j, cur, val, flag;
      if (type === 'js' || type ==='css') {
        s = sources[type], q = queue[type];
        s[url] = true;
        for (i = 0; i < q.length; i++) {
          cur = q[i];
          if (cur.urls.has(url)) {
            qi = cur, val = qi.urls.values();
            qi && (cbs = qi.callbacks);
            for (flag = true, j = 0; j < val.length; j++) {
              cur = val[j];
              if (!s[cur]) {
                flag = false;
              }
            }
            if (flag && cbs && cbs.length > 0) {
              for (j = 0; j < cbs.length; j++) {
                cbs[j].call(context);
              }
              qi.load = true;
            }
          }
        }
      }
    };
    var load = function(type, urls, callback) {
      var s, q, qi, node, i, cur,
        _urls = typeof urls === 'string' ? new Set([urls]) : new Set(urls), val, url;
      if (type === 'js' || type ==='css') {
        s = sources[type], q = queue[type];
        for (i = 0; i < q.length; i++) {
          cur = q[i];
          if (_urls.is(cur.urls)) {
            qi = cur;
            break;
          }
        }
        val = _urls.values();
        if (qi) {
          callback && (qi.load || qi.callbacks.push(callback));
          callback && (qi.load && callback());
        } else {
          q.push({
            urls: _urls,
            callbacks: callback ? [callback] : [],
            load: false
          });
          for (i = 0; i < val.length; i++) {
            node = null, url = val[i];
            if (s[url] === undefined) {
              (type === 'js' ) && (node = createNode('script', { src: url }));
              (type === 'css') && (node = createNode('link', { rel: 'stylesheet', href: url }));
              if (node) {
                node.onload = (function(type, url) {
                  return function() {
                    end(type, url);
                  };
                })(type, url);
                (doc.head || doc.body).appendChild(node);
                s[url] = false;
              }
            }
          }
        }
      }
    };
    return {
      js: function(url, callback) {
        load('js', url, callback);
      },
      css: function(url, callback) {
        load('css', url, callback);
      }
    };
  })(this.document);
})();
</script><script>
  (function() {
    var TEXT_VARIABLES = {
      version: '2.2.4',
      sources: {
        font_awesome: 'https://use.fontawesome.com/releases/v5.0.13/css/all.css',
        jquery: 'https://cdn.bootcss.com/jquery/3.1.1/jquery.min.js',
        leancloud_js_sdk: '//cdn1.lncld.net/static/js/3.4.1/av-min.js',
        chart: 'https://cdn.bootcss.com/Chart.js/2.7.2/Chart.bundle.min.js',
        gitalk: {
          js: 'https://cdn.bootcss.com/gitalk/1.2.2/gitalk.min.js',
          css: 'https://cdn.bootcss.com/gitalk/1.2.2/gitalk.min.css'
        },
        valine: 'https://unpkg.com/valine/dist/Valine.min.js',
        mathjax: 'https://cdn.bootcss.com/mathjax/2.7.4/MathJax.js?config=TeX-MML-AM_CHTML',
        mermaid: 'https://cdn.bootcss.com/mermaid/8.0.0-rc.8/mermaid.min.js'
      },
      site: {
        toc: {
          selectors: 'h1,h2,h3'
        }
      },
      paths: {
        search_js: '/assets/search.js'
      }
    };
    window.TEXT_VARIABLES = TEXT_VARIABLES;
  })();
</script></head>
  <body>
    <div class="root" data-is-touch="false">
      <h1>Latest Posts</h1>

<ul>
  
    <li>
      <h2><a href="/jekyll/update/2019/06/19/welcome-to-jekyll.html">Welcome to Jekyll, yeah yeah!</a></h2>
      <p></p>
<p>You’ll find this post in your <code class="highlighter-rouge">_posts</code> directory. Go ahead and edit it and re-build the site to see your changes. You can rebuild the site in many different ways, but the most common way is to run <code class="highlighter-rouge">jekyll serve</code>, which launches a web server and auto-regenerates your site when a file is updated.</p>

<p>To add new posts, simply add a file in the <code class="highlighter-rouge">_posts</code> directory that follows the convention <code class="highlighter-rouge">YYYY-MM-DD-name-of-post.ext</code> and includes the necessary front matter. Take a look at the source for this post to get an idea about how it works.</p>

<p>Jekyll also offers powerful support for code snippets:</p>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="k">def</span> <span class="nf">print_hi</span><span class="p">(</span><span class="nb">name</span><span class="p">)</span>
  <span class="nb">puts</span> <span class="s2">"Hi, </span><span class="si">#{</span><span class="nb">name</span><span class="si">}</span><span class="s2">"</span>
<span class="k">end</span>
<span class="n">print_hi</span><span class="p">(</span><span class="s1">'Tom'</span><span class="p">)</span>
<span class="c1">#=&gt; prints 'Hi, Tom' to STDOUT.</span></code></pre></figure>

<p>Check out the <a href="https://jekyllrb.com/docs/home">Jekyll docs</a> for more info on how to get the most out of Jekyll. File all bugs/feature requests at <a href="https://github.com/jekyll/jekyll">Jekyll’s GitHub repo</a>. If you have questions, you can ask them on <a href="https://talk.jekyllrb.com/">Jekyll Talk</a>.</p>


    </li>
  
    <li>
      <h2><a href="/2019/06/19/Race-and-IQ.html">Race and iq</a></h2>
      <p></p>
<h2 id="introduction">Introduction</h2>

<ul>
  <li>Current Differences</li>
  <li>Historical Differences</li>
  <li>Global Differences</li>
  <li>Differences show before school</li>
</ul>

<p>“One of the most serious misrepresentations in Rushton and Jensen’s (2005) article is their claim that the current difference in IQ between Blacks and Whites is slightly more than 15 points, or 1 standard deviation. The best evidence we have indicates that that value is out of date and that the Black–White IQ gap has lessened considerably in recent decades (Grissmer, 1994; Grissmer, Flanagan, &amp; Williamson, 1998; Grissmer, Williamson, Kirby, &amp; Berends, 1998; Hedges &amp; Nowell, 1998; Nisbett, 1995, 1998). We do not have actual IQ scores available to establish this point but rather various ability tests, most of which are highly correlated with IQ—some as high as .8 to .9. Though IQ scores would be preferable to speak directly to the question of IQ change, such data are unavailable in the form of a national random sample. In contrast, several probability samples of U.S. elementary and high school students are available. These include, over the period 1965–1994, the Equality of Educational Opportunity (EEO) survey, the National Longitudinal Study, the High School and Beyond survey, the National Education Longitudinal Study, and the National Assessment of Educational Progress program (NAEP).”</p>

<p>“The gap is substantially less than that at the present time, probably more like 0.6–0.7 standard deviation or approximately 10 IQ points.”</p>

<p>http://www1.udel.edu/educ/gottfredson/30years/Nisbett-commentary-on-30years.pdf</p>

<h3 id="traditional-explanations">Traditional Explanations</h3>

<ul>
  <li>Income</li>
  <li>Segregation</li>
  <li>Poverty</li>
  <li>School Funding</li>
  <li>Socioeconomic status generally</li>
  <li>Parental Education</li>
</ul>

<ol>
  <li>These explain very little of the gap</li>
  <li>To the extent that they do explain the gap, it is not clear how much of this can be attributed to genetic confounding</li>
</ol>

<p>Permanent income explains more?</p>

<h3 id="heritability">Heritability</h3>

<p>It is certainly possible that the Black-White IQ difference is largely genetic. There’s no law of biology that forbids this. After all, IQ <a href="https://en.wikipedia.org/wiki/Heritability_of_IQ">is largely heritable</a>, which means much of the <em>individual</em> variation in IQ is the result of genes. However, the extent to which IQ differences between Blacks and Whites (or any <em>groups</em>) is due to genes is a further question. To answer this question, we must <em>quantify</em> the genetic component of the racial IQ gap. So we need <em>direct</em> experiments/studies that isolate and quantify the environmental and genetic influences. Transracial adoption studies, I believe, are best suited to fulfill this purpose. I know of only four transracial adoption studies involving Blacks. I will consider each:</p>

<ol>
  <li>Problems: (1) They are typically used for a restricted range of elite environments. Heritability depends on population. Cannot be extrapolated to different environments. And (2) often, twins raised apart are in the same town, sometimes even by relatives</li>
  <li>Don’t indicate how much genetics cause a trait (e.g. see weight)</li>
  <li>Says nothing about between-group heritability</li>
  <li>Says nothing about how they are influenced by environmental changes (e.g. see Dyslexia, weight, height)</li>
</ol>

<p>Heritability tells us: if everyone in a specific population were placed in the average environment, how much variation would remain?</p>

<p>We want to know: if Blacks were raised in the same environment as whites, how much variation would remain?</p>

<h3 id="methodology">Methodology</h3>

<p>What kind of data matters</p>
<ul>
  <li>Data that (1) isolates the effects of either genetic or environmental factors and (2) quantifies the effect of that factor</li>
  <li>Data which does not quantify should not be considered - e.g. differences in brain size or reaction times and correlations of brain size with IQ do not reliably quantify IQ differences (also, it’s not clear how much of these differences can be attributed to environmental factors).</li>
</ul>

<h2 id="environmental-displacements">Environmental Displacements</h2>

<p>Includes black children raised not in typical environments</p>

<h3 id="minnesota-transracial-adoption-study">Minnesota Transracial Adoption Study</h3>

<p>This one is fairly popular, so I need not give it too much detail. Basically, the study examined the IQs of mixed children, black children, and white children who were adopted by white families. The study found higher IQ for the whites adoptees compared to the black and mixed adoptees <a href="http://www.kjplanet.com/amp-31-10-726.pdf">[1]</a>. If this study did indeed equalize the environments for blacks &amp; whites, then the results would seem to indicate that the IQ gap is largely genetic. However, there are a few reasons to doubt that the study equalized the environments for blacks &amp; whites:</p>

<p>(a) the black children were adopted substantially later than the other children. The average white child was adopted at 19 months old, but the average black child was adopted at 32 months old <a href="http://www.kjplanet.com/amp-31-10-726.pdf">[2]</a>. The study showed that late adoptees had much lower IQs than early adoptees, e.g. black/mixed children adopted within one year of birth had a mean IQ of 99, whereas later adopted black/mixed children had a mean IQ of 92 <a href="https://lesacreduprintemps19.files.wordpress.com/2012/12/the-minnesota-transracial-adoption-study-a-follow-up-of-iq-test-performance-at-adolescence1.pdf">[3]</a> (there was no information on the effect of time of placement for the White children). Disparities in age of adoption could have instigated or exaggerated IQ disparities.</p>

<p>(b) Even though the study did somewhat equalize environments <em>after</em> adoption, it could not have equalized environments <em>before</em> adoption. This is particularly important given the late ages of adoption that I mentioned in (a). For example, a high blood lead level in infants can result in a noticeable reduction in IQ during adulthood: one study <a href="http://www.precaution.org/lib/low-level_lead_longterm_followup.19921001.pdf">[4]</a> found that a 10 μg/dL increase in blood lead level for infants aged 24-months was associated with a 5.8-point decline in their age-10 IQ, and an 8.9-point decline in their age-10 KTEA Battery Composite Score (normalized to a mean of 100 and SD of 15, just like IQ scores). Blood lead level might have been particularly important for the MTAS because, when it was first published in the 1970s, black children aged 6 months-5 years had much higher blood lead levels than similarly aged white children: over half of black children (52%) in this age range had a blood lead level greater than 20 μg/dL, compared to only 18% of white children <a href="http://www.cdc.gov/nchs/data/ad/ad079acc.pdf">[5]</a>. Thus, blood lead level disparities (and any other potential pre-adoption environmental disparities) could have instigated or exaggerated IQ disparities.</p>

<p>It should be noted that despite little-to-no IQ gains, the black and mixed children saw much higher levels of academic achievement than their non-adopted racial peers. The mixed adoptees scored in the 60th, 59th, 50th, and 40th percentiles in vocabulary scores, reading scores, mathematics scores, and class rank, respectively <a href="https://lesacreduprintemps19.files.wordpress.com/2012/12/the-minnesota-transracial-adoption-study-a-follow-up-of-iq-test-performance-at-adolescence1.pdf">[6]</a>. For reference, the White adoptees scored in the 62th, 58th, 56th and 54th percentiles in those respective areas. The Black adoptees scored worse; they scored in the 54th, 48th, 36th, and 36th percentile. Considering the potential issues mentioned with (a) and (b), a 36 percentile is not <em>that</em> low (e.g. an IQ score in the 36th percentile is ~95). So while the black adoptees had significantly lower IQs, their academic achievement was not much lower than average.</p>

<p>In summary, ignoring the two issues raised by (a) and (b), this study seems compatible with a mainly genetic explanation of the IQ gap. However, the study is compatible with an environmental explanation of the <em>academic achievement</em> gap. Of the four adoption studies here, this is the study most in favor of a genetic explanation of the IQ gap, yet it <em>still</em> suggests that academic disparities are mainly environmental.</p>

<p>Other Problems:</p>

<p>“But perhaps the widening interracial differences in the MTRAS were genetically driven despite Rushton and Jensen’s error? Probably not, because attrition can explain the apparent widening. A total of 25 White adoptees were in the study when it began, nine of whom were lost at follow-up. The lost adoptees had relatively low IQs, so the remaining White adoptees were unrepresentatively high in IQ, as Mackintosh observed [25]. One can prove this by comparing the original IQs of the full sample and the subgroup who were measured at both ages 7 and 17; the latter subgroup had an initial mean IQ of 117.6 (with a minimum IQ of 92) but the full sample had an initial mean of 111.5 (minimum 62). Because initial and final IQs had a correlation of 0.63 among the White group, the elite subgroup would likely have had their final mean IQ inflated by about 0.63 × (117.6 − 111.5) = 3.8 points. Meanwhile, the BW and Black–Black adoptees lost to follow-up hardly differed in IQ from the remaining adoptees, so attrition inflated those groups’ mean IQs by about only 0.2 and −0.7 points respectively.”</p>

<p>“With the widening explained, the only racial IQ differences left to comment on are those present at initial testing. The scant initial gap of 2.5 ± 3.5 points between the fully White and BW adoptees is small enough to be simple statistical noise. Only the IQ of the Black–Black adoptees, who scored 12.2 ± 2.8 points below the BW adoptees, calls for a specific explanation. Differences in home environment are one possibility. On every reported environmental variable, the Black–Black adoptees were worse off than both the BW and fully White adoptees, which I quantify by comparing the former against the BW adoptees, measuring the environmental differences in BW SDs. I use the BW adoptees as a comparison group here because Scarr and Weinberg [13] present more data for BW adoptees than White adoptees. The Black–Black adoptees were older when adopted (by 2.1 SDs, or two years); had spent less time in their adoptive home (by 1.1 SDs); had more (by 0.4 SDs) and lower-quality (by 0.8 SDs) adoptive placements; and had adoptive parents with less education and lower mean IQ (by 0.2–0.3 SDs). Additionally, 97% of the BW adoptees had White mothers while the Black–Black adoptees all had Black mothers, with whatever prenatal environmental differences that entailed.”
https://www.mdpi.com/2079-3200/5/1/1/htm</p>

<h3 id="german-iq-study-by-klaus-eyferth">German IQ study by Klaus Eyferth</h3>

<p>Psychologist Klaus Eyferth studied the IQs of white and mixed children in Germany. The mothers of the children were all white. Their fathers were either white or black members of the US occupation forces. The white children had a mean IQ of 97.2, whereas the mixed children had a mean of 96.5, a negligible difference <a href="http://en.wikipedia.org/wiki/Eyferth_study">[7]</a>.</p>

<p>There are some issues with this study, however. Firstly, the samples aren’t representative of the average population, because about 30% of black applicants were rejected admission to the armed forces, while only about 3% of whites were rejected. However, despite the unrepresentative sample, if racial IQ differences were mainly genetic, the white children should have had much higher scores than the mixed children because:</p>

<p>(a) The white GIs should have had higher IQs than the black GIs. Even though the admission test filtered out candidates below a certain threshold, the IQ scores for the white soldiers would <em>still</em> be distributed higher than that of the black soldiers (e.g. imagine removing all men and all women below 5’2 from the population; the resulting population would still have men taller than women, on average). If the IQ gap were mainly genetic, then this difference should manifest itself in their children.</p>

<p>(b) <a href="https://en.wikipedia.org/wiki/Heritability#Response_to_selection">Regression to the mean</a>. Even if we assume that the white and black soldiers had similar IQs, the black children should have had lower IQs than the white children because, assuming that the racial IQ gap is mainly genetic, the black children IQs would regress to the genetic black mean, while the white children IQs would regress to the genetic white mean. Philippe Rushton and Arthur Jensen, by far two of the most prominent supporters of genetic racial IQ differences, <a href="http://www1.udel.edu/educ/gottfredson/30years/Rushton-Jensen30years.pdf">agree that</a> (go to section 9) this regression should occur insofar are racial IQ differences are genetic:</p>

<blockquote>
  <p>For any trait, scores should move toward the average for that population. So in the United States, genetic theory predicts that the children of Black parents of IQ 115 will regress toward the Black IQ average of 85, whereas children of White parents of IQ 115 will regress toward the White IQ average of 100.</p>
</blockquote>

<p>So if racial IQ differences are mainly genetic, then regression to the mean should occur. This means that even if the black GIs and white GIs had similar IQs, the mixed children should have considerably lower IQs. Note that regression to the mean is found in other genetic traits such as height. This regression is quantified by geneticists by an equation known as “breeder’s equation”.</p>

<p>“The most detailed summary of this study in English is found in Flynn (1980). Eyferth sampled roughly 5 percent (N = 181) of the children known to have been fathered by black French and American soldiers between 1945 and 1953. He then constructed a matched sample of 83 children fathered by white soldiers. The two samples were matched only on characteristics of the mother and location, not characteristics of the father, which were largely unknown. Eighty percent of the black fathers were American and 20 percent were French Africans. Flynn reports that in the U.S. army of occupation the black-white gap on the Army General Classification Test (a predecessor of the AFQT) was about four-fifths that in the general population.”</p>

<p>=&gt; The Black GIs did score significantly worse on the Army Classification Test</p>

<p>https://www.brookings.edu/wp-content/uploads/2013/01/9780815746096_chapter1.pdf</p>
<h3 id="british-study-of-young-children-in-nurseries">British study of young children in nurseries</h3>

<p>In this study, psychologist Barbara Tizard studied black, white, and mixed children raised in British long-stay residential nurseries. The children were given psychological tests to determine their cognitive abilities. The scores were normalized to give a mean of 100 and standard deviation of 10. On the Reynell Comprehension test, the white children scored 102.6 and the black/mixed children scored 106.3. On the Reynell Expression test, the white children scored 98.5 and the black/mixed children scored 98.6. On the Minnesota Nonverbal test, the white children scored 101.3 and the black/mixed children scored 107.7 <a href="http://www.jstor.org/stable/pdf/1127540.pdf?acceptTC=true">[8]</a>. Apparently there is a fourth test, but I didn’t manage to see it in the pdf. In any case, this study is compatible with a mainly environmental explanation of the IQ gap.</p>

<h3 id="iq-scores-of-black-children-raised-by-white-families-versus-black-families">IQ scores of black children raised by White families versus Black families</h3>

<p>In this study, psychologist Elsie Moore compared IQ test scores among 23 black children adopted by middle-class white families and 23 age-matched black children adopted by middle-class black families. The black children adopted by black families scored a 104 IQ, while the black children adopted by white families scored a 117 IQ <a href="http://psycnet.apa.org/psycinfo/1986-24139-001">[9]</a>. These two groups of blacks likely differed in their <em>environment</em> and not their <em>genes</em>. Therefore, the difference in the black/white family environments likely accounts for the 13 IQ point gap. Keep in mind that the black &amp; white families were of similar socioeconomic status (middle-class). In actuality, the average black family has a much lower socioeconomic status than the average white family; therefore the difference in black/white environments would probably account for more than 13 IQ points. Clearly, this study is compatible with a mainly environmental explanation of the IQ gap.</p>

<p>The significance of the Moore study is not just the high IQ of the Black children; this demonstrates that the environment of the Black parents is not as conducive to cognitive development as the environment of the White parents. I don’t know the cause of this disparity (different people would argue for different causes, e.g. lead, peer groups, parenting, wealth, schools, culture, neighborhoods, etc.), but it’s clear from this study that Black and White <em>environments</em> have significantly different effects on IQ. And this environmental difference persists even though both groups of parents are <em>upper-middle class</em>. Imagine what the difference would be if we did <em>not</em> ensure that both parents were upper-middle class. If the Black parents were, say, disproportionately poor (as is the case in reality), then we would expect that 13-point IQ difference to widen.</p>

<p>=&gt; Also, “She examined the IQs of Black and mixedrace children averaging 8.5 years of age who were adopted by middle-class families who were either Black or White. The children who were of half-European origin had virtually the same average IQ as the children who were of exclusively Black origin. Hence European genes were of no advantage to this group of “Blacks.”</p>

<p>https://pdfs.semanticscholar.org/c03f/f20904c35a370534a9d3710453dd6dc7a2d2.pdf</p>

<h3 id="iqs-of-mixed-children-with-a-white-versus-black-mother">IQs of mixed children with a White versus Black mother</h3>

<p>“If the Black–White IQ gap is largely hereditary, then children having one Black and one White parent should have the same IQ on average, regardless of which parent is Black. But if one assumes that mothers are particularly important to the intellectual socialization of their children and if the socialization practices of Whites are more favorable to IQ development than those of Black mothers, then children of White mothers and Black fathers should have higher IQs than children of Black mothers and White fathers. This could of course not have a plausible genetic explanation. In fact, it emerges that children of White mothers and Black fathers have IQs 9 points higher than children with Black mothers and White fathers (Willerman, Naylor, &amp; Myrianthopoulos, 1974). This result in itself suggests that most of the Black–White IQ gap is environmental in origin. But because mothers are not the only environmental influence on the child’s IQ, the 9-point difference might be regarded as a very conservative estimate of the environmental contribution to the gap”</p>

<p>http://www1.udel.edu/educ/gottfredson/30years/Nisbett-commentary-on-30years.pdf</p>

<p>“Willerman, Naylor, and Myrianthopoulos (1974) studied 129 four-year-olds, 101 of whom were raised by a white mother and 28 of whom were raised by a black mother. Among the married mothers the 50 children raised by a white mother and a black father had mean IQs of 104.7, while the 17 children raised by a black mother and a white father had mean IQs of 96.4. Among single mothers, who provide a cleaner comparison of the effects of growing up in a “white” rather than a “black” environment, the 51 children raised by a white mother had mean IQs of 99, while the 11 children raised by a black mother had mean IQs of 88.”</p>

<p>https://www.brookings.edu/wp-content/uploads/2013/01/9780815746096_chapter1.pdf</p>

<h2 id="european-ancestry-and-iq">European Ancestry and IQ</h2>

<p>“There are numerous studies of the association between skin color and IQ. Skin color can be used as at least a weak proxy for racial admixture. We can ask whether lighter, presumably more European, skin is associated with higher IQ. Of course, if it were, this would constitute only modest support for the genetic hypothesis because there would be valid grounds for assuming that more social and economic advantages accrued to people with relatively light skin than to people with relatively dark skin and that these advantages would be reflected in higher IQs. In fact, however, the correlation between lightness of skin and IQ, averaged over a large number of studies reviewed by Shuey (1966), is in the vicinity of .10. The average correlation between IQ and judged “Negroidness” of features is even lower.”</p>

<p>“Different races have different frequencies of various blood groups. If the hereditarian model is correct, Blacks having more blood groups characteristic of Europeans should have higher IQs. But Sandra Scarr and her colleagues (Scarr, Pakstis, Katz, &amp; Barker, 1977) found that the correlation between IQ and “European” heritage among Blacks as measured by blood groups was only .05 in a sample of 144 Black adolescent twin pairs. They found a typical correlation of .15 between skin color and IQ, which suggests that the comparable correlations between skin color and IQ in other studies are due not to more European genes on the part of light-skinned Blacks but to social and economic advantages accruing to individuals with lighter skin”</p>

<p>http://www1.udel.edu/educ/gottfredson/30years/Nisbett-commentary-on-30years.pdf</p>

<h2 id="conclusion">Conclusion</h2>

<h3 id="objections">Objections</h3>

<p>Many have criticized the three latter studies because they did not do follow-up testing on the children. The claim is that the heritability of IQ increases as people age (which is true); thus the IQ gains from the improved environment may fade as the impact of environment diminishes with age. I have three responses to this:</p>

<p>(1) The potential decline in IQ gains for adopted children is not necessarily relevant. We are concerned with the IQ <em>gap</em> between blacks &amp; whites. The Minnesota Transracial Study implies that there is no significant change in the IQ <em>gap</em> after age 7, even though the IQ gains diminished for all racial groups. Looking at this study, the black-white IQ gap fluctuated by only about 2 points after age 7. Therefore, assuming that the MTAS study is representative in this regard, the lack of follow-up studies is no good reason to discount the latter three studies. The only transracial adoption study that we have which featured follow-up studies suggests that the racial IQ gap does not significantly widen with age. While adoption studies do indicate that IQ gains tend to diminish with age, as far as I know, there is no data indicating that the diminishment is particularly strong for Black adoptees compared to White adoptees.</p>

<p>(2) The heritability of IQ in children is fairly significant (<a href="https://en.wikipedia.org/wiki/Heritability_of_IQ">about 45%</a>), meaning genes play a significant role in the IQ of children. Therefore, if there were significant racial genetic IQ differences, then there would <em>not</em> be similar IQ scores for blacks and whites raised in similar environment <em>even as children</em>. Insofar as IQ is significantly heritable in children, and insofar as there are significant genetic racial IQ disparities, there will be a significant racial IQ gap at childhood even after equalizing environments. Therefore, the lack of an IQ gap during childhood after equalizing environments implies that either (a) the genetic component of IQ is not significant during childhood, or (b) there is no significant genetic Black-White IQ gap. We know that (a) is false, so (b) must be true.</p>

<p>(3) These IQ studies show that there are significant environmental differences between Black children who are adopted and those who are not (and between those adopted by White families versus Black families). It is unclear exactly what these environmental differences consists in. However, their mere existence indicates a predominantly environmental explanation of the IQ gap <em>at childhood</em>. Even if we remain agnostic about whether these differences explain much of the IQ gap in late adolescence, we can be confident that there is significant improvement that can be done regarding the IQ gap of Black and White <em>children</em>.</p>

<p>–&gt; Check if there are significant gaps between middle-upper class Black <em>children</em> (not teenagers/adults) versus middle-upper class White children on either academic achievement or IQ tests. If so, this has to be some environmental difference that is not just income (because we know children adopted by Whites do well on these tests). So this special environmental difference, whatever it is, persists across income levels.</p>

<h3 id="analysis">Analysis</h3>

<p>It seems to me that the evidence suggests that the IQ gap is almost entirely environmental. The Minnesota study is the only adoption study that suggests otherwise, but it has flaws (as I’ve indicated earlier). The German study also has many flaws as well, but the latter two studies seem to support it. So three of the studies are compatible with a predominantly environmental explanation of the IQ gap. Taking a holistic account of all of the adoption studies seems to suggest that the IQ gap is, for the most part, environmental. The only way you could conclude otherwise is if you fully accepted the results of the MTAS and disregarded the latter three studies due to lack of follow-up testing. But even if so, then you would still have to admit that the <em>academic achievement</em> gap (arguably more important than IQ) in late adolescence is mainly environmental, and you would have to admit that the IQ/achievement gap at childhood is mainly environmental.</p>

<p>So the <em>best case scenario</em> for a genetic explanation of the IQ gap still implies that environmental differences explain most of the academic achievement gap. But if the races can attain roughly equal academic achievement, then I don’t really care about IQ differences. At the very least, we <em>know</em> that there is a significant environmental gap between Blacks and Whites that is plausibly responsible for much of the disparities we find in society today. Until we reach parity regarding academic achievement for Black &amp; White adults, and until we reach parity regarding IQ/achievement for Black and White children, there are still significant environmental gaps regarding intellectual development. Quantifying the precise proportion of the IQ/achievement gap that is due to environment (i.e. 40% or 80%) is important so that we know when we have exhausted the possible environmental efforts to reduce the gap. But we know we haven’t reached that point yet. Therefore, currently trying to precisely quantify the environmental proportion of the IQ/achievement gap serves more as a theoretical exercise than as a practical function. We can postpone answering questions about the exact genetic component of the gap until we know we’ve eliminated the significant environment differences. When that happens, the question will have more practical utility and we would likely be able to give more accurate answers.</p>

<p>So that’s all the data (that I’m aware of) that we have for transracial adoption studies with Black children. Even if you disagree with my interpretation, I hope that (at the very least) this post has been valuable as a coherent collection of all of the transracial adoption studies along with their biggest criticisms. With all of the raw data laid bare in one place, you can provide your own interpretation of the data that you find most compelling. Of course, there are very few of these adoption studies and many of them have several problems (which I hope to have made clear in this post), which means no interpretation is going to be perfect. Nevertheless, I believe the interpretation that I’ve provided here is the most reasonable response to the evidence.</p>

<h2 id="rushtons-paper">Rushton’s paper</h2>

<ol>
  <li>Global race-IQ differences
    <ul>
      <li>Doesn’t imply genetic causes</li>
    </ul>
  </li>
  <li>Correlation between g-factor and race-IQ differences
    <ul>
      <li>Doesn’t necessarily imply genetic causes</li>
      <li>Weakly quantifies differences</li>
    </ul>
  </li>
  <li>Heritability of IQ high across groups
    <ul>
      <li>Doesn’t imply genetic differences between groups</li>
    </ul>
  </li>
  <li>Brain size differences at birth
    <ul>
      <li>Allows for environmental pre-natal or maternal differences</li>
      <li>Weakly quantifies genetic differences</li>
    </ul>
  </li>
  <li>Transracial adoption studies
    <ul>
      <li>Support primarily environmental explanations</li>
    </ul>
  </li>
  <li>Racial Admixture
    <ul>
      <li>Support primarily environmental explanations</li>
    </ul>
  </li>
  <li>Regression to the mean
    <ul>
      <li>Not sure if this is statistically correct</li>
    </ul>
  </li>
  <li>Race-Behavior Matrix
    <ul>
      <li>Does not imply genetic differences</li>
    </ul>
  </li>
  <li>Human Origins
    <ul>
      <li>Evolutionary psychology; whether it can be empirically verified depends on earlier evidence</li>
      <li>Does not quantify genetic differences.</li>
    </ul>
  </li>
</ol>

<p>To categorize</p>

<p>Can be dismissed: 3, 9, 10, 11 (not sure if 9 is statistically valid)
Doesn’t imply genetic differences between groups: 4, 5, 8
Doesn’t strongly quantify differences: 6, 
Good pieces of evidence: 7</p>

<p>http://www1.udel.edu/educ/gottfredson/30years/Rushton-Jensen30years.pdf</p>

<hr>

<p><strong>Sources</strong></p>

<ul>
  <li>[1] <a href="https://en.wikipedia.org/wiki/Minnesota_Transracial_Adoption_Study">Minnesota Transracial Adoption</a>
</li>
  <li>[2] <a href="http://www.kjplanet.com/amp-31-10-726.pdf">Minnesota Transracial Adoption</a> - Pages 730 &amp; 732</li>
  <li>[3] <a href="https://lesacreduprintemps19.files.wordpress.com/2012/12/the-minnesota-transracial-adoption-study-a-follow-up-of-iq-test-performance-at-adolescence1.pdf">Minnesota Transracial Adoption, follow-up</a> - Page 123</li>
  <li>[4] <a href="http://www.precaution.org/lib/low-level_lead_longterm_followup.19921001.pdf">Lead &amp; IQ</a>
</li>
  <li>[5] <a href="http://www.cdc.gov/nchs/data/ad/ad079acc.pdf">Blood lead levels</a> - Page 6</li>
  <li>[6] <a href="https://lesacreduprintemps19.files.wordpress.com/2012/12/the-minnesota-transracial-adoption-study-a-follow-up-of-iq-test-performance-at-adolescence1.pdf">Minnesota Transracial Adoption, follow-up</a> - Page 129</li>
  <li>[7] <a href="http://en.wikipedia.org/wiki/Eyferth_study">Eyferth IQ Study</a>
</li>
  <li>[8] <a href="http://www.jstor.org/stable/pdf/1127540.pdf?acceptTC=true">Tizard IQ Study</a> - Page 351</li>
  <li>[9] <a href="http://psycnet.apa.org/psycinfo/1986-24139-001">Moore IQ Study</a>
</li>
</ul>

<p>References:</p>
<ul>
  <li>Analysis
    <ul>
      <li>Jensen, “How much can we boost IQ and scholastic achievement?” (1969)</li>
      <li>Murray, <em>The Bell Curve</em> (1994)</li>
      <li>Neisser, “Intelligence: Knowns and unknowns” (1996)</li>
      <li>
<em>The Black-White Test Score Gap</em> (1998)</li>
      <li>Rushton, “Thirty years of research on race differences in cognitive ability” (2005)</li>
      <li>Nisbett, “Commentary on Rushton and Jensen” (2005)</li>
      <li>Nisbett, “Intelligence: New Findings and Theoretical Developments” (2012)</li>
    </ul>
  </li>
  <li>Direct studies:
    <ul>
      <li>Minnesota Transracial Adoption Study</li>
      <li>Eyferth Study</li>
      <li>Moore Study</li>
      <li>Tizard Study</li>
      <li>Mixed children by race of mother</li>
      <li>Ancestry and IQ</li>
    </ul>
  </li>
</ul>

    </li>
  
    <li>
      <h2><a href="/2019/06/19/Free-Will.html">Free Will</a></h2>
      <p></p>
<p>I will be assuming determinism is true. So whether we have free will depends on whether compatibilism is true. My post here will argue for determinism. The first thing to settle when having these debates is meaning. We need to determine what we <em>mean</em> by “free will”. <em>What beliefs are we expressing when we say someone has free will?</em> After settling meaning, then we can determine whether people sometimes actually have free will or not. Obviously, if “free will” is <em>defined</em> as some sort of incompatibilist free will, then incompatibilism is true; no argument needed. But it’s equally true that if “free will” is <em>defined</em> as compatibilist free will, then compatibilism is true; no argument needed. Neither of these definitions illuminate the compatibilism/incompatibilism debate.</p>

<p>I would say that there are two principles components behind the <em>meaning</em> of free will, i.e. someone has free will if and only if these two components are met: (1) to say that someone had free will in performing an action is to say that they “could have done otherwise” in performing that action, and (2) to say that someone had free will in performing an action is to say that they could be morally responsible for performing that action. This isn’t exactly a definition per se, but I believe it serves as a useful enough analysis to help illuminate the meaning of an otherwise unclear concept; the hope is that the meaning behind <em>these</em> two components is more clear and less controversial than the meaning behind “free will”. Now that the meaning of “free will” is somewhat illuminated, we can discuss whether people <em>actually</em> have free will. We have to answer the following two questions: (1) Is it true that people could have done otherwise in a determined world? (2) Do people have moral responsibility in a determined world? People will have free will in performing a particular action whenever the answers to both of these questions are “yes”.</p>

<p>Now, to answer the first question: <strong>Is it true that people could have done otherwise in a determined world?</strong> The answer to this question depends on the meaning of “could have done otherwise”. I believe the only reasonable understanding of “could have done otherwise” is this: to say that someone <em>could</em> have done otherwise is to say that they <em>would</em> done otherwise <em>if they had different intentions</em>. For example, if a student misses class because he woke up late, then he might say “I <em>could</em> have made it to class”. We can make sense of this statement in a determined world because what he means is “I <em>would</em> have made it to class <em>if I intended to wake up earlier</em>”. On the other hand, if he misses class because he had an unexpected heart attack, then he might say “I could <em>not</em> have made it to class”. Here, we can make sense of this statement because what he means is “I <em>would not</em> have made it to class, <em>regardless</em> of my intentions” (presumably, their heart attack would have occurred regardless of their intentions). It should be clear that this reasonable understanding of “could have done otherwise” is a compatibilist analysis: on this analysis, some people “could have” done other than they actually did, even in a determined world (as the above examples show).</p>

<p>Incompatibilists try to claim that “could have done otherwise” deals with what a person would have done <em>if all the conditions were the same</em> (including everyone’s intentions). But this is pretty much cheating - no one uses “could have done otherwise” in this manner. Under this analysis of “could have done otherwise”, we cannot make sense of the examples mentioned earlier. Under this analysis, if the student who woke up late says “I could have made it to class”, the incompatibilist would have to respond to the student with “Actually, no, you could not have made it to class, because that would require that you do other than what you <em>actually</em> did. But, you see, the world has been determined from the Big Bang such that you <em>had</em> to sleep late”. No competent English speaker would respond to the incompatibilist with “Oh, I hadn’t considered that. I was mistaken. I guess I couldn’t have made it to class”. Rather, any competent English speaker would conclude that the incompatibilist simply <em>misunderstood the language</em> used by the late student; they <em>misunderstood the meaning</em> of “could have done otherwise”. Let’s do away with the flawed incompatibilist analysis of “could have done otherwise” and return to the more reasonable compatibilist analysis given above. Again, on the more reasonable interpretation, some people “could have done otherwise” even in a determined world.</p>

<p>For the second question: <strong>Do people have moral responsibility in a determined world?</strong> First, again, we must settle what it means to say that someone is morally responsible for an action. To say that someone is morally responsible for an action is to say that they can be morally blamed/praised for that action. And moral blameworthiness/praiseworthiness is just one particular form of <em>evaluation</em> - it’s an evaluation of one’s moral character. Now, you probably don’t think that evaluation <em>generally</em> is impossible in a deterministic world. For example, we can evaluate the quality of a certain car based on the car’s attributes (e.g. fuel efficiency, safety, etc.), despite the fact that the car obviously did not <em>cause</em> those attributes. It seems then that we can clearly perform evaluations of moral character <em>specifically</em> in a determined world, just as we can perform evaluations <em>generally</em>. We simply point to the relevant attributes of their moral character - i.e. their intentions. So to say that someone is morally responsible for an action is to say that that action was somehow the result of the agent’s intentions. Of course, this is perfectly coherent in a determined world.</p>

<p>This actually matches up nicely with the compatibilist understanding of “could have done otherwise” given above. On this analysis, if someone “could have done otherwise” when performing an action, then they must have performed the action because of their intentions. And, as stated earlier, someone is morally responsible for an action if that action was the result of their intentions. Thus, it follows that if a person “could have done otherwise” in performing an action, then they can be morally responsible for their action. So the analysis of moral responsibility converges nicely with the analysis of “could have done otherwise”. For example, the student who wakes up late can be morally responsible for missing class, because he missed class <em>as a result of his intentions</em>. On the other hand, he would not be morally responsible for missing class due to a heart attack, because he did not miss class as a result of his intentions. Again, this is all possible in a determined world. So people can be morally responsible in a determined world.</p>

<p>This focus on intentions allows for a very convenient analysis of “free will” where someone had free will in doing X if and only if they performed X <em>because of their will</em> (i.e. where I’m using “will” as a substitute for “intentions”). For example, the student (probably) did not have free will in missing class due to the heart attack, because the heart attack was (probably) independent of his will (his intentions). On the other hand, he (probably) did have free will in missing class due to waking up late, because he (probably) would have woke up earlier if his will (his intentions) were different.</p>

<p>In conclusion, because a person can be morally responsible in a determined world, and people “could have done otherwise” in a determined world, it follows that people can have free will in a determined world. So you should accept a compatibilist conception of free will. Assuming you agree that the world is determined in the relevant respects, you should also accept that we have free will.</p>

<p>Add three components:</p>

<ol>
  <li>Intuitions: the appeal of incompatibilism - it starts with an intuition that if people could not have done otherwise, then they don’t have free will (show examples). To best meet these intuitions, they say that free will means “could have done otherwise if all conditions were the same.” The appeal of this definition is that it <em>best captures our intuitions about usage.</em> But there’s no reason to believe the latter qualifier is necessary. Indeed, metaphysical rewinding of time with all variables fixed is not something that the ordinary person thinks about. If we modify the qualifier, then we have a different definition that <em>best captures our intuitions about the usage</em>.</li>
  <li>Even if that was not true, to incompatibilists that say we have maintain moral responsibility &amp; agency (and possibly morality, goodness, etc.), yet who think that I’m giving a new definition of free will: their argument would have to be something like: (P1) most people believe that free will requires indeterminism (not true but let’s assume it’s true); (P2) if most people believe that X is a feature of concept Y, then if your theory posits that X is not a feature of concept Y, then your theory must be a redefinition of Y (not true but let’s assume that it’s true); therefore, your theory, because it posits that free will does not require indeterminism, is a redefinition of free will. But this argument proves too much. If P2 is true, then I could say that you have redefined moral responsibility &amp; agency, as most people have believed it to require libertarianism. They might object that, while this is true, even more people believe that something other than libertarianism is more tightly associated with moral responsibility &amp; agency: that it warrants praiseworthiness/blameworthiness. But I could also say that praiseworthiness/blameworthiness is tightly associated with free will (as I have above). It’s important to keep tight the association between moral responsibility/agency and free will. It makes no sense to say that one is compatible with determinism (against common intuitions), while also saying that the other is incompatible with determinism (agreeing with common intuitions). If you’re going to be revisionist, then be consistently revisionist.</li>
  <li>Terminological: (1) Already mentioned earlier somewhat. “Free” will literally means our will is free, i.e. unconstrained in the proper manner. This is compatible with determinism. When we think of other normative concepts with “free” in the phrase: freedom, free speech, we don’t think that determinism is detrimental to this. For example, if I were to say “The slaves were free”, does anyone honestly doubt this on the grounds of determinism? No, so why assume this is the case with free will. If I were to say “Free speech is good”, would anyone rebut with “But free will is impossible, because of determinism”? No, so why do so with free will? They would have to show that “Free will” is special in that we think of metaphysical determinism when thinking of free will, but this is false. Only philosophers think of free will (see 1).</li>
</ol>

<p>Qualiification to “intentions”. I.e. “x is free to z iff x would z if he had the appropriate intentions and the intentions are of type T”?</p>
<ul>
  <li>Any intentions? E.g. We’re all free to be successful authors because we would be successful authors if we had the appropriate intentions, e.g. adopted the intentions involved in writing certain words on a piece of paper. But clearly there’s a sense in which some are free to be successful authors whereas others are not.</li>
  <li>Intentions that we know of. E.g. we’re not free to be successful authors because we do not know which intentions to adopt to become successful, even though we would be successful if we adopted those intentions.</li>
  <li>Intentions that we know of that are not coerced. E.g. if we would be killed if we did z (but there was no interference), then we are not free to do z. Less extremely, if there were severe penalties for doing z (e.g. social ostrasization) for doing z, then we are less free to do it.</li>
  <li>Intentions devoid of any causal influence. E.g. libertarian free will. No.</li>
</ul>

    </li>
  
    <li>
      <h2><a href="/2019/06/19/Affirmative-Action.html">Affirmative Action</a></h2>
      <p></p>
<h2 id="justification-of-the-intentions">Justification of the intentions</h2>

<p>We don’t think discrimination should be illegal on an individual small scale level (i.e. individuals agreeing to make a transaction) but we do think it should be illegal for larger companies. What’s the difference?</p>

<h3 id="private-universities">Private Universities</h3>

<p>For simplicity, I’ll limit my post to affirmative action among private universities, since public institutions runs into many complications. I would agree that affirmative action is mistaken insofar as it results in underqualified students being admitted. Admitting students who don’t have the qualifications to succeed is setting them up for failure, and we should not be setting students up for failure. But I don’t see anything wrong with racial affirmative action among private universities where only qualified students are accepted, i.e. giving preference to a member of a certain race when choosing between two qualified applicants of different races. This is what I wish to defend.</p>

<p>You are correct that race-based affirmative action is discriminatory. The question that remains, however, is whether it’s immoral. The fact that a policy is discriminatory, in itself, doesn’t imply that it’s immoral. If that were the case, then <em>all</em> employers would be immoral, since all employers discriminate between applicants based on their skills, knowledge, traits, etc. or even appearance. So it can’t be discrimination alone that makes race-based affirmative action immoral.</p>

<h3 id="arbitrary">Arbitrary</h3>

<p>You might instead say it’s immoral because it’s specifically <em>racial discrimination</em>. But that can’t be right either. There are also cases of morally permissible racial discrimination. For example, casting directors for movies and plays discriminate based on race all the time. Why is this morally permissible? It must have something to do with the fact that race might be a <em>relevant feature</em> of the actors and actresses of the given movie, play, etc. In other words, racial discrimination by casting directors might not be <em>arbitrary discrimination</em>, and this is why it’s not immoral. Race just so happens to be an essential component of the product that movie/play creators are trying to sell.</p>

<p>This seems right to me. Discrimination by itself can’t wrong, even if it’s racial discrimination. What’s also necessary to be wrong is <em>arbitrary discrimination</em>. This explains why racial discrimination seems almost always wrong. The reason is that racial discrimination is almost always arbitrary. Most jobs require you to apply manual labor or process information or something that has nothing to do with race. But if we imagine cases where race <em>is</em> a relevant characteristic, we see that racial discrimination is actually morally permissible. This also can explain why discrimination seems morally wrong when it has nothing to do with race. For example, let’s say that an applicant is denied a job as a programmer because the employer didn’t like his/her eye color. This sort of discrimination seems wrong not because it’s racial discrimination, but because it’s arbitrary discrimination.</p>

<p>So the arbitrariness of discrimination is what determines whether discrimination is morally wrong. Now, the question is whether affirmative action (of the kind I mentioned earlier) by private universities is arbitrary. In other words, is race a <em>relevant feature</em> of the students of a university? It seems clear to me that it almost always is. Universities aren’t just selling library usage and lectures to students. They also purport to offer a college campus of a certain kind. That is, the makeup and “atmosphere” of the college campus is a part of the overall product that universities wish to sell. Therefore, students are not just <em>customers</em> of a university; they are also a part of <em>the product</em> (just like actors/actresses are a part of the product of movies/plays). Thus, race <em>is</em> an essential component of the product/service of all universities that wish to advertise a college campus with a certain racial makeup (whether that be a racially diverse campus or a racially homogenous campus). Because of this, affirmative action among private universities is not an arbitrary form of racial discrimination, and is therefore not immoral.</p>

<p>If this still seems unintuitive, consider the fact that many universities already practice a similar form of discrimination in the form of sex-based discrimination. The most extreme form of discrimination of this kind comes from women’s colleges and men’s colleges, universities that only allow students of a certain sex. Most do not intuit that sex-based discrimination from these colleges is immoral. The reason is that the sexual makeup of the student campus is clearly an essential part of the product that these colleges wish to sell; thus, sex-based discrimination would not be arbitrary. No doubt there are also colleges out there that perform sex-based discrimination for the opposite goal, to maintain a roughly even male:female on campus. People don’t intuit that sex-based discrimination from such universities is morally wrong (I would argue) because it’s not <em>arbitrary</em> discrimination. I see no reason to treat race-based discrimination any differently.</p>

<h3 id="balancing-versus-exclusion">Balancing versus Exclusion</h3>

<p>It’s important to distinguish between two kinds of discrimination - racial balancing and racial exclusion. Racial balancing is what might be committed by universities with regard to affirmative action. Racial exclusion is the strict exclusion of people from certain racial groups from participating. Racial balancing is to include race in the application process as a way to shift the racial demographics towards that which is more representative of the general population. It seems to me that racial exclusion is what’s wrong here, not racial balancing.</p>

<p>Consider a Night Club, for example. Many night clubs have their own quotas in place for the proportion of male/females at a given time. I think most people would agree that there’s nothing wrong with this. Now imagine that they also had quotas for racial demographics. They don’t want the club to be too far skewed towards one particular race, for whatever reason. I would also say that there really is nothing wrong with this. At the very least, it seems far less wrong than flat out exclusions. Racial balancing at universities could play a similar role.</p>

<p>As another example, imagine if the NBA put in quotas for certain races to balance the demographics to be more representative of the country. You might think this is morally wrong in some way, but I don’t many would say it’s <em>racist</em>.</p>

<h3 id="public-versus-private">Public versus Private</h3>

<p>Another reason we might be upset with discrimination is if it allows for public embarassment or humiliation.
E.g. imagine a restaurant refuses to serve Black people
This seems wrong because (1) a person who doesn’t know this might mistakenly enter the restauarant and be humiliated
and (2) we can see the establishment and people moving freely in and out, giving the impression of a public place.
This wrongness does not apply with “private” groups or organizations
Which are (1) hidden from public view,
and (2) require some sort of registration process for joining the club (e.g. you don’t just walk in be served)
E.g. consider sex-segregated gyms, night clubs, golf clubs, etc.
These don’t seem wrong at all</p>

<h3 id="subjugation">Subjugation</h3>

<p>Why are these properties important? Why are arbitrariness and balancing versus exclusion relevant considerations that determine whether discrimination is bad? Well, we have to discuss why discrimination is ever bad. We cannot just assume that discrimination is bad sometimes without understanding <em>why</em>? In order for anything to be bad, it has to be considerably bad for someone somewhere. Now, note that there’s nothing inherent to discrimination that implies that it is considerably bad for someone somewhere, i.e. their life would have to be relevantly damanged (I don’t consider upset feelings as relevantly bad, because if that were the case then all discrimination would be bad). So what is it about discrimination that sometimes makes it significantly bad in the relevant manner? The answer has to be that discrimination has historically been used as a tool for racial oppression and subjugation, something that destroyed the lives of many minorities. Thus, we implicitly associate discrimination (which isn’t inherently bad) with oppression/subjugation (which is inherently bad, as people’s lives are destroyed). That is what makes arbitrariness and balancing versus exclusion relevant factors: in order for discrimination to actually ruin a group’s lives, it must be arbitrary and it must be exclusionary. Otherwise, there’s no way that it can be harmful.</p>

<p>Now, racial discrimination would definitely be deemed immoral by most people. But I contend that the intuitions of most people are wrong here. Such a school would <em>not</em> be immoral. The intuition that it is immoral can be explained by the deep connection we have between racial <em>discrimination</em> and racial <em>oppression</em>. We have an immediate disapproving reaction to racial discrimination in schools because this was used as a tool for racial oppression in the past. If we could magically disassociate racial discrimination from racial oppression, then I think our intuitions regarding race-based discrimination would be more in line with our intuitions regarding socially accepted forms of discrimination (e.g. sex-based discrimination at all-male/all-female schools, sexual/racial discrimination by casting directors, sexual balancing at night clubs).</p>

<p>I think the laws enacted during the civil rights era chased morality in the sense that they corrected for the wrongs and damages resulting from governmental systematic racial oppression and they gave racial minorities a fair chance at integrating into society. Therefore, civil rights laws had a deeply moral motivation. However, it doesn’t follow from this that all policies prohibited by these laws were themselves immoral. The reason it doesn’t follow is that prohibiting some otherwise moral activities might be necessary to accomplish some broader moral goal. For example, I don’t think hard drug usage or prostitution is inherently immoral, but outlawing them might be necessary to accomplish a broader moral goal - i.e. to prevent violence and harms that would inevitably occur when these acts are legal. Likewise, I would say racial discrimination by private companies is not inherently immoral, but outlawing them might have been necessary to accomplish a broader moral goal - i.e. to correct for systematic racial injustice and integrate racial minorities into society.</p>

<h3 id="public-universities">Public Universities</h3>

<p>TBD</p>

<h2 id="consequences">Consequences</h2>

<p>The problem <em>with certain implementations of affirmative action</em> (this qualifier is important) is that it leads to <em>under</em>qualified students. This is a problem because admitting underqualified applicants actually hurts the students that it tries to help. Admitting students who don’t have the qualifications to succeed is setting them up for failure, and we should not be setting students up for failure. For example, <a href="https://www.youtube.com/watch?v=VVvnTByzTmA">here’s an interview</a> where economist Thomas Sowell shares that the black students at MIT were in the top 10% of the country in terms of mathematics, but they were in the bottom 10% at MIT. The result was that many were on academic probation and one-fourth never graduated. That’s absurd. Students who would have otherwise excelled in their environment were struggling just to pass. This is not helping anyone.</p>

<p>For a somewhat more modern example, look at <a href="http://www.foxnews.com/us/2014/11/18/rejected-asian-students-sue-harvard-over-admissions-that-favor-other-minorities.html">Harvard University</a>. The 2009 study cited notes that “the average Asian American applicant needed a much higher 1460 SAT score to be admitted, a white student with similar GPA and other qualifications only needed a score of 1320, while blacks needed 1010 and Hispanics 1190.” Combining that with <a href="http://www.collegeboard.com/prod_downloads/about/news_info/cbsenior/yr2005/02_v&amp;m_composite_percentile_ranks_0506.pdf">these percentile charts</a>, Asians were in the 98th percentile, Whites were in the 92nd percentile, Hispanics were in the 77th percentile, and Blacks were in the 48th percentile. These are huge differences and it would be naive to assume that this was the best environment for the underrepresented students to thrive academically.</p>

<p>If a kid from a disadvantaged background is in the 80th percentile of students, then the most <em>effective</em> way for this kid to succeed is to attend an institution that teaches to kids roughly in the 80th percentile. Sending him to an institution that teaches to, say, the 99th percentile will increase the probability that he will switch to a “soft” major and/or drop out. That puts the kid in an even <em>more</em> disadvantaged position, all in the ironic pursuit of equality. You might think that academics are not the only valuable attribute of college applicants, and you might be right. But it must be granted that there is a <em>base threshold</em> of college readiness that all students should have to meet before being accepted (you seem to grant this in your first paragraph). No doubt this threshold varies from college to college depending on the abilities of each school’s student body. Accepting students who do not meet this threshold hurts them more than it helps them. My central claim is that affirmative action is wrong at least insofar as it allows for the acceptance of students that do not meet this threshold of college readiness.</p>

<p>It is not sufficient that the <em>intentions</em> of affirmative action are morally justifiable (that’s a different concern that I bypass here). It is also necessary to consider the practical <em>consequences</em> of affirmative action. Often, discussions of affirmative action focus entirely on the former and none at all on the latter, but both concerns are necessary for good policy. We can’t evaluate policy purely from a philosophical normative position. Normative evaluation is only valuable insofar as it guides what our <em>goal</em> should be. Once we agree on our <em>goal</em>, we have to empirically investigate the consequences of various policies to determine effective methods of achieving that goal. I would like to believe that most agree that our <em>goal</em> is to help underrepresented minorities thrive. However, affirmative action (of the kind mentioned here) is not the proper <em>policy</em> to accomplish that goal precisely because the consequences are ineffective. College readiness <em>matters</em>, and this fact cannot be ignored just because our intentions are good, because the consequences will come to hurt the students in the end.</p>

<p>You might say that certain groups tend to experience pre-university disadvantages that unfairly reduce their performance on traditional measurements of scholarly assessment (e.g. grades, test scores, writing ability, etc.). Okay, I can grant all of that. However, insofar as these disadvantages exist, the fact is that these disadvantages also (albeit unfairly) reduce their college <em>readiness</em>. The fact is, accepting unprepared students is not going to erase the lifetime of disadvantages that they have already endured. I grant the disadvantages, but the solution cannot be to add <em>more</em> disadvantages by mismatching students to institutions that don’t cater to their abilities. The solution must be to remove disadvantages for the next generation and to help disadvantaged students by sending them to institutions that cater to their abilities (whether that be less prestigious universities, community colleges, trade schools, etc.).</p>

    </li>
  
    <li>
      <h2><a href="/2019/06/19/Abortion.html">Abortion</a></h2>
      <p></p>
<h2 id="pro-life-argument">Pro-life argument</h2>

<ol>
  <li>A fetus is a life
    <ul>
      <li>A. Arbitrariness argument
        <ol>
          <li>The line drawn to designate when life begins must be non-arbitrary.</li>
          <li>The only non-arbitrary, non-repugnant line to draw for life before birth is conception.</li>
          <li>[from 1 &amp; 2] Life begins at conception.</li>
        </ol>
      </li>
      <li>B. Potentiality argument
        <ol>
          <li>If X has the potential to develop into a being of type T, then X should be afforded all the same rights afforded to beings of type T.</li>
          <li>Fetuses have potential develop into human life.</li>
          <li>[from 1 &amp; 2] Fetuses have a right to life.</li>
        </ol>
      </li>
    </ul>
  </li>
  <li>It is wrong to terminate a life</li>
  <li>Abortion is wrong.</li>
</ol>

<h2 id="rebuttal">Rebuttal</h2>

<p>Rebuttal against 3:</p>
<ul>
  <li>The pro-life argument works only if the fetus is understood as being a full life deserving of full rights to personhood. But if a fetus deserves full rights to personhood, then there are following two hugely unintuitive conclusions:
    <ul>
      <li>Abortion would be unjustified even when the pregnancy is due to rape: One cannot accept (1) a fetus deserves full rights to personhood, and (2) abortion is justified in the case of rape. Because (1) implies the falsity of (2). In other circumstances, when a person has full rights to personhood, another person cannot revoke those rights just because they were victimized. E.g. I cannot kill you to account for a crime that someone else committed.</li>
      <li>Abortion would be unjustified even when the mother’s life is at risk: One cannot accept (1) a fetus deserves full rights to personhood, and (2) abortion is justified when the mother’s life is at risk. Because (1) implies the falsity of (2). In other circumstances, when a person has full rights to personhood, another person cannot revoke those rights just to save their life. E.g. I cannot kill you because I need a heart transplant.</li>
    </ul>
  </li>
  <li>There are two options:
    <ol>
      <li>Bite the bullet and assert that abortion is unjutsified in the case of rape and danger to the mother.</li>
      <li>Admit that fetus don’t really have full rights to personhood, but rather some weird form of pseudo-right to personhood. But what is the nature of the pseudo-rights and why should we believe that it encompasses protection of life only when the mother consented to pregnancy and/or is in danger. These are strange forms of rights not seen anywhere else. The only forms of rights either involve full rights to personhood (i.e. humans) or rights to not be subjected to pain but no rights to life (i.e. animals).</li>
    </ol>
  </li>
</ul>

<p>Rebuttal against 1A1:</p>
<ul>
  <li>General cases: we can say the same about plenty of things - age when one should be able to consent, vote, work, smoke, drink, run for office, etc. Why the discrepancy?</li>
  <li>Abortion-specific case: assuming they believe that the mother can abort if her life is in danger. What non-arbitrary percentage of danger can you point to to say that the mother is justified in abortion?</li>
</ul>

<p>Rebuttal against 1B1:</p>
<ul>
  <li>We don’t think chlidren should have the right to vote, run for office, drive vehicles, consent to sex, etc. even though they have the <em>potential</em> to develop the capacities that would ordinarily generate these rights.</li>
  <li>Furthermore, what is meant by “potential”? Some children don’t have the potential to develop these capacities. For example, let’s say that we know the child will die before adulthood because of a genetic disorder.</li>
</ul>

<p>Rebuttal against 2:</p>
<ul>
  <li>Counter-examples:
    <ul>
      <li>Killing in self-defense. (2) is modified to: it is wrong to terminate an innocent life.</li>
      <li>Killing with consent. (2) is modified to: it is wrong to terminate an innocent life without consent.</li>
      <li>Killing to put someone out of misery who can’t consent. (2) is modified to: it is wrong to terminate an innocent life without indication of consent or misery.</li>
      <li>Killing someone who would have died at that moment: (2) is modified to: it is wrong to terminate an innocent life without indication of consent, misery, or probable future death.</li>
    </ul>
  </li>
  <li>Blood transfusion case: people should not be forced to donate blood to others.
    <ul>
      <li>They respond by invoking responsibility. But, even if someone has put someone else’s life in danger through their own voluntary actions, we don’t force them to donate blood. Why the discrepancy?</li>
      <li>They bite the bullet and say that we should force people to donate blood in these circumstances. Okay, but the impact of the responsibility is different. In the case of abortion, no being has their life deprived whereas in the case of the voluntary danger, someone’s life has been deprived. The initial voluntary action X produces a responsibility to Y only if X without Y deprives the person of a life that they would have otherwise had.</li>
      <li>They bite the bullet and say that we should be forced to donate blood to people when we put them in circumstances where they need blood, even if they would not have been alive anyway.</li>
    </ul>
  </li>
  <li>Philosophical first principles: liberty</li>
</ul>

<p>(1) There is no morally relevant difference between detaching in the Modified Blood Transfusion Hypothetical and and detaching in pregnancy.
(2) If there is no morally relevant difference between action X and Y, then X and Y must be given the same moral evaluation.
(3) It is morally permissible to detach in the Modified Blood Transfusion Hypothetical.
(4) (from 1 &amp; 2) Detaching in the Modified Blood Transfusion Hypothetical must be given the same moral evaluation as detaching in pregnancy.
(5) (from 3 &amp; 4) Detaching in pregnancy is morally permissible.</p>

<p>Notes:</p>
<ul>
  <li>The deprivation argument has no independent force. It is not meant to show that you are permitted to harm anyone you bring into existence. That’s absurd. E.g. giving a fetus FAS is also immoral.</li>
  <li>It has force only in a very narrow context if other principles are adopted. I.e. it removes the relevance of responsibility caused by voluntary behavior, specifically when the produced state of affairs is the creation of a new life.</li>
  <li>It is meant to show a conditional claim: IF it is permissible for the woman to abort due to rape THEN responsibility does not compel her to abort due to consensual sex. More generally: IF A is permitted to not sustain D because of bodily autonomy when they are not responsible for D’s dependence THEN A is also permitted to not sustain D because of bodily autonomy when they ARE responsible for D’s dependence if D would have never existed had A never performed the initial action that provided the responsibility.</li>
  <li>This does not allow the woman to give the fetus FAS because it is not permissible to give the fetus FAS even in the cases of rape. It does not allow parents to kill children because it is not permissible to kill children even in cases of rape. It might even allow that mothers can be compelled to raise and care for children assuming that we think mothers can be compelled to raise and care for children due to rape (perhaps we do?).</li>
  <li>Do not try to justify the deprivation point by saying conception + death is no worse off than never conceiving, therefore abortion is permissible. This could justify all sorts of bad stuff. I.e. birth + premature murder is no worse off than never being born, therefore premature murder to one’s offspring is permissible. The principle does not have wide scope. It’s scope only shows that responsibility does not cancel bodily autonomy if it is responsibility for one’s existence.</li>
</ul>

<p>Objections:</p>
<ul>
  <li>Mentioned in Boonin’s paper - Langer, Tooley, etc.</li>
  <li>Future like ours objection</li>
  <li>“The Impairment Principle” argument:
    <ul>
      <li>If impairing an organism to the nth degree is immoral, then (all things else equal) impairing the organism to the nth+1 degree is also immoral.</li>
      <li>Giving an infant FAS is immoral. Killing an infant causes more impairment than giving an infant FAS. Therefore, killing an infant is immoral.</li>
      <li>Response: Giving an infant FAS in the case of rape is immoral. However, aborting an infant in the case of rape is not immoral.</li>
    </ul>
  </li>
  <li>Imagine a program is created which requests some stranger to donate their kidney to save someone. If you sign up, you have to stay signed up. This makes sense. Even though your intiial signing up did not deprive the victim of a previous state, it did deprive them of a life that they would have otherwise had (because otherwise someone else could have signed up).</li>
</ul>

    </li>
  
    <li>
      <h2><a href="/2019/06/19/Theories-of-Normative-Talk.html">Theories of Normative Thought</a></h2>
      <p></p>
<h2 id="the-problem">The problem</h2>

<p>Now that we have illustrated what I take to be the main features of normative judgments, we can now return to the original task.
We can now attempt to characterize the kind of attitude involved in <em>deliberative endorsement</em>. 
Is it more like a belief which represents some kind of normative reality?
Or is it more like a desire that disposes agents to behave in certain ways?
When one makes a normative judgment, is this judgment capable of being true or false?
If normative judgments are like beliefs, what are they attempting to represent?
If they are like desires, then what kind of motivational states are they?</p>

<p>The characterization has to be one that can be applied to the normative judgments of virtually all people.
This universal characterization is required because it is necessary to ground a shared concept, and a shared concept is necessary for the genuine disagreements we have with others. 
Otherwise, these “disagreements” wouldn’t really be disagreements, we would just be talking past each other with different concepts.
E.g. if “good” for Adam meant “approved by society” and “good” for Bob meant “approved by God”, then when Adam says “X is good” and Bob says “No, X is not good”, what is really happening is Adam is saying “X is approved by society” and Bob is saying “No, X is not approved by God”. 
But this characterization of normative judgment clearly does not allow for a disagreement (there is no contradiction with X being approved by society and X not be approved by God).
Since Adam and Bob clearly do disagreement when one says “X is good” and the other says “No, X is not good” (i.e. Adam and Bob both judge that the other person is <em>incorrect</em>), this characterization does not suffice.</p>

<p>Possible characterizations can be broadly seperated into two categories - world-to-mind states of mind and mind-to-world states of mind.
Both are states of mind that that have propositional content as their objects, i.e. agents have beliefs and desires with regard to p where p is some proposition. 
Mind-to-world states of mind are states whereby the propositional content of the attitude is meant to <em>correspond</em> to an external reality. 
E.g. if one believes that p, then p is aimed at corresponding to reality. 
World-to-mind states of mind are states whereby the agent is disposed to modify the world so that the propositional content of the attitude is made true. 
E.g. if one desires that p, then they are disposed to try to make it the case that p is true. 
Whereas mind-to-world states have a <em>correspondence</em> role, world-to-mind states have a <em>dispositional</em> or <em>functional</em> role regarding one’s motivations.</p>

<p>How do we determine whether an attitude has a mind-to-world direction of fit or a world-to-mind direction of fit?
One test for the direction of fit of an attitude is to determine whether the attitude persists despite observing evidence against the propositional content of the attitude. 
For example, someone’s belief in p will tend to diminish upon observing evidence against p. 
E.g. if someone <em>believes</em> that their home football team will win the game tonight, this will (usually) tend to diminish as they observe evidence that the team will lose, e.g. if the home team loses their best player, then this will diminish one’s belief they they will win. 
On the other hand, if one <em>desires</em> that their home team win, then this attitude (usually) does not tend to diminish upon observing that the team will lose, e.g. if the home team loses their best player, then this will <em>not</em> diminish one’s desire that they win.
Like most desires, the desire here persists despite evidence against the truth of the corresponding propositional content.</p>

<p>It seems clear to me that normative attitudes have a world-to-mind direction of fit.
That is, when a person endorses A’s adoption of attitude X, this does not tend to diminish as one learns that A fails to adopt attitude X.
This to me lends evidence to a non-cognitive analysis of normative judgments.
This implies that normative judgments are not <em>beliefs</em> or other cognitive states that represent a normative reality. 
Rather, they are sophisticated forms of desire-like states (or dispositions to have certain desire-like states).
However, other theories of normative talk purport to explain the appearances better.</p>

<p>In this piece, I will be examining the main competing characterizations of normative thought.
I begin by analyzing varieties of mind-to-world, or <em>representation</em>, characterizations.
These would be <em>cognitive</em> theories because they suggest that that our normative judgments are capable of being true or false.
These theories posit that there exists a normative reality of normative entities, properties, relations, etc. which our normative judgments are aiming to properly represent. 
E.g. there exists a property <em>goodness</em> which are attempting to refer to when we judge that something is “good”.
E.g. there is a relation of <em>oguht</em> that holds between agents and attitudes that we aim to reference when we judge that an agent “ought” to adopt an attitude.
These cognitive theories can be split into two variants - non-naturalism and naturalism.
Naturalism posits that the normative properties are natural properties. 
“Natural” here is meant to describe properties that belong to the subject-matter of physics and can be discovered a posteriori.
Under naturalism, the normative <em>properties</em> just are reducible to ordinary non-normative natural <em>properties</em>.
On some strong versions of naturalism, normative <em>concepts</em> can also be reduced to natural <em>concepts</em>.
While naturalism is often taken to imply Naturalistic <em>Moral Realism</em>, the label is sometimes often used for non-realist theories as well.
For purposes here, I will take naturalism to include all cognitive theories that don’t involve non-natural normative properties.
Non-naturalism includes all cognitive theories which are not natural.
This means that normative properties cannot be reduced to “natural” properties.
Normative properties are not the subject-matter of physics or science and must be discovered a priori.
Normative properties and concepts cannot be reduced to non-normative or natural properties and concepts.</p>

<p>In the end, I will argue that all cognitive theories fail, either for failing to satisfy the features of normative thought that I mentioned earlier or because of other problems that they bring.
I then present non-cognitivism as a viable alternative to the failed theories and argue why it does not suffer from similar issues as the earlier theories and also give positive reason to accept it.
I end by considering some objections to non-cognitivism.</p>

<h2 id="naturalism">Naturalism</h2>

<h3 id="analytic-reductionism">Analytic reductionism</h3>

<ul>
  <li>“A would have a certain pro-attitude with regard to X in circumstances C” where C is given a non-normative characterization.
“A ought to X” = “A desires to do X” or “A desires to desire to do X” or “A would desire X if fully informed”</li>
</ul>

<p><em>Open Question Argument</em>. (1) Any proposed analytic reduction of a term must be uninformative and obvious. (2) Any analytic reduction of goodness would be informative and nonobvious. (3) Therefore, there can be no analytic reduction of moral terms. Consider the question “Is X good”. Now, imagine that a proposed complex analysis of goodness states that all questions of the form ‘Is X good’ are questions of the form ‘Does X have naturalistic property Y’. The problem with this is that, we can always further ask “Is it good that X has property Y”. This further question is clearly intelligible and coherent. But, if goodness that could be analyzed in terms of Y, then such a question would not be intelligible.</p>

<p><em>Descriptive beliefs don’t entail normative judgments</em>. If M and N are <em>definitionally</em> identical, then if A <em>believes</em> that X has property M, then it logically follows that A also <em>believes</em> X has property N (and vice-versa). Note that this is stronger than mere <em>property</em> identity, e.g. H2O might be identical to water, but the fact that A believes water is H2O does not logically entail that A believes it is water (or vice-versa). However, this logical relation does not hold between and normative property and any natural property. If we know that A believes that X has natural property N and he later says that “X has moral property M”, then we have always learned something new about A.</p>

<p>Response: deny that all analytic reductions must be trivial and uninformative. Counter: Explain why the normative instance of the paradox of analysis differs from other cases. Normative judgments are supposed to provide reasons for action. In other cases, we would be fine to abandon the terms being analyzed (i.e. no problem switching from “knowledge” to “justified true belief”). But this is not true in the normative case.</p>

<p><em>Insistence on Normative Language</em>. If normative term N really meant natural term M, then why not carry on making claims about M? If the thesis were true, this would be equivalent to making claims about N, so there should be no difference. The fact that one chooses not to do so implies either (1) he believes that there really is something about N not captured in M, or (2) he believes that society believes that there is something about N not captured in M. Either way, either he or society believes that N and M are not analytically equivalent.</p>

<p><em>Normativity reduced to Tautology</em>. While it may be appropriate for an analytic reduction to be nontrivial, it is not appropriate that an analytic reduction could ever provide one with a <em>reason</em> for action. If normative concept M can be analytically reduced to natural concept N, then saying “N is M” would be a tautology, and thus could provide no reason for action. For example, if goodness could be analytically reduced to pleasure, then if someone said “pleasure is good”, then this would be equivalent to saying “pleasure is pleasure” or “goodness is goodness”. But presumably the claim “pleasure is good” is supposed to provide someone with reason for action. But no tautology such as “pleasure is pleasure” or “goodness is goodness” could ever provide a reason or motive for someone to promote pleasure.</p>

<p><em>Ethical disagreements reduced to disputed semantics or descriptions.</em> If analytic naturalism is true, then two parties disagree ethically only if they disagree descriptively. But people can disagree ethically without disagreeing descriptively. There can be two people who represent reality identically without having similar ethical attitudes with regard to that representation. This can only be explained by positing that the two parties have different semantics, but then this wouldn’t even be a genuine disagreement. This means that two societies with ethical terms that had different semantic meaning (but were identical in that those terms guided the respective society’s behavior) would not really disagree with each other. They would be talking passed one another.</p>

<p><em>Subjectivist forms don’t allow disagreement</em>. Note that reducing ethical judgments to <em>beliefs about attitudes</em> cannot account for this. If A believes he desires X and B believes he desires not-X, then these beliefs are not in disagreement because they can both be <em>correct</em>. E.g. A saying “X is good” and B saying “X is not good” would not be a contradiction, since it would amount to “A desires X” and “B does not desire X”. In fact, they would both be <em>true</em>. But it seems that ethical disagreement can persist despite accepting these truths.</p>

<p><em>Objectivist forms don’t explain motivation</em>. See below.</p>

<h3 id="synthetic-reductionism">Synthetic reductionism</h3>

<p><em>A Priori Argument</em>. It seems we can come to learn about normative truths a priori. This is inexplicable if there is an a posteriori synthetic relationship between normative facts and non-normative facts. I.e. we cannot learn a priori that yellow is such and such wavelength, or that water is H2O. Yet how can it be the case that we can learn a priori that, e.g. some natural property <em>necessarily</em> co-instantiates a normative property?</p>

<p><em>Lack of Disagreement</em>. Synthetic identities can be found in other domains because we can easily fix the referrents of terms like “water” or “yellow”, and then we can find that property that is always instantiated with that referrent. One strategy for doing this is to present a dispositional analysis: an entity is “yellow” just in case it causes sensation that we normally perceive as “yellow”. Such a dispositional analysis is not promising for moral terms. Imagine that two societies are lingustically identical except when one society used the word “good” they referred to pleasure and the other society referred to God’s will. On this reading, the two cultures wouldn’t even disagree with each other, since the content of “good” in these two societies are different - they are using the same word to track different phenomenon. But it seems that these cultures can coherently disagree with each other, especailly if they each act in accordance with what is good.</p>

<h3 id="non-reductionism">Non-reductionism</h3>
<ul>
  <li>Succeeds!</li>
  <li>Although it doesn’t actually suffice to give a theory.</li>
  <li>Synthetic and Analytic</li>
</ul>

<h2 id="non-naturalism">Non-naturalism</h2>

<p>The lack of influence that normative properties place on the world pose the following three problems:</p>

<ol>
  <li>
<strong>Concept</strong>: <em>There is no evolutionary benefit to developing a capacity to track these properties</em>. In order for there to be a benefit in developing a perceptual faculty, that faculty must be useful at increasing an organism’s biological fitness. The only perceptual faculties useful in increasing an organism’s biological fitness are faculties that track relevant natural facts, as natural facts are the only facts that influence an organism’s chance at reproducing.</li>
  <li>
<strong>Epistemology</strong>: <em>We have no epistemic access to non-natural facts</em>. It is a necessary condition on justified belief that one’s belief be explained by the facts in question. Perceptions of natural facts are good evidence for natural properties not because of an intrinsic connection between <em>perceiving</em> p and p being true. Rather, <em>perceiving</em> p is good evidence for p only if p <em>being true</em> causally exlpains why one perceives p. The reliable causal connection between <em>p being true</em> and <em>perceiving p</em> is required to treat <em>perceiving p</em> as a relibable detection of p. There is no way that a non-natural fact p could ever causally explain how we perceive or judge p to be true. Thus, we cannot treat our judging that non-natural fact p as evidence that p is true. This means none of our normative beliefs are ever justified.</li>
  <li>
<strong>Ontology</strong>: <em>Parsimony is preferrable to complexity with regard to ontology</em>. When determining which entities exist in the world, we should use inference to the best explanation. Theories with fewer assumptions and better explanatory power are superior. Imagine a world without any non-natural properties but with all the same natural properties. These two worlds would have equal explanatory power, but the world without unneeded properties would have less assumptions and would therefore be superior. The reason is because non-natural properties must be causally inert. The existing of non-natural properties is not necessary to explain reality as we see it.</li>
</ol>

<p>It seems to be an a priori conceptual truth that moral properties supervene on the non-moral properties, i.e. two circumstances which have identical non-moral properties must also have identical moral properties. This can be easily explained by naturalism, but it is difficult to see how this is explained by non-naturalism. There are two issues here, one epistemological and one ontological.</p>

<ol>
  <li>
<strong>Epistemology</strong>: When we see an action that we judge to be wrong, we don’t just judge it to be wrong in that particular circumstance. We judge that a particular action with certain natural properties always coinstantiates normative properties. Non-naturalism purports that we perceive the non-natural moral facts as we perceive certain natural facts. But there is nothing about this perceptual model that <em>necessarily guarantees</em> that we will perceive the same moral facts in circumstances where we perceive the same natural facts. Any perceived supervenience would be, at best, a posteriori; the supervenience relation couldn’t be perceived, for have only perceived the one circumstance Thus, the perceptual model of non-naturalism cannot explain the supervenience of the moral on the non-moral.</li>
  <li>
<strong>Ontology</strong>: It is a <em>conceptual</em> truth that the normative supervenes on the non-normative. No two worlds can have the same non-normative properties yet have different normative properties. Thus, normative properties and non-normative properties are not just coextensive, they are <em>necessarily</em> coexstensive; they are coexstensive in all possible worlds. However, there are no distinct properties that are coextensive in all possible worlds. If two properties are distinct, then there must be <em>some</em> possible worlds where only one of the properties obtain. Thus, normative properties, <em>if they are properties</em>, must be natural.</li>
</ol>

<h2 id="general-problems-for-cognitivism">General Problems for cognitivism</h2>

<p><em>Motivation</em>. One can infer that an agent has a world-to-mind fit state of mind with respect to X if they judge that they have normative reason to X. With moral judgments, this is particularly true if they <em>exclaim</em> that a certain action is (im)moral. This is easy to explain if judgments of normative reasons are themselves world-to-mind fits. Otherwise, this is difficult to explain. Attributions of goodness to P have a conceptual link with the guidance of action towards promoting P (judgment internalism). For any (non-)naturalistic property R, we can imagine clear-headed beings who would fail to find appropriate reason or motive to action in the mere fact that R obtains regarding P. The fact that attributions of goodness are <em>necessarily</em> action-guiding whereas attributions of R are only <em>contingently</em> action-guiding suggests that goodness and R are not analytically equivalent. Non-naturalism fails to account for the motivational feature of normative judgments for the very same reasons that mind-independent naturalism fails. The fact that moral properties move from the natural realm to the non-natural realm does not increase the motivational weight. If such properties did not have motivational force, how can they gain a motivational force by postulating that they cannot be investigated by the hard sciences?</p>

<p><em>Translation</em> Imagine we are trying to translate words for descriptive concepts to another language. This involves picking an extension of the relevant concept that we can all agree with and finding the word from the other language that correlates with this extension. For example, if we want to find the translation for the word “red”, we would establish an extension of the concept RED - e.g. blood, stop signs, crayons, etc. Then we would find which word in the other language is often used to refer to the entities in that extension. On the other hand, we cannot do this for normative terms. Firstly, it is doubtful that we could establish an extension of any normative concept that we all agree on. But, more importantly, even if we could, it would not be enough to find the foreign word that corresponds to this extension in order to translate the term. We would also need to know the other society’s motivational and non-cognitive attitudes and dispositions with regard to the extension. For, it is conceivable that they could think that the extensions was either good or bad. This attacks all forms of non-naturalism and objectivist forms of naturalism.
-&gt; Also imagine a culture with an identical nonverbal language of our own except that they didn’t speak verbally. They used sign language predominantly to communicate. Some analysis of their movements would be reducible to expressions of beliefs. How would we analyze the meaning of showing a middle finger? How would we analyze a parent who angrily points at a child’s bedroom (ordering him to go)? Imagine they needed to express more sophisticated thoughts using this language. Is it truly questionable whether they could express the entire range of human attitudes, including the attitudes themselves, dispositions to have the attitudes, endorsement of the attitudes? Is it questionable whether questionable whether they could use their language in a way to influence the behavior of others? Would we have any need to posit the existence of mind-independent action-guiding properties to explain the phenomenon? Would it change if they spoke verbally?</p>

<p><em>Disagreement</em>. Descriptivism cannot explain the role of attitude in ethical disagreements. There are two forms of disagreement, (1) disagreements in belief (both cannot be true) and (2) disagreement in attitudes (cannot be satisfied). Note that reducing ethical judgments to <em>beliefs about attitudes</em> cannot account for this (see above). Ethical disagreements commonly feature disagreements in attitudes and in beliefs. But attitudes play the primary role because (1) The attitudes determine which beliefs are relevant, and (2) Ethical disagreement persist after agreement in belief. Perhaps this is actually a disagreement in beliefs about each agent’s idealized attitudes, where idealized attitudes are assumed to be convergent. Disagreement in idealized attitudes maybe can account for disagreements in certain normative domains, e.g. disagreements in desires, emotions, maybe even beliefs (i.e. we think other people would come to similar beliefs as us under idealized conditions, because our epistemic frameworks are assumed to be similar). But ethical disagreement can persist despite agreement about the beliefs of everyone’s fully rational, fully informed attitudes. This is not the case with something like think art, humor, taste, etc. This is because ethical judgments have a <em>prescriptive</em> aspect in that they are meant to guide the behavior of other agents. Such prescriptions cannot <em>both</em> be actualized when they conflict.</p>

<p><em>Expanded Twin Earth</em>. What our terms refer is a contingent matter that depends upon our culture and history. It is a feature of our contingent culture that we happened to have hooked up the term “good” with any particular natural or non-natural property good. So, imagine that a group of people whom you disagreed with merely stipulated that what they meant by “good” was not the (natural or non-natural) property that you refered to by “good” and they went on using their terms to regulate their behavior in their society. It still seems that you would disagree with them and think that they were incorrect.</p>

<h2 id="non-cognitivism">Non-cognitivism</h2>

<ul>
  <li>Succeeds on all fronts!</li>
  <li>Biggest issue is the linguistic/semantic issues.</li>
  <li>It doesn’t explain what the base attitudes are.</li>
</ul>

<p>More on ethical disagreement:</p>
<ul>
  <li>Attitudes determine which beliefs are relevant to a disagreement.</li>
  <li>Attitudes determine when the disagreement is resolved.</li>
</ul>

<p>Kinds of attitudes when S says “A ought to X”:</p>
<ul>
  <li>Expression of endorsement
    <ul>
      <li>S endorses a pro-attitude for A X-ing</li>
      <li>S endorses X-ing in A’s circumstances</li>
    </ul>
  </li>
  <li>Prescriptions
    <ul>
      <li>S prescribes X to A</li>
    </ul>
  </li>
</ul>

<p>“X is wrong” =&gt;</p>
<ul>
  <li>Expressive
    <ul>
      <li>of attitudes, e.g. disapproval of X</li>
      <li>of dispositions:
        <ul>
          <li>of attitudes, e.g. disapproval of X</li>
          <li>of behavior, e.g. tendency to not</li>
        </ul>
      </li>
      <li>of endorsement
        <ul>
          <li>of the above cognitive states</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>Prescriptive
    <ul>
      <li>influence the attitudes of others</li>
    </ul>
  </li>
</ul>

<h3 id="attitude">Attitude</h3>

<h4 id="expressive">Expressive</h4>

<p>One aspect of normative judgments is that they express world-to-mind fit attitudes, some of the attitudes associated with the belief-based theories. The difference is that instead of <em>reporting</em> those attitudes, normative judgments <em>express</em> those attitudes. It’s why it would be fair to <em>infer</em> (not in the sense of logical inference) that someone has a particular attitude given their normative statements, but we cannot <em>deduce</em> their attitudes given such a statement. This is similar to how assertions can <em>express</em> a subject’s belief even though they do not <em>report</em> an agent’s beliefs. E.g. if someone says “P is true”, it would not be a contradiction for them to say “I do not believe P”. This is strange, because the belief is <em>expressed</em> but not <em>reported</em> by assertions. In the same way, certain attitudes are <em>expressed</em> but not <em>reported</em> with normative judgments.</p>

<p>Sometimes, normative statements express straightforwardly ordinary attitudes. For example, if someone says “X is funny”, this can commonly be read as expressing an attitude of amusement. When someone says, “good”, that can be read as expressing an attitude of desire or approval. Similar considerations can be said about reasons-statements in general, i.e. if someone says there is reason to hold attitude X, this oftentimes simply expresses that the agent holds the attitude in question. Also, instead of straightforwardly expressing an attitude, such normative statements can also express <em>dispositions</em> to have certain attitudes. So when someone says that X is wrong, this need not necessarily express the attitude of blame or resentment in that particular moment. Rather, it can express a <em>tendency</em> to blame or resent X in normal circumstances.</p>

<h4 id="deliberative-endorsement">Deliberative Endorsement</h4>

<p>However, this is not all there is to all normative judgments. There are times when a person judges themselves to have reason to adopt attitude X without actually adopting X (and perhaps even without a tendency to adopt X). Indeed, one can take a step back and question their attitudes at any given moment. It is a common feature of human life that we have attitudes that we renounce, and that we endorse attitudes that we lack. It is common for there to be a disconnect between the attitudes we <em>actually</em> hold and the attitudes we think we have <em>reason to</em> hold. This suggests that there is a special attitude involved in a normative judgment in favor of X can be distinct from the attitude of holding X itself. This is the attitude of <em>deliberative endorsement</em>. This state of mind is essential to normative thinking, and is often what we express with normative statements.</p>

<p>This attitude is what grounds a common subject matter in all normative concepts. Without this attitude of deliberative endorsement, there would be very little in common involved in judging that a fear, desire, belief, anger, etc. were justified. These would just be expressions of different ordinary attitudes or dispositions. However, what’s common to all these judgments (or what can be common) is that the ordinary attitudes can be the object of a single attitude - endorsement. This is not to say that e.g. the psychology of judging that e.g. anger is reasonable is exactly the same as judging that e.g. a belief is reasonable. Clearly they are different - the former expresses (but doesn’t <em>report</em>) that the agent has disposition to feel anger in the given circumstances and the latter expresses that the agent probably adopts the belief in question. However, the point is that the attitude of deliberative endorsement is an attitude common to both of these judgments.</p>

<p>This kind of attitude is found only in creatures with higher order thinking (i.e. thoughts about thoughts) as it is an attitude <em>about</em> other attitudes; the <em>object</em> of the endorsement is one’s attitudes. E.g. one endorses or (renounces) their fear, anger, resentment, desires, etc. Because of this, normative judgments of this kind are probably only present in humans (and perhaps some very rare outliers of others species). Whereas an animal acts according to its desires and believes according to its perceptions, humans have the capacity to step back from their desires/perceptions (and attitudes in general) and question whether those initial attitudes constitute reasons for action/belief, and (if the initial attitudes are normatively assessable) whether there is reason to adopt those initial attitudes.</p>

<p>There may be a sense in which a person can have unreflective endorsement of their attitudes. For example, if you asked a thoughtless person what they think they should do, they might quickly respond with an action that satisfies their most present desires. They might never actually take a step back and question whether they endorsed their desire or whether they have reason to hold the desire. They might never question <em>why</em> they have that desire or what kind of reason they have to pursue the object of that desire. They might never investigate the relevant features of the object of the desire that grounds the reasons. They may never question whether the desire provides them with reason for action. They might never consider how that desire conflicts with other desires that they approve of and what kind of importance or priority the desire should have relative to other reasons he acknowledges. But since they do approve of their desire in a trivial sense, they can be said to endorse their desire in a weak sense. While this oftentimes does happen with normative judgments/statements, this is somewhat similar to the case of a person who expresses straightforwardly non-normative attitudes. This is not the essential feature of normative judgments, which is endorsement after reflection and questioning what one actually takes to be a reason.</p>

<h4 id="prescriptive">Prescriptive</h4>

<p>There is another core element to normative judgments in addition to <em>expressing</em> deliberative endorsement. That is their function at <em>evoking</em> the attitudes of others. Thus, there is an <em>expressive</em> component and a <em>prescriptive</em> component to normative judgments. The prescriptive component is particularly strong for moral judgments. When someone judges that X is wrong, they are expressing a lot of attitudes: they endorse not performing X, they endorse blaming anyone who does X, etc. But it also serves to influence the attitudes of others around them; it is using language as a tool to cause others to refrain from doing X, to blame anyone does X, to incite guilt in anyone who does X, etc. This is the second way that non-cognitivism expands the role of normative langauge. The considerations mentioned earlier showed how normative judgments are extended from expressions of mind-to-world state beliefs to expressions of world-to-mind state attitudes. Now, we see how normative language is extended even further, from a tool for <em>expressing</em> attitudes to a tool for <em>inciting</em> attitudes.</p>

<h3 id="language">Language</h3>

<ol>
  <li>Emotive Language</li>
  <li>Normative education (Descriptivism.md)</li>
  <li>Evolution -&gt; Non-cognitivism necessary and sufficient</li>
</ol>

<p>Concepts that become used emotively (thick ethical concepts?):</p>
<ul>
  <li>(Real) Man</li>
  <li>Son, E.g. when a father disowns a son, he says “You are not my son”. How does this make sense? Because calling someone a “son” doesn’t just describe an ancestral relationship. In our culture, it is implicitly tied to a normative judgment that certain attitudes are appropriate for anyone in this relationship (e.g. to be loving, to care for each other’s interests, to assist one another). But if one abandons these attitudes and no longer sees them as appropriate, they also refuse to ascribe the concept as well.</li>
  <li>Cool</li>
  <li>racist</li>
</ul>

<p>Some of these may have descriptive references, but given that they can be used emotively, people can use them in ways independent of their descriptive reference. E.g. A real man provides for his family, there’s nothing cool about taking unnecessary blows in a boxing match, a real nigga doesn’t go to prison, white nationalist arguing that they aren’t racist, etc. These are all normative expressions because they are ignoring the reference of these terms and instead using them as they are useful for expressing certain dynamic content. These are concepts that regulate specific attitudes in that they express them and prescribe them to others. Saying that a real man does X expresses the imperative that man ought to do X. Saying X is cool expresses the imperative that we ought to appreciate and celebrate someone who does X, etc.</p>

<p>Why there is objective purport? Why not have our language just be “Boo!” and “Yay!”</p>
<ul>
  <li>Evolutionary advantages: Objective prescriptions more likely to be adopted by others</li>
  <li>Subject-verb form statements allow for more precision/clarity. We find it already with phrases like “that’s a tasty dish” instead of saying “mmmm”</li>
</ul>

<h3 id="truth">Truth</h3>

<p>Indispensability argument for normative truth</p>

<p>The theory of truth should be such that any agent who accepts its truth abides by the above considerations. I.e. a theory which says “A ought to X iff relation R holds between A and X” implies that any agent who accepts relation R is disposed to follow the above considerations regarding ubiquity, motivation, reasoning, and disagreement.</p>

<p>Third-personal normative judgments. When A judges that B ought to X, how is this to be analyzed? Is it, A, from his own perspective, endorsing B having the attitude? Or is it A imagining what he would endorse if in B’s perspective? Both can occur. The former is an external reasons judgment (expressive, prescriptive, speaker-endorsement) whereas the latter is an internal reasons judgment (constructivism, explanatory, subject-endorsement). There are two normative concepts we use. It makes sense to say “the capitalist ought to raise prices that maximize his profits” (in the sense that it would be irrational to do otherwise, a normative conception) and to say “the capitalize ought not to just maximize his profits” (not that it would be irrational, but in that it is not endorsed from the speaker’s perspective). 
-&gt; Internal personal reasons: the only reasons that do not entail a subject-indexed reasons. E.g. on external reason judgment (focused around speaker endorsement), we can never say “R is a reason for A to X”. We would have to say “R is a reason for A to X, from B’s perspective”. This is not useful.
-&gt; Do the above considerations (ubiquity, motivation, disagreement, and reasoning) apply to both internal and external reasons. For subject-endorsed normative judgments, they always apply (e.g. external reasons). For subject-endorsed reasons, they apply when the speaker is the subject (i.e. someone is deciding what they ought to do). What about 3rd party subject-endorsed reasons? Do they entail a form of motivation or disagreement? Perhaps under a universal conception of reasons (see Michael Smith), we can account for disagreement. Perhaps we can also account for speaker-motivation - i.e. when S says “A ought to X”, the speaker would be motivated to do X in A’s circumstances. Thus, we have the following:
	- A believes “I ought to X” 
		-&gt; Judgment: A is motivated to X
		-&gt; Truth: A would be motivated to X insofar as he is rational
	- S believes “A ought to X”
		-&gt; External Judgment: S is disposed to have pro-attitude with regard to A doing X
		-&gt; External Truth: 
			- S would be motivated to have the pro-attitude with regard to A doing X insofar as S is rational 
			- Appeal to the features constituitive of the pro-attitude that A holds. 
			- Can this avoid speaker-indexed truth? Maybe not, but that’s okay.
		-&gt; Internal Judgment: S is disposed to be motivated to X in A’s circumstances
		-&gt; Internal Truth: 
			- Option 1: S would be motivated to X in A’s circumstances insofar as S is rational [speaker-indexed truth, weird]
				-&gt; What does “circumstances” even mean? It has to include the desires, goals, interests, etc. of A. Does it include all of his motivations? 
			- Option 2: A would be motivated to X insofar as A is rational
				–&gt; Perhaps both can be accepted, if we have a universal conception of reasons???
		-&gt; Thus, all are based on speaker endorsement and what’s rational for the speaker, Just one is concerned with whether the pro-attitude of the speaker is appropriate and one is concerned with whether the hypothetical behavior of the speaker in certain circumstances are appropriate.
		-&gt; Not sure if a fully universal conception of reasons is necessary. Perhaps we just need enough objectivity to have meaningful disagreements.</p>

<p>Explantory/Motivational/Internal aspect (some belong here, some belong in Normative Correctness.md):</p>
<ul>
  <li>Psychological: They would not have evolved if they were not motivational. Beliefs are not necessarily motivational but they are still evolutionarily advantageous as they are about the real world, which influences are reproductive ability.</li>
  <li>Rationality: Even if we have an external reason to adopt an attitude, we need an internal/procedural characterization of reasons because there needs to be a method for us to determine what to do when we don’t have access to those external reasons. E.g. there is some external reason for all of us to hold beliefs that are true, but we may be completely cut off from which beliefs are true. We only know which are justified given our sensory input - and so we need an internal conception of reasons to articulate the nature of this justification. The same goes for external reasons for action like kindness or generosity, etc. We might be cut off from this. It might be argued we are not cut off from this. We are aware of what kindness is, and we know what it is to be kind, so we have access. But this is just like saying we know what P is and we know what it is to believe P, so if P is true then we have reason to believe P, because we have access. But this is clearly wrong. That P is true cannot itself be a reason that anyone accepts as a reason to believe P. Likewise, than an action exhibits kindndess is no reason to perform that action.</li>
  <li>Irrationality: There is a conception of reasons such that insofar as one accepts that they have reason to X yet fail to X they are being irrational.</li>
  <li>Motivational: when one judges that they ought to X, this produces are motivation to X insofar as they are rational. But this is only true under the internalist conception of reasons. But this can only true (necessarily) if they accept that X is the rational extension of their current normative stance. I.e. its only true if they acknowledge that X is the rational extension of their current normative stance and fail to do X (internal reason). It would not be true if they acknowledge that X has certain properties which are independent of their current normative stance but which are virtuous or perceieved to be virtuous in some way. One might respond by saying “to be rational” is just to be receptive to reasons. But this is not true, at least not under an externalist conception of reasons. I.e. we wouldn’t acuse someone of being irrational just for not believing something that was true, even if it was a priori knowable.</li>
  <li>Ought implies can: To say that A has reason to X implies not just that A is capable of doing X but that A is rationally capable of doing X. E.g. in a weak sense everyone is logically capable of writing genius level papers. However, we wouldn’t say everyone is rationally capable of doing such. Thus, we wouldn’t say German Jews were irrational for not writing genuis level material to get enough attention to escape the Holocaust. So rational capacity has to be stronger than logical, metaphysical, physical or biological possibility. It’s not just as simple as saying “That which is rationally accessible is that which a person would do if they intended”. Because it is true of most people that if they intended to write out [insert proof of some theory here], then that person would have written out [insert proof of some theory here]. However, this clearly is not something we are all rationally capable of. In addition to saying “A is rationally capable of doing X so long as A would do X if A intended to”, we also have to say “X is rationally accessible to us” where rational accessibility does not apply to something like [insert proof of some theory here]. Note that this may actually be stronger than what an agent has reason to do or what is the rational extension of an agent’s given attitudes - e.g. the proof of certain mathematical theories are accessible in the sense that we can deduce them from first principles, but there is a sense that there are not rationally accessible to us. However, it can’t be so strong that it only includes whatever action an agent actually does. There are cases where an agent fails to do something that is rationally accessible to them.
    <ul>
      <li>The above cases of derivability (but not counterfactual motivation) might lack the accessibility for charges of irrationality.</li>
      <li>But derivability is sufficient for charges of reasons for/against (counterfactual motivation is not necessary, unless it is <em>perfect, ideal</em> counuterfactual motivation. Ideal, perfect counterfactual motivation = derivability?).
–&gt; Three relevant axis regarding action X and agent A:</li>
      <li>(1) Freedom: Would A X if he intended to? T</li>
      <li>(2) Accessibility: Is A aware that X is an option? Would he be aware if he applied the appropriate standards to his thinking?</li>
      <li>(3) Rational accessibility: is A motivated to X (motivating reason)? Would A be motivated to X if he intended to deliberate according to standards he endorses (strong internal reason)? Is X the rational extension of his current motivations (e.g. mathematical proofs derivable, but he might not discover it if he intended to deliberative according to standards he endorses) (weak internal reason)?</li>
    </ul>
  </li>
  <li>(1) and (3) necessary to have reason to do an action</li>
  <li>(1) and (2) necessary to have free will, i.e. to be blamed for not doing an action, character assessmenets (i.e. assessments of their character).</li>
  <li>(1), (2) and (3) necessary for charges of irrationality.</li>
  <li>The three pillars? Desire, Belief and Opportunity. Belief + Desire =&gt; Intention. Intention + Opportunity =&gt; Action.</li>
</ul>

<h3 id="comparisons-with-alternative-theories">Comparisons with Alternative Theories</h3>

<p>Compare non-cognitivism with other theories</p>

<p><em>Beliefs and attitudes are logically independent</em> Take a descriptivist theory of normative judgment which says that ascriptions of goodness to x express belief p to x. Take a non-descriptivist theory of normative judgment which says that such ascriptions express non-descriptivist attitude q to x. Imagine an agent held q with regard to x but they did not hold p with regard to x. It seems safe to say that they judge x to be good. Now imagine that they held p with regard to x but they did not hold q with regard to x. It seems safe to say that they don’t judge to be good.</p>

<ul>
  <li>Non-naturalism: imagine someone used normative terms with the same extension as normal, competent English speakers. It is possible that someone could do this without sincerely making a normative judgment (or even by making inverse normative judgments) under both non-cognitivism and non-naturalism. They happen to be using the same terms and extension as us, but they <em>mean</em> differently and have a different <em>intension</em>. I.e. they are using the same terms but expressing different concepts with those terms. Non-cognitivism explains this by the presence or lack of certain attitudes. We can use look at their attitudes to learn whether or not they were using the same concepts. On non-naturalism, it is impossible to know if they had the same meaning. We might try to appeal to their attitudes, but on non-naturalism such attitudes are not necessary. And if they were necessary, then how?
–&gt; Even imagine that someone thought an object had certain normative properties. It is still an open question as to whether someone would endorse/approve or reject/disapprove those properties. I.e. they could have a negative attitude with regard to the normative properties that we take to be good.</li>
</ul>

<p>Non-cognitivism explains many features</p>
<ul>
  <li>The Open Question Argument</li>
  <li>The is/ought gap</li>
</ul>

<p>This analysis of normative statements and normative judgments solves the issues that plagued belief-based theories.</p>

<p>Firstly, unlike some of the simpler belief-based theories, this analysis can account for familiar normative disagreement. The key issue mentioned earlier with belief-based theories was that it seemed that people could have normative disagreements (especially morally) even if all parties agreed on all of the facts about the world. This can be accounted for with a non-cognitive analysis because normative judgments are not beliefs or other mind-to-world state that represent the world. Rather, they are more akin to plans or some other world-to-mind state that consists of how how one orients themselves in the world. So, two people can have conflicting plans (in the sense that they cannot both be <em>actualized</em>), which suffices for normative disagreement, even though they might have identical mind-to-world states.</p>

<p>Secondly, a non-cognitive analysis can be generalized for all normative judgments and statements. As mentioned earlier, there is a core attitude shared among all normative judgments - that is the attitude of deliberative endorsement. Normative concepts differ depending on the object of the endorsement - whether it’s a belief, a desire, fear, anger, etc. that is being endorsed. The key element of endorsement is what’s shared.</p>

<p>This analysis avoids any controversial issues regarding the correctness of normative judgments. The reason is that this analysis mantains that normative of judgments don’t purport to correspond to an independent normative realm. Because there is no independent normative realm, it doesn’t posit a realm that would be the standard for normative judgments. Thus, normative judgments are not actually true or false on this theory, at least not if “true” and “false” are used in the ordinary sense, which is to say correspondence to some independent reality. It may be possible that there is a kind of “correctness” that we can construct for normative langauge that is distinct from the standard of truth for ordinary descriptive judgments, but non-cognitivism doesn’t necessarily have any say on the matter.</p>

<p>A non-cognitive analysis also escapes the semantic problems that plague belief-based theories. As mentioned earlier, for any belief-based theory that suggest a definitional reduction between normative property M and natural property N, such a theory implies that if a person believes that an object is M, then we can deduce that the person also believed that the object is N (and vice-versa). In other words, we can deduce normative beliefs from factual beliefs (and vice-versa). Non-cognitive analysis does not suffer from same issue. In fact, it <em>explains</em> why the disconnect exists in the first place. Because normative judgments express a world-to-mind fit state whereas factual judgments express a mind-to-world fit, non-cognitivism avoids reducing either domain to the other and explains why any system that attempts to do this is doomed to failure. For any proposed naturalistic properties about an attitude, an agent could either endorse or renounce the attitude in question. Thus, the agent could simultaneously judge themselves to have reason to adopt or not adopt the attitude in question, all without betraying incoherence.</p>

<p>This analysis also explains why normative language is important and inescapable. The reason we still use normative language is because we need to express the attitudes we need to express the world-to-mind fit attitudes that we happen to have. One of the purposes of communications is to allow agents to express their attitudes. Verbal language is one of the many tools to aid in communication (e.g. there’s also non-verbal language such as body langauge). All agents must have both mind-to-world fit and world-to-mind fit attitudes. Therefore, there is just as much communicative benefit to expressing world-to-mind fit attitudes as there is for expressing mind-to-world fit attitudes.</p>

<p>In fact, the communication of non-cognitive attitudes is arguably even more important. Because humans are natural social animals, our success depends in large part on how we are to coordinate and cooperate with one other. Coordination involves the coordination of attitudes. Such coordination will require some sort of tool to express and modify the attitudes of others. Normative language is one such tool to accomplish this. There are, of course, other ways of achieving this, e.g. sticking a middle finger at someone, frowning to someone, crossing your arms with a certain facial expression, etc. can all express anger. The benefit of using language is that it allows for more fine-grained, clear and precise expressions and modifications of one’s attitudes. The precision of language even aids in concept-formation as we learn about what our attitudes actually are.</p>

<h2 id="objections">Objections</h2>


    </li>
  
    <li>
      <h2><a href="/2019/06/19/Substantive-Morality.html">Substantive Morality</a></h2>
      <p></p>
<p>This is to flesh out my substantive ethical theory, to specify specifically which actions are right and wrong in a way that can be characterized without reference to normative terms.</p>

<ul>
  <li>Constructivism
    <ul>
      <li>Reasons are contingent, subjective constructions.</li>
      <li>Moral discussions committed to reasons for all.</li>
      <li>Moral discussions committed to methodological objectivity.</li>
      <li>Moral obligations exist only for those contingently engaged in moral discussions.</li>
      <li>Moral truth = socially constructed.</li>
    </ul>
  </li>
  <li>Moral principles
    <ul>
      <li>Regulating societal approval/disapproval</li>
    </ul>
  </li>
  <li>Legal principles
    <ul>
      <li>Regulating coercion</li>
      <li>More disagreement -&gt; more libertarian principles. Why?</li>
    </ul>
  </li>
  <li>Goodness/Badness
    <ul>
      <li>Reason for an individual to promote/desire</li>
      <li>Individual Instantaneous Goodness</li>
      <li>Lifetime Goodness</li>
      <li>Collective Goodness</li>
    </ul>
  </li>
  <li>Rightness/Wrongness
    <ul>
      <li>Reason for a society to approve/praise/disapprove/resent</li>
      <li>Wrongness requires something bad for someone</li>
      <li>Large increases justify small deficits</li>
    </ul>
  </li>
  <li>Political Principles
    <ul>
      <li>Egalitarian Libertarian</li>
      <li>Social Ownership</li>
    </ul>
  </li>
  <li>Political Views
    <ul>
      <li>Abortion: Radical Pro-choice</li>
      <li>Education: Robust Subsidization</li>
      <li>Healthcare: Robust Subsidization</li>
      <li>Gay Marriage: Mandated Legalized</li>
      <li>Crimally Justice: Radical Rehabilitation</li>
      <li>Welfare: Non-dsygenic</li>
      <li>Affirmative Action: Ineffective</li>
      <li>Immigration: Skilled, Required labor only</li>
      <li>Discrimination: Legal in some circumstances</li>
    </ul>
  </li>
</ul>

<h2 id="types-of-moral-arguments">Types of moral arguments</h2>

<p>To argue that a particular act X is wrong/right in a particular circumstance C, there are a few possible arguments:</p>

<ul>
  <li>Appeal to some fundamental principle that provides a determinate answer to the rightness/wrongness of X in circumstance C. See below for arguments in favor of fundamental principles. Of course, this is assuming that the fundamental moral principles form determinate answers, which need not be the case. This also assumes that there are fundamental moral principles, which need not be the case.</li>
  <li>Appeal to the obvious rightness/wrongness of an analogous act X’ in an analogous circumstance C’. This theory can remain agnostic to the truth/weight of any fundamental moral principles (if any such principles even exist). This strategy is committed only to the fact that there clearly is a constraint on which <em>considerations</em> are morally relevant (regardless of whether and how those considerations can be reduced to certain principles). Considerations such as happiness, desires, autonomy, responsibility, etc. are potentially relevant moral considerations (i.e. humans clearly use these considerations in ordinary moral thinking; whether they really should be used and/or whether some of these are only instrumentally valuable is a further question). But there are clearly considerations that don’t count as morally relevant. This style of argument works if it can be shown that the differences between C and C’ are definitely not potentially relevant moral considerations.</li>
</ul>

<p>To argue for certain fundamental principles:</p>

<ul>
  <li>Reflective Equilibrium: Argue that these principles best explain, or cohere with, our considered moral judgments. The problem here is that the best principles that explain our moral judgments might not be nonconflicting, i.e. the considerations that explain our considered moral judgments might not reduce to the same principles (which means it might not provide determinate answers in all circumstances), and/or different people might have fundamentally different irreconcilable considered moral judgments.</li>
  <li>Foundational: Build these principles from the ground up, either from a metaethical theory, or pure rationality, or pure consistency, or from minimal constraints on any coherent moral theory. This may be too ambitious.</li>
</ul>

<h2 id="the-good">The Good</h2>

<ul>
  <li>Badness only occurs when there is conflict. Even though things might not be very good without conflict.</li>
  <li>Force only justified if other force is prevented. Even though things might not be very good if this weren’t the case.</li>
</ul>

<p>–&gt; self-defense from blameworthy agent -&gt; self-defense from non-blameworthy agent -&gt; self-defense by harming unrelated agent.
–&gt; radical egoism (everyone promote my interests) -&gt; egoism -&gt; 
–&gt; All interests are not commensurate, e.g. there is no N such that losing a limb = N pinches. How to determine the layers of harm? Ask an individual if they themselves consider the harms to be commensurate, i.e. would they lose a limb in favor of N backrubs? If no, then these cannot be weighted for/against each other across persons.</p>

<h3 id="individual-goodness">Individual Goodness</h3>

<p>Concerns our reasons for desires/intentions</p>

<p>Only one constraint that I’m convinced of for now: in order for something to be good or bad for someone, that person has to be alive. Possibilties for individual goodness:</p>

<ul>
  <li>Experience Based
    <ul>
      <li>Quantitative hedonism (sensory experience):
        <ul>
          <li>What if someone doesn’t value this intrinsically?</li>
        </ul>
      </li>
      <li>Qualitative Hedonism (sensory experience):
        <ul>
          <li>But how to compare different pleasures?</li>
          <li>Mill’s test seems unmotivated.</li>
        </ul>
      </li>
      <li>Preference hedonism (attitudinal pleasure):
        <ul>
          <li>Preferred states of consciousness</li>
          <li>Enjoyment</li>
        </ul>
      </li>
      <li>General Problems
        <ul>
          <li>What if someone’s preferred state of consciousness is based on false beliefs? E.g. A thinks P is true which makes him happy, but P is false.</li>
          <li>What if someone values something else intrinsically?</li>
          <li>Should we prohibit fully informed decisions of adults if they choose something that lowers their happiness?</li>
          <li>How to compare pleasure and pain? Not an objection per se, but defeats the alleged virtue of simplicity.</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>Preference Based
    <ul>
      <li>Unrestricted preference satisfaction:
        <ul>
          <li>People can have uninformed, irrational preferences</li>
        </ul>
      </li>
      <li>Fully informed, rational aims/preferences:</li>
      <li>Success theory: Satisfaction of preferences about one’s own life, i.e. preferences about features that are introspectively discernable</li>
      <li>General Problems
        <ul>
          <li>If someone’s preference is satisfied without their knowledge, how is that good for them?</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>Other
    <ul>
      <li>Objective list theory / Pluralism: knowledge, friendship, etc.
        <ul>
          <li>Seems unmotivated.</li>
          <li>What unites them?</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>General Issues
    <ul>
      <li>Why assume its telelogical?
        <ul>
          <li>Oftentimes to say X is good, we mean we have reason to promote X</li>
          <li>But not always: e.g. loyalty is good =/= we have reason to promote loyalty, i.e. betraying a friend to promote loyalty is not to value loyalty.</li>
        </ul>
      </li>
      <li>Why assume we can reduce to a single utility, that can be represented by some number.
        <ul>
          <li>Lexical Orderings? E.g. no amount of small pleasures can outweigh torture.</li>
        </ul>
      </li>
      <li>How to quantify pleasure/preferences into a numerical unit?</li>
      <li>What if pleasure/desires are sadistic? Should it be desert-adjusted?</li>
      <li>What if someone doesn’t deserve the pleasure/desire satisfaction? Double desert-adjusted?</li>
    </ul>
  </li>
  <li>Best approach
    <ul>
      <li>Ignore ideas about “maximizing” or “increasing” or “promoting” some end good.</li>
      <li>Rather, experiences are ranked according to whether people endorse those states.</li>
      <li>There may be states that cannot be said to be strictly better than another because they are incomparable, e.g. if you have two options A and B, and regardless of the one you pick you will be happy for your choice.</li>
    </ul>
  </li>
</ul>

<h3 id="collective-goodness">Collective Goodness:</h3>

<p>For aggregating across time and aggregating across time</p>

<ul>
  <li>Interpersonal comparisons
    <ul>
      <li>How to measure the strength of one pleasure/preference over someone else’s?</li>
      <li>E.g. A prefers/takes pleasure in X whereas B prefers/takes pleasure in not-X</li>
    </ul>
  </li>
  <li>Maximizing the sum of utility.
    <ul>
      <li>Adding more people is somehow better. Who could have reason to bring in new people?</li>
      <li>Repugnant conclusion: If everyone in S1 has X well-being and everyone in S2 has Y well-being (where X »&gt; Y), then S2 is better than S1 so longer as the number of people in S2 is large enough. Some examples that are against leftist reasoning:
        <ul>
          <li>Denying minorities certain rights in a bigoted society</li>
          <li>Abortion must be outlawed</li>
          <li>Hate speech against minorities</li>
        </ul>
      </li>
      <li>Utility Monster: one being produces far more pleasure than another, or far stronger preferences.</li>
    </ul>
  </li>
  <li>Maximizing the average.
    <ul>
      <li>Having children with below average utility makes the world a worse place.</li>
      <li>Utility monster.</li>
    </ul>
  </li>
  <li>Minimizing pain:
    <ul>
      <li>Killing people painlessly would be good.</li>
      <li>Imagine inflicting small amount of pain to produce a large amount of pleasure.</li>
    </ul>
  </li>
  <li>Other options:
    <ul>
      <li>Pareto optimality.</li>
      <li>Principles that would be preferred by everyone if they didn’t know where they would fall within the distribution.</li>
      <li>Small diminishes to someone with high well-being for a large increase to someone with low well-being.</li>
    </ul>
  </li>
  <li>Best approach
    <ul>
      <li>Ignore ideas about “maximizing” or “increasing” or “promoting” some end good.</li>
      <li>Rather, states are ranked according to whether people prefer living in that world.</li>
      <li>There may be states that cannot be said to be strictly better than another because they are incomparable, e.g. if people have different preferences. E.g. A would prefer living in a world with a higher average but lower floor, whereas B prefers living in a world with lower average but higher floor.</li>
    </ul>
  </li>
</ul>

<h2 id="the-right---fundamental-moral-principles">The Right - Fundamental moral principles</h2>

<p>In order for an action to be wrong, it must be bad for someone, i.e. limiting in their fully rational aims in some way.</p>

<p>There are fundamentally different kinds of aims. Cannot be reduced to one another, neither in their significance to the person nor in their relevance for moral decisions (e.g. coercion cannot be justified by compensating preferred state of consciousness):</p>

<ol>
  <li>Preferred states of consciousness</li>
  <li>Resource acquisition</li>
  <li>Bodily autonomy</li>
</ol>

<p>Limitations on (3) can only be justified by preventing other limitations on (3). Limitations on (2) can be justified to prevent limitations on (2) or (3). Limitations on (1) can be justified by preventing limitations on (1), (2) or (3).</p>

<p>Argument for deontic restrictions (“side constraints”)</p>
<ol>
  <li>[Premise] Moral Reason: A is morally obligated to X only if A has no reason to reject a principle that requires him to X</li>
  <li>[Premise] Reasons: A has reason to reject a principle that requires him to subjugate himself as a means to maximize the impersonal good.</li>
  <li>[Premise] Symmetry: if A is not morally obligated to X, then others are not morally permitted to coerce A into doing X.</li>
  <li>[from 1 and 2] Moral Perogative: A is morally permitted to refuse to subjugate himself as a means to maximize the impersonal good.</li>
  <li>[from 3 and 4] Moral restrictions: Other people are not morally permitted to coerce A into subjugation as a means to maximize the impersonal good.</li>
</ol>

<h3 id="against-utilitarianism">Against utilitarianism</h3>

<p>Problems:</p>
<ol>
  <li>How to quantify the good?
    <ul>
      <li>In ordinary circumstances (not philosophical thought experiments), there is a balance of certain people being harmed on both sides (consider restrictions on free speech). How do you know that the harms from one side outweigh the other?</li>
    </ul>
  </li>
  <li>What aggregation function for collective well-being?
    <ul>
      <li>See earlier issues</li>
    </ul>
  </li>
  <li>Why assume that the right reduces to the good?
    <ul>
      <li>The good is all we care about. Sure, but that says nothing about morality. Plenty of normative realms are not just matters of promoting the good (epistemology, ettiquette, etc.), so why assume that’s the case for morality? E.g. epistemology is not consequentialist.</li>
      <li>Metaethical: morality just is social rationality, and rationality is promoting the good. Is that what morality is?</li>
      <li>Intuition:
        <ul>
          <li>From an impartial perspective (e.g. behind a veil of ignorance, not using indexicals, etc. and only looking at goods of foundational value, e.g. happiness, preferences generally, etc. regardless of whether it is degenerate interests, distinguishing between deserved/predictable harms versus undeserved/unpredictable harms, etc.), I might agree that it is “better” to live in world where there were less innocent deaths. But that doesn’t commit me to thinking it is moral to kill an innocent to reduce deaths (even if there was a rule that reliably reduced the death efficiently by killing innocents). One might say that this is because I think killing innocents is worse than killing people dying due to desert or negligence. However, I don’t know why these features are relevant from an impartial perspective (i.e. behind the veil of ignorance, you only care about happiness generally, not whether its distributed toward those with the appropriate intentions). From an impartial perspective, there is no distinction between two worlds with identical amount of happiness, preference-satisfaction, etc. etc. where in one world the happiness is distributed to the virtuous but in another case it is distributed toward the vicious. From an impartial perspective, these are “equally” good, i.e. would be preferred equally by someone who didn’t know if they would be vicious or virtuous. However, I believe there is a moral distinction. So there is clearly a difference between good and moral.</li>
          <li>And if we are not speaking about our preferences from behind the veil of ignorance, then my preferences might be fairly egoistic. In this case, “good” might coincide with “moral”. But then what I count to be “good” would probably diverge greatly from what others think.</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>Why does everyone have reason to accept this? Why would X have reason to make significant sacrifices to himself to improve the overall state?
    <ul>
      <li>It seems individuals don’t have reason to accept a system that would subjugate them to impersonal optimality. To use intuitions to show this: if utilitarianism were true, then individual agents would be morally required to subjugate <em>themselves</em> to impersonal optimality (not just that <em>others</em> would be morally required to do this). But it does not seem that individuals have reason to do this. Because agents have no duty to do what they lack reason to do, agents do not have a moral duty to maximize the good</li>
    </ul>
  </li>
  <li>People morally obligated to sacrifice themselves for (1) the the life of another, if it is known that the other’s life would be better, and (2) the well-being of many others, if it is known that their well-being would exceed your own.</li>
</ol>

<h2 id="consequentialism">Consequentialism</h2>

<p>Features of consequentialism:</p>

<p>All systems are aimed at reaching some state of affairs. The question is what constitutes the value of those states of affairs. E.g. deontology can be considered something that “A should not X” means “A should reduce the promotion of A doing X in the particular instance that A acts”.</p>

<p>From most necessary for consequentialism to least necessary:</p>

<ul>
  <li>Requirements:
    <ul>
      <li>Moral right/wrongness reduces to goodness of the resulting states of affairs.</li>
      <li>Universal Teleology. All reasons are reasons to bring certain entities into existence or promote states of affairs.</li>
      <li>Completeness: for all possible states of affairs and region of time, there is a complete order. “Complete” means for all possibilities, x,y: U(x) &gt;= U(y) or U(y) &gt;= U(x). “Order” means transitive and reflexive. Must be additive in a very general sense: there is a function f that takes as input a given space-time region of the universe (a state of affairs across a period of time) and returns some integer representing its overall value.</li>
      <li>If the below conditions are rejected, the system basically becomes a way for you to endorse whatever states of affairs you prefer living in. This can be consequentialist in a broad sense, but does not meet the maximizing spirit of consequentialism. There are two reasons for this:
        <ol>
          <li>Because there is effectively no measure, it doesn’t make much sense to say “more utility” is guiding the decisions. Rather, one just endorses the kind of world that they prefer living in. Appealing to utility does no work here.</li>
          <li>This is a rather egoistic interpretation, which goes against the spirit of conseqentialism. Someone might say the world that they prefer to live in is one where everyone maximizes his pleasure. But that doesn’t mean it satisfies the spirit of consequentialism.</li>
        </ol>
      </li>
    </ul>
  </li>
  <li>Agent-neutrality and temporal-neutrality:
    <ul>
      <li>R is an agent-neutral reason for A to X (i.e. A has reason to X <em>because</em> of fact R) iff: R is characterized without reference to A. This focuses on the general form or principle of R, not just the particular token of the reason. E.g. the general form of the reason in “A has reason to help his friend because it would make his friend happy” can be either “A has reason to make his friends happy” (agent-relative) or “A has reason to make others happy” (agent-neutral).</li>
      <li>The state of affairs to be promoted can <em>always</em> be characterized without reference to the particular agent doing the acting. We can say X is better than Y simpliciter, not X is better than Y <em>for</em> Bob or Jane. This is not to say that we ought not do different things in particular cases. We can, but the goal is always towards the same ideal state of affairs (e.g. maybe Bob doing X and Jane doing not-X is the best way to maximize utility). E.g. a world with 1 bad act &gt; world with 2 bad acts. Thus, we should achieve the former between the two. This means A must perform 1 bad act if it prevents 2 bad acts. The only this can be avoided by defining good state of affairs to be relative to the acting agent, but this cannot be done.</li>
      <li>E.g. the moral obligation for an agent does not give a special status to that agent. This seems off to me. Agents can value themselves slightly more than others.</li>
      <li>E.g. the moral obligation is towards a non-indexed state of affairs, not an agent-indexed action. E.g. A has reason to rape if it reduces overall rape. Not sure about this.</li>
      <li>Similar remarks can be made about certain times: the state of affairs to be promoted can be characterized without reference to the time that the agent does the acting.</li>
      <li>Egoism rejects this, but egoism shouldn’t be understood as consequentialism which is focused on maximizing <em>The</em> Good. <em>The</em> Good assumes there is one good to be maximized, not many different goods relative to different agents.</li>
    </ul>
  </li>
  <li>Aggregative/Atomism/Maximizing:
    <ul>
      <li>Value of the whole = sum of value of the parts. Small utilities build up over large utilities. Contrast this atomistic consequentialism with a hollistic form of consequentialism, which might, e.g., look at distributions as relevant.</li>
      <li>This entails reasons which are agent/time-neutral, or at least not <em>strictly</em> agent/time-relative (see above). E.g. if a reason is strictly agent-relative, i.e. concerning the occurence of a particular agent performing an action, then there is no sense in a duty concerned with aggregating over everyone’s actions and summing utilities up.</li>
      <li>Aggregative across people. E.g. assuming U(A) &gt;= U(B) &gt;= 0 where A and B are persons, U(A+B) &gt; max(U(A), U(B)). Assuming N number of people with identical individual utility, U strictly increases as N increases. I reject this.</li>
      <li>Aggregative across time. E.g. assuming U(X) &gt;= U(Y) &gt;= where X and Y are time slices of the world. U(X+Y) &gt; max(U(X), U(Y)). Assuming t timespan of a particular region with identical instantaneous utility, U strictly increases with t. I reject this.</li>
    </ul>
  </li>
  <li>Commensurability/Comparability:
    <ul>
      <li>Must be promotional of a single quantifiable utility. All values (e.g. pleasure, suffering, pain, freedom, beauty, knowledge, virtuous actions, virtuous intentions, rights, etc.) can be reduced to single comparable utility units.</li>
      <li>Also, its possible to compare different person’s pleasures, preferences, etc.</li>
      <li>E.g. not just a hierarchy of possible states of affairs (even a deontologist would agree with that). The difference is that consequentialist rankings must be determined by the existence of a certain amount of a good. Some constant good in the universe that we appeal to to measure utility. Needed in order to quantify goodness on a number line.</li>
    </ul>
  </li>
  <li>Hedonism:
    <ul>
      <li>Pleasure is the single value (this does not include “suffering” or “pain” except as a lack of value).</li>
      <li>Contrast this with pluralism.</li>
    </ul>
  </li>
</ul>

<p>Not all of these features are necessary for all consequentialism. All are accepted by hedonistic utilitarianism, but not accepted by all consequentialists. Prerequisite list:</p>

<p>Consequentialism &lt; Teleology (teleology = requirement for consequentialism)
Consequentialism &lt; Completeness (Completeness = requirement for consequentialism)
Consequentialism &lt;~ Agent/Time-neutrality (Neutrality required if consequentialism is focused on maximizing <em>The</em> Good, rather than the Good <em>for</em> a particular agent)
Aggregation &lt; Agent/Time-neutrality
Hedonism &lt; Aggregation
Hedonism &lt; Commensurability</p>

<p>From SEP entry on consequentialism</p>

<ul>
  <li>Consequentialism = whether an act is morally right depends only on consequences (as opposed to the circumstances or the intrinsic nature of the act or anything that happens before the act).</li>
  <li>System
    <ul>
      <li>Actual Consequentialism = whether an act is morally right depends only on the actual consequences (as opposed to foreseen, foreseeable, intended, or likely consequences).</li>
      <li>Direct Consequentialism = whether an act is morally right depends only on the consequences of that act itself (as opposed to the consequences of the agent’s motive, of a rule or practice that covers other acts of the same kind, and so on).</li>
      <li>Maximizing Consequentialism = moral rightness depends only on which consequences are best (as opposed to merely satisfactory or an improvement over the status quo).</li>
    </ul>
  </li>
  <li>Value
    <ul>
      <li>Evaluative Consequentialism = moral rightness depends only on the value of the consequences (as opposed to non-evaluative features of the consequences).</li>
      <li>Hedonism = the value of the consequences depends only on the pleasures and pains in the consequences (as opposed to other supposed goods, such as freedom, knowledge, life, and so on).</li>
    </ul>
  </li>
  <li>Aggregation Function
    <ul>
      <li>Aggregative Consequentialism = which consequences are best is some function of the values of parts of those consequences (as opposed to rankings of whole worlds or sets of consequences).</li>
      <li>Total Consequentialism = moral rightness depends only on the total net good in the consequences (as opposed to the average net good per person).</li>
    </ul>
  </li>
  <li>Neutrality
    <ul>
      <li>Universal Consequentialism = moral rightness depends on the consequences for all people or sentient beings (as opposed to only the individual agent, members of the individual’s society, present people, or any other limited group).</li>
      <li>Equal Consideration = in determining moral rightness, benefits to one person matter just as much as similar benefits to any other person (= all who count count equally).</li>
      <li>Agent-neutrality = whether some consequences are better than others does not depend on whether the consequences are evaluated from the perspective of the agent (as opposed to an observer).</li>
    </ul>
  </li>
</ul>


    </li>
  
    <li>
      <h2><a href="/2019/06/19/Political-Philosophy.html">Political Philosophy</a></h2>
      <p></p>
<h2 id="readings">Readings</h2>

<p>From Sep: https://plato.stanford.edu/entries/libertarianism</p>
<ul>
  <li>They hold, for example, that each person has a right to maximum equal negative liberty, which is understood as the absence of forcible interference from other agents (e.g., Narveson 1988; Steiner 1994; Narveson &amp; Sterba 2010). This is sometimes called “Spencerian Libertarianism” (after Herbert Spencer).</li>
  <li>Most, however, focus more on the idea of self-ownership. Famously, this view is attributed to Robert Nozick (Cohen 1995; but see the discussion below).</li>
  <li>Full self-ownership might seem to condemn as wrongful even very minor infringements of the personal sphere, such as when tiny bits of pollution fall upon an unconsenting person…This objection, however, is of dubious force as it presupposes an (even more) implausible conception of full self-ownership than its defenders have reason to endorse. Suppose we understand the moral benefits that self-ownership confers along two dimensions: protections from unwanted uses of our bodies, and liberties to use our bodies. As the objection points out, it is not possible to simultaneously maximize the value of both dimensions: our protections restrict our liberties by restricting the possible uses of one’s body, and vice versa. Since maximizing the protection-dimension implausibly restricts the use-dimension, the correct response is not to reject self-ownership, but rather to loosen the protection-dimension somewhat in order to enhance the use-dimension. Doing this would allow minor infringements for the sake of self-ownership. As Eric Mack (2015) puts it, a good theory of self-ownership offers people some “elbow room.” (For more discussion, see Brennan &amp; Van der Vossen 2017)</li>
  <li>Libertarian theory can thus be defended in many different ways [rather than taking self-ownership to be a self-evident foundational principle]. This is true both of theories that give pride of place to self-ownership and of theories that don’t. Examples of the former include Eric Mack (2002, 2010) who sees self-ownership rights as among several natural rights grounded in our nature as purposive beings. In Mack’s view, the protections and freedoms offered by the idea are justified in order to grant to all individuals a separate sphere in which they can act in accordance to their self-chosen purposes. Similarly, Loren Lomasky (1987) derives rights from a related, although slightly different, conception of people as project pursuers. John Tomasi (2012) argues that strong rights over our bodies are required by the ideal of democratic legitimacy. According to Daniel Russell (2018), self-ownership rights provide the only way that people who live together can all genuinely live their own lives.</li>
</ul>

<p>From Sep: https://plato.stanford.edu/entries/liberty-positive-negative/ (read to get in text citations)</p>
<ul>
  <li>Feinberg, J., 1973, Social Philosophy, New Jersey: Prentice-Hall, ch. 1 [article-length general introduction].</li>
  <li>Flickschuh, K., 2007, Freedom. Contemporary Liberal Perspectives, Cambridge: Polity [introduction to Berlin and MacCallum together with analysis of the conceptions of freedom of Nozick, Steiner, Dworkin and Raz].</li>
  <li>Carter, I., Kramer, M. H. and Steiner, H. (eds.), 2007, Freedom: A Philosophical Anthology, Oxford: Blackwell [large number of excerpts from all the major contemporary contributions to the interpretation of freedom, with editorial introductions. The first of its nine sections is specifically on positive vs negative liberty].</li>
  <li>Gray, T., 1991, Freedom, London: Macmillan [comprehensive book-length introduction].</li>
  <li>Kukathas, C., 1993, Liberty, in R. Goodin and P. Pettit (eds.), A Companion to Contemporary Political Philosophy, Oxford: Blackwell [article-length general introduction].</li>
  <li>Pelczynski, Z. and Gray, J. (eds.), 1984, Conceptions of Liberty in Political Philosophy, London: Athlone Press [collection of essays on single authors, mostly historical].</li>
  <li>Miller, D. (ed.), 1991, Liberty, Oxford: Oxford University Press. 2nd ed., The Liberty Reader, Boulder, CO: Paradigm Publishers, 2006 [representative collection of contemporary essays, including Berlin and his critics, with editorial introduction and a guide to further reading].</li>
  <li>Plant, R., 1991, Modern Political Thought, Oxford: Blackwell, ch 1 [article-length general introduction].</li>
  <li>Schmidtz, D. (ed.), 2017, The Oxford Handbook of Freedom, New York: Oxford University Press [collection of up-to-date essays by major contemporary authors].</li>
</ul>

<p>From Kymlicka’s Introduction to Political Philosophy</p>
<ul>
  <li>For collections of recent libertarian thought,
    <ul>
      <li>see Tibor Machan and Douglas Rasmussen (eds.), Liberty for the Twenty-First Century: Contemporary Libertarian Thought</li>
      <li>David Boaz (ed.), The Libertarian Reader: Classic and Contemporary Writings from Lao-tzu to Milton Friedman (Free Press, 1997). The</li>
      <li>Norman Barry, Libertarianism in Philosophy and Politics (Cambridge University Press, 1991).</li>
      <li>For a comprehensive critique, see Alan Haworth, Anti-Libertarianism: Markets, Philosophy and Myth (Routledge, 1994).</li>
    </ul>
  </li>
  <li>The most influential account of the self-ownership argument is Robert Nozick’s Anarchy, State, and Utopia (Basic Books, 1974).</li>
  <li>The most powerful critique is G. A. Cohen’s Self-Ownership, Freedom and Equality (Cambridge University Press, 1995).</li>
  <li>For more general overviews of the debate around Nozick’s defence of libertarianism, see:
    <ul>
      <li>Jeffrey Paul (ed.), Reading Nozick (Rowman and Littlefield, 1981)</li>
      <li>and Jonathan Wolff, Robert Nozick: Property, Justice, and the Minimal State (Stanford University Press, 1991).</li>
    </ul>
  </li>
  <li>For a comprehensive overview of left-libertarianism, see the two-volume set edited by Peter Vallentyne and Hillel Steiner (The Origins of Left-Libertarianism: An Anthology of Historical Writings and Left-Libertarianism and its Critics: The Contemporary Debate, both published by Palgrave, 2000).</li>
</ul>

<p>Important Works</p>
<ul>
  <li>Isaiah Berlin’, “Two Concepts of Liberty”</li>
  <li>Gerald MacCallum, “Negative and Positive Freedom”</li>
  <li>Dworkin, All political theories have equality as the foundational value</li>
</ul>

<p>Critiques</p>
<ul>
  <li>Peter Railton, “Locke, Stock, and Peril: Natural Property Rights, Pollution,
and Risk” http://philosophyfaculty.ucsd.edu/faculty/rarneson/Courses/RailtonOnNozick.pdf</li>
</ul>

<h2 id="notes">Notes</h2>

<p>The Libertarian project:</p>
<ol>
  <li>Some moral principle (i.e. Kantian treating everyone as an end)
    <ul>
      <li>Self-ownership versus maximum equal liberty.
        <ul>
          <li>MEL avoids some of the problems with self-ownership. E.g. using force in dire circumstances. Permitting minor infringements on self-ownership to promote the liberty of others. It may be able to explain democratic regions with coercive policies. It allows saving a N number of people’s lives by sacrificing a few lives (note: this concerns comparable harm).</li>
          <li>MEL also retains the appeal of self-ownership. E.g. it is not permitted to cause major infringement to a small number of people to alleviate minor limitations of a large number of people. It need not be aggregative.</li>
          <li>Self-ownership might be a good hueristic given that certain liberties are already granted for the most part (e.g. not being tortured to death). The prinicple of MEL might be the more general principle.</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>Articulate a conception of liberty
    <ul>
      <li>Triadic relation: x is free iff x (an agent) has freedom from y (some interference) in achieving z (some goal).</li>
      <li>What kind of x matters? The actual agent? Their fully informed rational self? Their moral self?</li>
      <li>What kind of interferences matter? External agents? All external constraints? Internal constraints?</li>
      <li>What kind of goals? Any arbitrary goals? Goals related to one’s movement of their body?</li>
    </ul>
  </li>
  <li>Articulate how we ought to respect liberty
    <ul>
      <li>Never constrain others? Literally impossible. Even under anarchism, there are justified constraints on the behavior of others. E.g. private property justified using force to stop others from acquiring certain resources, self defense, etc.</li>
      <li>Maximize? Doesn’t seem right.</li>
      <li>Threshold? Perhaps.</li>
    </ul>
  </li>
  <li>Articulate a conception of property rights
    <ul>
      <li>A system of norms determining when force can be used to constrain how resources are to be used.</li>
      <li>What constitutes ownership? Full exercise of property use? Partial?</li>
      <li>Communal property or individual?</li>
      <li>Explain how the Lockean proviso is justified</li>
    </ul>
  </li>
  <li>Explain how the state is justified (for non-anarchists)
    <ul>
      <li>A centralized authority on the use of force not granted to common citizens.</li>
    </ul>
  </li>
</ol>

<p>Questions to be answered</p>
<ol>
  <li>Relationship bewteen morality and political legitimacy</li>
  <li>Justified uses of coercion
    <ul>
      <li>What <em>kinds</em> of behaviors are subject to coercion? E.g. can private life be coerced?</li>
      <li>What <em>kinds</em> of interests could justify coercing another group? can hatred justify coercion?</li>
    </ul>
  </li>
  <li>Why it seems we owe less to distant others? I.e. account for the sovereignty of nations
    <ul>
      <li>Many of the justifications to a local state do not apply globally. E.g. to protect oneself in a region might require using force in that region, but it does not require forcing everyone across the globe. I.e. anarchy is feasible on a global scale. Hypothetically, if some group could not get protection without the aid of some foreign country, then it could be justified to force that nation to assist. However, this is weird because (1) The poor nation would probably just be acquired by the stronger one, and (2) it seems strange that the poorer nation could force us to help if they can’t protect themselves,</li>
      <li>The scope of coercion can only be as expansive (geographically and temporally) as necessary (e.g. perhaps force is required temporally to provide people with the education to be self-sufficient, at which point it is no longer justified.).</li>
    </ul>
  </li>
  <li>Justifying the state without positive rights.</li>
  <li>Different levels of coercion: physical coercion, property redistribution, etc.
    <ul>
      <li>Major infringements of bodily autonomy (e.g. enslavement)</li>
      <li>Minor infringements of bodily autonomy (e.g. brushing against someone).</li>
      <li>Property confiscation.</li>
    </ul>
  </li>
  <li>Account for dire circumstances/consequences
    <ul>
      <li>Preconditions for moral duties to apply depend upon a certain relationship existing. If we’re all starving to death, morality doesn’t apply. It’s just a power struggle. We have to be in conditions such that we now have reason to enter a relationship of mutual recognition.</li>
      <li>If we are considering inflicting <em>massive</em> harm to an individual to alleviate <em>minor</em> harm to a lot of people, this is never justified.</li>
      <li>If we are considering inflicting some <em>massive</em> harm to an innocent individual to alleviate <em>comparable</em> harm to more innocents, this is justified when:
        <ul>
          <li>If we do nothing, all parties will suffer the harm.</li>
          <li>All parties are equally responsible for exposing themselves to the risk of the harm. E.g. the workers on the trolley problem. Contrast this with: killing a random innocent to save a group of people working on the trolley; the innocent did not consent to the risk whereas the workers did.</li>
          <li>In other cases, generally, no, this is not justified. What about dire circumstances? I.e. 1 person versus one million? This is a difficult question with no obvious answer. It’s not obvious that there needs to be an obvious answer.</li>
        </ul>
      </li>
    </ul>
  </li>
</ol>

<h2 id="against-common-libertarian-arguments">Against common libertarian arguments</h2>

<h3 id="against-anarchism">Against Anarchism</h3>

<p>Intuitive: Is it justified to break someone’s property to save someone drowning? The say no.</p>

<p>Historical:
	- Anarchism has been destroyed at every point in history. Why assume an anarchist society could defend itself?
	- Maybe it won’t.
		- Then this is pointless.</p>

<p>Logistical:
	- How do people defend themselves from assault?
	- Private defense agencies.
	- How is that different from a state?
	- (a) no monopoly, (b) no taxation, and (c) they follow the NAP
	- As for (b) and (c), why assume there would respect the NAP? History shows that people don’t in general follow the NAP, so why assume they would under anarchism?
	- So we’ve established that these coorporations would not follow the NAP.
	- As for (a), (b) and (c): there could be a sole coorporation in a given area, either because they were the first or because they outcompeted everyone else. What’s stop them from becoming a state? If there is competition, what’s to stop a war from occuring between several defense agencies (e.g. over religion or whatever) leading to a victor.</p>

<h3 id="against-minarchism">Against Minarchism</h3>

<p>Intuitive:
	- Is it justified to break someone’s property to save someone from drowning if they were pushed in by someone else whom you cannot identify?
	- Yes, because you have to protect their negative rights.
	- But this violates the negative rights of the property owner.
	- This is okay, because we have a duty to protect the negative rights of others.
	- Shouldn’t we also have a duty to protect the positive rights of others then?
	- No
	- What if someone is drowning not because someone pushed him but because of a gust of wind? Is this a relevant consideration?</p>

<p>What justifies using coercion to force others to support a state?</p>

<p>To protect the negative rights of others.</p>

<p>So people have a positive right to protection from violence</p>

<p>Against Nozick’s minimum state</p>
<ul>
  <li>We all have full and absolute rights to self-ownership and any property rights that follow from this. Whether a distribution is just depends on historical facts about how the distribution came to be, not end state facts about the current state of the distribution. If all property owned today came either via initial acquisition or free transfer, then the distribution is just, regardless of its inequality.</li>
  <li>(1) How to account for any just violations of liberty? Self-ownership implies full and absolute propety rights. How to account for positive rights to negative liberty (e.g. taxation)? Minor infringements on liberty to alleviate major constraints on others? Everyday behaviors that inevitably put others at risk (e.g. smoking causes pollution)? A theory of maximum equal baseline liberty can account for this. But a self-ownership argument to support this seems ad hoc, and may actually require appealing to maximum baseline liberty.</li>
  <li>(2) How to account for property in the real world? Nozick states that we have rights to property because we have a right to our bodies, our labor and talents. Thus we have a right to any external resources we gain with the exercise of our talents/labor. But this is conditional on legitimate acquisition of those resources. We can own property by (1) appropriating unowned property contingent on the Lockean proviso, (2) being the recipient of a free transfer of property, or (3) being the recipient of legitimate rectification. The problem is almost none of the property owned today has been justly acquired since it’s the result of war, subjugation, oppression, plunder, etc. and the idea of rectifying these unjustices in implausible. If we instead have a system of maximum equal baseline liberty, we can have a just system without dealing with going through history.</li>
</ul>

<h2 id="analysis-of-political-legitimacy--justice">Analysis of political legitimacy &amp; Justice</h2>

<p>Can it be reduced to morality? The moral justification of force?</p>

<p>It has to do with justification of state coercion.</p>

<p>Whether people should have a right to do X cannot reduce to whether X is immoral. Consider the following:</p>
<ul>
  <li>There are times when X is immoral but people should still have the right to do X. Lying, adultery, cheating in a game with friends, being disloyal, manipulating someone’s emotions, being an overall asshole, etc.</li>
  <li>There are times when X is not immoral but it can be justified to retract someone’s right to do X. These are instances where an individual doing X wouldn’t be immoral or even bad, but legalizing X would significantly harm the lives of people in society or a particular group in society. Certain forms of racial discrimination, hard drug usage, selling dangerous products, etc.</li>
</ul>

<p>It does not reduce to whether it is moral to stop people from doing X.</p>
<ul>
  <li>This may handle the above cases, but there are also some exceptions. There are cases where a person should have the right to do X, even though it would be moral to stop him from doing X. And there are cases where a person should not have the right to do X, even though it would be immoral to stop him from doing X.</li>
  <li>It would not be immoral for A to steal from B if it required saving A’s life, but B should the right to refuse.</li>
  <li>It would be immoral for B to stop A from getting B’s money to save his life, but A should not have that right.</li>
  <li>The distinction is due to the difference between an individual being morally permitted to coerce someone, and the state being permitted to coerce someone. You can have individual permission without state permission, and vice-versa.</li>
  <li>E.g. individual permission without state permission: an individual can kill one person to save themselves. And perhaps an individual can kill one person to save another. But the state cannot kill one to save one.</li>
  <li>This is because to do so would be to express priority of one person’s life to another. The state is supposed to be impartial with regard to the value of its individual citizens. An individual has permission to give priority of his own life over others in situations where one must die, but not the state. The state is supposed to be an impartial judge that can be justified to all citizens.</li>
  <li>E.g. in the other direction: It is justified to tax the rich to fund the education of the poor, but the poor cannot steal from the rich to fund their own education. You might say: this is because of the negative effects of allowing the latter moral principle to govern society, i.e. we would be afraid of being robbed spontaneously, unlike the government which is transparent and predictable. But even if the stealing was transparent and predictable (i.e. say, the church was doing the stealing, and they had their own constitution), it would still be wrong.</li>
</ul>

<h2 id="my-theory">My Theory</h2>

<p>Main differences with traditional libertarianism</p>
<ul>
  <li>Property
    <ul>
      <li>Everyone owns an equal share of the world’s raw resources</li>
      <li>Ccompensation is required when an initial agent uses/appropriates so much that others <em>actually attempt to</em>, but are prevented from, attaining an equal share as the initial agent.</li>
      <li>Some sort of communal property is possible. People can join together and form communities where they decide on coercive laws.</li>
    </ul>
  </li>
  <li>Central value
    <ul>
      <li>Not justified based on self-ownership,</li>
      <li>Some sort of entitlement to maximum baseline equal liberty, i.e. everyone entitled to the basic conditions necessary for the exercise of one’s capacity to pursue their conception of a good life.</li>
      <li>This includes negative liberty e.g. protection from assault, but also positive liberty, e.g. accessibility to basic needs, etc.</li>
    </ul>
  </li>
</ul>

<p>Possible critique, the theory doesn’t address some obscure issues:</p>
<ul>
  <li>E.g. the theory doesn’t tell us if someone can kill another to save themselves from being paralyzed, if they make someone undergo torture to save their life, etc.</li>
  <li>This is fine because (1) this sort of event never happens, and (2) it is not obvious that there is a right answer to this.</li>
  <li>There are only two reasons that a theory has to address an issue: (1) the issue is something we actually deal with and so we need a right answer, and (2) the issue might not happen but we intuit a strong answer, and so the theory needs to have the right answer.</li>
  <li>It’s okay if the theory says nothing about a case that meets neither of these conditions. In fact, it would be okay if the theory said anything because we are not really sure if it would be right or wrong.</li>
</ul>

<p>Intuitions:</p>

<p>Why liberty is the only thing that matters</p>
<ul>
  <li>Imagine a world of fully informed, fully rational agents with maximal equal liberty. How can coercion be justified here? To promote the aims of a particular agent?</li>
  <li>Imagine every possible political/economic system was available to people, and people could make a fully informed, consensual uncoerced decision on where to live. In this case, there can be no justification for coercion, even if that coercion resulted in more equality, utility, etc. So liberty is the primary value, and all other values - e.g. equality, utility, social order, etc. - are pursuable only insofar as they respect the demands of liberty.</li>
  <li>At the very least one has to accept that coercion is prima facie wrong and there needs to be justified exceptions to the rule. What constitutes the exceptions?
Why anarchy is wrong:</li>
  <li>Minor coercion to alleviate minor constraints is justifiable. E.g. taxation to protect people, breaking a fence to save a child.</li>
  <li>A lot of our everyday actions put others at risk. E.g. smoking causes pollution.</li>
  <li>Uninitiated minor/major coercion is justifiable. Coercion against A in self-defense is justified independently of whether A is responsible. E.g. imagine A presents a danger to others, but he is not responsible, but coercing A is the only way to stop the danger.
Why negative rights are wrong:</li>
  <li>Negative rights only are unsustainable. All taxation assumes that people have a positive right to negative liberty. Why not assume a positive right to positive liberty?</li>
</ul>

<p>Principles I accept:</p>
<ul>
  <li>Unprompted coercion against A at the benefit of B:
    <ul>
      <li>Can only be justified when:
        <ul>
          <li>The burden alleviated from B is great.</li>
          <li>The burden placed on A is minor.</li>
          <li>B does not have the opportunity to improve his situation. I.e. either
            <ul>
              <li>he isn’t aware of the actions he can take to improve his situation, or (force is justified for education)</li>
              <li>there are no actions he can take to alleviate his situation (force is justified for assistance)</li>
            </ul>
          </li>
        </ul>
      </li>
      <li>Intuition:
        <ul>
          <li>Imagine A and B have equal opportunity to the base requirements.
            <ul>
              <li>They directly have access to the same amount of raw resources.</li>
              <li>The are equally aware of the behaviors they can adopt to develop more resources.</li>
              <li>They would develop the same amount of resources if they performed the same behaviors.</li>
              <li>They are equally capable of performing these behaviors if they wanted (i.e. they aren’t starving)</li>
              <li>If A decides to dedicate more time/energy into developing his raw resources, B does not deserve any of the excess.</li>
            </ul>
          </li>
        </ul>
      </li>
    </ul>
  </li>
  <li>The scope of the coercion:
    <ul>
      <li>It must be limited:
        <ul>
          <li>as small a scope as necessary</li>
          <li>minimum force required</li>
        </ul>
      </li>
      <li>Intuition:
        <ul>
          <li>We don’t fund other nations’ governments when they are capable of doing so.</li>
          <li>Cities don’t fund other cities’ police, firefighting, education, etc. when they are capable of doing so.</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>Instances of coercion against A to benefit B must be democratically elected
    <ul>
      <li>These principles only show when coercion is justified, not when it is obligatory.</li>
      <li>If they are not agreed upon, then anarchism is fine.</li>
    </ul>
  </li>
  <li>Terminology
    <ul>
      <li>belief + desire = intention</li>
      <li>ability (internal to agent) + opportunity (external to agent) = capacity</li>
      <li>intention + capacity = actualization</li>
      <li>“constrained” = there is an interference</li>
      <li>“coercion” = the interference is via another agent.</li>
    </ul>
  </li>
  <li>Triadic relationship:
    <ul>
      <li>x is free iff x (an agent) has freedom from y (some interference) in achieving z (some goal).</li>
      <li>Formal versus Effective freedom concerns which characterizations of y matter. Is an agent free simply if they lack interference from other external agents (formal freedom) or if they lack interference from other agents and non-agent inference, including interference from their lack of abilites or internal characteristics (effective freedom)?</li>
      <li>A different way of characterizating the relationship:
        <ul>
          <li>x is free to z iff x (an agent) would achieve z if certain conditions C obtained. Insofar as x does not achieve z (assuming x is free to z), it is due to failing to meet some condition in C rather than some cause y (y is not in C). If x does not achieve z because of y, then x is not free.</li>
          <li>Formal Freedom: x is free iff x would achieve z if x had the appropriate intentions, ability, lack of external interferences, etc. Insofar as x does not achieve z (assuming x is free), this is due to some reason other than agent interference.</li>
          <li>Maximal Effective Freedom: x is free iff x would achieve z if x had the appropriate intentions. Insofar as x does not achieve z (assuming x is free to z), this is due to some reason other than some interference.</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>What counts as x?:
    <ul>
      <li>Preference vs autonomy?</li>
      <li>Freedom to do as one wants, or freedom to do as what one would want if they were rational?</li>
      <li>E.g. rational self vs animal/empirical self</li>
    </ul>
  </li>
  <li>What sources of interference y?:
    <ul>
      <li>Internal interferences, external interferences, other agent interferences?</li>
      <li>Formal liberty:
        <ul class="task-list">
          <li class="task-list-item">
<input type="checkbox" class="task-list-item-checkbox" disabled>Lack of agent intereference in seeking z</li>
        </ul>
      </li>
      <li>Effective liberty:
        <ul class="task-list">
          <li class="task-list-item">
<input type="checkbox" class="task-list-item-checkbox" disabled>Lack of external/internal interference in seeking z</li>
          <li class="task-list-item">
<input type="checkbox" class="task-list-item-checkbox" disabled>x would z if he had the appropriate present intentions/abilities and historical intentions/abilities (i.e. he might not have the capacity to achieve z now, but he is free to z because would be have the capacity to achieve z if he had planned accordingly).</li>
          <li class="task-list-item">
<input type="checkbox" class="task-list-item-checkbox" disabled>x would z if he had the appropriate present intentions/abilities</li>
          <li class="task-list-item">
<input type="checkbox" class="task-list-item-checkbox" disabled checked>x would z if he had the appropriate present intentions
            <ul>
              <li>i.e. people don’t have a right to these things per se, e.g. food, water. So they can’t justify coercing people just because they lack them. Rather they have the right to the opportunity to acquire these goods. E.g. if a person is in a situation where through no fault of their own they are unable to acquire food, they can coerce others to retrieve it.</li>
            </ul>
          </li>
          <li class="task-list-item">
<input type="checkbox" class="task-list-item-checkbox" disabled>Directly providing z (A has z)</li>
        </ul>
      </li>
      <li>Qualiification to “intentions”. I.e. “x is free to z iff x would z if he had the appropriate intentions and the intentions are of type T”?
        <ul>
          <li>Any intentions? E.g. We’re all free to be successful authors because we would be successful authors if we had the appropriate intentions, e.g. adopted the intentions involved in writing certain words on a piece of paper. But clearly there’s a sense in which some are free to be successful authors whereas others are not.</li>
          <li>Intentions that we know of. E.g. we’re not free to be successful authors because we do not know which intentions to adopt to become successful, even though we would be successful if we adopted those intentions.</li>
          <li>Intentions that we know of that are not coerced. E.g. if we would be killed if we did z (but there was no interference), then we are not free to do z. Less extremely, if there were severe penalties for doing z (e.g. social ostrasization) for doing z, then we are less free to do it.</li>
          <li>Intentions devoid of any causal influence. E.g. libertarian free will. No.</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>What constitutes “interference”?
    <ul>
      <li>At the very least, it must be something that plays a causal role in preventing an agent from actualizing an intention.</li>
      <li>Physical obstacle?</li>
      <li>Emotional distress?</li>
      <li>Something in the middle?
        <ul>
          <li>Loud music, bright lights, etc. are harmful even though they are no more “physical” than disliked music, colors, etc. Why are they special?</li>
          <li>Because they are harms that bypass an interpretative framework?</li>
          <li>Because they are of a higher quantity than other harms?</li>
          <li>They restrict an agent’s aims, independently of their intentions.</li>
        </ul>
      </li>
      <li>y is an interference for x achieving z if the following conditions are met:
        <ul>
          <li>y causes a state of affairs such that x cannot achieve z regardless of his intentions.
            <ul>
              <li>Too strong? What if y makes it such that x can only achieve z with rather costly intentions?</li>
              <li>(avoid issues regarding the meaning “causation”)</li>
            </ul>
          </li>
        </ul>
      </li>
    </ul>
  </li>
  <li>What kind of z are people entitled to?
    <ul>
      <li>Any arbitrary aim? Property? Well-being? Suffering? Capacity for self-actualization?</li>
      <li>Can’t be any aim. E.g. you might have the aim that I not be homosexuals.</li>
      <li>Can’t be happiness.</li>
      <li>Requires a qualitative ranking of what kinds of liberties matter.</li>
      <li>Things that matters:
        <ul>
          <li>Basic Needs - food, water, shelter</li>
          <li>Protection from assault, bodily autonomy</li>
          <li>Property</li>
          <li>Occupation?</li>
        </ul>
      </li>
      <li>This requires a qualitative, rather than merely quantitative, comparison of liberty tradeoffs. E.g. it might be the case that taxation reduces a rich person’s liberty more than it promotes the liberty of a poor person. If you just enumerated all the activities that the rich person is prevented from doing and all the activities that the poor person can now do, it might be that more activities were reduced for the rich. However, this doesn’t mean we can’t limit the rich person’s freedom. What matters is not just the amount of liberty, but the value of the liberty. The poor person is now free to perform more important activities (e.g. afford shelting, healthy food, etc.). Speaking of “overall liberty” when making these tradeoffs is a red herring.</li>
    </ul>
  </li>
  <li>Function: how to respect liberty?
    <ul>
      <li>Simple Consequentialist?
        <ul>
          <li>E.g. Maximize sum, maximize average, maximize worse-off, minimize number of people below a threshold?</li>
          <li>Maybe minimize number of people below a threshold, but no to the maximizing options.</li>
        </ul>
      </li>
      <li>Simple Deontologist? Never restrict or limit?
        <ul>
          <li>E.g. Self-ownership, from which we extend property rights</li>
          <li>No. Too strong. Leads to anarchism</li>
        </ul>
      </li>
      <li>Hierarchical Deontology? Possibly
        <ul>
          <li>Not consequentialist because:
            <ul>
              <li>People are permitted to harm others to save themselves, even if this makes a worse state of affairs.</li>
              <li>Our duties are not to aim towards some ideal state of affairs.</li>
              <li>Agent-relative</li>
              <li>Not aggregative</li>
            </ul>
          </li>
          <li>Create a ranked order of constraints on liberty, e.g. type 0, type 1, type 2, etc.
            <ul>
              <li>Type 0 are most important, e.g. constraints on life, movement, etc. (this does not include significant emotional harm, e.g. seeing what you perceive to be a sin, because there could be a norm whereby that harm is diminished). These are features that can limit a person independently of their intentions.</li>
              <li>Type 0 violations are permitted to prevent other type 0 constraints</li>
              <li>For all i, type i violations are permitted to prevent type j (where j&lt; i) constraints</li>
              <li>Constraints of different types are not commensurate</li>
              <li>Type 0 = basic needs</li>
              <li>Type 1 = bodily autonomy</li>
              <li>Type 2 = property</li>
            </ul>
          </li>
          <li>Who is causally responsible for the constraints to A?
  -&gt; If B is responsible, B is required to assist and A permitted to use force. The state is justified in coercing B.
  -&gt; If A is responsible, A is not permitted to use force. The state is not justified in coercing B.
  -&gt; Otherwise, (no one is responsible)
      -&gt; If there’s a reasonable way to alleviate the constraint on A without constraining B,
          - that route must be chosen
      -&gt; Otherwise, A is permitted to use force, and B is permitted to resist. A conflict has occurred. 
          - If the harms to A and infringement to B are comparable (e.g. A must kill B to stay alive), the state cannot coerce B. The state must be impartial.
          - Otherwise, if the harms to A are major and the infringement to B are minor (e.g. tax B to educate A), the state can coerce B. The state is remaining impartial; A is given priority not because A happens to be A, but because of the stronger burden on B. B is still permitted to resist.</li>
          <li>Threshold
            <ul>
              <li>Concerns what the state can do.</li>
              <li>There is some base level threshold of freedom. The state is justified in enacting coercion M to group A in order to help group B, so long as (1) A is above the threshold, (2) B is below the threshold, (3) M does not leave individuals in A below the threshold, (4) M brings individuals in B above the threshold.</li>
              <li>There might be multiple thresholds. Today, that threshold might involve something like public education, healthcare, police force, etc. Hypothetically, it could also involve saving people from torture. We might be able to force those in A to save those in B from being tortured, even if it subjects those in A to poor education, policing, etc. Or maybe there’s a single threshold and if everyone is forced to be under it, there are no moral standards.</li>
              <li>Insofar as the individuals in A are responsible for B being worse-off, they are obligated to assist in this.</li>
              <li>Insofar as the individuals in B are not responsible, they are permitted to resist (even though the state is still justified to use force).</li>
              <li>When coercion is permissible
                <ul>
                  <li>If everyone is above the threshold, coercion is never permissible.</li>
                  <li>If everyone is below the threshold, and there’s no way for an individual to get above the threshold without preventing someone else frmo going above it, then coercion is always permissible. There’s just a conflict. Although it might be that justification and permissibility are concepts that don’t really apply (e.g. in the state of nature).</li>
                </ul>
              </li>
            </ul>
          </li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<h3 id="justified-uses-of-coercion">Justified uses of coercion</h3>

<p>Central principle:
	- What kind of world do fully informed, full rational individuals prefer to live in?
	- Individual permissions 
		- Individuals are permitted to freely form contracts without outside interference.
		- Or, rather, the contracts that they would form if they were fully informed, fully rational, etc.
		- Individuals can apply force to others if the other person is impaired.
		- Individuals can force others to compensate for actions that undermined contract-formation (e.g. theft, violence, etc.).
		- Individuals can defend themselves via force.
	- State power: 
		- Individuals can produce preferred systems that cannot be secured via contracts.
		- People in a region have shared preferences, but cannot be satisfied without the use of state power within that region.
		- Optional democratic uses of state coercion: 
			- (1) Individuals have a right to collectivize to guarantee the exercise of the individual permissions above. E.g. protections against violence. It’s justified as a minor constraint to alleviate major constraints.
			- (2) if (1) is justified, then it’s also justified to collective to guarantee those same protections against non-agent forces, e.g. natural disasters if they so chose. 
			- (3) Unwanted externalities <em>due to</em> contracts can be prevented, e.g. unwanted systems which would be incentivized by everyone’s incentivized contracts. This is only if the restrictions caused by this prevention is comparable to the restriction that would be caused if left to the market. If so, this should be decided democratically. 
		- Mandatory uses of state coercion:
			- Compensation to individuals made worse-off by state activity - e.g. people who are made worse-off by state enforcement of property rights.
			- Subsidizing the basic requirements for ensuring everyone’s values are input in the democratic system:
				- Courts, Police, Military, Prison, Education</p>

<ul>
  <li>Consent:
    <ul>
      <li>Explicit</li>
      <li>Implicit
        <ul>
          <li>A implicitly suggests that they desire F (e.g. cues in romantic situations).</li>
          <li>A doesn’t desire F, but they engage in an informal agreement that clearly indicated that F would be done to them (honor cultures, gangs, etc.). A implicit agrees to F iff they perform a behavior X whereby:
            <ul>
              <li>There is a clear standard that F is the consequence for X,</li>
              <li>Performing X is optional, and they are not coerced into doing X.</li>
            </ul>
          </li>
        </ul>
      </li>
      <li>Revoked
        <ul>
          <li>E.g. to enforce contracts</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>Impairment:
    <ul>
      <li>Lack of rationality</li>
      <li>Lack of information</li>
      <li>Maybe this isn’t sufficient, maybe we also need A to prefer to be coerced under the condition that they are irrational/uninformed; otherwise, this force may not be permissible</li>
    </ul>
  </li>
  <li>Rectification: Compensation for constraints imposed
    <ul>
      <li>Past physical damages</li>
      <li>Excess resource usage AND others attempt to access their fair share but are prevented</li>
      <li>Mandated safety nets in societies where a person is worse-off due to the presence of a state or economic system.</li>
    </ul>
  </li>
  <li>Forced Compensation: taking someone’s resources and compensating them, only if:
    <ul>
      <li>The portion taken is too small to cause large harm to the person’s interests (e.g. in taxation)</li>
      <li>The person is compensated for the transaction in the same resources</li>
      <li>E.g. taxation to support welfare. If we didn’t, we would have to pay for prisons, etc. Of course, this needs to be balanced against creating poor incentives for unfit reproduction.</li>
    </ul>
  </li>
  <li>The preconditions for basic democracy don’t require democratic support
    <ul>
      <li>Assuming they <em>did</em> require democratic support, we would still need these in place to know if they had democratic support.</li>
      <li>Courts, Voting Infrastructure</li>
      <li>Police protection to provide safe access for citizens to vote</li>
      <li>Education
        <ul>
          <li>Otherwise, people might not know they have the right to vote</li>
          <li>They might not know what’s good for them</li>
          <li>They might be coerced non-violently by others</li>
        </ul>
      </li>
      <li>The goal is to make sure everyone’s interests are taken into consideration during voting, not to make sure everyone has equal opportunity to a good life.
        <ul>
          <li>So, if food is provided (not sure if it should be), it’s not to prevent people from dying. It’s to prevent people from being manipulated out of hunger which leads to their interests not being expressed in the political system.</li>
          <li>Similar considerations may apply to provide for healthcare.</li>
        </ul>
      </li>
      <li>Conditions necessary:
        <ul>
          <li>Not offering provisions by the government would result in people not having them. So they don’t need to be provided if the private sector can account for it.</li>
          <li>They don’t require democratic support.</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>Unwanted Economic Externalities
    <ul>
      <li>Justification
        <ul>
          <li>The justification here is different from the justification for protection.</li>
          <li>I.e. it doesn’t matter that it is a minor constraint to alleviate major restrictions. even if applying minor constraints to alleviate minor constraints is not generally justifiable, it’s justifiable in this case because of its contractual nature. Contracts only get their validity from consensual support.</li>
        </ul>
      </li>
      <li>Requirements:
        <ul>
          <li>Most people in a region prefer the opportunities to form contracts with features X</li>
          <li>Most people are incentivized such that their actions in the market make it impossible for contracts of feature X to succeed</li>
          <li>Thus, people’s choices in a free makert are not expressions of their preferred contract system</li>
          <li>People can express their contract preferences via voting</li>
          <li>Note that the competing harms here are identical, e.g. people being restricted due to the free market versus the voting system.</li>
          <li>Not that this applies to deciding how contracts are formed, not necessarily other preferred systems (e.g. this doesn’t apply to whether people prefer gay people to be around). Why contracts?
            <ul>
              <li>(1) If everyone in a free market acted to incentivize contracts of type X, then contracts of type not-X would be disincentenvized from existing.</li>
              <li>(2) If everyone in a free market acted to incentivize contracts of type X, this would not be an unjust restriction on employees/employers who prefer contracts of type not-X.</li>
              <li>(3) Whether an employer/employee is restricted from engaging in contracts of type not-X due to forces of free market versus forces of the political system does not influence the <em>personal harm</em> that this places on those employees/employers. Harm here is measured in their opportunity to satisfy their preferences.</li>
              <li>(4) Whether a political/economic system is just supervenes on the harm it places on people.</li>
              <li>(5) [1 and 2] if contracts of type not-X are disincentivized from existing due to free market actions, then this would not be an unjust restrictions on those who preferred contracts of type not-X.</li>
              <li>(6) [3 and 4] Whether people are restricted from engaging in contracts of type not-X due to forces of the free market versus the political system is not relevant to whether they are treated justly.</li>
              <li>(7) [5 and 6] if contracts of type not-X are disincentivized from existing due to a voting system, then this would not be an unjust restriction on those who preferred contracts of type not-X.</li>
            </ul>
          </li>
          <li>This does not work for things like wanting there to be no gay people because the 2nd permise wouldn’t pass through. E.g. if everyone in a free makret acted to incentivize killing gay people, this WOULD be an unjust restriction on gay people.s</li>
        </ul>
      </li>
      <li>Example: workplace benefits, regulations, etc.
        <ul>
          <li>Most employees in a region would prefer mandated time off from their employers if they were fully informed, fully rational and had the power to unilaterally decide what kind of system to live in.</li>
          <li>However, most employees are incentivized to go to companies that do not provide benefits because these companies tend to be more successful because they are more economically efficient.</li>
          <li>What about the employees who prefer companies that do not provide benefits? Aren’t we forcing them by restricting their opportunities?
            <ul>
              <li>It is the same restriction that one would feel if either they preferred a style of company that offerred benefits but the market didn’t incentivize it.</li>
              <li>Thus, without these regulations, people who preferred these regulations would feel the same restrictions in the opposite direction. So the restrictions are equivalent and we should side with whatever is democratically decided. The only difference is one is decided by individuals via their choices in the market, and the other is decided by individuals via their voting preferences. The mechanism imposing the restriction is different, but the restriction <em>on the minority employees/employees</em> is identical.</li>
              <li>It might be argued that the restrictions are different, because in a regulated system there will be <em>no</em> companies without these benefits. Whereas in a free system, there would still be <em>some</em> companies with those benefits, but people would be incentivized against going there so they would be less successful/frequent. Two responses: (1) the hypothetical was that the free system was such that there are <em>no</em> viable, successful companies with benefits in a free market. In which case, the restrictions would be equivalent. (2) if it is the case that there would be some viable successful companies with benefits in a free market but they would be a bit less efficient and so less frequent, then it is not just to force all companies to offer benefits. However, it is just to manipulate taxation such that companies with benefits are at no disadvantage. Assuming the only unwanted externality of the free market as that one’s preferred company receives less income (i.e. assuming that’s the only reason why people are individually incentivized to perpetuate a system that they don’t want), then this will be sufficient regulation and no more is justified.</li>
            </ul>
          </li>
          <li>Okay, employees are not forced any more than in a free market. What about the employers who do not want to provide benefits? Aren’t we forcing them by not even allowing them to open up their business?
            <ul>
              <li>See above. The same answers apply.</li>
            </ul>
          </li>
        </ul>
      </li>
      <li>Similar examlpes:
        <ul>
          <li>Workplace benefits, regulations, etc.</li>
          <li>Large business undercutting small businesses with low profit margins</li>
          <li>Theft?</li>
        </ul>
      </li>
      <li>When local preferences does not match global preferences
        <ul>
          <li>I.e. when a person wants system X but they are individually incentivized to perform actions that lead to system Y, because their actions (in an unconstrained free market) only affect their individual benefits, rather than the system as a whole.</li>
          <li>Prisoner dillemma, e.g. a company’s existence makes everyone’s lives worse (e.g. automates all jobs) but no individual has the economic ability to outcompete it (because the larger company’s products are all uncompetitively cheap) due to no individual having the incentive to purchase from a different company.</li>
          <li>^ Similar justification as the argument for implementing private property over communally owned resources. E.g. avoids the tragedy of the commons.</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>Protection against other constraints
    <ul>
      <li>When considering whether to force A to assist B</li>
      <li>Whether current or future (i.e. pre-emptive protection is justified)</li>
      <li>Examples of protection. Protect against:
        <ul>
          <li>Physical coercion,</li>
          <li>Excess resource usage,</li>
          <li>Non-agent caused constraints</li>
        </ul>
      </li>
      <li>Ways that A can be responsible for B’s diminished liberty
        <ul>
          <li>R1: A <em>intended</em> B being worse-off. E.g. taking someone’s water.</li>
          <li>R2: A didn’t <em>intend</em>, but his actions did <em>cause</em> B to be worse-off. i.e. if A stopped performing his actions, B would not be poor. E.g. owning the entire water supply.</li>
          <li>R3: A didn’t <em>cause</em>, but it is not possible to alleviate B’s condition with A’s current behavior. i.e. if A stopped performing his actions, B would still be poor; nevertheless, the only way to improve B’s situation is by coercing A. E.g. A has opportunity to water but doesn’t know how to utilize it without education.</li>
        </ul>
      </li>
      <li>If A is causally responsible for B’s diminished liberty (R1 or R2),
        <ul>
          <li>The state is permitted to force A.</li>
          <li>B permitted to force.</li>
          <li>A obligated to assist.</li>
          <li>Is democratic support a requirement?
            <ul>
              <li>What if people decided to be anarchists who didn’t want to support a state?</li>
            </ul>
          </li>
        </ul>
      </li>
      <li>If neither are responsible, the following conditions must be met (R3):
        <ul>
          <li>(1) This system requires democratic support</li>
          <li>(2) It imposes a minor restriction on A to alleviate major restriction on B</li>
          <li>(3) Such a restriction is the only way to alleviate the major restriction, i.e. B wouldn’t have the opportunity otherwise.</li>
          <li>(4) From 3, The geographic scope of the restriction must be as low as logistically possible, unless other regions have agreed to integrate into a common taxation jurisdiction.</li>
        </ul>
      </li>
      <li>Questions
        <ul>
          <li>Enacting major constraints to alleviate major constraints?
            <ul>
              <li>The state is not permitted to do this???</li>
              <li>Individuals are permitted to do this</li>
            </ul>
          </li>
          <li>Enacting minor constraints to alleviate minor constraints?
            <ul>
              <li>If there is democratic support?</li>
              <li>What are some examples that don’t fall into the contractual case mentioned above?</li>
              <li>Taxing the rich to make the poor better off? No, unless the poor are worse-off <em>because</em> of restricted opportunities <em>because</em> either (1) the rich are rich or (2) of the current state or economic system.</li>
              <li>Okay, what if the poor don’t have the opportunity to become rich (minor constraint). Can they then impose a minor constraint on the rich via redistribution? (1) this wouldn’t solve the issue because you can’t make all of the poor rich via taxation (at least not without making the rich poor in the process). At best you could make the moderately better off, which leads to (2). (2) The poor probably do have the opportunity to become moderately better off. If they do not, then redistribution (not necessarily via handouts, but subsidized education, etc.) can be provided to account for this. But then, is this really a minor constraint on the poor? This could be major. In the end redistribution for the sake of reducing inequality is unjustified.</li>
              <li>Does laws against slander/libel count as minor constraints to alleviate major constraints? What about subsidizing laws against petty theft? Is it because the effects of not having a law against these actions would result in major constraints?</li>
            </ul>
          </li>
          <li>How to handle state failures?
            <ul>
              <li>Either due to incompetence or mallace, a state fails to provide individuals with certain opportunities.</li>
              <li>Do other sibling states or parent states have permission/obligation to intervene to provide individuals with opportunity?</li>
              <li>They have the permission, but not the obligation. It depends on the democratic support of the other/broader society.</li>
              <li>The intervention should be minor/temporary to bring the minor states up to a level of competence.</li>
            </ul>
          </li>
        </ul>
      </li>
    </ul>
  </li>
  <li>Arbitrary (non-economic) democratic preferences
    <ul>
      <li>Doesn’t have to be based on contracts.</li>
      <li>When a community has preferences which might conflict with the preferences of others.</li>
      <li>There are two kinds of conflicts:
        <ul>
          <li>Conflicts with preferences of individuals within the community
            <ul>
              <li>The preferences can be acted upon assuming:
                <ul>
                  <li>There is widespread support. The amount of support required depends on the trade-off of harms by enacting the preferences versus not enacting the preferences.</li>
                  <li>If the harms are comparable, then we just go with the majority.</li>
                  <li>Otherwise, ???</li>
                </ul>
              </li>
            </ul>
          </li>
          <li>Conflicts with preferences of groups outside of the community
            <ul>
              <li>The preferences can be acted upon assuming groups outside of the group have equal opportunity to accomplish those same preferences</li>
              <li>E.g. restrictive immigration don’t coerce those outside the group, so its fine</li>
            </ul>
          </li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<h3 id="bodily-autonomy">Bodily Autonomy</h3>

<p>Below discusses property rights, but also need to flesh out rights to self-ownership and bodily autonomy.
I don’t endorse full self-ownership or bodily autonomy.
Bodily autonomy can be violated whenever (even assuming the other agent is perfectly innocent, has not infringed anyone else’s rights):</p>
<ol>
  <li>The constraints on bodily autonomy are minor relative to the constraints it will prevent, and such coercion is the only reasonable way to alleviate major constraints on others. The state and private individuals can infringe upon bodily autonomy in this case.</li>
  <li>The constraint is comparable to the constraint that the victim would otherwise face. E.g. steal from one person to prevent another from stealing from you, kill a person to save your life. These are justified by private individuals, but not the state (the state can’t give priority to one life over another; the state must be impartial). Are they even justified by private individuals?</li>
</ol>

<h3 id="equal-share-libertarianism">Equal Share Libertarianism</h3>

<p>Note: Erase this section?</p>

<p>Note: might wanna change “values/interests” to “material opportunity”. Because:</p>
<ol>
  <li>cases of compensation are not focused per se on increasing the welfare of the agents, but on compensating for their lost negative liberty;</li>
  <li>people are free to form more substantive communal laws not because this necessarily increases their welfare, but because not allowing them to do that (and forcing them to live in a libertarian society) deprives them of some negative liberty.</li>
</ol>

<p>My theory does not prioritize self-ownership in the sense that people should necessarily have full control over their bodies (and therefore property). 
Rather, I prioritize the values/interests of individuals. 
I believe that an individual’s values/interests cannot be significantly suppressed/limited in promotion of someone else’s values/interests. 
Note that supressing/limiting values/interests is not the same as controlling one’s body. 
There may be instances where controlling one’s body does not significantly suppress/limit their values/interests, or even where controlling one’s body actually promotes their values/interests. 
This means that, under special circumstances, others can control A’s body against A’s will, but only it is in the promotion of A’s interests or values.</p>

<h3 id="equal-share--communal-property">Equal Share + Communal Property</h3>

<p>Equal-share libertarianism is probably a close approximation of my own view. 
If I were to try to modify this conception to be in agreement with my view, it would have the following caveats:</p>

<p>Note that “local community” means “more local than the global community”, so a country counts as a “local community”.</p>

<ol>
  <li>Rather than compensation being required whenever one uses/appropriates more than their per capita share, compensation is required in a local community when an initial agent uses/appropriates so much that others <em>actually attempt to</em>, but are prevented from, attaining an equal share as the initial agent.
    <ul>
      <li>Examples of those forced to compensate
        <ul>
          <li>Monopolies that own all the resources. Individual companies physically hogging resources.</li>
          <li>Economic societies as a whole that materially value only certain traits, e.g. certain cognitive ability (under capitalism), certain race (under racist capatilistic society), etc.; people without these characteristics cannot have a decent life. People who benefit from a system must compensate those who were harmed by the system.</li>
        </ul>
      </li>
      <li>Examples of compensation
        <ul>
          <li>Redistribution</li>
          <li>Safety nets: disability, unemployment</li>
          <li>Anti-discrimination laws</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>Some sort of communal property is possible. People can join together and form communities where they own all the property within that community amongst themselves (which includes SOME control over the bodies of the individuals living there).
    <ul>
      <li>These are optional, democratic choices from local communities for a way of life. The extent to which people can then enforce more positive, substantive laws, is based on the extent to which there is:
        <ul>
          <li>Less restrictions the coerced:
            <ul>
              <li>The limitations on the persons are minimized</li>
              <li>There is agreement in values within the community</li>
              <li>People are free to exit the community,</li>
              <li>There is sufficient equal valuable resources outside of the community,</li>
            </ul>
          </li>
          <li>More value to the benefactors:
            <ul>
              <li>These laws have significant effects on the liberty of those in the community.</li>
              <li>It is infeasible to achieve the same effect by enforcing laws on a smaller scale.</li>
            </ul>
          </li>
        </ul>
      </li>
      <li>These are almost always justified by enacting minor confiscation of the property of others (i.e. taxation, regulation, etc.) in order to prevent significant, material harms to others (i.e. assault, sickness, death, un-education,  etc.):
        <ul>
          <li>Borders/Military</li>
          <li>Police</li>
          <li>Courts</li>
          <li>Firefighting</li>
          <li>Education</li>
          <li>Food/drug regulation</li>
          <li>Certain anti-discrimination laws (if the harm is material disadvantage, not psychological pain of seeing racism).</li>
          <li>Healthcare</li>
        </ul>
      </li>
    </ul>
  </li>
</ol>

<ul>
  <li>Other attempts to justify the state - i.e. non-consensual use of force against fully informed, fully rational agents that is not based on rectification/compensation. Other libertarian arguments cannot do this:
    <ul>
      <li>
<em>Right to avoid risk</em>. People have a right to avoid risky situations. Anyone who refrains from supporting a state commits a rights violations as this would make life risky for everyone else. Therefore, a state is justified to prevent rights violations against those who refuse to support it.
        <ul>
          <li>Counter: This is a bad argument because we have a negative right to avoid threats that are direct and immediate and so we can coerce anyone who makes such threats insofar as they advance such threats. But this doesn’t justify coercing taxpayers to support a state because they need not to have violating anyone’s rights violations.</li>
        </ul>
      </li>
      <li>
<em>Right to law.</em> People have a right to have their right to liberty, life, etc. codified in a body of law. But why though?</li>
      <li>
<em>Samariton rights</em>. People have a right to violate others’ right to property when doing so is needed to escape dire circumstances. E.g. someone lost in a snow blizzard has a right to break into someone else’s cabin to save themselves. This may be valid, but it invokes positive rights which is not in the spirit of libertarianism.
        <ul>
          <li>This, however, may be prferrable because it can justify, e.g., a police force even when the majority of people do not consent to it under a democratic system. There is guaranteed harm in the state of nature. It would lead to widespread rights violations to people. There are two points needed to support this:
            <ol>
              <li>People have a right to pre-emptively use force to protect themselves from these probable future rights violations by specific individual.</li>
              <li>People have a right to pre-emptively use force to protect themselves from probable future rights violations by a general group even if we don’t know which specific individuals in the group will perform the rights violations. This can guarantee the following protection regardless of democratic agreements (1) Borders/Military, (2) Police, and (3) Courts. Two questions
                <ol>
                  <li>If taxpayers have a positive duty to protect individuals’ negative liberty, why don’t they also have a positive duty to protect individuals’ postive liberty? It seems that whether someone is harmed because of another agent versus a non-agent has no implication on the relationship between taxpayers and the victims. This may justify Firefighters, healthcare, etc.</li>
                  <li>Why doesn’t this extend across the entire planet? For example, we don’t have a duty to protect those in Africa from rights violations. Maybe this: people have the right to use the minimal force necessary to protect themselves from rights violations.</li>
                </ol>
              </li>
            </ol>
          </li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<h3 id="disagreement">Disagreement</h3>

<p>Broader laws are mandatory, non-negotiable. Local laws are decided democratically. Note also that the broader laws tend to be more libertarian whereas the local laws have the potential to be more authoritarian. In principle, the broader laws could be more authoritarian in different countries where there is homogenous culture where everyone agrees to some authoritarian rules.</p>

<p>Perhaps, the ideal laws for a given region are simply the upshot of norms of the culture of that region. For homogenous societies, they are free to enforce whatever rules they prefer. However, when a region has a large diversity of opinion, then the range of acceptable laws narrows. The ideal laws for a region are the laws that it would be rational for that region to accept. However, if the views of a region are so diverse, then the only laws that it would be rational for a region to accept would be minimal libertarian laws that emphasized freedom and liberty. Laws regulating international affairs are the extreme of this: the only international laws there are are basic respect for the sovereignty of nations, protection from genocide, etc.</p>

<p>Coercive laws for members of group G are justified if and only if such laws would be approved of by fully informed and fully rational members of group G assuming they sought coercive laws to regulate behavior. A law is appropriate for group G only if it is the upshot of ideal social construction. When there is broad disagreement, the only laws that overlap with everyone’s fully rational interest would be minimal libertarian laws.</p>

<p>Must explain the relationship between disagreement and ideal socially constructed norms in a way that explains:</p>
<ol>
  <li>That widespread disagreement implies that minarchism.</li>
  <li>That minimal, but existent, disagreement does not imply minarchism.</li>
</ol>

<h3 id="justified-coercion-by-region">Justified coercion by region</h3>

<p>Global</p>
<ul>
  <li>Basically anarchism.</li>
  <li>Respect for the sovereignty of other countries.</li>
  <li>Retaliation against those that violate the sovereignty.
Diverse community (e.g. U.S.). All above plus</li>
  <li>Minarchism</li>
  <li>Military</li>
  <li>Courts for federal laws</li>
  <li>Police to enforce federal laws</li>
  <li>Food/drug regulation</li>
  <li>Compensation for monopolies
    <ul>
      <li>Redistribution</li>
    </ul>
  </li>
  <li>Compensation for societal disadvantage
    <ul>
      <li>Safety nets: low cognitive functioning, disability, unemployment</li>
      <li>Anti-discrimination laws
Homogeneous community (e.g. US state/city or European countries). Any of these could be valued (could even be minarchist). All above plus</li>
    </ul>
  </li>
  <li>Courts for local laws</li>
  <li>Police to enforce local laws</li>
  <li>Firefighters</li>
  <li>Education</li>
  <li>Healthcare</li>
</ul>

<h3 id="by-contemporary-politics">By Contemporary Politics</h3>

<p>Left-Leaning:</p>

<ul>
  <li>Abortion
    <ul>
      <li>No restrictions</li>
    </ul>
  </li>
  <li>Criminal justice
    <ul>
      <li>Rehabilitation and safety</li>
      <li>Decriminalize drugs, don’t legalize</li>
      <li>Not retribution. Consider the cases:
        <ul>
          <li>Agent is morally evil but no longer a threat.
            <ul>
              <li>Has been expelled, restrained, incapacitated or killed (not rehabilitated). He experiences no suffering. Should we still inflict harm?</li>
            </ul>
          </li>
          <li>Agent is a threat but not morally good.
            <ul>
              <li>He should be rehabilitated, expelled, restrained, incapacitated or killed. Doesn’t matter whether this is due to moral corruption or uncontrollable circumstances.</li>
            </ul>
          </li>
          <li>Agent is neither morally bad or a threat.
            <ul>
              <li>Has been rehabilitated.</li>
            </ul>
          </li>
          <li>We can agree that if an agent has been expelled, restrained, incapacitated or killed, then we shouldn’t inflict suffering. Why is this not also true if he’s been rehabilitated.</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>Gay marriage
    <ul>
      <li>Government shouldn’t be involved in marriage.</li>
      <li>If they are, then it should not discriminate based on sex.</li>
    </ul>
  </li>
  <li>Subsidized Loans
    <ul>
      <li>Only awarded to those likely to repay them (based on e.g. test scores, grades, etc.)</li>
      <li>Only have to be paid off after acquiring a certain income level</li>
    </ul>
  </li>
  <li>Subsidized Healthcare
    <ul>
      <li>Maybe, if its effective.</li>
    </ul>
  </li>
</ul>

<p>Right-Leaning:</p>

<ul>
  <li>Free Speech
    <ul>
      <li>Hate Speech allowed</li>
      <li>Can be outlawed to prevent systematic subjugation (e.g. Nazi Germany)</li>
    </ul>
  </li>
  <li>Freedom of Association
    <ul>
      <li>Including discrimination</li>
      <li>Not inherently wrong</li>
      <li>Wrong if its arbitrary and exclusionary (rather than balancing)</li>
      <li>Can be outlawed to prevent systematic subjugation (e.g. Racist USA)</li>
    </ul>
  </li>
  <li>Affirmative Action
    <ul>
      <li>Ineffective insofar as it admits students of low standards</li>
      <li>Don’t care otherwise</li>
    </ul>
  </li>
  <li>Welfare
    <ul>
      <li>Provide a means of living for the poor</li>
      <li>Maybe enough for a limited number of children</li>
      <li>Don’t incentivize unlimited reproduction for the unfit</li>
    </ul>
  </li>
  <li>Immigration
    <ul>
      <li>We have the right to any restrictions</li>
      <li>We should filter in-demand immigrants that can’t be filled by natives</li>
      <li>I desire low influx of immigrants</li>
    </ul>
  </li>
</ul>

<p>Other:</p>

<ul>
  <li>Gun Control
    <ul>
      <li>Don’t care</li>
    </ul>
  </li>
  <li>Education
    <ul>
      <li>Make impractical subjects optional</li>
      <li>Less encouragement for college</li>
      <li>Add practical skills</li>
      <li>Add values.</li>
    </ul>
  </li>
</ul>

<p>Very Important:</p>
<ul>
  <li>Abortion</li>
  <li>Immigration</li>
  <li>Welfare</li>
  <li>Free Speech</li>
  <li>Freedom of Association</li>
  <li>Rehabalitive Justice</li>
</ul>

<h3 id="particulars">Particulars</h3>

<p>Protection against physical coercion
	- Caused by agents
		- Protections against violence
			- Police
			- Prisons/Jails
			- Courts
			- Military
			- Borders
		- Risk
			- Gun licenses
			- Driver’s licenses
			- Drunk Driving
		- Pseudo violence
			- (Noise?) Pollution
			- Threats (risk?)
	- Caused by non-agents
		- Subsidized Housing/Food
		- Basic Welfare
		- Subsidized Healthcare
		- Natural Disaster Relief (incl. firefighting)
Protections against damages to property
	- Caused by agents
		- Theft
		- Property crime
	- Caused by non-agents
		- Natural Disaster Relief (incl. firefighting)
Developing Autonomy
	- HS Education
	- Higher Education?
Constraints on contract-formation
	- Protections against violations of basic conditions of contract-formation
		- Fraud
		- Defamation/Slander/Libel
		- Contract Enforcement
	- Protecting against direct physical harm
		- Require accessible information about the dangers/risks of a product 
		- Housing Safety (e.g. no asbestos, lead in paint)
		- Employment Safety
		- Food/Drug
	- Workplace Regulations
		- Minimum Wage
		- Mandated Benefits
		- Overtime Extra pay
		- Equal Pay
		- Maternity Leave
		- Disability Accomodation
		- Employment termination notices
	- Banks require insurance
	- Housing eviction notices
Other market regulations
	- Economic Protections
		- Anti-Monopoly 
		- Tarrifs
		- Union Protections
		- Copyright/Intellectual Property
	- Employment/Customer/Housing Discrimination
Individual regulations
	- Offensive Behavior
		- Hate speech laws
		- Disturbing the peace
		- Disorderly conduct
		- Harrasment
	- Individual Harm
		- Seat Belt laws
		- Gambling
		- Soft Drugs
		- Prostitution
	- Societal collapse
		- Hard drugs
		- Hate Speech laws
	- Varying Taxation
		- Progressive Taxation
		- Marriage tax cuts
		- Charity tax cuts
Luxories
	- Free
		- Roads
	- Heavily Regulated
		- Electricity
		- Water
		- Gas
		- Sewerage
		- Telephones
		- Internet
		- Mailing
	- Subsidized
		- Transportation
	- Amenities
		- Libraries
		- Museums
		- National Parks</p>

<p>Justifications for state coercion:</p>
<ul>
  <li>Assume the state can do nothing. I.e. there is no state</li>
  <li>For any candidate coercive power to give to the state, the following conditions must be met:
    <ul>
      <li>The scope of coercion for some end can only be as expansive as is necessary to achieve the end (e.g. even policing).</li>
      <li>The coercion itself must be supported by the people. E.g. even police forces should be optional.</li>
      <li>One of the following:
        <ul>
          <li>It must be minor coercive constraints to alleviate major constraints</li>
          <li>Place regulations on contract-formation when collectively we decide that we prefer contracts to be made under certain terms (as opposed to forcing individuals to negotiate with large companies). E.g. Minimum wage, mandated benefits, etc.</li>
          <li>Restrict the autonomy of people who violate the autonomy of others, or who violate the basic standards required for autonomy. E.g. violent crime, theft. This isn’t met under “coercive constraints to alleviate major constraints”, e.g. imagine someone poor stole from someone rich.</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

    </li>
  
    <li>
      <h2><a href="/2019/06/19/Normative-Truth.html">Normative Truth</a></h2>
      <p></p>
<p>Existence internalism characterizes rationality without explicitly requiring any particular motivations. Note that this does not reduce internalism to an Actual Motivational view whereby an agent needs to be actually motivated to perform the action. Usually, rationality is specified by some form of <em>ideal</em> deliberation, i.e. R is a reason for agent A if and only if R is the upshot of <em>sound, valid, fully imaginative</em> (from Williams) deliberation. Other forms of internalism might require being in a sound state of mind, having full experience, etc. In other words, normative reasons are the rational extension of one’s motivating reasons. A consideration C counts as a reason if and only if there is some rational procedure from an agent’s motivational reasons to C (without presupposing any new motivational states along the way).</p>

<p>Split into seperate articles
(1) Introduction to the problem
(2) The failure of externalism
	- Main arguments for internalism
	- Appeal to analogy with theoretical reasons
(3) Internalism too broad 
	- Kinds of internalism: state vs motivational; actual vs counterfactual
	- Some motivational elements that don’t justify; appeal to analogy with theoretical reasons
(4) Constructivism, constituitive properties, analogy with other domains, alternative form of truth
(5) Explaining intuitive features with externalism, internalism, constructivism
(6) Objections</p>

<p>??? example “Readings”
	- Collections
		- Reasons, Motives, and the Demands of Morality: An Introduction
		- Essays: <em>The Oxford Handbook of Reasons and Normativity</em> (OHRN)
		- Essays: <em>Internal Reasons: Contemporary Readings (MIT Readers in Contemporary Philosophy)</em>
		- Essays: <em>Constructivism in Practical Philosophy</em>
		- Also see Philosophy of mind/action syllabus
	- Books
		- R. Brandt, <em>A Theory of the Good and the Right</em> (1979)
		- Bond <em>Reason and Value</em> (1983)
		- Milgram <em>Practical Induction</em> (1997) 
		- S. Darwall, <em>Impartial Reason</em> (1983)
		- J. Dancy, <em>Practical Reality</em> (2000)
		- K. Setiya, <em>Reasons without Rationalism</em> (2007),
		- Derek Parfit, <em>Reasons and Persons</em> 
		- Mark Schroeder, <em>Slaves of the Passions</em>
	- Conceptual
		- Ralph Wedgwood, “The Unity of Normativity”
		- Mark Schroeder, 
			- “The Unity of Reasons”
			- “The Ubiquity of State-Given Reasons”
			- “Value and the right kind of reason”
		- Shyam Nair and John Horty, “The Logic of Reasons”
		- Aaron Bronfman and J. L. Dowell, “The Language of Ought, and Reasons”
		- John Hawthorne and Ofra Magidor, “Reflections on the Ideology of Reasons”
		=&gt; From section 1 of OHRN
	- Substantive
		- Donald Davidson, “Actions, Reasons, and Causes” (1963)
		- Ulrike Heuer, “Reasons for actions and desires”
		- Peter Railton, “Toward a Unified Account of Rationality in Belief, Desire, and Action”
		- Stephen Darwall, “Making the ‘Hard’ Problem of Normativity Easier”
		- Stephen Finlay
			- “The Reasons that Matter” (2006)
			- “Responding to Normativity” (2007)
		- David Velleman,
			- “On the Aim of Belief” (2000)
			- “The Possibility of Practical Reason”
		- Kelly, “Epistemic Rationality as Instrumental Rationality: A Critique” (2003)
	- Desires
		- Thomas Nagel, “The Possibility of Altruism” (1970)
		- W. Quinn, “Putting Rationality in its Place” (1993)
	- Deliberation
		- Antti Kauppinen, “Practical Reasoning”
		- Garrett Cullity, “Weighing Reasons”
		- Joshua Gert, “Underdetermination by Reasons”
		- Stephen Kearns, “Reasons, Choices, and Responsibility”
		=&gt; From section 5 of OHRN
	- Internalism/Externalism
		- Kieran Setiya, “Internal Reasons” (2012) (Introduction to <em>Internal Reasons: Contemporary Readings</em> )
		- Bernard Williams 
			- “Internal and External Reasons” from <em>Moral Luck</em> (1979)
			- “Internal Reasons and the Obscurity of Blame” (1989)
			- “Replies” (1995)
		- Stephen Finlay, “The Obscurity of Internal Reasons” (2009)
		- Christine Korsgard, “Skepticism About Practical Reasons” (1986)
		- John McDowell, “Might There Be External Reasons?” (1995)
		- Michael Smith, “Internal Reasons” (1995)
		=&gt; Above are from <em>Internal Reasons: Contemporary Readings</em>
		- T. M. Scanlon - “On Williams’ Internal and External Reasons” (from <em>What We Owe to Each Other</em>)
		- Kieran Setiya, “Against Internalism” (2004)
		- Philip Pettit &amp; Michael Smith “External Reasons” (2006)
		- Julia Markovits, 
			- “Why Be an Internalist about Reasons?” (2011)
			- “Kantian Internalism” in <em>Moral Reason</em> 
		- Elijah Millgram, “Williams’ Argument Against External Reasons” (1996) 
		- Bedke, “Rationalist Restrictions and External Reasons” (2010) 
		- Michael Smith
			- “The Humean Theory of Motivation” (1995)
			- “The Anti-Humean Theory of Normative Reasons” (1995)
		=&gt; below are from section 2 of OHRN
		- Hille Paakkunainen, “Internalism and Externalism about Reasons”
		- David McNaughton and Piers Rawling, “Motivating Reasons and Normative Reasons”
		- Eric Wiland, “Psychologism and Anti-psychologism about Motivating Reasons”
		- Benjamin Wald and Sergio Tenenbaum, “Reasons and Action Explanation”
		- Bart Streumer, “Reasons and Ability”
	- Constructivism
		- Christine Korsgard:
			- “The Sources of Normativity”
			- “Realism and Constructivism in Twentieth-Century Moral Philosophy”
			- <em>Self-Constitution. Agency, Identity and Integrity</em>.
		- Essays: Sharon Street
			- “What is Constructivism in Ethics and Metaethics”
			- “Constructivism about Reasons”
			- “A Darwinian Dilemma for Realist Theories of Value”
			- “Evolution and the Normativity of Epistemic Reasons”
			- “Coming to Terms with Contingency : Humean Constructivism About Practical Reason”
			- “In Defense of Future Tuesday Indifference”
		- James Lenman, “Expressivism and Constructivism”
		- Harry Frankfurt, “Freedom of the Will and the Concept of a Person”
		- Michael Smith, “A Constituvist theory of reasons”
		- Critics
			- “A Problem for Ambitious Metanormative Constructivism” by Nadeem J. Z. Hussain
			- “The Appeal and Limits of Constructivism” by T. M. Scanlon
			- David Enoch - “Can There Be a Global, Interesting, Coherent Constructivism About Practical Reason?”</p>

<p>??? question “Some questions left unanswered”
	- How to distinguish well-being (what makes a life go best) from reasons for action/desires? 
		- Some differences:
			1. X might provide high well-being without an agent having reason to X, e.g. experience machine, animals, etc.
			2. It is sensible to ask whether an agent has reason to do something that promotes their well-being due to some other end.
		- Reasons for action/desire = considerations in favor of an action, whether the agent knows it or not.
		- Well-being = how an agent assesses their own life to be going from their first-personal perspective, possibly under idealized conditions.
	- I understand the argument that there is no normative truth independent of normative judgments (i.e. the metaphysical/epistemological/motivational problems with realism).. But how do we establish that normative truth for a given agent’s depends on <em>that</em> agent’s normative judgments? E.g. why not the normative judgments of the agent’s community? Or the normative judgments of the speaker? Why not understood “reasons” broadly as a standard by which to criticize someone, e.g. because people are subject to criticism for being cruel, and because reasons are standards of criticism, why not say cruel people are unreasonable? There are infinitely many possible theories of normative truth that don’t reduce normative truth for A to A’s normative judgments, without also having the metaphysical/epistemological problems of realism. 
		- We can understand “should” claims as general standards to ground criticism, e.g. people “should” not act immorally, even though they may have no reason not to do so.
		- “Reasons” may be sometimes used in this broad sense, but for clarity this concept will be identified with the narrow sense (connected with an agent’s normative judgments) leaving “should” the job of handling general grounds for criticism. 
		- A motivational argument can be given perhaps. 
		- Kosgaard’s states that such an account is the only thing that can explain the normative authority of deliberation for agents. What does this mean?
		- Why focus on reasons in the internal sense? Similar considerations can be used to explain why reasons for belief are internal rather than external (i.e. rather than simply beliefs that are true).
		- The internal sense is what we use not just for charges of criticism but for charges of irrationality.
		- The internal sense is the kind of reason we acknowledge when we judge that something is a reason from a first-person perspective rather thana third-person perspective.
	- What is the general strategy for determining what is constitutive of a given activity?
	- What are the procedures for ideal deliberation?
	- Why do some attitudes have higher authority over others, i.e. the attitude that values the upshot of idealized reflection are more important than an agent’s present desires.
	- Do unreflective desires provide reasons and why?</p>

<h2 id="existence-internalism">Existence Internalism</h2>

<p>Some twists</p>
<ol>
  <li>Externalism too broad, move to internalism.</li>
  <li>Actual motivations too narrow, require idealized conditions.</li>
  <li>Not all actual states provide reasons, move to constructivism.</li>
</ol>

<p>Consider analogy with theoretical reasons along the way.</p>

<p>Varieties of internalism:</p>
<ul>
  <li>Actual Motivation: A has reason to X only if A is motivated to X.</li>
  <li>Actual State: A has reason to X only if A has some motivational attitude that supports doing X.</li>
  <li>Counterfactual Motivation: A has reason to X only if A would be motivated to X under circumstances C.</li>
  <li>Counterfactual State: A has reason to X only if A would have some motivational attitude that supports doing X under circumstances C.</li>
</ul>

<p>For Motivation views, “is motivated” and “can be motivated” don’t just mean some motivation that may be overridden by other motivations. It means the source of an agent’s volition that drives them to act intentionally. For State views, a Motivational attitude is a certain kind of psychological state which plays a role in motivation. These states are often taken to be desires, but can include other attitudes such as emotions, intentions, and aversions. Motivation views do not, by themselves, require the presence of any particular kind of psychological state which does the motivating, and State views do not, by themselves, require that the motivating state which is present actually does any motivating.</p>

<p>It is a platitude about reasons and rationality that: R is a normative reason for A to X iff R would be a motivating reason for A to X if A were rational and A was aware of R. In other words, reasons are the upshot of full rationality and full information. The question is how to characterize rationality. Internalism gives a <em>procedural</em> characterization of rationality. It usually specifies a form of ideal <em>deliberation</em>, i.e. of moving from certain motivations to action and other motivations. Externalism specifies an <em>substantive</em> characterization of rationality that specifies certain substantive elements like “a motivation to help others”. i.e. being rational might require being converted rather than sound reasoning.</p>

<p>The above is a true platitude only if we use a fairly broad definition of rationality. But Scanlon narrows rationality to just doing that which you judge yourself to have reason to do. Which means to be irrational is to fail to adopt the attitudes that one judges themselves to have reason to adopt. This makes sense to me. I wouldn’t call someone irrational if they failed to do what they would do if they reflected more or were more experienced. “Rationality” as used above seems to simply mean “idealized person”.</p>

<p>Existence internalism characterizes rationality without explicitly requiring any particular motivations. Note that this does not reduce internalism to an Actual Motivational view whereby an agent needs to be actually motivated to perform the action. Usually, rationality is specified by some form of <em>ideal</em> deliberation, i.e. R is a reason for agent A if and only if R is the upshot of <em>sound, valid, fully imaginative</em> (from Williams) deliberation. Other forms of internalism might require being in a sound state of mind, having full experience, etc. In other words, normative reasons are the rational extension of one’s motivating reasons. A consideration C counts as a reason if and only if there is some rational procedure from an agent’s motivational reasons to C (without presupposing any new motivational states along the way).</p>

<p>??? warning “Todo”
	Include the categories mentioned in the sep article. I.e.
		- state versus motivational forms of internalism
		- actual versus counterfactual forms
		- different ways to characterize the counterfactual conditions</p>

<h3 id="motivational-argument-1">Motivational Argument 1</h3>

<p>One argument for internal reasons states that reasons must be capable of motivating action.</p>

<p>Note:</p>

<ul>
  <li>R is characterized as propositions.</li>
  <li>A motivational set is merely a set of dispositions towards behaviors under certain beliefs.</li>
</ul>

<p>The argument:</p>

<ol>
  <li>R is a reason for A to X only if A would be motivated to X by believing R insofar as A were fully rational.</li>
  <li>A, if fully rational, would be motivated to X by believing R only if A is disposed to X by believing R.</li>
  <li>If R is an external reason for A to X, then A is not disposed to X by believing R.</li>
  <li>Therefore there are no external reasons.</li>
</ol>

<p>The central question here is (2). (1) and (3) are both a priori, conceptual truths. (2) depends on whether we take rationality to have substantive or procedural requirements, so may seem to be question-begging. We need to give an independent argument for (2), in a way that explains how to pick out which dispositions provide reasons.</p>

<p>Modifications:</p>

<ul>
  <li>“Fully Rational” may need to be explicitly characterized in terms of “ideal sound deliberation” or something more specific, so that (2) is not seen as question-begging against the (rare) externalist who says that full rationality might endorse behaviors for A that A has no dispositions to do.</li>
  <li>From Scanlon: One option is to characterize “rationality” just in terms of consistency. So that one is irrational only if they fail to adopt an attitude that they do not judge themselves to have reason to have.</li>
</ul>

<p><strong>Procedural rationality</strong></p>

<p>This is to support (2) of the explanatory argument: A, if fully rational, would be motivated to X by believing R only if A is disposed to X by believing R. (2) depends on whether we take rationality to have substantive or procedural requirements. We need an independent argument for procedural rationality to support (2). And we also need to explain why it’s not just any ol’ dispositions that are needed to supply an agent with reasons for action, i.e. an agent might have a disposition to overvalue short-term gains at the expense of long-term losses, but this <em>mere</em> disposition is not what grounds any reasons to value short-term gains as one might think from (2). Instead, what matters is what dispositions that agent actually endorses under deliberation. But now we seem to be making the deliberative argument below:</p>

<h3 id="motivational-argument-2">Motivational Argument 2</h3>

<ol>
  <li>R is a reason for A to X only if A would be motivated to X by believing R insofar as A deliberated soundly.</li>
  <li>A would be motivated to X by believing R under sound deliberation only if A is disposed to X by believing R.</li>
  <li>If R is an external reason for A to X, then A is not disposed to X by believing R.</li>
  <li>Therefore there are no external reasons.</li>
</ol>

<p>Now, (1) needs to be argued for, as it is no longer merely a plattitude. It almost may seem to be question-begging against the externalist. We might be able to accept (1) if we accepted constructivism. Normative truth derives from the normative judgments an agent makes, and it is constituitive of agency to value one’s motivations under deliberation. So we just need to argue for constructivism.</p>

<h3 id="rational-argument">Rational Argument</h3>

<p>–&gt; “A judges that he has reason R to X” entails</p>

<ol>
  <li>For A to judge that he has reason to X entails that A would be irrational, from his own perspective, for A to not be motivated to X.</li>
  <li>…</li>
  <li>…</li>
</ol>

<p>This differs from the motivational arguments in two respects:
(1) It deals with the conditions necessary for someone to <em>judge</em> that they have a reason, rather than the conditions necessary for a reason to <em>apply</em> to them. Thus, it deals with the concept of a reason in this sense.
(2) Rationality here is not just defined as being receptive to reasons. Rather, it is supposed to be the kind of irraitonality related to not responding to standards that he holds himself to.</p>

<p>The idea is that there is this narrow concept of a reason which we ordinarily use. This concept is distinct from external reasons which serve as broad groads for criticism. E.g. if a “reason” is simply an external ground for criticism that comes from some evaluative perspective, e.g. a perspective of ettiquette, then it would not be irrational for someone to say that they have a reason to be kind (if they understand that “reason” in this to be standards generated from the ettiquette perspective) while lacking any motivation to be kind. On the other hand, it <em>would</em> be irrational for someone to say that they have a reason to X (if they understand “reason” in this sense to be internal to their own motivational sources) while lacking any motivation to X. This latter concept of reason is more closely related to rationality. Where rationality is defined in procedural terms, for reasons to be explained below. In particular, these reasons must be not just internal to their motivational set, but to their normative judgments (see constructivism).</p>

<h3 id="explanatory-argument">Explanatory Argument</h3>

<p>Normative reasons are counterfactual explanatory reasons (Michael Smith w/out ideal observer).</p>

<ol>
  <li>R is a reason for A to X only if R could explain why A would X under sound, ideal deliberation.</li>
  <li>That A is motivated to X by believing R can be explained only by something in A’s desires, goals, etc. favoring doing X by believing R.</li>
  <li>If R is an external reason for A to X, then there is nothing in A’s desires, goals, etc. that motivate a sound, deliberative A to X by believing R.</li>
  <li>Therefore there are no external reasons.</li>
</ol>

<p>Note we have (1) which is not a plattitude which one might object to. However an argument for (1) might be: (1) should be accepted by considering the cases where we perform actions because of normative reasons. The times where there is a disconnect between our motivating and normative reasons, we can point to some sort of problem, either we aren’t aware of the reasons, we have false information, we suffer from addition, etc.</p>

<p>The reason that reasons statements are not based on the hypothetical motivational sets of e.g. a fully moral A, i.e. A+, is because it is important that reasons statements apply directly to A. Note, however, that we can still focus on the somewhat idealized A who has deliberated, because we can infer that A already values the motivations of himself after he has deliberated. We can infer this from the fact that he is in fact deliberating. So he already values his deliberation.</p>

<p>But why should reasons statements for A be based on what he actually values in any present moment? This seems question-begging against the externalist. Two reasons (1) We make claims about reasons for the purpose of influencing, motivating, or guiding agents. But the only thing that can guide agents (assuming they don’t suffer from addictions, false beliefs, etc.) are elements from their motivational set. And (2) this is a basic premise of constructivism (see below).</p>

<h3 id="focus-on-theoretical-reasons">Focus on Theoretical Reasons</h3>

<p>(not a different argument from above; perhaps an elaboration of the explanatory argument).</p>

<p>Points to be learned:</p>
<ul>
  <li>Existence internalism may seem to be disproven by theoretical reasons because beliefs are justified by features other than one’s motivational set (i.e. one’s desires).</li>
  <li>However, the motivational set for beliefs wouldn’t just be desires; it would be other beliefs, perceptions, judgments, intuitions, etc. And these DO justify beliefs.</li>
  <li>Not all elements from one’s motivational set are relevant. E.g. desires don’t justify beliefs.</li>
  <li>Which elements are relevant?</li>
  <li>Why are those elements relevant?</li>
  <li>The relevant elements are the agent’s normative judgments.</li>
</ul>

<p>As mentioned before, there is a narrow and broad sense of normative judgments. The broad sense refers to general “should” statements that could simply serve as standards by which we can criticize and evaluate the behavior of others - this includes internal and external reasons. There is also a narrow sense that refers to internal “reasons” statements. The question is why this distinction is important and what is special/important about internal reasons statements.</p>

<p>Consider reasons for belief. One could say that one has reason to believe just whatever is true. In a sense, this could be true. But it seems that there is another, independent role played by reasons statements about belief. Reasons in this more narrow sense are conferred to considerations that guide our deliberation as we decide what to believe. The fact that something is an external reason for belief - the fact that it’s true, for example - cannot be a consideration that one takes to be reason to decide their belief. I.e. if you asked someone why they believed X and they responded with “because X is true”, this would do nothing to explain their belief. We expect them to respond with an accessible feature of their motivational set - e.g. their other beliefs, their intuitions, their normative judgments, etc. Likewise, external reasons for action cannot be a consideration that someone takes to be a reason for action, unless we assume it’s already connected with their motivational set. E.g. if you asked someone why they did X, and they responded with “because X is kind” (yet they had no care for kindness), this wouldn’t really explain why they did X.</p>

<h3 id="procedural-rationality">Procedural Rationality</h3>

<p>There are two types of reasons:</p>
<ol>
  <li>Internal: What could be entailed from the appropriate elements of an agent’s motivational set via some idealized procedure or set of conditions. The rational extension of one’s motivational set.</li>
  <li>External: general grounds for criticizing an agent, i.e. broad use of “should”. A general positive status that we confer to behaviors that we approve of.</li>
</ol>

<p>Why is the distinction important and what is special/important about internal reasons statements?</p>

<p>Consider the earlier discussion of theoretical reasons. That is, reasons for beliefs must be internal to an agent’s perceptions, intuitions, etc. even though there is a sense in which it is appropriate to confer a positive status to certain beliefs on the basis of external reasons i.e. their truth. The reason is because, regardless of the appropriateness a attitude on externalist grounds, we <em>need</em> a system to confer status to attitudes on internalist grounds. There are times when we don’t have access to considerations that warrant approval of certain attitudes. In those circumstances, we still need to make a choice. Thus, we need a procedure that determines which attitudes are worth adopting. And we need an element of language to play this role in explaining this status. Internal reasons statements play this role.</p>

<p>When we deliberate, we are trying to answer the question of which attitudes to adopt. During theoretical reasoning, we are determining what beliefs to adopt. During practical reasoning, we are determining what intentinos to adopt. Because theoretical reasoning involves determining whether a given proposition, say, P is true, the <em>mere fact that P is true</em> cannot possibly serve as a reason to believe P; at least not when “reason” is understood as the status we confer to beliefs during deliberation about what to believe. From the agent’s perspective, s/he begins unsure as to whether or not P is true and is trying to answer that question. He thus cannot use <em>the fact that P is true</em> as a reason to believe P. Similar considerations apply to practical reasoning. Practical reasoning involves determining whether a given intention X is to be adopted. Therefore, the <em>mere fact that X is virtuous or kind or fair</em> cannot serve as a reason to do X. Again, the agent begins unsure as to whether virtue or kindness or fairness is a reason to intend to something. Thus, the mere fact that an action has these properties cannot be taken as a reason for an intention. In general when deliberating, the only considerations that we can appeal to as reasons for action are considerations that we already accept to be reasons for action. There is no normative truth outside of what we take to be normative.</p>

<p>The very activity of normative reasoning is to address conflicts in motivations. The problem to which normative thinking is designed to address is conflicts in our motivations. This means that normative thinking is not designed to track any mind-independent truth. Evenif it can be said that there is some mind-independent truth external to the world of the relevant kind, there is no way that this could relate to normative reasoning. Normative thinking is only answerable to our given motivations and normative judgments.</p>

<h3 id="constructivist-argument">Constructivist Argument</h3>

<p>Constructivism + Judgment Internalism = Existence Internalism</p>

<ol>
  <li>Constructivism: A has a reason to X only if A’s normative judgments in some sense endorse X-ing.</li>
  <li>Judgment Internalism: A’s normative judgments endorse X-ing only if A has some motivation to X.</li>
  <li>Existence Internalism: A has a reason to X only if A has some motivation to X.</li>
</ol>

<p>Constructivism is actually a narrow form of existence internalism if we accept judgment internalism and if we believe one can have motivating reasons without judging them to be normative reasons. In that case, the motivating reasons corresponding to one’s normative judgments would be a strict subset of their motivational set. Of course, there is still the question of why we should accept constructivism in the first place.</p>

<h2 id="constructivism">Constructivism</h2>

<p>Three categories of normative judgments</p>

<ol>
  <li>Constituitive: normative judgments held by all agents insofar as they are rational</li>
  <li>Internal: normative judgments held by a particular agent, i.e. narrow use of “reason”. Or what is entailed from an agent’s normative judgments.</li>
  <li>External: grounds for criticizing an agent, i.e. broad use of “should”</li>
</ol>

<p>The question is why does the internal/external divide matter and why do internal reasons count as real reasons?</p>

<p>The answer is this: There is a sense of reasons such that if an agent fails to do what <em>he judges</em> to be a reason R, then he is irrational. But this can be true only if the agent judges R to be an internal reason. I.e. if an agent fails to do what he <em>endorses</em> (i.e. an internal reason judgment), then he is irrational. But if he fails to do what he judges to be endorsed from some other perspective (which would be an external reason judgment), e.g. the moral perspective, then he is not being irrational. So reasons in the sense of being connected with rationality or irrationality must be internal. The property of <em>being a reason</em> is a status we confer give to considerations that we endorse upon deliberation.</p>

<p>The question now is why assume rationality cannot be broadened to include substantive normative judgments, so that someone who fails to respond to e.g. moral reasons are irrationality beause rationality requires being moral?</p>

<p>Some Arguments</p>

<ol>
  <li>Little ontological baggage.</li>
  <li>Allows for a credible epistemology.</li>
  <li>Explains many constituitive properties of certain normative domains.</li>
  <li>Explains existence internalism (assuming we accept judgment internalism).</li>
  <li>Doesn’t seem like reasons can be discarded as meaningless. One can’t ask “why be rational”.</li>
</ol>

<p>See: Christine Korsgaard, Sharon Street, (Bernard Williams?)</p>

<p>The fact that X is a reason to Y for agent A is constituted by the fact that the judgment that X is a reason to Y (for A) withstands scrutiny from the standpoint of A’s other judgments about reasons. Note that X is never a reason in favor of Y, absolutely. X can only be in favor of Y for some particular agent, as determined by the standards set by the normative judgments of A himself.</p>

<p>A normative judgment withstands scrutiny for an agent only if the agent could mantain the judgment in full awareness, which is determined by the constituitive standards of the attitude in question. For example, someone who judges that X is a reason to Y cannot also simultaneously and in full awareness judge that X is not a reason to Y (consistency is constitutive of normative judgments). Also, one cannot take oneself to have conclusive reason to Y without taking oneself to have reason to take the means to Y (means-end reasoning is constituitive of normative judgments). The force of <em>cannot</em> is not rational, but what is <em>constituitive</em> of the concept of forming normative judgments. These standards of correctness are legislated by the very person making the normative judgments. This allows that one can be genuinely mistaken about their normative judgments only insofar as they are not in full awareness of certain relevant features of their judgments.</p>

<h3 id="disallowing-brute-error">Disallowing Brute Error</h3>

<p>See “Constructing Ortagorean Objectivity.md”</p>

<h3 id="theory-of-error">Theory of Error</h3>

<p>The basic idea is that we have reason to adopt attitude X if adopting attitude can be entailed from our current set of judgments.
But how to account for agents who have false normative judgments?
After all, such judgments are a part of their judgments, so it can be said to be “entailed” from their current set of judgments.</p>

<p>The answer is that some normative judgments are strictly of higher priority than others. 
There are a few reasons for this:</p>
<ol>
  <li>Judgment A sets the context for when judgment B is relavent. E.g. the difference between endorsing what you would endorse if unemotional, fully reflective, etc. versus what one endorses in the heat of the moment. The former is an endorsement about the kinds of conditions that determine when one’s actual endorsements are valid.</li>
  <li>Judgment A is constituitive of the very activity. Thus, it cannot be discarded in favor of A. E.g. judging that one has reason to adopt the means to meet an end is constitutive of adopting the end.</li>
  <li>Judgment A is extremely difficult to get rid of. E.g. relying on induction, memories, perceptions, caring about our future selves, etc. In fact, insofar as someone were able to not rely on these features, they would have psychological states completely unlike anything of our own.</li>
</ol>

<p>Part of the practice of establishing normative attitudes is establishing attitudes that regulate other attitudes.
There is a hierarchy of normative judgments abound.
Other considerations for favoring one judgment over another:</p>
<ul>
  <li>It is more likely to acccomplish
If there is no significant difference in any of the points mentioned above between two potential normative judgment, there is not necessarily a more “correct” position to adopt.</li>
</ul>

<h3 id="alternative-conceptions-of-truth">Alternative conceptions of truth</h3>

<p>There are plenty of other domains of propositions whereby truth is based on something other than correspondence. The general structure is that one takes an attitude with regard to a proposition p, and then finds standards of correctness constituitive of the attitude. Consider the following examples:</p>

<ul>
  <li>Descriptive judgments: Judgment S expresses a relation involving a description D and reality R, namely that D represents R. S is true if and only if D represents reality.</li>
  <li>Logical judgments: Judgment S expresses a relation involving a set of propositions P1 and another set of propositions P2, namely that P1 entails P2, i.e. the truth values constitutive of P1 are also constitutive of P2. S is true if and only if P1 entails P2.</li>
  <li>Modal judgments:</li>
  <li>Probabilistic judgments:</li>
  <li>Causal judgments:</li>
  <li>Counterfactual judgments:</li>
</ul>

<p>Rational Judgments</p>

<ul>
  <li>Epistemic Rationality:</li>
  <li>Prudential Rationality:</li>
  <li>Moral Rationality:</li>
</ul>

<p>Under constructivism, for normative judgments, truth is not based on some correspondence to some mind-independent normative reality. There is no standard of correctness for normative judgments independent of what we ourselves decide to be valuable. There is no sense in determining that someone has a reason to do something if it cannot be inferred from what they actually judge themselves to have reason to do.</p>

<p>If we remain committed to the correspondence theory of truth, we can abandon truth-aptness. Normative judgments are rationalility-apt. Normative propositions have the property of being rational or irrational, whereas descriptive propositions have the property of being true or false. Ascriptions of rationality can be siblings to ascriptions of truth, while not being reduced in those terms. This can be considered a form of quasi-truth. All the purported values of cognitivism can be withheld:</p>

<ul>
  <li>Normative thinking is a rational enterprise.</li>
  <li>Certain normative judgments are better than others.</li>
  <li>The better normative judgments are independent of our actual judgments.</li>
</ul>

<h3 id="constituitive-features">Constituitive Features</h3>

<p>The central question is how to determine what requirements are constitutive of a type of behavior. One candidate is this: a requirement is constituitive of a behavior if no agent could consciously reject the requirement in full awareness.</p>

<p>Logical Consistency. One basic constituitive feature of normative judgments (and thuoghts generally) is logical consistency. No person can consciously believe X and believe not-X in full awareness.</p>

<p><strong>General</strong></p>

<ol>
  <li>Consistency: Consistent/Coherent norms trump inconsistent/incoherent norms (This is required for all other constituive features to have force). Without a concern for consistency, an agent could not count as a normative reasoning agent. The very activity of normative reasoning is to address conflicts in motivations.</li>
  <li>Soundness: Norms endorsed under a sound state of mind trump norms endorsed under psychological compulsions, physical addictions, emotional disturbances, etc.</li>
  <li>Deliberation: Norms endorsed under deliberation trump unreflective dispositions that we discard under deliberation.</li>
  <li>Experience: Norms that maintain endorsement upon experiencing their outcome trump ends which are not.</li>
  <li>Full Information: Norms endorsed with full information trump norms based on false beliefs?</li>
</ol>

<p>Stability?
Commonality?</p>

<p><strong>Epistemic</strong></p>

<p>The normativity of beliefs (against people who think the normativity of beliefs just reduce to their truth, so normativity is descriptive):</p>
<ul>
  <li>We are all familiar with the idea of justifying beliefs. I.e. people who believe in Santa Clause who are exposed to the appropriate evidence have unjustified beliefs, people who believe in God (or lack belief if you’re religious), people with opposing beliefs about the efficacy of gun control, etc.</li>
  <li>Justification and truth are separate concepts, i.e. a belief can be justified yet false or unjustified yet true. So justification cannot be descriptive, as it is not concerned with truth.</li>
  <li>
    <p>Normative principles come prior to descriptive beliefs. We need normative principles to establish descriptive beliefs. We need a procedure to proceed from evidential input - i.e. sensory perceptions, memories, intuitions, etc. - to belief outputs. We must establish what counts as evidence to make this inference. Deductive reasoning is required at a minimum. But this is not sufficient, we need induction, abduction, etc.</p>
  </li>
  <li>Deductive:
    <ul>
      <li>Basic constistency: we cannot believe P and ~P.</li>
      <li>Logical rules of inference: if P-&gt;Q and P, then Q.</li>
      <li>Constraints on thought. We cannot help but follow logical constraints in our thinking.</li>
    </ul>
  </li>
  <li>Subjective:
    <ul>
      <li>Perceptions/memories: the reason that a perception that p provides one with reason to believe that p is because part of what it is to perceive p is to acquire an unreflective belief that p. If perceptions didn’t provide one with an unreflective belief that p, then perceiving that p would be like imagining that p, and this would not provide one with a reason to believe p. Similar considerations apply to memories.</li>
    </ul>
  </li>
  <li>Abduction:
    <ul>
      <li>Falsifiability</li>
      <li>Generality</li>
      <li>Parisomony (Occam’s Razor)</li>
      <li>Explanatory</li>
    </ul>
  </li>
  <li>Induction:
    <ul>
      <li>Past -&gt; Future</li>
      <li>Observed -&gt; Unobserved</li>
    </ul>
  </li>
</ul>

<p>All of these are either:
	- Constraints on our thoughts. We cannot help but believe them. Or,
	- Things we don’t <em>have</em> to trust, but which we just so happen to do. This isn’t just something that individuals happen to trust, but that everyone happens to trust. If there were beings that didn’t abide by induction or abduction, then we wouldn’t call them irrational; they just wouldn’t have cognitive structures like our own. Normativity only deals with resolving conflicts. Thus, if induction, abduction, etc. are already adopted by most people, then we don’t need to justify them.</p>

<p>This seems to be too low of a standard. It seems we can still question the validity of a belief system that is internally coherent and held by everyone else. E.g. think about beliefs about God back when everyone was religious. Why is this unjustified? Appeal to a more foundational principle that we all intuitive adopt, which is abduction. How do we know that abduction is more foundational than beliefs about God? (1) abduction is not a belief in that it is representation; it is a framework for establishing representations. (2) God is something we come to believe after engaging in abduction. (3) everyone participates in abduction, not everyone participates in believing God. Someone might say that they specifically place God on a more foundational level than abduction, but then their position wouldn’t be reasonable for other people. And usually, when we say X provides a reason to believe Y in circumstances C, we take that to be a universal claim, i.e. <em>every</em> agent has reason to take X to provide reason to believe Y in circumstances C.</p>

<p>Reason is purely procedural. It is concerned with amelierating <em>conflicts</em> and striving for <em>coherence</em> of our aims. Beliefs are not justified in isolation. Rather they are justified based on their coherence with other beliefs. It may seem that all propositions must be justified in a non-circular non-infinite regress, and any beliefs that cannot be justified are irrational. This is the case only because of the context of ordinary uses of “rational” or “irrational”. When we talk of “rational” in the context of a debate, it usually applied to propositions that can be justified to all parties involved. However, even though propositions may not be justifiable in this sense (in the sense of collective support), they can justifiable to an individual (based on their coherence with the individual’s other beliefs). The “rational” sense as used in collective support is not constituitive of rationality itself (i.e. agents can be rational without jutsifying themselves to others), but having debates with others implicitly commits oneself to a constructed “game” where the rules are intersubjective justifiability.</p>

<p>Objectivity: imagine people have widely divergent beliefs. Objectivity is possible when there happens to be an intersection in the beliefs held by these people. More specifically, it’s possible when there is an intersection in what these people judge to be solid methods for establishing truth. E.g. think of science. People might have widely different beliefs. But everyone agrees that one’s beliefs should cohere with their other beliefs, and we happen to be beings with sensory inputs that automatically impress beliefs within us (which means our beliefs must cohere with our sensory inputs), and our sensory inputs happen to converge a lot of the time. There are other features we happen to agree with as well (or can be shown to agree with), e.g. repeated observations from different independent sources/experiments provide more evidence for a hypothesis than one-offs, etc. It is this convergence that grounds the objectivity of science. I.e. two people might disagree over whether theory X or Y is true, but they can agree on method for determining whether X or Y is true, e.g. by appealing to observation, abduction, induction. Without this, objectivity is impossible. Even if we disagree on method, we can ideally point to a meta-principle that we both agree with (or can be shown to agree with) that settles which method is valid (e.g. reflective equilibrium).</p>

<p>Methodology:</p>
<ul>
  <li>There are no exhaustive general principles. There are only procedures for establishing principles and truths. Procedure -&gt; Principles -&gt; Truth.</li>
  <li>Conflicts must be handled by (1) reflective equilibrium - checking coherence with other beliefs/truths, and (2) by appeal to higher level principles that are agreed upon. Applies to individual beliefs and interpersonal disagreement.</li>
</ul>

<p><strong>Prudential</strong></p>

<p>Constructivism provides an easy explanation of the following norms of practical reasoning.</p>

<p>Constitutive Features</p>

<ol>
  <li>End-Satisfaction: agents have reason to satisfy their ends.</li>
  <li>Instrumental: agents have reason to adopt the means to satisfy their ends.</li>
  <li>Time: agents have reason to satisfy the goals of their future self. 
 Agents justified in criticizing the goals of our past selves.</li>
</ol>

<p>Other Features. May not be constitutive (?), but depend on features implicit in most people</p>

<ol>
  <li>Conflict: how to deal with conflicting goals? 
 Is there a goal hierarchy? 
 Ends constitutive of one’s identity (i.e. valuing reflection) trump conflicting ends.</li>
  <li>Feasibility: goals which are more likely to be satisfied trump equivalent goals that cannot be satisfied.</li>
  <li>Pain/Suffering: pain/suffering provides one with reason to avoid it is precisely because people judge that they have reason to avoid it (or they have an unreflective aversion towards it). 
 If a person had no (un)reflective aversion toward pain, then there would be no actual reason to avoid it. 
 It is not the pure sensation of pain that provides us with reason to avoid it.</li>
  <li>Desires: a desire to X tends to provide one with reason to X because
    <ul>
      <li>people tend to judge that they have reason to X if they desire to X, and</li>
      <li>all intentional actions are done because of some desire; otherwise, they would be involuntary actions.</li>
    </ul>
  </li>
</ol>

<h3 id="against-consequentialism">Against consequentialism</h3>

<p>For a particular agent, their reasons need not be consequentialist. For example, this is true insofar as the agent accepts that they have reason to hold certain attitudes, attitudes that cannot be reduced to merely promoting some desired state of affairs. For example, an agent might value friendship, meaning they think they have reason to be loyal to their friends, care about their interests, etc. These reasons are not reasons to promote some state of affairs. This would imply that there could be some end state of affairs that would justify them betraying these current reasons to reach that desired state, but this need not be what an agent has reason to do.</p>

<p>In sum, not all reasons are teleological, i.e. all states of affairs are given some amount of weight which can be theoretically quantified which competes against are conflicting states of affairs. Instead, there reasons can be structural, where some features are given zero weight due to higher order reasons.</p>

<p>Kinds of consequentialism:</p>
<ol>
  <li>Maximizing - Define some good which can be quantified, we have most reason to act so as to promote that quantity. This can be disproven above.</li>
  <li>Trivial - Rank possible states of affairs according to how you judge yourself to have most reason to act. Have a complete ranking of all the states. Because constructivism is true, we have most reason to promote that state of affairs. This seems trivially true.</li>
</ol>

<h3 id="methodology">Methodology</h3>

<p>Objectivity:</p>
<ul>
  <li>There is no objectivity in the mind-independence sense. But there is a kind of objectivity in terms of what is constituitive of agency itself. E.g. in order to count as an agent who values anything, they must take themselves to have reason to adopt the means to fulfill their ends, they must value their capacity for agency, etc.</li>
  <li>One might doubt whether this is a important kind of objectivity. They might say: you are cheating by talking about what is valuable after presupposing someone is an agent. This isn’t really interesting.
–&gt; Response: this is the same kind of objectivity that we get with deductive reasoning. I.e. the only reason P -&gt; P, ~(P ^ ~P), (P-&gt;Q ^ P) -&gt; Q, etc. is because of what it is to believe a proposition to be true. It is constituitive of belief that one not believe contradictions. Indeed, for “agents” without these tendencies, we wouldn’t be able to rationally persuade them otherwise. But it’s not clear that the concept of “rationality” even applies to them. They’re neither rational nor irrational. No one questions the objectivity here:
—&gt; One might still question its objectivity because it doesn’t have the mind-independence. In that case, I question if this usage of “objectivity” is interesting or important. What does it take to call something “objectivity”? I look to the role that “objectivity” plays in discourse. When we call something objectivity, we apply this to domains of propositions that (1) people can be mistaken about, (2) we can criticize others/ourselves about, (3) we can have improve about, (4) we can disagree about, etc. The characterization given thus far fulfills that role. 
—&gt; Speaking of roles, think of normative “truth”. When we attribute the predicate TRUE to a normative judgment about what one ought to do, this implies something above and beyond typical desires:
—&gt; That that judgment will be more <em>stable</em> than other desires upon reflection. So reflective stability under ideal deliberation is a test for rationality among agents. Reflective stability under idealized <em>conditions</em> can be a test for the <em>reasons</em> of an agent (where the idealized conditions are the conditions that an agent endorses under ideal deliberation, i.e. full information, full experience, fully imaginative, etc.). Might stability under idealized social negotiation be a test <em>moral reasons</em>. Stability is one of the reasons why our value of reflection has normative authority over any conflicting unreflective judgments we might have.</li>
  <li>Another “kind” of objectivity. It may not be constituitive of agency per se, but it is nearly universal among humans:
—&gt; Standing in mutual recognition with other agents (i.e. being a moral agent). As an agent, one doesn’t <em>have</em> to care about this. But almost all agents do. Because for the ones who did not, they would have had a difficult time spreading their genes. Of course, evolutionarily, the circle of mutual recognition was often small, limited to one’s tribe or in-group. But we have the rational capacity to question whether differences between tribes are actually relevant, and most will conclude that they are not. This is not only evolutionarily necessary, it is also neurologically necessary for all current humans. Humans who are not touched and played with as infants either die or grow to have developmental disorders.
—&gt; A similar non-constituitive “tendency” that agents have is to value the values of their future self. This need not be constituitive of agency. However, it is near-universal among humans for very similar reasons as being a moral agent. For those who did not, they would have had a difficult time spreading their genes. Of course, our tendency to plan for the future is often limited based on certain factors (i.e. impulsivity, excitement, etc.), but we can question whether those considerations are rationally relevant, and most will conclude that they are not. [there is a further question as to whether caring for future selves commits one to care about other persons. This is a question I will not answer].</li>
  <li>Different kinds of constituitive features:
—&gt; Constituitive of psychological attitudes: Fear -&gt; Attributions of danger
—&gt; Constituitive of linguistic concepts: thick ethical concepts, coward -&gt; attribution of fear
—&gt; Constructed social norms: moral norms -&gt; impartial concern with others. Based on the role or function that the norms plays in our lives. Find the job description of morality. E.g. compare with ettiquette, science, etc. Morality is like thick ethical concepts in that sense. For that reason, they can sometimes be used non-motivationally, e.g. someone who sincerely (i.e. not in the “inverted comma” sense) says “X is a generous” might not have any motivation by focusing on the descriptive component of the thick ethical concept “generous” - i.e. that he give to others, etc. Likewise, someone can sincerely judge “X is wrong” without any motivational by focusing on the thick component of wrongness - i.e. that others have reason to blame one for this, that people motivated to stand in mutual recognition have reason to accept the norm, etc. The thick component here is also normative (i.e. it uses the concept of a reason), but it need not be motivational, because it relates to reasons for other people. So it may just express a disposition for motivation of the speaker in certain counterfactual circumstances.</li>
</ul>

<h2 id="desire-theories">Desire Theories</h2>

<p>!!! danger “Deprecate”
	Delete this section. Consider the pros and cons of desire theories when discussing the merits of various forms of internalism.</p>

<p>This examines theories for normative correctness that reduce in some way to an agents desires, whether first-order or higher-order, actual or hypothetical, etc.</p>

<h3 id="humean-model">Humean Model</h3>

<p>The Humean theory of rationality states the following</p>

<p>A has a reason to X if and only if (1) X promotes A’s desire d and (2) d is not based on any false beliefs. This can be simplified to: A has a reason to X if and only if X promotes a foundational (rather than derivative) desire in A. Desires are then the upshot of the following</p>

<ul>
  <li>Full information</li>
  <li>Correct means-end deliberation (generation of a desire to X as a result of combining a desire to Y and a belief that X -&gt; Y).</li>
</ul>

<p>Desires can be given three components:</p>

<ul>
  <li>A certain positive or negative sensation</li>
  <li>A disposition to promote some state of affairs</li>
  <li>An unreflective normative judgment that one has reason to promote a state of affairs</li>
</ul>

<p>Not clear if an “urge” can be reduced to a sensation/disposition pair.</p>

<p><strong>Problems</strong></p>

<p>These are problems insofar as desires are divorced from normative judgments (e.g. plans, goals, etc.).</p>

<ul>
  <li>Normativity of desires: Why would a desire, in terms of just sensations and dispositions, provide someone with reasons for action? Imagine someone had a disposition where they just felt the urge to turn on radios whenever they saw one but they didn’t think they had any reason to do so. Imagine A is injected with a drug that makes him crave the drug much more, and this is his strongest desire by far. Does he have most reason to take the drug?</li>
  <li>Disconnects: Assume the normativity of desires are accounted for. How to account for disconnects between an agent’s reasons and their desires? These disconnects can happen under physical addiction, emotional disturbances, psychological compulsions, etc.
    <ul>
      <li>We sometimes have reasons without corresponding desires - e.g. weakness of will</li>
      <li>We sometimes have desires without corresponding reasons - e.g. addictions</li>
      <li>These cannot be accounted for with full information. There can be degenerate desires that are produced from, or persist despite, full information. Imagine that if a person became fully informed about all the germs on one’s hands, this would trigger a natural underived disgust reaction in the person, causing them to never touch anything directly and to constantly wash their hands everyday. Imagine that they are aware that the germs cause no actual danger or harm. They would be against coming into contact with germs because of an intrinsic disgust reaction, and they would think, all things else considered, satisfying their desire to reduce germs is more important than the sacrifice that doing so requires. The fact that full information would produce certain responses in people doesn’t make those responses rational.</li>
    </ul>
  </li>
  <li>Priority: Assume the disconnect between reasons and desires is accounted for (perhaps by looking at a mode of desires). On this model, the authority of desires are simply based on their “strength”.
    <ul>
      <li>How does this account for the authority we want to give to categorically superior desires? E.g. the priority of higher-order desires or desires under full experience, reflection, sound state of mind, etc. which may have low strength?</li>
      <li>How can we ground criticisms of fully informed desires that are based on inexperience, lack of reflection, unsound, etc.?</li>
    </ul>
  </li>
  <li>Prudence: Why agents have reason to satisfy the desires of their future self?</li>
</ul>

<h3 id="dispositionalism--sophisticated-humean-model">Dispositionalism / Sophisticated Humean Model</h3>

<p>The idealization for discovering reasons requires, at a minimum, full information and correct means-end-deliberation. Some other possibilities include. We can supplement the Humean model by incorportating other requirements:</p>

<ul>
  <li>Fully Informed</li>
  <li>Correct means-end deliberation.</li>
  <li>Reflection - desires endorsed under reflection have priority over others
    <ul>
      <li>Using imagination to determine how a desire would be satisfied.</li>
      <li>Deciding which desires one places most weight.</li>
    </ul>
  </li>
  <li>Soundness - free of psychological compulsions, physical addictions, emotional disturbances.</li>
  <li>Fully Experienced - not merely knowledge of a proposition p, but exposure to a stimuli (i.e. a perception, an argument, etc.) that provokes the attitude.</li>
  <li>Systematically unified desires.</li>
</ul>

<p>Reasons = Full Experience + Full Information + Full Reflection + Sound mental state + …</p>

<p>At bottom, the concern is that we are starting with an agent’s given motivational set and find a sound deliberative route or procedure with the aforemention properties to discover reasons.</p>

<p>Some theories allow the creation/destruction of underived desires. Williams and Smith think this allows for the creation and destruction of underived desires via imagination and, for Smith, the focus on unification. Smith takes a more radical approach in that he believes certain seemingly arational desires (e.g. desiring value only one’s interests at the expense of others) are irrational. This is because some theories are “fully rational”, not merely fully informed, where “fully rational” extends beyond correct ends-means deliberation. This is necessary to handle irrational desires.</p>

<p><strong>Problems</strong></p>

<p>Hasn’t solved the following problems from above:</p>

<ul>
  <li>Normativity of desires: why do mere sensations/dispositions even under idealized circumstances, in the absence of a normative judgment, provide a reason for action? It doesn’t seem that they do. Instead, we should focus on the normative judgments an agent would make (e.g. their plans, goals), under these idealized conditions.</li>
  <li>Unification: what do these conditions all have in common? It cannot just be that we all desire to satisfy the desires that we would have under these conditions because not everyone has this desire.</li>
  <li>Priority: assume everyone does actually desire the desires they would have under idealized conditions. What gives these desires the priority that they have? On desire-based theories, priority must be determined purely by “strength” and very often we can have desires that are stronger than our desire to satisfy the desires we would have under idealized conditions.</li>
</ul>

<p>??? example “Ideal Observer”</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>See: Peter Railton, Michael Smith

Ideal agent vs Ideal Observer: *Ideal agent*: an agent A has reason to X in circumstances C if and only if an ideal version of themselves, A+, would desire to X in C. *Ideal Observer*: an ideal agent A has reason to X in circumstances C if and only if an ideal version of the agent, A+, would desire that A desires to X in C. 

*Observer-based not agent-based.* The reasons that X has reduces to whether A+ would desire A to desire X, not whether A+ would desire X. This is because doing otherwise cannot account for reasons under uncertainty. Consider the case when one has reason to seek new information. A fully informed being would have no desire to seek information, even though they have reason to do so.

It's not clear why this means we should focus on observers rather than agents. For example, imagine the case where someone drinks a glass of soda that they believe to be water and they desire to drink water. We can easily say that they have reason to not drink from the glass, even though they do have reason to drink from the glass given the information that they have. In this case, there is no problem with saying someone has most reason to do something which they have no rational way of endorsing given their currently held beliefs. Likewise, it seems we can say that people don't actually have reason to seek information, but rather they have reason to seek information given their currently held beliefs. There is no problem with saying, for example, that someone lost in the woods has most reason to take route X, even though this is not something which they have a rational way of endorsing given their currently held beliefs.

**Problems** 

- They cannot account for degenerate idealized counterparts. What if a fully idealized counterpart, A+, desired that his less idealized counterpart, A, do something that he didn't have reason to do? What if A+ was viscious? The only way to avoid this conclusion is by assuming that some desire or concern for the sake of others is somehow constitutive of a fully rational agent. But this seems dubious. This is especially dubious for theories that allow any non-self-defeating desire in principle to be rational (unlike, e.g. Smith who thinks that something like this might be constitutive of a fully rational agent). But these seem like poor candidates for an analysis as they are assuming substantive desires as being rational in their analysis... This, combined with the earlier notes on ideal observer, might be enough to ignore the observer aspect and focus on the agent. We can distinguish what to do under uncertainty versus full information by distinguishing rationality and reasons.
- ~~~They cannot account for rationality in general. Take an analysis of reasons for belief. A world-to-mind fit analysis might say "A has reason to believe X in C iff an idealized version of himself, A+, would desire that A believed X in C". But this certainly does not seem to be true. Let's assume A+ is concerned ultimately with the welfare of A above all else (which is a dubious assumption as mentioned earlier). Then this certainly makes it possible for there to be cases where A+ desires that A believes X even though A has normative reason to not believe X, e.g. if believing X made A's life worse, even though it was justified. Theories about the direct beliefs of A+ (i.e. "A has reason to believe X iff an idealized version of himself, A+, would believe X in those circumstances") fail because (1) insofar as the idealization involves full information, this is flawed because the reasons to hold a belief are not determined by the truth of that belief, and (2) insofar as the idealization involves full rationality, it is circular.~~~ Actually, this can account for rationality in general. The full information requirement is not to account for *rationality*, but to account for *reasons*. It is full information + rationality that provides reasons. The account of rationality is independent from full information, and this account can be extended to other domains.
</code></pre></div></div>

<h3 id="general-problems">General Problems</h3>

<p>General problems with desire accounts and counterfactual attitude accounts.</p>

<ol>
  <li>The elements posited as providing reasons (desires, informed desires, motivations, ideal desires, ideal observer’s desires, etc.) don’t necessarily provide reasons, i.e. when they disconnect with an agent’s normative judgments. Consider a case where dispositionalism (but not constructivism) would say someone has reason. On what grounds can the person be said to have that reason if they are not in some way committed to the action?</li>
  <li>Insofar as they do provide reasons, constructivism explains why they provide reasons, why they matter and a unifying theme explaining the authority of the elements that do matter. E.g. if certain features are constituitive of agency, caring about desires under experience, future desires, etc.</li>
  <li>Constructivism can give a clean general account of all reasons.
    <ul>
      <li>How to give a metaphysical account of reasons for belief? One response is that one has reason to believe P only if they would believe P in circumstance P. How to account for a reason to believe <em>that</em> counterfactual? The response is that one has reason to believe that they would believe P in circumstances C iff they would believe that “they would believe P in circumstances C” in circumstances C. This is circular… This may not actually be an issue on the metaphysical/epistemic level. It may still be an issue on the linguistic/psychological level, however.</li>
    </ul>
  </li>
</ol>

    </li>
  
    <li>
      <h2><a href="/2019/06/19/Normative-Thought.html">Features of Normative Thought</a></h2>
      <p></p>
<h2 id="introduction">Introduction</h2>

<p>Animals have desires and beliefs.
Both beliefs and desires are attitudes with proposition content.
“Belief” here is to be understood broadly as an attitude that is essentially representational.
Beliefs and similar attitudes are said to have a <em>mind-to-world</em> direction of fit.
The contents of these kinds of attitudes are aimed at matching or corresponding to reality.
A “desire” is to be understood as an attitude that is essentially dispositional.
Desires and similar attitudes are said to have a <em>world-to-mind</em> direction of fit.
These attitudes are such that the agent is disposed to modify the world to match the contents of the desire.
This characterization is just a rough sketch but it suffices for present purposes.</p>

<p>Hume noted that belief and desire are both necessary to explain and motivate intentional action.
Belief alone can never explain or motivate intentional action.
E.g. A’s belief that it’s raining cannot explain A’s motivation to wear an umbrella.
However, A’s belief that it’s raining <em>and</em> A’s desires to not be wet can explain A’s motivation to wear an umbrella.
In general, people with identical beliefs can have different action if they have different desires.
Likewise, desire alone can never explain or motivate intentional action.
E.g. A’s desire to not be wet cannot explain A’s motivation to wear an umbrella.
For example, if A believed it was not raining, A might not be motivated to wear the umbrella.
In general, people with identical desires can have different action if they have different beliefs.</p>

<p>These attitudes are shared with other animals.
When a dog rushes to the door excitingly at the sound of the doorbell, this can be explained (1) by a belief (or a similar mind-to-world attitude) that its owner is at the door and (b) by a desire (or a smiilar mind-to-world attitude) to see its owner.
One capacity that seperates us seemingly from most other animals is our capacity for self-reflection.
Many animals believe whatever they perceive. 
And they act according to whatever they desire at the moment.
There are some exceptions to this rule in particular contexts but nothing that seems to match the essentially deliberative and reflective nature found in normal humans.</p>

<p>This self-reflection allows us to have higher-order attitudes - attitudes about other attitudes.
We can form believes about our beliefs.
We can form desires about our desires.
We can form beliefs about our desires.
Perhaps, we can even have desires about our beliefs.
Some of these higher-order attitudes are normative judgments - judgments about what we ought to do or what we have reason to do.
More precisely, they are judgments about what attitudes we have reason to adopt.</p>

<p>As humans, our perceptions do not <em>always</em> produce corresponding beliefs.
We can step back from our perceptions and question whether we have reason to believe the appearances.
E.g. a person might experience certain perceptions due to a known optical illusion yet suspend belief in the information presented by their perception.
Nor do we always let desires produce action.
We can step back from our desires and question whether we have reason to act on a particular desire.
E.g. a person might have a strong desire to eat chocolate yet refrain from doing so if they know it isn’t good for them.
Unlike most animals whose base desires almost always drive their actions, humans are capable of <em>endorsing</em> certain desires over others.
In general, when we are unreflectively presented with certain inputs (such as a perception or desire), we can reflect and deliberate over whether we actually endorse those inputs as guiding our decisions, i.e. we can question what attitudes we ought to hold given those inputs.
This faculty of <em>deliberative endorsement</em> is what constitutes normative thinking and normative judgments.</p>

<p>The task here is to characterize the thoughts and attitudes involved in deliberative endorsement. 
Is it more like a belief which represents some kind of normative reality?
Or is it more like a desire that disposes agents to behave in certain ways?
When one makes a normative judgment, is this judgment capable of being true or false?
If normative judgments are like beliefs, what are they attempting to represent?
If they are like desires, then what kind of motivational states are they?
Before answering these questions, it makes sense to consider certain features of the endorsement involved with normative judgments.
Once we better understand what is involved with this kind of attitude, we will be better suited to answer the above questions.
I will be reviewing what I take to be four key features of normative judgments that must be accounted for by any characterization of normative thoughts.</p>

<h2 id="1-ubiquity">1. Ubiquity</h2>

<p>The first feature is the ubiquity of normative thinking. 
We find normative thinking everywhere in human lives. 
As already mentioned, we regularly endorse or reject beliefs and desires. 
E.g. we question whether our current and past perception provides us with reason for a belief, and we question whether our desires (and other attitudes) provides us with reason for action.
Normative thinking is also ubiquitous in another sense, in that it takes a wide variety of attitudes as its object.
Normative thinking is present whenever we are determining whether an attitude is <em>warranted</em>, <em>appropriate</em>, <em>justified</em>, <em>reasonable</em>, etc.
E.g. we question whether we have <em>reason</em> to have certain desires, whether fear is <em>justified</em> in certain contexts, whether we <em>should</em> admire certain people or certain acts, whether we <em>should</em> appreciate certain pieces of art, whether hatred or anger is <em>appropriate</em>, etc.</p>

<p>The precise terminology is not important.
Whether a person has a normative thought does not depend on whether they happen to use a particular term to express that thought, e.g. it doesn’t depend on whether they use the word “should”, “reason”, “justified”, etc. 
So trying to tie normative <em>thinking</em> to any necessarily normative <em>language</em> is not likely to be fruitful.
Normative terms are used here because they commonly refer to what we already understand to be normative thoughts.
However, these thoughts can be understood without reference to any particular terms.
In fact, we could even use prescriptive or declarative language to express normative thoughts without <em>any</em> normative terms. 
E.g. when a parent scolds their child and utters the prescriptive statement “Don’t hit people to settle disputes” or the declarative statement “We don’t hit each other to settle disputes!”, this can easily be understood as expressing the same thought as expressed by a normatively-laden statement such as “You <em>shouldn’t</em> hit people to settle disputes” or “It’s <em>wrong</em> to hit people to settle disputes”.</p>

<p>I take the idea of a normative thought or attitude to be basic, a kind of attitude familiar to all normal humans which can be better understood upon reflection.
Any agent who is unfamiliar with normative thoughts is unlikely to understand them through any kind of communication. 
It is impossible to explain what a kind of thought is like to a creature that has never experienced those thoughts or anything related to those thoughts. 
Just as it is impossible to explain what it is like to perceive certain colors to a blind person, it is also impossible to explain what it is like to have normative thoughts to someone who doesn’t already have them.
Creatures that do not have normative attitudes (e.g. think of creatures without higher-order attitudes, such as animals, young children, developmentally disabled adults, etc.) cannot hope to understand them.
Thus, I will be assuming we all have a shared understanding of normative thoughts and attitudes.
My task here is merely to point out features of normative attitudes to clarify this shared understanding.</p>

<p>All normative attitudes involve at least two entities: an agent A and some attitude X. 
All normative judgments can be reduced to: “A has reason to adopt attitude X”, “A ought to adopt attitude X”, “A is justified in adopting attitude X”, “it is appropriate for A to adopt attitude X”, etc.
Specific examples: we might judge that we have reason to go to a party (e.g. because it would make us happy), that we have reason to believe evolutionary theory over creationism, that we ought to admire generous people, that we have no reason to take our anger out the messenger, etc.
If we assumed that normative attitudes expressed truth-apt propositions (something which I do not assume at this point), then we can say they express that a relation holds between an agent and an attitude.</p>

<p>Note that not all instances of attitudes which can be the object of normative attitudes involve normative judgments.
Sometimes we are prompted with attitudes without reasoning.
For examlpe, a fear of spiders might be biological or instilled from environment, not because someone reasoned that they should fear spiders.
Many of our desires are not produced by reason; rather, they are simply inputs that we take into account during reasoning by deciding how much weight they should have in determining our action (which sometimes results in the desire disappearing after we realize the desire is unreasonable).s</p>

<p>I said before that all of normative thinking involves a judgment that an agent ought to adopt a certain attitude.
This implies that all normative concepts can be reduced to a relation involving an agent and an attitude. 
I believe this can be done with all actual normative concepts. 
Consider the following reductions of common normative concepts:</p>
<ul>
  <li>“X is good” = “[some agent(s)] ought to <em>desire</em> X”</li>
  <li>“X is credible” = “[some agent(s)] ought to <em>believe</em> X”</li>
  <li>“X is morally wrong” = “[some agent(s)] ought not to <em>do</em> X” and/or “[some agent(s)] ought to <em>blame</em> those who do X”</li>
  <li>“X is beautiful” = “[some agent(s)] ought to <em>admire</em> or <em>appreciate</em> X”
etc.</li>
</ul>

<p>Again, the terminology is not what’s important. 
In place of “reason” or “ought”, we could use any term that allows us to refer to a relation involving an agent and the <em>appropriate</em> or <em>justified</em> attitude.</p>

<p>There are two ways the normativity of belief can be misinterpreted.
Firstly, it should be noted that “X is credible” is not meant to be taken as “X is true”.
It is more akin to “X is justified”.
But we know there can be cases where a true belief is unjustified and cases where a false belief may be justified.
A belief is justified for a particular agent depending on whether that agent has evidence to support the belief.
A belief is true depending on whether it accurately corresponds to the world.
The former is a normative notion whereas the latter is a purely descriptive notion.
Secondly, the “ought” involved in the statement “X is credible” is not the same type of “ought” as in “X is morally obligatory”.
The former is concerned with epistemic justification, which is not identical to the justification involved with moral justification.</p>

<p>All normative concepts and thoughts are similar in that they are all concerned with a special kind of <em>endorsement</em> of a certain attitude.
They differ in terms of the attitude that the concept “calls for” or that the agent endorses.
There will be as many normative concepts as there are attitudes that can be subject to normative inquiry.
But what kind of attitudes can be subject to normative inquiry?</p>

<h2 id="2-motivation">2. Motivation</h2>

<p>I believe that the kinds of attitudes that can be subject to normative inquiry are what Thomas Scanlon calls <em>judgment-sensitive</em> attitudes.
This includes all attitudes X such that one’s judgment that they ought to adopt attitude X can in principle influence whether they actually adopt attitude X.
In other words, this includes attitudes whose adoption by an agent is influenced by that agent’s endorsement of the attitude.
As already mentioned, this includes beliefs, desires, intentions, etc.
One’s beliefs, desires, intentions, etc. are regularly changed depending on whether one thinks the beliefs, desires, intentions, etc. are warranted.
In the case of belief, this almost always happens immediately and without struggle.
E.g. if one judges that they have reason to believe X, they will almost always believe X.
In the case of desire or intention, there is a possibility for weakness of will.
E.g. sometimes a person thinks they have reason to do X, but they fail to do X because their degenerate desires (i.e. desires which they judge themselves not to have reason to give weight to) overpower their normative judgments.
E.g. one might judge that they have reason to study, but their desire to surf the internet wins out and they never study.</p>

<p>Other judgment-sensitive attitudes includes admiration, fear, anger, blame, pride, etc. 
All of these attitudes can in principle be motivated by judgments regarding their appropriateness.
Again, there are also regularly cases where one’s actual attitudes diverges from their normative judgments.
E.g. one might fear the dark even in contexts where they know they are safe and the fear is unjustified.
Insofar as one fails to adopt a judgment-sensitive attitude that they judge to be appropriate, they can be said to be <em>irrational</em>.
E.g. procrastinating when you know you shouldn’t, fearing the dark when you know you shouldn’t, etc. are all instances of irrational behavior.</p>

<p>Attitudes that cannot be the subject of normative inquiry are attitudes that are not judgment-sensitive. 
E.g. hunger, uncomfortableness, intoxicated, confused, having certain perceptions, etc.
These are attitudes or states of mind that one can adopt which are not influenced by one’s judgment of their appropriateness. 
E.g. it would not make sense to call someone irrational for <em>being</em> hungry, uncomfortable, intoxicated, confused, having certain perceptions, etc.
Of course, they might be irrational for earlier intentional actions that they did to make themselves, hungry, intoxicated, confused, etc. but the final attitudes themselves cannot be irrational, precisely because they are not influenced by normative judgments.
Because of this, these attitudes cannot be attributed to agents in the same way that judgment-sensitive attitudes can be attributed to agents. 
Judgment-sensitive attitudes can be attributed to agents because one’s judgment-sensitive attitudes indicates something about either their normative judgments (if they adopt the attitudes that they take to be appropriate) or their rationality (if they don’t adopt the attitudes that they take to be appropriate).</p>

<p>Because normative thinking only involves judgment-sensitive attitudes, this means that normative judgments must be intrinsically motivating.
Otherwise, no attitudes could in principle be influenced by one’s normative judgments, which means there would be no judgment-sensitive attitudes.
But if there are no judgment-sensitive attitudes, then normative thinking is not possible.
Since normative thinking clearly is possible, normative judgments must be intrinsically motivating.
An agent who comes to judge that they have reason to adopt attitude X must develop some motivation to adopt attitude X.
Note that this motivation is <em>defeasible</em>. 
The normative faculty is not perfect, because the normative faculty is not the only motivational system in humans.
As mentioned above, humans are motivated by normative judgments, but they are also motivated by other degenerate desires as well (e.g. desires that we do not endorse).
This occurs in everyday human life, especially for more impulsive people such as children or the mentally handicapped.
This covers the second feature of normative thinking: normative judgments are intrinsically motivating yet defeasible.</p>

<p>It might be questioned whether it makes sense to say that normative judgments must necessarily be intrinsically motivational if they are defeasible.
But we already accept this with other attitudes that are necessarily motivational.
E.g. desires are necessarily motivational states, but, for any particular desire, an agent might not act on that particular desire if they have a conflicting desire.
E.g. someone might desire to read a book, but a stronger desire to watch a movie might win out.
Likewise, a stronger desire might win out over a normative judgment.
Similar considerations apply to all attitudes like beliefs, fear, admiration, anger, etc. 
E.g. someone might judge that have no reason to be angry with someone, yet neverthless feel angry.
To endorse any of these attitudes entails some motivation, but it can be defeated by other base motivations.
Another way of putting it: normative judgments must be <em>capable</em> of motivating an agent to adopt the relevant attitude on its own, without the need to posit an additional desire.
In other words, the normative judgment that attitude X is appropriate entails a disposition to adopt attitude X, the same as any other motivational state such as a desire.</p>

<h2 id="3-disagreement">3. Disagreement</h2>

<p>The third feature of normative judgments is the possibility for normative disagreements.
Perhaps the most prominent case of this kind of disagreement concerns (normative) reasons for belief.
Most disagreements about what is true involve disagreements about what (normative) reason we have for belief.
E.g. imagine an atheist and a theist who agree with certain facts, e.g. that the universe is complex.
That might not only disagree over whether God exists, but they also disagree over whether a certain set of facts or observations (facts which they agree with) <em>justify</em> the belief in God, e.g. whether the complexity of the universe is a (normative) <em>reason</em> to believe in God.
It is a disagreement about what the <em>evidence supports</em>, which is a seperate question from what is true.
It is a question about what it is <em>appropriate</em> to infer given observations that we all agree with.
This is a normative dispute.</p>

<p>Similar disputes are had regarding the natural empirical world.
E.g. some pro gun-control advocates think that the <em>evidence indicates</em> that gun control reduces violent crime whereas some opponents think the opposite is supported by the evidence.
Again, these are seperate questions from what is true.
Whether a belief is justified for an agent depends on the evidence available to that agent.
Whether a belief is true is a seperate question.
A justified belief might be false and a true belief might be unjustified.</p>

<p>There are even arguments regarding more general principles for justifying beliefs.
There is agreement among most that certain methods of inference can justify beliefs. E.g. deduction, induction, abduction.
There is dispute about whether we are justified in relying on sense data, memories, inferring causation, etc. to form beliefs
There is dispute over various epistemic principles and how best to understand them: e.g. occam’s razor, whether falsifcation, verification, etc. are requirement of a scientific theory and what they consist in.
Most people accept these principles in at least some contexts.
The most extreme skeptics deny that they can ever justify a belief.
There are disagreements over general theories of justification. E.g. coherentism vs foundationalism.</p>

<p>The next most prominent form of normative disagreement is moral disagreement.
There is widespread disagreement over what we should do, who ought to be blamed for what actions, what kinds of beings deserve moral consideration, etc.
There are moral disagreements about political issues, e.g. what the government’s stance ought to be regrading abortion, immigration, taxation, welfare, affirmative action, free speech, etc.
There are moral disagreements regarding personal behavior, e.g. how one ought to treat their friends, loved ones, children, the appropriate standards for behavior in polite society and the ramification for failing to meet those standards.
We disagree with our friends, strangers in our society, strangers of other societies and cultures, about how people ought to behave and what ought to be acceptable.</p>

<p>There are moral disagreements about general ethical theories, often among philosophers. 
Consequentialists argue that actions are to be morally evaluated based on some relation to their consequent state of affairs.
Deontologists argue that actions are to be morally evaluated based on at least some features other than their consequent state of affairs.
Kantians argue that people are to never be treated as a mere means but always as an end.
Certain deontologists have certain rights that ought to never be violated for the sake of some overall good.
Certain anarchists argue that the initation of force is always wrong.
Hedonists argue that the only good thing is pleasure or happiness.
Pluralists argue that there are distinct and perhaps incomensurate types of value that cannot be reduced to any single good.
Generally speaking, when one person says “X is good” and another says “No, X is not good”, they have expressed <em>conflicting</em> attitudes.
Similar points apply when “good” is replaced with other common moral terms, such as “right”, “bad”, etc.</p>

<p>Similar disagreement (though often less heated) disagreement is found in other domains as well.
E.g. in aesthetics, people disagree over whether a piece of art is beautiful, whether someone is funny or not, whether a movie is good, etc. sAn analysis of normative terms must allow for and explain the conflict we regularly find in normative disagreements.</p>

<h2 id="4-non-empirical">4. Non-empirical</h2>

<p>Disagreement is so widespread in fact that two people can even agree that an object has certain physical properties while disagreeing on what attitudes are appropriate with regard to that object, without either person contradicting themselves.
This is due to the fourth and final feature of normative judgments: no set of empirical beliefs logically entail any set of normative judgments (or vice versa).
This relation is similar to the relation between beliefs and desire - no set of beliefs can logically entail any set of desires.
Just like any pair of beliefs and desire is possible, any pair of empirical beliefs and normative judgments is possible.
When a person judges that someone has reason to do something, we cannot infer that the judge also believes any particular <em>empirical</em> relation holds between the agent and the attitude.
E.g. two people might agree on all the relevant empirical facts regarding abortion, but still disagree over whether women should be able to perform abortions.
Also unlike empirical beliefs, we seem to discover normative truths a priori.
We ordinarily do not perform observations in the world to determine a normative truth.
Rather, we think conceptual analysis and reason alone is enough to establish normative truths.</p>

<h2 id="the-problem">The problem</h2>

<p>Now that we have illustrated what I take to be the main features of normative judgments, we can now return to the original task.
We can now attempt to characterize the kind of attitude involved in <em>deliberative endorsement</em>. 
The characterization has to be one that can be applied to the normative judgments of virtually all people.
This universal characterization is required because it is necessary to ground a shared concept, and a shared concept is necessary for the genuine disagreements we have with others. 
Otherwise, these “disagreements” wouldn’t really be disagreements, we would just be talking past each other with different concepts.
E.g. if “good” for Adam meant “approved by society” and “good” for Bob meant “approved by God”, then when Adam says “X is good” and Bob says “No, X is not good”, what is really happening is Adam is saying “X is approved by society” and Bob is saying “No, X is not approved by God”. 
But this characterization of normative judgment clearly does not allow for a disagreement (there is no contradiction with X being approved by society and X not be approved by God).
Since Adam and Bob clearly do disagreement when one says “X is good” and the other says “No, X is not good” (i.e. Adam and Bob both judge that the other person is <em>incorrect</em>), this characterization does not suffice.</p>

<p>Possible characterizations can be broadly seperated into two categories - world-to-mind states of mind and mind-to-world states of mind.
Both are states of mind that that have propositional content as their objects, i.e. agents have beliefs and desires with regard to p where p is some proposition. 
Mind-to-world states of mind are states whereby the propositional content of the attitude is meant to <em>correspond</em> to an external reality. 
E.g. if one believes that p, then p is aimed at corresponding to reality. 
World-to-mind states of mind are states whereby the agent is disposed to modify the world so that the propositional content of the attitude is made true. 
E.g. if one desires that p, then they are disposed to try to make it the case that p is true. 
Whereas mind-to-world states have a <em>correspondence</em> role, world-to-mind states have a <em>dispositional</em> or <em>functional</em> role regarding one’s motivations.</p>

<p>How do we determine whether an attitude has a mind-to-world direction of fit or a world-to-mind direction of fit?
One test for the direction of fit of an attitude is to determine whether the attitude persists despite observing evidence against the propositional content of the attitude. 
For example, someone’s belief in p will tend to diminish upon observing evidence against p. 
E.g. if someone <em>believes</em> that their home football team will win the game tonight, this will (usually) tend to diminish as they observe evidence that the team will lose, e.g. if the home team loses their best player, then this will diminish one’s belief they they will win. 
On the other hand, if one <em>desires</em> that their home team win, then this attitude (usually) does not tend to diminish upon observing that the team will lose, e.g. if the home team loses their best player, then this will <em>not</em> diminish one’s desire that they win.
Like most desires, the desire here persists despite evidence against the truth of the corresponding propositional content.</p>

<p>It seems clear to me that normative attitudes have a world-to-mind direction of fit.
That is, when a person endorses A’s adoption of attitude X, this does not tend to diminish as one learns that A fails to adopt attitude X.
This to me lends evidence to a non-cognitive analysis of normative judgments.
This implies that normative judgments are not <em>beliefs</em> or other cognitive states that represent a normative reality. 
Rather, they are sophisticated forms of desire-like states (or dispositions to have certain desire-like states).
However, other theories of normative talk purport to explain the appearances better. 
These theories are discussed in “Theories of Normative Talk”.
In the end, I believe that non-cognitivism is the best account of our normative thinking.</p>

    </li>
  
    <li>
      <h2><a href="/2019/06/19/Normative-Talk.html">Normative Talk</a></h2>
      <p></p>
<p>Readings for analyzing normativity</p>
<ul>
  <li>A.C. Ewing, “A Suggested Non-Naturalistic Definition of Good”</li>
  <li>Christine Kosgaard, “The Sources of Normativity”</li>
  <li>Justin D’Arms, “Two Arguments for Sentimentalism”</li>
  <li>Maybe
    <ul>
      <li>Henry Sidgwick, “Ethical Judgments”, from <em>The Methods of Ethics</em>
</li>
      <li>H.A. Prichard, “Does Moral Philosophy Rest on a Mistake?”</li>
    </ul>
  </li>
</ul>

<p>Outline:
Bold means seperate create a article for that section</p>

<p>Copied in Topics.md</p>

<ul>
  <li>
<em>Normativity</em>
    <ul>
      <li>Examples</li>
      <li>Contrast with descriptions</li>
      <li>Plattitudes</li>
    </ul>
  </li>
  <li>
<em>Analysis</em> (the <em>content</em> of normative judgments)
    <ul>
      <li>Domains
        <ul>
          <li>Rationality</li>
          <li>Well-being versus reasons for action</li>
          <li>Epistemology</li>
          <li>Aesthetics</li>
          <li>Morality</li>
          <li>Ettiquette</li>
        </ul>
      </li>
      <li>Flexibility of language</li>
      <li>General: shoulds, justifications, warrant, etc. a relation involving an agent and an attitude. Grounds charges of criticism generally.</li>
      <li>Narrow: Reasons. A relation that grounds charges of irrationality specifically.</li>
      <li>Kinds of reasons concepts
        <ul>
          <li>Normative vs non-normative “should” (e.g. “he should arrive here soon”)</li>
          <li>Explanatory vs Justificatory reasons</li>
          <li>Objective vs Subjective reasons / Available vs Potential Reasons (e.g. reasons under lack of information)</li>
          <li>Right/Wrong kinds of reasons</li>
          <li>Internal vs External reasons
  —&gt;
            <ul>
              <li>Available Reasons =&gt; Rationality</li>
              <li>Potential Reasons =&gt; Counterfactual endorsements under rationally endorsed conditions</li>
              <li>External Reasons</li>
            </ul>
          </li>
        </ul>
      </li>
      <li>Other different categories of reasons
        <ul>
          <li>Deontic vs Evaluative (proposition P should be true versus agent A ought to acquire attitude X)</li>
          <li>Agent-Neutral / Agent-relative</li>
        </ul>
      </li>
      <li>Intrinsic/Instrumental</li>
      <li>Not all based in pleasure/happiness</li>
      <li>Not all based in teleology</li>
      <li>Hierarchical structure, pro-tanto &amp; prima facie</li>
      <li>Works: Moore, Ross, Ewing, Sidgwick, Wiggins, McDowell, D’arms/Jacobson, Parfit, Raz</li>
    </ul>
  </li>
  <li>Psychology (the <em>psychology</em> of normative judgments)
  <em>Introduction</em>: the problem and possible solutions
  <em>Failure of descriptivism</em> 
  <em>Characterization of non-descriptivism</em>
      - World-to-mind fit that cannot be otherwise reduced
      - Expressive of deliberative endorsement and prescriptive
      - Possibility of an alternative standard of truth
      - Competing motivational faculties
  <em>Evolution</em>: selections for descriptivism vs non-descriptivism
  <em>Observations</em>: examples of other evaluative language, normative education, emphasizing the dynamic component of certain terms (e.g. no one admits to being “racist” despite meeting the criteria)
  <em>Objections</em>
      - Seems intuitively false
      - Frege-Geach
      - Which attitude
    <ul>
      <li>Works: Stevenson, Ayer, Gibbard, Blackburn, Timmons/Horgan</li>
    </ul>
  </li>
  <li>Correctness (the <em>correctness</em> of normative judgments)
    <ul>
      <li>
<em>Introduction</em>: the problem and possible solutions</li>
      <li>
<em>Failure of externalism</em>
        <ul>
          <li>Repeat many arguments from Williams’s article</li>
          <li>Use analogy with theoretical reasons</li>
        </ul>
      </li>
      <li>
<em>Failure of broad internalism</em>
        <ul>
          <li>Critique Williams’s position</li>
          <li>Use analogy with thoeretical reasons (e.g. desires don’t justify beliefs, even if they can explain them).</li>
        </ul>
      </li>
      <li>
<em>Constructivism</em>
        <ul>
          <li>Normative judgments, not desires/sensations, provide reasons</li>
          <li>Analogy with other domains</li>
          <li>Constituitive features</li>
          <li>Explaining intuitive reasons versus broad internalism, externalism, etc.</li>
        </ul>
      </li>
      <li>
<em>Objections</em>
        <ul>
          <li>Methodology
            <ul>
              <li>General Theory unlikely</li>
              <li>Conflicting reasons</li>
              <li>Deliberation/reflection</li>
            </ul>
          </li>
        </ul>
      </li>
      <li>Works: Koorsgard, Street, Scanlon, Parfit, Frankfurt, Nagel, Gauthier</li>
    </ul>
  </li>
  <li>
<em>Morality</em>
    <ul>
      <li>
<em>Introduction</em>: the problem of reasons and objectivity</li>
      <li>Sentimentalism</li>
      <li>Contractualism</li>
      <li>Methodology
        <ul>
          <li>General Theory unlikely</li>
          <li>Conflicting interests</li>
          <li>Argumentation/Discussion</li>
        </ul>
      </li>
      <li>Works: Scanlon, Kant</li>
    </ul>
  </li>
</ul>

<p>Some insights that I haven’t seen explored elsewhere</p>

<ol>
  <li>Individual rationality need not reduce to individual goodness. For example, individual goodness might reduce to desired states of consciousness, even though it might be rational to act to attain desired states of consciousness (e.g. experience machine). Can this relate to morality? How should goodness and rationality be analyzed? If this is true, then what does it mean to say that something ought to be desired/preferred/promoted (i.e. goodness) even though we ought not necessarily act to promote it (e.g. rationality). So not even individual rationality need be consequentialist.</li>
  <li>Different irreducible domains of morality, e.g. ettiquette, aesthetic morality and justice morality. These distinctions are not necessarily a part of a linguistic culture.</li>
  <li>We are not consequentialist about epistemology.</li>
  <li>Formulating a revisionist cognitivist analysis of normative judgments from historical non-cognitive uses.</li>
  <li>Normative judgments are all judgments of relations, not properties.</li>
</ol>

<h2 id="introduction">Introduction</h2>

<h3 id="applies-ethics-normative-ethics-and-metaethics">Applies Ethics, Normative Ethics and Metaethics</h3>

<h3 id="the-insufficiency-of-reflective-equilibrium-and-the-need-for-metaethics">The insufficiency of reflective equilibrium and the need for metaethics</h3>

<p>Can we recreate moral positions using non-moral terms?</p>

<p>Reflective equilibrium with regard to normative ethical reasoning fails to settle disputes when two different parties reach different conclusions in their reflective equilibriums, either because of different foundational principles or different considered judgments. At this point, it may seem that the disagreements are irresolvable. To settle the dispute, we need to take a step back from answering the normative questions themselves. Instead of internally justifying our positions, we need to ask external questions about the normative questions. We need to determine what is actually at dispute among the parties.</p>

<p>We need a strategy for communicating the meanings of our expressions to an agent unfamiliar with our language. This can work for descriptive concepts by merely presenting instances of the entity in question and associating it with certain words.</p>

<p>The strategy for doing this is as follows. (1) list out all of the assertions from two parties in an ethical debate. (2) Replace the assertions that the parties make with different non-ethical statements about the parties in a manner that preserves the significant psychological and social commitments of all parties.</p>

<p>For example, if given the following ethical dispute:</p>
<ul>
  <li>A judges that X is morally wrong.</li>
  <li>B judges that X is not morally wrong.</li>
</ul>

<p>There are a few ways to translate this:</p>

<h4 id="definitions">Definitions</h4>

<p>We might do this by substituting the normative terms with non-normative terms as if in a strict dictionary definition. The definition could be the agent’s subjective definition, societal definitions, etc. For example, the earlier dispute might be replaced as:</p>
<ul>
  <li>A believes that X promotes suffering.</li>
  <li>B believes that X does not promote suffering.</li>
</ul>

<h4 id="plattitudes">Plattitudes</h4>

<p>Maybe there can be no strict definition. Instead, we just encapsulate all the plattitudes that are necessary to come to have mastery of the concept, i.e. the inferential and judgmental dispositions of those who have mastery. This can be done by finding the role that these terms play in linguistic discourse.</p>
<ul>
  <li>A judges that we have reason to disapprove of those who X.</li>
  <li>A is disposed to disapprove of X.</li>
  <li>A is disposed to not do X, all things else being equal.
…</li>
  <li>B denies these.</li>
</ul>

<p>One issue with these is that they also use other normative terms, e.g. “reasons”. More work would need to be done to explain those.</p>

<p>Another issue is that it may seem that some terms don’t have a clear role in language. For example, while the role of moral rightnes/wrongness might be clearly associated with motivation for and reasons for approval/disapproval, etc. but other normative terms like “rationality” might not have such a clear role in language. So it may be unclear how to settle disputes about “rationality”. Perhaps, what we can do is look for what roles we would need to be filled in, and argue that only certain interpretations of “rationality” can fill that void, and other interpretations don’t account for anything linguistically important.</p>

<h4 id="job-of-metaethics">Job of metaethics</h4>

<p>Explain the following</p>
<ul>
  <li>Semantics: what we mean when making a moral statement.</li>
  <li>Psychology: what state of mind characterized by moral judgment.</li>
  <li>Ontology: what grounds moral properties, if they exist.</li>
  <li>Epistemology: how we can learn/reason about moral truth.</li>
  <li>Rationality: why we have reason to be moral.</li>
</ul>

<p>The most important are accounting for semantics/psychology and giving a realistic account of epistemology/rationality, i.e. we need an objective methodology for handling moral disputes, as disputes are the most important feature of moral beliefs. The ontology doesn’t really matter.</p>

<h2 id="plattitudes-1">Plattitudes</h2>

<p>The role of normative thinking is to handle conflicts in our motivations.
Normative thinking requires the followings: (a) beings with motivations, which sometimes conflict, (b) beings capable of stepping back and acknowledging these motivations and assessing them, (c) beings capable of deciding on which motivation to will after normative reflection.
This explains why there cannot be inconsistent upshots of normative reasoning.
The very practice of normative thinking was created as a response to motivational conflicts.
Thus, a being who doesn’t care about such conflicts doesn’t count as a normative reasoning agent.
Or, a person who doesn’t have normative conflicts wouldn’t count as a normative reasoning agent. There would be no need for normativity to arise.
The basic goal is to move from disjointed conflict to unity.</p>

<p>Normative “conflict” generally does not mean inconsistency specifically. 
Inconsistency refers to conflicts in beliefs, where there can be conflicts in desires, intentions, attitudes, etc.</p>

<h3 id="ubiquitous">Ubiquitous</h3>

<p>Normative judgments are found in all creatures who deliberate, insofar as those deliberations influence action.</p>

<p>Perceptions and desires are pre-reflective cognitive elements that dispose us towards a certain behavior. A perception that p consists of a pre-reflective disposition towards believing p. A desire that p consists of a pre-reflective dispositions towards performing M whenever one believes M -&gt; p. These pre-reflective elements can be identified as the animalistic motivational system.</p>

<p>Non-human animals typically behave according to their pre-reflective cognitive dispositions. They believe whatever they perceive, and they act according to whatever desire happens to be strongest. The beliefs and actions of humans, on the other hand, are usually not strictly identical with our perceptions and desires. We deliberate and reflect about what to do, and this inevitably involves our perceptions and desires. However it involves much more than our perceptions and desires. (1) We decide which beliefs and actions are <em>justified</em> from our perceptions/desires, which may not be identical with whatever the perceptions/desires indicate/favor. (2) We <em>reject</em> some perceptions/desires as mistaken or irrational. (3) We <em>endorse</em> certain perceptions/desires as rational or justified.</p>

<p>When we deliberate and reflective, we try to determine the <em>reasons</em> we have for a kind of behavior. Whenever we act, insofar as we are deliberative and reflective, we act according to what we have judged ourselves to have <em>reason</em> to do. To the extent that we don’t act according to what we judge ourselves to have reason to do, we are acting <em>irrationally</em>. The deliberation involved with the connection between are given pre-reflective <em>dispositions</em> favoring a certain behavior (i.e. perceptions, desires, sensations, etc.) and are post-reflective conscious <em>endorsements</em> of a certain behavior (i.e. what we determined ourselves to have reason to do) is <em>normative reasoning</em>. The motivational system associated with normative reasoning is the <em>normative motivational system.</em></p>

<p>Supplement:</p>
<ul>
  <li>Korsgaard’s contrast of animals and humans</li>
</ul>

<h3 id="supervenience">Supervenience</h3>

<p>Normative judgments supervene on non-normative beliefs. If one has a competent grasp of normative concepts, then if they judge two things to be different normatively then this must be due to a judged difference in non-normative properties. Equivalently, once one’s beliefs about the non-normative properties of a thing is fixed, so too are his normative judgments about the thing.</p>

<h3 id="deliberative">Deliberative</h3>

<p>Argumentation/reasoning influences our normative judgments. Our judgments of normative reason are typically the upshots of deliberation, whereas our motivating reasons can be a given</p>

<p>Supplement:</p>
<ul>
  <li>Smith’s elaboration on the deliberative and the intentional.</li>
  <li>Koorsgard’s theory of normativity</li>
</ul>

<h3 id="motivational">Motivational</h3>

<p>Normative judgments influence action. Judging that one has normative reason to do x is typically associated with a motivating reason to do x. But this is not perfect: there are cases where one judges that they have normative reason to do x without having a corresponding motivating reason to do x, and there are cases where one has a motivating reason to do x without a corresponding judgment that they have normative reason to do x. Think of cases of psychological compulsion, physical addiction or emotional disturbances. Such cases are usually not the norm; an explanation of some such sort must be invoked to explain not intending what one judges to have reason to do.</p>

<p>Supplement:</p>
<ul>
  <li>Supplement on Smith’s elaboration of the deliberative and the intentional</li>
  <li>Gibbard’s evolutionary arguments for the value of motivational content</li>
  <li>considerations about translations from other cultures</li>
  <li>sincere inferences of normative judgments of others</li>
</ul>

<h3 id="disagreement">Disagreement</h3>

<p>People have normative disagreements.</p>

<p>People have epistemic disagreements. Two parties can have identical perceptions and evidence in front of them, and yet disagree about what they have most <em>epistemic reason</em> to believe given the evidence. They can disagree about what can be <em>rationally inferred</em> given the evidence.</p>

<p>People have moral disagreements. Two parties can have identical beliefs with regard to the empirical world, and yet disagree about what we have <em>moral reason</em> to do. They can.</p>

<p>People have prudential disagreements. Two parties can have identical beliefs about a hypothetical agent’s desires, interests, etc. and the empirical world, and yet have disagreements about what that agent has most reason to do. One parties might say he should satisfy his present desires, others say he should do what will in fact make him happiest, others that he should do what will result in the least regret, etc.</p>

<p>People have aesthetic disagreements.</p>

<p>While these disagreements sometimes stem from logical or semantic errors, they need not always. Rather, the disagreements are often the result of differing normative principles.</p>

<p>We need a shared concept in order for disagreement to be possible.</p>

<p>Supplement:</p>
<ul>
  <li>Stevenson’s article on disagreement.</li>
</ul>

<h2 id="unification">Unification</h2>

<p>All normative judgments can be expressed in the form of a prescription that recommends a particular behavior X for an agent A in circumstances. There are often expressed in declarative form via some relation that involves entities A, X, C. The basic terms underlying this relation can be any term that supports this relation grammatically, i.e. “A ought to X in circumstances C”, “A has reason to X in circumstances C”, “A is justified in X-ing in circumstances C”, “It is fitting for A to X in circumstances C”, etc.</p>

<p>They are also sometimes expressed without using strictly normative terms, e.g. “A must do X in C”, “A has to do X in C”, etc. Finally, they can also be expressed purely as imperatives, i.e. “A, do X in C”. All of these are ways of communicating a normative judgment to someone else.</p>

<p>A normative system can be understood by the following components:</p>

<ul>
  <li>T - The types of behavior regulated (actions, beliefs, driving, etc.) - this constraints genuine normative statements to be action guiding in some way. Normative propositions that cannot be expressed in this manner are not coherent normative propositions.</li>
  <li>R - The considerations that serve as reasons for the norm. Different normative realms have different relavent considerations.
Then we can determine the content of the normative system:</li>
  <li>S - The actual norms of the normative system. These are entailed from whatever the relevant considerations are plus any observational content.</li>
</ul>

<p>Other considerations concerning the content of normative judgments</p>

<ul>
  <li>Right/Wrong kinds of reason</li>
  <li>Ought implies can &amp; cannot</li>
  <li>Is/Ought gap -&gt; logical/analytic/synthetic</li>
</ul>

<p>There are a few different classes of normative judgments:</p>
<ul>
  <li>Rational judgments - A has reason to do X</li>
  <li>Aesthetic judgments - A expresses attitude with regard to X</li>
  <li>Moral judgments - A encourages the attitudes of others</li>
</ul>

<h2 id="rational-psycholgoy">Rational Psycholgoy</h2>

<p><a href="Rational%20Psychology.md">Main Page</a></p>

<h3 id="intentional-and-deliberative">Intentional and Deliberative</h3>

<p>Intentional action can be explained from two perspectives, the <em>intentional</em> and the <em>deliberative</em>. From the intentional perspective, intentional action can be explained by citing <em>motivating reasons</em>, i.e. by citing a belief-desire pair that fits into a pattern of teleological explanation. From the deliberative perspective, intentional action can be explained by citing <em>normative reasons</em>, i.e. by citing a pattern of rational deliberation that either did, or could have, produced it. This involves citing the considerations that one reflects over in deciding what to do.</p>

<p>The deliberative perspective must be explanatory to satisfy the judgment internalism thesis about normativity, i.e. when we decide what to do after deliberation, that often makes a difference in what we do. This would be impossible if the deliberative perspective were not explanatory, since the connection between deliberation and our action would be purely causally contingent. Thus, our attitudes towards the propositions that figure in our deliberations must be capable of figuring an explanation of our action.</p>

<p>However, there must also be some slack between desires and values. An agent may desire to X without valuing to X (e.g. kleptomaniac, addicts, etc.). Likewise, an agent may value X without desiring to X (e.g. the depressed, weakness of will). In general, due to psychological compulsions, physical addictions, emotional disturbances, etc. there is an imperfect connection between what an agent judges to be a normative reasons for action and the agent’s motivating reasons for action.</p>

<p>To judge that one has normative reason to X is to <em>endorse</em> X under deliberation. Normative judgments then can be vaguely characterized as <em>deliberative endorsement</em> of some propositional content. Contrast this with undeliberative or unreflective endorsement, which are the sources of one’s <em>motivating reasons</em>, the explanation of their intentional behavior. Voluntary actions can be explained by a belief and desire; these actions are done on the basis of normative reasnoing insofar as deliberation and reflection play a role in how the belief and desire manifest into action, e.g. if deliberation influences what one desires, which desires are actualized, etc. The question is to determine what it is to form deliberative endorsement of an action. Is it a desire, belief of some sort, etc?</p>

<h3 id="world-to-mind">World-to-mind</h3>

<p>The question is whether deliberative endorsement is a world-to-mind fit (dispositional) or mind-to-world fit (representational). Good candidates for a representational analysis are counterfactual beliefs about an agent’s hypothetical attitudes under certain circumstances. Nevertheless, it seems that normative judgments and deliberative endorsement are best explained by a world-to-mind, dispositional fit. This best explains why people who judge that they have normative reason to X are disposed to X. If it was a mere mind-to-world state of mind (even if a counterfactual belief about one’s attitudes), then there would have to be some <em>additional</em> world-to-mind state of mind that explained why one’s deliberation influences their motivation, and <em>this</em> state of mind would be the core feature of normative judgments.</p>

<p>However, normative judgments are not best characterized as desires. It seems clear that normative judgments and desires can sometimes diverge. Goals and preferences seem to be a distinctive form of world-to-mind fit. And we can clearly understand how one might not have a desire to achieve one of their goals. It seems like the distinction between desires and goals are similar to the distinction between desires and values. It seems like we can distinguish different world-to-mind fits based on their relationship to consciousness (thoughts) and deliberation (thoughts about thoughts).</p>

<h2 id="rational-correctness">Rational Correctness</h2>

<p><a href="Rational%20Correctness.md">Main Page</a></p>

<h3 id="existence-internalist">Existence Internalist</h3>

<p>R is a normative reason for A to X iff R would be a motivating reason for A to X insofar as A is rational and A was aware of R. Thus, R is a reason for agent A if and only if R is the upshot of sound rational deliberation. In other wrods, normative reasons are the rational extensions of one’s motivating reasons. A consideration C counts as a reason if and only if there is a sound deliberative route from an agent’s motivational reasons to C.</p>

<p>The question is then how to account for what “rational extension” and “sound deliberative route” consists in. At the very least, this seems to require logical consistency. A constructivist account of normativity can explain what rational extension consists in generally.</p>

<h3 id="constructivist">Constructivist</h3>

<p>Truth for rationality is not correspondence. That is, the standard of correctness for a normative proposition is not an mind-independent entity or set of entities which the proposition is purported to correspond to. Rather, the standard of correctness is rules and requirements constructed by and internal to the agents who hold the proposition.</p>

<p>The fact that X is a reason to Y for agent A is constituted by the fact that the judgment that X is a reason to Y (for A) withstands scrutiny from the standpoint of A’s other judgments about reasons. Note that X is never a reason in favor of Y, absolutely. X can only be in favor of Y for some particular agent, as determined by the standards set by the normative judgments of A himself.</p>

<p>A normative judgment withstands scrutiny for an agent only if the agent could mantain the judgment in full awareness, which is determined by the constituitive standards of the attitude in question. For example, someone who judges that X is a reason to Y cannot also simultaneously and in full awareness judge that X is not a reason to Y (consistency is constitutive of normative judgments). Also, one cannot take oneself to have conclusive reason to Y without taking oneself to have reason to take the means to Y (means-end reasoning is constituitive of normative judgments). The force of <em>cannot</em> is not rational, but what is <em>constituitive</em> of the concept of forming normative judgments.</p>

<p>These standards of correctness are legislated by the very person making the normative judgments. This allows that one can be genuinely mistaken about their normative judgments only insofar as they are not in full awareness of certain relevant features of their judgments.</p>

<h3 id="constituitive-features">Constituitive Features</h3>

<p>The central question is how to determine what requirements are constitutive of a type of behavior. One candidate is this: a requirement is constituitive of a behavior if no agent could consciously reject the requirement in full awareness.</p>

<p>Logical Consistency. One basic constituitive feature of normative judgments (and thuoghts generally) is logical consistency. No person can consciously believe X and believe not-X in full awareness.</p>

<h4 id="epistemic">Epistemic</h4>

<ul>
  <li>Perceptions/memories: the reason that a perception that p provides one with reason to believe that p is because part of what it is to perceive p is to acquire an unreflective belief that p. If perceptions didn’t provide one with an unreflective belief that p, then perceiving that p would be like imagining that p, and this would not provide one with a reason to believe p. Similar considerations apply to memories.</li>
  <li>Abduction:</li>
  <li>Induction:</li>
  <li>Causation:</li>
</ul>

<h4 id="prudential">Prudential</h4>

<ul>
  <li>Desires: the reason that a desire to X tends to provide one with reason to X is (1) people tend to judge that they have reason to X if they desire to X, and (2) all intentional actions are done because of some desire; if they are not done because of a desire, then they would be involuntary actions.</li>
  <li>Instrumental Reasoning: one cannot take oneself to have conclusive reason to X without taking oneself to have reason to take the means to X. Part of what it is to judge one has a reason to X consists of judging one to have a reason to adopt the means.</li>
  <li>Pain/Suffering: the reason that pain/suffering provides one with reason to avoid it is precisely because people judge that they have reason to avoid it (or they have an unreflective aversion towards it). If a person had no aversion toward pain and didn’t judge that they had reason to avoid it, then there would be no actual reason to avoid it. It is not the pure sensation of pain that provides us with reason to avoid it.</li>
</ul>

<h3 id="competing-reasons">Competing reasons</h3>

<p>The most fundamental question is how to determine what one ought to do when there are some considerations that give one reason to X and some considerations that give one reason to not-X. This is especially important for moral considerations when weighing reasons from different agents.</p>

<h2 id="moral-psychology">Moral Psychology</h2>

<p><a href="Moral%20Psychology.md">Main Page</a></p>

<p>Two puzzles that must be resolved by a moral psychology and ontology (or standard of correctness)</p>

<p>Psychology</p>

<ol>
  <li>Moral judgments are truth-apt.</li>
  <li>Truth-apt judgments must be beliefs (i.e. descriptive).</li>
  <li>Moral judgments are intrinsically motivating.</li>
  <li>Beliefs are not sufficient for intrinsic motivation.</li>
</ol>

<p>Truth</p>

<ol>
  <li>Rational: Moral duties provide agents with reason for action.</li>
  <li>Categorical: Moral duties apply to all agents (some infer an independence of any agent’s desires).</li>
  <li>Internalism: Practical reasons are necessarily dependent on desires.</li>
  <li>Contingency: There are no necessary desires in all rational agents</li>
  <li>Success Theory: There are moral truths.</li>
</ol>

<h2 id="moral-reasons">Moral Reasons</h2>

<p><a href="Moral%20Reasons.md">Main Page</a></p>

<h3 id="aesthetic">Aesthetic</h3>

<h3 id="constructivist-1">Constructivist</h3>

<h3 id="objectivity">Objectivity</h3>

<h4 id="game-only-exists-in-certain-cultures">Game only exists in certain cultures</h4>

<p>This constructed morality “game” only exist in cultures where moral discussion involves providing reasons for all persons to follow. But this need not necessarily be the case in certain authoritarian/hierarchical societies where moral discussion is a vehicle for the powerful to issue non-negotiable and enforced commands rather than a cooperative, negotiative role. E.g. if there is a king commanding peasants to act in a certain way. There are no objective moral standards that the kind has to follow; the best one can hope for is to destroy their opponents and/or try to manipulate their emotions.</p>

<p>Did we really lose anything by being unable to say that they are unreasonable? We can still say that they are immoral, bad, evil, etc. So what have we lost? The only thing we’ve realize now is that they cannot be <em>rationally motivated</em> to be moral. But this would be the case even if there was an independent ontology of moral facts. Do we really think that if such a realm existed, we could <em>rationally motivate</em> all undesirable villians to behave. We have lost nothing.</p>

<h4 id="not-motivationally-necessary-constructivist">Not motivationally necessary (constructivist)</h4>

<h4 id="contingent-upon-our-interests-aesthetic">Contingent upon our interests (aesthetic)</h4>

<h4 id="not-rationally-necessary">Not rationally necessary</h4>

<p>One could say morality is not rationally necessary in the sense that one has no reason to be moral if they didn’t already have an interest in being moral. But a similar truth is found in other domains:</p>

<ul>
  <li>One has no reason to accept logic if they didn’t already accept it (this wouldn’t really be an agent to begin with).</li>
  <li>One has no reason to believe X if none of their perceptions indicated X.</li>
  <li>One has no reason to accept science if they had no interest in science.</li>
  <li>One has no reason to avoid pain if they had no interest in avoiding the sensation.</li>
</ul>

<p>Standards of moral correctness only matter for people who are interested in settling moral arguments for moral reasons. For people who are uninterested, no objective moral ontology would have mattered to them anyway. For those who are interested, a standard of correctness that’s internal to contingent moral desires is motivating enough.</p>

<h4 id="objective-methodology">Objective methodology</h4>

<p>The importance of objectivity does not require an independent realm of moral facts, nor does it require rational reason for all agents. The importance of objectviity was:</p>

<ul>
  <li>Normative thinking is a rational enterprise.</li>
  <li>Someone is incorrect in moral arguments.</li>
  <li>There is an independent standard to determine who is incorrect.</li>
</ul>


    </li>
  
    <li>
      <h2><a href="/2019/06/19/Moral-Reasons.html">Moral Reasons</a></h2>
      <p></p>
<p>Moral judgments are deeply tied to distinctly moral emotions and attitudes - blame and guilt. There are two ways that moral judgments are associated with these basic attitudes. Firstly, agents who make moral judgments directly express those attitudes, or a disposition to have those attitudes in certain situations. Secondly, agents who make moral judgments express a normative judgment that said attitudes are appropriate, i.e. they express their <em>endorsement</em> of those attitudes in certain situations. First, let us discuss the motivational implications of moral judgments. When an agent makes a moral judgment, (1) the agent is disposed to regulate his behavior as prescribed by the judgment, (2) he is disposed to feel guilt himself for violating the standard, and (3) he is disposed to blame others for violating the perscribed standard. Oftentimes, the agent thinks others are <em>capable</em> of being motivated to regulate their behavior in accord with the norm, i.e. they would be receptive to the reasons favoring the norm. E.g. while it might make sense for A to <em>dislike</em> B’s preference for ice crean, it doesn’t make sense for A to <em>disapprove</em> of B’s preference for ice cream, but it would make sense if B regarded A as his dietary adviser. This is true even when B’s actions might harm A. E.g. it doesn’t make sense for A to disapprove of B’s attack against him if B would be completely unreceptive (e.g. animal, child, evil person, aliens etc.), but it would make sense for someone who was receptive (i.e. normal rational agent).</p>

<p>??? example “Readings”
	Derek Parfit
		- <em>Reasons and Persons</em> (1984)
		- <em>On What Matters</em> (2011)
		- “Justifiability to Each Person” (2003)
		- look up his discussion on “Kantian Contractualism”
	Thomas Scanlon
		- <em>What We Owe to Each Other</em>
		- “Contractualism and What We Owe to Each Other”
		- “Contractualism and Utilitarianism”
		- <em>Moral Dimensions: Permissibility, Meaning, Blame</em>
	T. Pogge, “What We Can Reasonably Reject” (2001)
	R. Kumar, “Reasonable reasons in contractualist moral argument” (2003)
	- Gilbert Harman, “Moral Relativism Defended”
	- Philippa Foot, “Morality as a System of Hypothetical Imperatives”
	- Essay: Nick Zangwill, “Externalist Moral Motivation”
	- Essay: David Brink, “Externalist Moral Realism”
	- David Gauthier, <em>Morals By Agreement</em> (as in DGR)
	- Habermas,
	- Christine Kosgaard, “Kant’s Formulation of Universal Law”</p>

<p>??? question “Some questions”
	- Contractualism rejects that the only relevant consideration for moral reasoning is well-being. It includes anything that people have reason to care about. Some questions:
		1. Can this “cares” be reduced to a common good? It doesn’t seem like it. It obviously wouldn’t be well-being. Maybe something like goals.
		2. If yes, can we ignore referring to specific kinds of goals? Instead use a language that just refers to intrinsic goals generally without losing importance? Doesn’t seem like it. E.g. imagine an agent had two goals: to be entertained and to provide food for his children. It you characterize this just as goal X and goal Y, you seem to lose just how much more important Y is compared to X. 
		3. If yes, can goals be compared numerically? Harms of qualitative differences don’t seem comparable, e.g. physical versus emotional harm. Also, significant quantitative differences in harm don’t seem comparable on a linear scale, e.g. being tortured versus a pinch can’t be compared on some numerical scale such that N instances of a pinch matches 1 instance of torture. Some kinds of harms:
			- Sensation
				- Physical pain
				- Emotional pain
			- Liberty limitation
				- In ability, e.g. losing a limb, mobility, etc.
				- In opportunity, e.g. discrimination, oppression, etc.
	- Establishing a method for establishing moral truth.
	- How can we use conceptual analysis to determine the role of moral norms but not all norms
		-&gt; We can determine the role for norms, but not the role for attitudes.
		-&gt; As for rational <em>norms</em> (not the <em>attitudes</em>), we can discover them (i.e. instrumental rationality as constituitive), but we must give a non-reductive analysis (i.e. constructivism).</p>

<p>Some disputes:</p>

<p>Epistemology:</p>
<ol>
  <li>Moral truths can be determined by reason alone</li>
  <li>More truths can motivate intrinsically</li>
  <li>Reason alone cannot motivate intrinsically</li>
</ol>

<p>Normativity</p>
<ol>
  <li>All rational agents have reason to be moral</li>
  <li>Morality does not depend on any agent’s particular desires or interests</li>
  <li>Reasons for action depend on an agent’s particular desires or interests</li>
</ol>

<p>Personal/Interpersonal</p>
<ol>
  <li>All rational agents have reason to be moral</li>
  <li>Society has reason to socially coerce people into being moral</li>
  <li>What society has reason to coerce people to do =/= what individuals have reason to do</li>
</ol>

<p>Substantive vs Formal characterizations - what kind of reasons are moral reasons?</p>
<ol>
  <li>Formal characterizations
    <ul>
      <li>Moral reasons are reasons in general.</li>
      <li>Don’t seem to get at what morality is.</li>
      <li>Prudential reasons =&gt; Seem like a bribe, also not categorical</li>
      <li>Categorical reasons =&gt; Also seems like a bribe, seems inappropriate (e.g. rules of logic are not moral)</li>
    </ul>
  </li>
  <li>Substantive characterizations
    <ul>
      <li>Particular kinds of reasons</li>
      <li>Reasons toward a particular end</li>
      <li>We can still sensibly ask, Why be moral?</li>
    </ul>
  </li>
</ol>

<p>Thomas Scanlon distinctions on blame (from a YouTube series, similar to the one where he mentions the substantive vs formal characterizations above)</p>

<h2 id="moral-reasons">Moral Reasons</h2>

<p>Moral judgments are deeply tied to distinctly moral emotions and attitudes - blame and guilt. There are two ways that moral judgments are associated with these basic attitudes. Firstly, agents who make moral judgments directly express those attitudes, or a disposition to have those attitudes in certain situations. Secondly, agents who make moral judgments express a normative judgment that said attitudes are appropriate, i.e. they express their <em>endorsement</em> of those attitudes in certain situations. First, let us discuss the motivational implications of moral judgments. When an agent makes a moral judgment, (1) the agent is disposed to regulate his behavior as prescribed by the judgment, (2) he is disposed to feel guilt himself for violating the standard, and (3) he is disposed to blame others for violating the perscribed standard. Oftentimes, the agent thinks others are <em>capable</em> of being motivated to regulate their behavior in accord with the norm, i.e. they would be receptive to the reasons favoring the norm. E.g. while it might make sense for A to <em>dislike</em> B’s preference for ice crean, it doesn’t make sense for A to <em>disapprove</em> of B’s preference for ice cream, but it would make sense if B regarded A as his dietary adviser. This is true even when B’s actions might harm A. E.g. it doesn’t make sense for A to disapprove of B’s attack against him if B would be completely unreceptive (e.g. animal, child, evil person, aliens etc.), but it would make sense for someone who was receptive (i.e. normal rational agent).</p>

<p>Moreover, like all normative judgments, moral judgments are also judgments about when certain attitudes are appropriate. That is, they express an agent’s endorsement of blame and guilt in certain situations. They state which attitudes agents ought to adopt. And like all ought-statements, these ought claims are to be explained by the <em>reasons</em> agents have for acting as such. So morality consists of a system of moral reasons, and agents who act immorally are not receptive to the moral reasons that apply to them. The task is to characterize what is distinctive of moral reasons, explaining how they differ from normative reasons in general and (possibly) how they differ from practical reasons in general. To judge that an action X is morally wrong implies some variation of the following ought claims: (1) agents ought not to intend X, (2) agents ought to feel guilt for intending X, and (3) an agent does who X would be blameworthy if they were responsible for doing X (i.e. there were no extenuating circumstances that excuse their behavior). Someone who invokes any of these ought-claims judges that there are reasons explaining why agents ought to act as claimed.</p>

<p>These features can be exposed by considering the implicit commitments of moral judgments. Consider an implicit commitment of <em>assertions</em>: if someone says “X is P”, we would expect that they believe X is P, even though this belief does not actually <em>logically</em> follow from their asserted proposition (nor is it an <em>analytic implication</em>, s.t. if A believes “X is P” we can deduce that they also believe that they believe “X is P”). If someone said “X is P, but I don’t believe X is P”, we would have a difficult time interpreting the mental state of this person, even though they have expressed a proposition with coherent truth conditions. We can say that <em>beliefs</em> are implications of <em>assertions</em>. Likewise, if someone says “X is wrong”, we would expect that others have reason to refrain from doing X, even though this normative judgment does not actually follow from what they said. If someone said “X is wrong, but I don’t judge that anyone ought to refrain from X”, we would have a difficult time interpreting his mental state. Thus, we can say <em>reasons</em> judgments are implications of <em>moral</em> judgments. Similar remarks apply to how moral/normative judgments imply non-cognitive attitudes.</p>

<p>Features (2) and (3) are necessary for any normative domain in any culture in order for it to qualify as a moral system. A hypothetical normative system in a hypothetical culture that did not make claims about the appropriateness of moral emotions would not count as a moral system. If someone made a judgment that only involved (1), this would seem more akin to a pure prudential or rational judgment, as opposed to a moral judgment. It also seems that (1) must also be necessary in any conceivable society’s morality. It does not seem sensible for someone to genuinely endorse shaming a certain behavior and endorse feeling guilt for performing that behavior, while simultaneously not prescribing agents to not perform the action. In fact, that seems to be what it is to shame a certain behavior, i.e. that you prescribe others to not do it. Therefore, if you endorse shaming a certain behavior, then you endorse prescribing others not to do it.</p>

<h3 id="blame-and-relationships">Blame and Relationships</h3>

<p>To understand what it is to judge that an action/person is <em>blameworthy</em> (i.e. the appropriate object of blame), we need to understand what constitutes the attitude of blame. There are two (not necessarily conflicting) characterizations of the attitude of blame. Firstly, (1) to blame someone is just to make the the evaluative <em>judgment</em> that he has done something wrong. This can be seen as a sober assessment of someone’s character. It is a grading of their sets of intentions, desires, goals, etc. against some preferred standard. Insofar an agent’s behavior falls short of that standard, we judge their actions to be morally wrong and thus blame them. Secondly, (2) to blame someone is to adopt more of a functional, dispositional or motivational role and is more akin to an emotion. Blaming someone involves several other non-cognitive attitudes. To blame someone is to hold some sort of disapproving attitude with regard to that person, i.e. it is to be adopt the attitude of anger, resentment, disgust, shame, hatred, etc. Blaming someone in this sense can be seen as a social tool to serve as a sanction that motivates others to behave in accordance with an individual’s preferred standard. It plays the role of modifying the attitudes of others, of both the person being blamed and other individuals in society.</p>

<p>While these attitudes are commonly invoked when one engages in blaming someone, there is a more important aspect of blaming that is neither an evaluative judgment nor a social saction. To blame someone also involves a modification of one’s attitudes about the person. In particular, when A blames B for an action A judges that his relationship with B has been impaired in some way due to B’s actions. A judges that B violated certain expectations that were supposed to govern his actions by virtue of being in that relationship. It suggests that some reconciliation is needed by B to mend the relationship, if that is even possible. Because blame involves more than the judgment that someone or an action is wrong, it is possible to judge an action to be wrong without blaming them. This can happen (1) when an action is wrong but is not seen as bad enough to warrant a revision of attitudes. But it also occurs (2) when someone does something that <em>would</em> violate a standard of a relationship if such one existed but such a relationship does not exist (thus they never violating any expectations).</p>

<p>When (2) this happens and the agent can potentially be in relationships with others, we can still judge their actions to be <em>blameworthy</em> (without actually blaming them), because we understand that it would be appropriate to someone to blame them if they were in the appropriate relationship. But when it happens to someone that we see as incapable of being in such relationships (i.e. completely cut off from our moral community, e.g. animals, aliens, sociopaths, enemies in war, etc. or people who are incapable of living up to such expectations, e.g. children, mentally disabled, etc.), we neither blame them nor judge them blameworthy. Similar remarks can be made about disapproval in general. If someone does not belong to our moral community, it does not make sense to <em>disapprove</em> of their actions. It makes sense to <em>dislike</em> their actions, but disapproval implies that they are receptive to our complaints in some way, i.e. that we stand in a certain relationship with them.</p>

<p>This analysis of blame can account for many of the features of the standards for other kinds of interpersonal relationships we form. E.g. when two people are in a friendship, there are certain expectations and restrictions on how they behave that would not exist if it were not for the relationship. It is expected that one’s friends will be loyal, trustworthy, helpful, interested in their well-being, etc. When someone does something that violates these standards, their behavior can be said to be wrong <em>from a friendship perspective</em>. However, this would not suffice to blame a person for this behavior, e.g. if a stranger did some of these things (e.g. failed to be loyal to you), you would not <em>blame</em> him because you had no <em>expectation</em> that he would do so (though you might judge him <em>blameworthy</em>, i.e. that an person in the appropriate circumstances has reason to revise their attitudes regarding the person). Blame for being wrong in this way is only appropriate when one is expected to be a good friend; you would revise your attitudes with regard to that person because they have impaired the relationship, e.g. you would no longer trust them, confide in them, become less interested in their interests, etc. which is to stop treating them as a friend. Similar remarks can be said about romantic relationships, ettiquette, etc.</p>

<p>All relationships can be defined as a system of expected attitudes and dispositions which specify standards for any person within that relationship. Moral wrongness is based on the standards of a <em>moral relationship</em>. This is a general kind of relationship that consists of expectations that others’ behavior will be constrained by mutual recognition and respect, rather than specific expectations of other more “optional” relationships (e.g. loyalty, love, faithfulness, etc.). The nature of this relationship is characterized by common reasons that we all recognize <em>as reasons</em>. The nature of these reasons is spelled by the contractualist formula. We only blame someone when we expected them to be in this relationship. This expectation is a “default” expectation that is only withdrawn in particular cases, e.g. children, mentally disabled, sociopaths, enemies in war, etc. Just as you wouldn’t blame a non-friend for being unfriendly to you, you wouldn’t blame an irredeemably moral non-participant person for being immoral to you. This is not to say that we wouldn’t be justified in being unfriendly, untrustworthy or combative against those people. However, this wouldn’t be a <em>revision</em> (because we were never friendly, trustworthy, etc. to begin with).</p>

<p>This analysis also determines when blame is appropriate. Blame is appropriate when we have reason to judge that a relationship has been impaired or to revise our attitudes with regard to a person in light of violated expectations. Likewise, judgments of blameworthiness are appropriate when we have reason to believe that anyone in the appropriate relationship would have reason to revise their attitudes as such. Note that this kind of reason is distinct from other consequentualistic kinds of reasons for blaming someone, i.e. the positive benefits of blaming someone (e.g. someone who did an action accidentally or because of non-culpable ignorance, while possibly beneficial to blame - e.g. if people were motivated to be more careful, more informed after seeing this blame - would not actually be blameworthy). While these may be reasons to blame someone, these are secondary reasons (i.e. the “Wrong” kind of reason). The primary reason to blame someone lies in our reason to revise our attitudes. Note also that <em>this</em> reason (to revise our attitudes) is also evaluative in nature rather than consequentialist. E.g. if one of the expectations of a relationship is trustworthiness, and someone in the relationship reveals that they are no longer trustworthy because they are dishonest, then this provides the primary reason to revise our attitudes with this person (by no longer trusting them), regardless of the benefits of this revision.</p>

<p>This analysis of blame also makes blame appropriate even in a deterministic world. There are two senses in which this is true: (1) in the secondary sense of “reasons” for blame which are based on consequences: we have reason to establish norms for blame if it produces good consequences, independent of their free will, and (2) in the primary sense of “reasons” for blame: we have reason to blame someone if someone has impaired a relationship that calls for revising our attitudes of that person. This impairment can occur independent of the consequences of blaming them and also independent of that person’s free will. Thus, the revision of our attitudes can be appropriate independently of their free will. For example, it is appropriate to be suspiscous of someone who is untrustworthy, defensive to someone who is insulting, etc. independent of their free will. Likewise, it is appropriate to revise our attitudes towards suspiscion or defensiveness toward someone insofar as they reveal themselves to be untrustworthy or abusive, independent of their free will. If this relevation violates an expected standard of a relationship, then this is enough to justify blaming them.</p>

<p>Ordinarily, these standards apply to an individual only if a person agrees to the standards of the relationship, e.g. friendship, romantic, etc. But are there some that are not optional, e.g. being a parent to one’s offspring, moral relationships, etc.</p>

<p>Ordinarily, when people fail to meet the standards of a relationship, we do not adopt the attitudes that constitutute the relationship (e.g. bad friends are not treated like friends anymore). Does the same apply to the moral relationship, e.g. murderers/rapists get no moral consideration.</p>

<p>The task, now, is to specify the moral relationship that we take ourselves to stand in relation to for every other person. See below.</p>

<h3 id="possibilities">Possibilities</h3>

<p>How to get to various moral theories</p>
<ul>
  <li>Rationality = Teleological =&gt; Consequentialism
    <ul>
      <li>Morality = Rationality =&gt;
        <ul>
          <li>Rationality = Self Interest =&gt; Egoistic Consequentialism</li>
          <li>Rationality = Impartial =&gt; ~Impartial Consequentialism (e.g. Smith)</li>
        </ul>
      </li>
      <li>Morality = Impartiality =&gt; Impartial Consequentialism (e.g. Railton); strip away indexical reasons. Seems like because morality is built off of rationality, then if rationality is consequentialist then so must morality.</li>
    </ul>
  </li>
  <li>Rationality = Deontological =&gt;
    <ul>
      <li>Morality = Rationality =&gt; Deontology</li>
      <li>Morality = Impartiality; strip away indexical reasons. Are the remaining reasons consequentialist? Do they respect the seperateness of persons?
        <ul>
          <li>Moral Reasons = Consequentialist Reasons =&gt; Consequentialism</li>
          <li>Moral Reasons = Some Deontological Reasons =&gt;
            <ul>
              <li>Seperateness of Persons =&gt; Deontology</li>
              <li>Not Seperateness of Persons =&gt; Impartial Consequentialism, ???</li>
            </ul>
          </li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<ol>
  <li>Standard Personal reasons - I satisfy my interests
    <ul>
      <li>Not a moral theory. Doesn’t specify rules for everyone.</li>
    </ul>
  </li>
  <li>Speaker-personal reasons - everyone satisfy my interests
    <ul>
      <li>Indexical, so not a moral theory.</li>
      <li>While not inconsistent, really doesn’t make sense. It violates a constraint implicit in normative judgments, that others have reason to accept your principle. E.g. “You are morally forbidden from stealing from me when it benefits you, but I am morally permitted to do so when it benefits me”. Strictly speaking, it is not a contradiction, but it does seem weird (like saying “X is true but I don’t believe X”). 
====&gt; Below here are substantive questions. The above don’t qualify as moral theories. They don’t fulfill the role that moral discourse plays.</li>
    </ul>
  </li>
  <li>Interpersonal reasons - everyone satisfy their interests
    <ul>
      <li>While not inconsistent, violates the <em>interpersonal</em> nature of moral judgments, i.e. that others make interpersonal demands on the actions of others (and that we are sometimes answerable the demands of others).</li>
    </ul>
  </li>
  <li>Impartial interpersonal reasons - everyone satisfy everyone’s interests
    <ul>
      <li>Seems like there are sometimes cases where we can favor our own interests over others.</li>
    </ul>
  </li>
  <li>Reasons for action versus reasons for blame/shame</li>
</ol>

<p>Private vs Public reasons</p>
<ul>
  <li>See here: https://plato.stanford.edu/entries/reasons-agent/#RelDis</li>
  <li>Agent-relative vs agent-neutral</li>
  <li>Internal vs External:
    <ul>
      <li>Internalism -&gt; AR</li>
      <li>Externalism -&gt; AR/AN</li>
    </ul>
  </li>
  <li>Intersubjective vs Non-intersubjective (reasons A has s.t. we can communicate this to A)</li>
  <li>Essentially-shared/Not-essentially-shared (reasons we all have)</li>
</ul>

<p>The first feature (1) makes a claim about the reasons that individual agents have. It is the “agents ought not X” or “agents have reason to not do X” related to one’s judgment that X is immoral. This can be be most easily seen in cultures where <em>discussion</em> and <em>argument</em> play a key role in moral reasoning and communication. Moral argument involves an intention to motivate changes in the attitudes of other agents. We prescribe others to adopt other attitudes, whether these be intentions, dispositions of moral approval/disapproval, anger, guilt, etc. However, what is particular about moral <em>argument</em> is that we don’t seem to be interested in <em>merely</em> motivating such changes. Mere motivation can be achieved with emotional manipulation, rhetorical tricks, threats, force, etc. We seem to be trying to <em>rationally</em> motivate a change in attitudes, i.e. we want to expose to them a reason that they have which they were not receptive to. In fact, it is difficult to imagine a society where moral judgments don’t play this same role; surely, someone who believed that X is wrong would believe that other agents had <em>reasons</em> to not perform the action. It would seem incoherent for this to not be the case. One moral system that focuses on this aspect of the normativity of moral judgments is ethical egoism.</p>

<p>The third feature (3) makes a claim about the reasons from an <em>interpersonal</em> perspective rather than an individual or personal perspective. It is the “<em>others</em> have reason to blame, disapprove or otherwise prohibit for X-ing” related to a judgment that X is immoral. Unlike personal reasons, interpersonal reasons often involve more than one agent. The question is whether there are grounds for one person (i.e. the judge) to disapprove of another person (i.e. the actor). One way of characterizing interpersonal reasons is by appealing to the personal reasons of society collectively. “Collectively” here must refer to some way of encapsulating the interests of people in general without merely reducing to the interests of <em>everyone</em> (e.g. perhaps by looking at the interests of most people, by aggregating everyone’s interests, etc.). There are two explanations for why we can’t do that: firstly, if we sought agent-neutral principles (e.g. “all agents ought to X”, where X makes no reference to some feature of the acting agent), it doesn’t seem that there are any behaviors that would satisfy the personal reasons of <em>everyone</em>; and, secondly, if we sought agent-relative principles (e.g. “all agents ought to X”, where X does no specific reference to some feature of the acting agent), then it would just reduce to (1). So these principles must be receptive to some encapsulated summary of the interests of all agents in society. This is the <em>impartial</em> or <em>interpersonal</em> feature of morality. One example of a moral system that focuses on the collective aspect of the normativity of moral judgments is utilitarianism (where the encapsulation function is an aggregation over the well-being of all involved creatures).</p>

<p>The problem is that both of these features of moral judgments have detestable consequences if considered on their own. The first feature (1) only appeals to <em>personal</em> reasons, i.e. goal-oriented, desire-based, prudential, etc. reasons. The issue is these reasons don’t seem to give the interests of others any intrinsic weight. One’s goal-oriented or prudential reasons can be in principle wholly independent of the interests of others. One would be morally obligated to take into account the interest of others only if they (a) happened to care about the interests of others intrinsically, or (b) doing so would promote their other intrinsic interests. This does seem to miss the force of moral judgments. It also implies that individuals can have incompatible moral obligations, which seems wrong. On the other hand, focusing on what is reasonable from the interpersonal perspective seems to risk subjugating the individual to the demands of the collective. Because it focuses on an encapsulation of everyone’s reasons, thus eliminating the seperateness of persons, it seems to allow for some principles to be moral even though they might grossly violate the rights of particular agents as a means to maximize the collective.</p>

<p>The solution is to somehow strike a balance between the two features. The problem is that these two considerations pull in opposing directions. One way of doing this is to focus on individual personal reasons combined with some additional constraint that indirectly includes the interests of other agents. For example, you could consider the individual personal reasons a person has for selecting certain principles to govern society, while ignorant of their particular features in the society (Rawls). They would be placed behind a veil of ignorance where they don’t know what their race, gender, wealth, talent, etc. will be in society. In this circumstance, an individual would have personal reason to consider the interests of everyone because (for all they know) they might be in any of those positions. Another might be to consider the individual personal reasons a person has for selecting a principle, assuming everyone followed that principle (Contractarianism, Gauthier, etc.). This can handle cases where everyone has individual reason to X over Y, but if everyone collectively did X over Y, then everyone would be severely worse-off than if everyone did Y (prisoner’s dilemma). Kant is concerned with what you could rationally will <em>to be a universal law</em> which all other agents would follow. Other similar strategies include Habermas, Hare, etc.</p>

<p>??? question “Other interpretations of impartiality”
	Impartiality: Moral reasons can be distinguished from practical reasons in that the moral reasons are reasons for action with some impartiality constraint (e.g. science = interpsonal reasons for belief). Possible conceptions of moral norms
	- Individual practical reasons that everyone individual has.
		- Korsgaard: Valuing anything requires valuing the capacity to value.
		- Denial of Metaphysical Egoism: There is no valid distinction to make between different individuals.
	- Aggregation
		- Reasons that follow after considering everyone’s individual goodness. 
		- Maximizing the total utility of everyone (e.g. utilitarianism).
		- Technical problem with aggregate
			- The idea of there being a numerical assessment of well-being is dubious. What would the numbers mean?
		- Intuitive problems with aggregation
			- If we must choose between causing one person extreme harm and N people minor harm, then it the size of N doesn’t matter.
			- If we must choose between causing one person harm and N people comparable harm, then it the size of N does matter.
			- If we must choose between causing one person extreme harm and N people serious but not as extreme harm (e.g. paralysis versus loss of limb), then does the size of N matter? There may be no determinate answer to cases like this.
	- Veil of Ignorance
		- Personal reasons a person has under the veil of ignorance.
	- Contractualist:
		- Norms no one could reasonably reject as a basis for unenforced, informed cooperation given that one has such a desire.
		- This does suggest that all agents should be treated as ends in themselves? (maybe not as strong as in the Kantian sense). If agents are not ends, then why does it matter if they can reasonably reject a principle?
	- Universalization:
		- Maxims that A can rationally willed to be a maxim followed by agents. This requires:
			- It be conceivable for the maxim to be universalizable, and
			- It be possible for someone to rationally will the maxim to be universalizable. E.g. Kant says (1) for any agent A, A’s ends sometimes require help, (2) if all agents adopted a maxim whereby they never helped anyone, then this would frustrate A’s end, therefore (3) A cannot rationally will a maxim that prescribe agents to never help.
		- Necessary but not sufficient.
			- Provides some formal constraints on possible maxims.
			- May need to be supplanted (e.g. with Contractualism) to account for immoral ends which are conceivable and rational.
		- Cannot account for moral actions that are inconceivable as universal laws
			- e.g. Donate to charity more than the average
		- Cannot account for immoral actions that are conceivable/rational as universal laws
			- e.g. Ritualized bullying for newcomers.
		- Too stringent, e.g. Never Lie
		- Non-rational creatures have no moral consideration
	- Kantian Contractualism (from Parfit)
		- Everyone ought to follow the principles whose universal acceptance everyone could rationally will.
		- “An act is wrong unless such acts are permitted by some principle whose universal acceptance everyone could rationally will”
		- Different from standard Kantianism which says “follow principles whose universal acceptance YOU could rationally will.”</p>

<h3 id="contractualism">Contractualism</h3>

<p>The problem is that these strategies focus on reasons as such or rationality as such, and then try to indirectly draw a path toward moral reasons by incorporating non-moral considerations. It is true that morality is concerned with these impartial considerations. However, moral reasons cannot be reduced to non-moral reasons in some strange situations where agents have incentive to weigh the interests of others. Instead, moral reasons have to be identified by a particular <em>aim</em> that agents have, namely a <em>moral</em> aim. Some agents do not have the aim of being moral. Such positions also eliminate the separateness of persons.</p>

<p>The other theories may be useful in that their conclusions may overlap with actual moral reasons, and considering their scenarios may fuel moral motivation. But (1) this overlap is only approximate. These theories can do a very good job at excluding morally irrelevant considerations from our reasoning (i.e. those that focus on an agent’s particular situation). However, the considerations that remain (i.e. our personal self-interest) may not be genuinely moral reasons. The strategy of excluding morally irrelevant features needs to go further into we focus precisely on the uniquely moral source of our reasoning. And (2) the motivation from considering these scenarios only makes sense <em>because</em> of a prior <em>direct</em> interest in moral reasons. If we did not have this <em>direct</em> interest, then the above scenarios would have no motivational force. To illuminate the nature of morality, we need to <em>directly</em> find the interest that characterizes moral agents.</p>

<p>The aim is a <em>contractualist</em> characterization of moral reasons that focuses on <em>intersubjective justifiability</em>. We are aiming to find principles for regulating behavior that can be justified to others. But not principles that can be justified to <em>everyone</em>. In particular, we are seeking principles that can be justified to everyone <em>who also has the aim</em> of seeking such principles (i.e. everyone with the aim of seeking principles that could be justified to others). This satisfies the force of both (1) and (3). (1) is satisfied because we appeal to the personal reasons of certain agents, namely <em>moral</em> agents, i.e. agents with the aim of finding principles with intersubjective justifiability. In fact, this interest is an implicit assumption in moral arguments; it wouldn’t make sense for someone to engage in a moral discussion if they had no interest in justifying themselves to others. It also satisfies the force of (3) because does not <em>just</em> depend on an individual’s personal reasons. It addresses the interests of society at large, particular those members of society with an interest in intersubjective justifability. This also avoids the downsides of focusing solely on either of the two features. It avoids the downside of (1) because it doesn’t focus on reasons <em>as such</em> but rather the reasons that relate to a particular <em>moral</em> aim. It also avoids the downsides of (3) because it is concerned with what is reasonable from the perspective of <em>each individual</em> with that aim.</p>

<p>This characterization is only true for the moral system of societies where <em>argument</em> and <em>discussion</em> play a key role in moral reasoning, i.e. any society where <em>reasons</em> are posited to explain why agents ought to follow moral duties. As stated earlier, this seems like it would cover any society that has anything resembling a moral system. However, conceivably there could be a moral system that didn’t involve judgments about what individuals ought to do (lacking feature (1) above), and just had a standard for shaming the behavior of people. It is difficult to imagine how this would work with rational creatures who have the capacity to ask <em>why</em> they are commanded to perform certain actions (surely, <em>reasons</em> would have to be provided?).</p>

<p>Note that these standards are not motivating for (even ideal versions of) all individuals/societies, particularly those individuals/societies that don’t use discussion/argument/reasons (rather than rhetoric, emotions, threats, force, divinity, etc.) as a means to persuading others to adopt certain moral norms. Such norms would still be applicable to these parties (i.e. we could still call them morally wrong), but they could never appreciate these standards, nor would they have any personal reason to do so. This makes sense. We find that we really don’t think people are <em>irrational</em> per se when they are immoral, i.e. we probably wouldn’t acuse Hitler, psychopaths, war enemies, etc. of being irrational when they do something we find immoral. And we don’t even acuse them of being irrational for believing that they’re morally justified (assuming their judgments are consistent with the judgments of their idealized selves). We acuse them of being irrational when they try to justify their actions to us in moral <em>argument</em> and <em>discussion</em>.</p>

<h2 id="content">Content</h2>

<p>The task is now to determine the substance or content of this characterization of moral reasons. We need to address some variation of the following questions:</p>

<ol>
  <li>Which intentions are morally wrong?</li>
  <li>Which considerations are relavent when deliberating what is morally wrong?</li>
  <li>How ought one deliberate about what is morally wrong?</li>
</ol>

<p>??? questions “Questions”
	1. What is the object of inquiry? Idealized standards for behavior or idealized standards of societal (dis)approval?
	2. How to distinguish between the content of morality and ideal law? The former concerned with societal disapproval and the latter concerned with coercion.
	3. How to ground an account of wrongness and appropriateness of societal disapproval that does not just reduce to the benefits of societal disapproval? What’s the relation between what makes something appropriate to disapprove (as an assessment of historical behavior) and having reason to blame it (as a tool for promoting benefits)? Which is prior?</p>

<p>This deals with the level of analysis between the meaning of normativity and substantive moral theories. It deals with the nature and motivational force of <em>moral</em> reasons, i.e. their relation to normativity generally. Moral principles are principles that could be justified to everyone with the aim of finding such principles. In other words, these are principles that could be justified to everyone in group G, where group G is defined as the group interested in principles that can be justified to everyone in G. There are possibly objective standards of correctness for this form of moral judgments, as there is a fixed goal to which there are objectively (in)correct means for satisfying it. The standards of intersubjective justifiability extends beyond morality in the narrow sense of moral rightness and wrongness (e.g. it also sets standards of corrctness for ettiquette and justice).</p>

<p>Moral discussion concerns what <em>norms</em> to accept in society. Particular actions are assessed secondarily based on their conformity with those norms. This allows for some rule-consequential reasoning about the justification of norms, which is not possible when focusing strictly on actions. This is not to say that all justifications must be rule-consequentialist. There might also be deontological justification of certain rules. Note that the concern here is primarily on when certain actions are justified. These are standards for <em>actions</em>, as opposed to standards for particular moral emotions, such as blame. The standards for these moral emotions are given below.</p>

<h3 id="relevant-considerations">Relevant Considerations</h3>

<p>The <em>justification</em> of a norm is not based on it being reasonable to any <em>particular</em> agent. Thus, a moral system is <em>completely</em> unsupported if its justification reduces to “<em>I</em> just prefer this system” (e.g. even a system with impartial <em>content</em> like utilitarianism must be shown to be reasonable to all parties involved if it is to be <em>justified</em>; it is a substantive question whether this can be done). Norms are justified because they can be reasonable from the “moral point of view”, i.e. reasonable from the perspective of an agent with the aim of finding principles with intersubjective justifiability. The structural nature of reasons allow for there to be reasons to discount the relevance of other considerations that would serve as reasons in other contexts. When considering the reasons that constitute the moral perspective, there are some constraints on the relevance of certain principles for moral reasoning:</p>

<ul>
  <li>Personal Reasons: only personal reasons can be reasons to reject a principle. Personal reasons relate to well-being, desires, goals, freedom, etc. They do not include impersonal reasons (e.g. someone who has a concern for the environment) or interpersonal reasons (e.g. someone who has a concern with the interests of others).</li>
  <li>Impartiality: considerations that are indexical can be dismissed. This places an impartiality constraint on moral reasons in three ways: (1) the content - the nature of the duty, (2) the application - who the duty applies to, and (3) the justification of moral norms must not make reference to any proper nouns. E.g. (1) there can be no duties that say “benefit person A”.  (2) there can be no duties that vary depending on who someone happens to be (it depends on their circumstances). (3) that A in particular is harmed is not a reason against a principle if all alternative principles would result in a comparable or worse harm for others.</li>
  <li>Degenerate Interests: Interests that either (a) neglect the interests of others or (2) are based upon a desire for the harm of others can be dismissed.</li>
  <li>Responsibility: Harm to those who are responsible is more justifiable tham harm to those who are irresponsible. E.g. if a principle would impose a burden on people by virtue of negligence, poor intentions, etc.</li>
  <li>Aggregation: aggregation in itself doesn’t matter. See T.M. Scanlon</li>
  <li>Hard question: how to handle norms that harm some and help others.</li>
</ul>

<p>Note that principles must be reasonable not to agents in some veil of ignorance, but rather to agents in the actual world. Behind a veil of ignorance, it might be reasonable for all to accept a princple that resulted in a state where well-being was 80 and 60 instead of 100 and 40 (imagine there are two people, A and B). However, in the actual world, if A=100 and B=40, it would be reasonable for A to reject a principle where force was used that resulted in A=60 and B=80, even though this end state is superior.</p>

<p>One question is whether contractualism is committed to solely consequentialist reasons. A consequentualist method of justification first specifies a ranking of ideal states of affairs and then assess actions as right or wrong based on that ranking. Personal reasons would be consequentialist insofar as they are reasons for promoting some end state of affairs. But clearly contractualism is not committed to saying people only have these kinds of reasons. Contractualism allows that people can have reason to hold certain attitudes, attitudes which may be distinct from promoting some good with a positive weight which competes with other goods. However, even if we accept non-consequentialism for personal reasons. We might be consequentialist for moral reasons if we abandon the seperateness of persons. Contractualism is not committed to this either. There is no end state of affairs that is most desirable that we are trying to reach. The procedures matter for their own sake. Principles can be wrong if they permit wrong actions, even if that principle results in a better state of affairs. We do not lose the separateness of persons.</p>

<p>These distinctions are similar to consequentialist systems which distinguish between ideal behaviors and decision theories. E.g. Even act-consequentialist say that it is a theory about what conditions makes actions <em>right</em> or <em>wrong</em>. This is distinct from whether those conditions should be taken into account for any particular agent when deciding what to do (e.g. if it is infeasible for an individual to weigh the consequences in any particular circumstances.</p>
<ul>
  <li>So there are three levels of analysis for act-consequentialists: (1) the best state of affairs, (2) right/wrong actions, and (3) decisions about what we ought to do.</li>
  <li>Rules consequentialism for norms for <em>behavior</em> has the following levels of analysis: (1) the best state of affairs, (2) good/bad norms for behavior, (3) right/wrong actions - based on their adherence to the norms, (4) decisions about what we ought to do - probably just refers back to the norms.</li>
  <li>Rule consequentialism for norms of <em>moral emotions</em> has the following levels: (1) the best state of affairs, (2) good/bad norms for moral emotions, (3) right/wrong actions - whether it’s the appropriate object of blame given the norms, (4) decisions about whether we ought to blame - probably just refers back to the norm.</li>
  <li>The contractualist analysis: (1) right/wrong actions - just depends on intersubjective justifiability, (2) good/bad norms for moral emotions - depends on whether it promotes/diminishes undesirable behavior.</li>
</ul>

<h3 id="comparison-with-veil-of-ignorance-style-characterizations">Comparison with Veil of Ignorance style characterizations</h3>

<p>Two differences:</p>
<ul>
  <li>Veil of ignorance is concerned with rationality. Contractualism concerned with what is reasonable - i.e. what is reasonable contingent on the aim of finding principles that can be justified to others who are similarly motivated.</li>
  <li>Veil of ignorance strips people of knowledge of their particular features. Contractualism does not?</li>
</ul>

<p>Possibilities:</p>
<ul>
  <li>Rationality + awareness of particular features: this can’t work because people would be biased towards irrelevant features.</li>
  <li>Rationality + ignorance: Veil of ignorance. This is has bad implications because:
    <ul>
      <li>It strips away certain irrelevant features. But by only focusing on rationality simpliciter, it still includes some irrelevant features.</li>
      <li>It only looks at the end distribution of well-being, ignoring the particular individuals who earned/deserve it.</li>
      <li>If there is a fixed distribution of pleasure/pain to be distributed, it wouldn’t matter whether the larger bundles went to people who deserved/earned/virtuous it versus whether it went to the people who don’t deserve it or the vicious.</li>
      <li>Degenerate interests are given just as much weight as everyone else.</li>
      <li>It doesn’t care about whether people are personally responsible for their diminished well-being. E.g. someone who has diminished well-being because they are lazy.</li>
    </ul>
  </li>
  <li>Reasonableness + awareness: ???</li>
  <li>Reasonableness + ignorance: ???</li>
</ul>

<h2 id="extensions-of-other-systems">Extensions of other systems</h2>

<h3 id="constructed-normative-domains">Constructed normative domains</h3>

<p>Imagine social games with their own personal rules.
We can use those rules as standards of criticism without rationally criticizing an agent.</p>

<p>Or consider the constructed standards of relationships</p>
<ul>
  <li>To stand in a certain relation to someone (e.g. friend, lover, partner, cooperator, self-respecting individuals, etc.) has certain expectations for behavior by the parties involved. To the extent that someone violates these expectations, it is appropriate to not extend those behaviors to them, since they would now stand outside of the relationship.</li>
  <li>This might work for friends and ettiquette (i.e. to the extent that someone doesn’t uphold the standards of good friendship, ettiquette, it is appropriate to not treat them as a friend, or with ettiquette). Maybe it also works for aesthetic morality. But maybe this doesn’t work for forceful morality (maybe if someone is immoral, we still have moral obligations towards them, i.e. we can exclude them from society, but we cannot kill them).</li>
</ul>

<p>Other constructed normative domains</p>
<ul>
  <li>Prudential Rationality: there are no independent standards for bodily movements. But insofar as one is deliberative and reflective and evaluates their own actions, i.e. one is a rational agent, there are standards for behavior.</li>
  <li>Games: there are no independent standards for moving small pieces across a checkered board. But insofar as one is playing chess, there are constituitive standards of the activity that entail standards of correctness.</li>
  <li>Relationships: there are no independent standards of kindness, respect, loyalty, etc. with regard to how to treat others. But insofar as one is being a friend, partner or other normatively-laden relationships, there are constituitive standards of the activity that entail standards of behavior.</li>
  <li>Communication: there are no independent standards of speaking or language. But insofar as one is communicating as a means to transfer ideas to someone else, there are standards of correctness.</li>
  <li>Conversation: To engage in a <em>discussion</em> or <em>conversation</em> with someone, one implies that they will listen to the other party, not cut them off, etc. even though there may be no independent reason to do thees things.</li>
  <li>Negotiation: To engage in a <em>negotiation</em> implies that people are willing to sacrifice or deviate from their most preferred plan to help satisfy the interests of others. Now, one might have no reason to do these things (i.e. if they had full power), but then they wouldn’t be negotiating. They would be bad negotiators.</li>
  <li>Morality: there are no independent standards of behavior. But insofar as one is engaged in moral argument as a procedure for finding <em>impartial reasons</em>, or reasons that all can accept, there are constituitive standards of correctness.</li>
</ul>

<p>Communicative constraints regarding reasons for belief and/or conversations/arguments generally.</p>
<ul>
  <li>Burden of proof depends on the speaker who asserts a claim, not on the mere content of the proposition. That someone asserts a claim has a burden of proof cannot be entailed from the content of the propositions expressed. When Mike says “God Exists”, it follows that he has reason to follow the rule, even though this reason is not trivially included in the rational extension of his motivational set for beliefs.</li>
  <li>Even though an anecdotal experience might provide one with a personal reason for belief, it would not provide everyone with a reason for belief (e.g. a scientific reason).</li>
  <li>How to know what the standards are? We check what would happen if everyone accepted it. If no one accepted a burden of proof, the central goal of argument would be defeated.</li>
  <li>Don’t interrupt others, cut them off, etc. Listen to them.</li>
</ul>

<h3 id="intersubjective-justification">Intersubjective Justification</h3>

<p>Many normative domains are concerned with what can be justified to different agents, not any individual agent. E.g.</p>

<ul>
  <li>Personal experience / intuition / presuppositions might provide an individual agent with reasons for believe. But they cannot independently provide anyone else with a reason for belief (unless the other agent believes the other person’s experience/intuition/etc. are accurate). Science is a system that searches for intersubjective justification for beliefs. Thus, such instances are not scientifically justified.</li>
  <li>That a principle benefits A at the expense of everyone else might be a reason for A to adopt the principle, but that is no reason for anyone else to accept it (e.g. a principle that said everyone has a moral obligation to maximize my pleasure). Thus, such a principle cannot be morally justified.</li>
</ul>

<h3 id="golden-rule">Golden Rule</h3>

<ul>
  <li>Golden Rule: Treat others in the way you would want to be treated.
    <ul>
      <li>Upshot: don’t kill if you wouldn’t want to be killed.</li>
      <li>Problem 1: what if I would have different desires than the recipients? E.g. a masochist wouldn’t mind being attacked.</li>
      <li>Problem 2: what if I would have desires that people treat me unreasonably? E.g. I would want others to always benefit me at the expense of others.</li>
    </ul>
  </li>
  <li>Moral Emotions: Treat others in the way that you would not blame someone for treating you
  Upshot: You can treat others in a way that you would dislike, so long as you wouldn’t blame them for it.</li>
  <li>Rationalized: Treat others not based on counterfactual desires, but on our counterfactual reasons for blame.
    <ul>
      <li>Upshot: don’t kill if they don’t have reason to want to be killed (e.g. even if they’re in an intoxicated state where they want to be killed).</li>
      <li>Doesn’t solve either problem. Just idealizes desires/blame.</li>
    </ul>
  </li>
  <li>Inversed: Treat others in the way they want you to treat them or would not blame you for.
    <ul>
      <li>Upshot: don’t attack if the person doesn’t want to be attacked.</li>
      <li>Solves Problem 1.</li>
    </ul>
  </li>
  <li>Abstracted: Treat others in accord with principles any rational agent would endorse, independent of their actual circumstances, desires, interests, etc. (i.e. veil of ignorance), if the agent knew he had a chance of any combination of circumstances or desires.
    <ul>
      <li>Upshot: don’t kill it would be forbidden by any principles that no one could rationally reject.</li>
      <li>Solves Problem 1 and Problem 2.</li>
      <li>Reasons from Ignorant self-interest =/= reasons from morality.</li>
    </ul>
  </li>
  <li>Moralized: Treat others in accord with principles no rational agent could rationally reject, contingent upon that agent having a goal of finding such principles that others couldn’t rationally reject.</li>
</ul>

<h3 id="negotiation">Negotiation</h3>

<ul>
  <li>Normal negotions:
    <ul>
      <li>Two parties are interested in trading goods.</li>
      <li>Each party has a ranked set of alternative systems of trade they would be willing to accept.</li>
      <li>e.g. one party is willing to pay no more than $100 for some good X. The other is willing to sell X for no less than $50.</li>
      <li>A good negotiation is one where X is sold for somewhere between $50 and $100.</li>
      <li>The exact number to make the sell is indeterminate.</li>
      <li>Agents may not have <em>reasons</em> to be good negotiators, i.e. if one party could coerce the other, that might be in their best interests.</li>
    </ul>
  </li>
  <li>Morality features the following augmentations
    <ul>
      <li>Concerns alternative systems of principles to regulate society; not systems of trade.</li>
      <li>Impartiality: Abstracts from any particular irrelevant circumstances, i.e. wealth, power, fame, race, etc.</li>
    </ul>
  </li>
</ul>

<h2 id="sentimentalism">Sentimentalism</h2>

<p>Even if one rejects the contractualist analysis, we can still give a general theory of truth for all moral systems, even those which do not adhere to the contractualist characterization given above. This can be done by treating moral judgments like aesthetic judgments.</p>

<p>This concerns the attitudes or emotions (e.g. disgust, blame, shame, resentment, guilt, anger, etc.) involved in moral judgments and makes them akin to aesthetic attitudes. These would be any moral judgments we hold regarding a certain behavior despite not judging that they have any intersubjective justifiability. For example, we might mantain a disgust reaction to, e.g., a man has sex with a corpse, even if it isn’t unjustifiable given the aim of intersubjective justifiability (e.g. if we somehow know that this doesn’t affect the man’s relationship with others, that allowing this in society will not have negative effects, etc.). This is not to say that these judgments do not regularly figure in moral arguments. Sometimes they do. But when they do figure in, the argument merely concerns systemezing whatever morally optional sentiments we have (“optional” in the sense of not being necessary from the perspective of intersubjective justifiability).</p>

<p>There are possibly two ways of establishing truth for these kinds of moral judgments: (1) dispositionalism and (2) rational sentimentalism. Dispositionalism focuses on the refined attitudes that an agent would have under certain idealized conditions, e.g. full information, full deliberation/reflection, full experienced, under a sound state of mind, etc. Rational sentimentalism focuses on what is <em>constituitive</em> of moral emotions to determine the appropriate object of said emotions.</p>

<p>Dispositionalism states the following: one has reason to feel attitude R with regard to X if and only if X is such as to elicit R in circumstances C. The circumstances C can be given several formulations such as, e.g., normal circumstances. This is similar to the truth conditions for when an entity is a certain color; i.e. X is red if and only if X is such as to elicit the perception of redness in normal humans under normal circumstances. However, moral judgments must be based on the attitudes in <em>idealized</em> circumstance rather than “normal” circumstances because of the following problems with using “normal” circumstances: (1) It cannot be used to criticize conventional or one’s present - assuming they are normal 0 attitudes, (2) It doesn’t explain why one’s evaluative judgments influence their attitudes, whereas one’s judgments about color concepts don’t influence their color perceptions, and (3) It doesn’t explain why moral truth can be discovered a priori under reflection, whereas truth about color concepts cannot.</p>

<p>Thus, moral truth depends on certain agent’s counterfactual attitudes under idealized conditions. Truth could either be specific to an individual’s idealized attitudes or the idealized attitudes of normal agents. If the latter, this may allow for some rigidifcation which creates a universal standard for truth common to all agents in the actual world. Regardless, because correctness depends on contingent psychological sensibilities, correctness is not mind-dependent in a way that allows for robust objectivity. This is similar to aesthetic judgments in general (think ettiquette) and perhaps secondary properties. Truth would be based on a refinement of one’s attitudes with experience, imagination, deliberation, etc. It doesn’t seem that there would standards for moral correctness independent of moral assumptions. Thus, reflective equilibrium seems to be the dominant method for seeking moral truth.</p>

<p>Rational sentimentalism states: one has reason to feel R with regard to X if and only if X has the properties ascribed by R. For example, to fear X involves some sort of perception that it is dangerous. This is constitutive of fear, and there is clear evolutionary reason to develop such a psychological faculty. One has reason, then, to fear X if and only if X is dangerous. Moral emotions, e.g. blame, resentment, guilty, etc., are emotions like that. Unforunately, there may in fact be no constituitive standards of attitudes such as anger, resentment, etc. apart from moral judgments that something is morally wrong. That is, it may not be possible to describe the constituitive features of moral attitudes using non-moral terms.</p>

<h2 id="motivation">Motivation</h2>

<p>Both forms of morality (sentimentalism and contractualism) explains why agents have reason to endorse certain moral principles. But neither explains why an agent has reason to abide by the duties prescribed by the moral principles. An agent would have such a reason insofar as they either (1) have natural sympathy with the welfare of others (meaning the reasons that others hold would be reasons that they also hold), or (2) judge that their behavior should be consistent with the norms they endorse.</p>

<h2 id="methodologyobjectivity">Methodology/Objectivity</h2>

<p>Morality is rationally optional, but this doesn’t diminish its authority:</p>

<ul>
  <li>Contingent on our interests:
    <ul>
      <li>Nearly universal: most people interested in impartial/social reasons, having a system of norms regulating blame.</li>
      <li>Emphasizes the negotiation aspect: people cant just have independent that they claim are objective with no consideration of other person’s reasons.</li>
      <li>Other analogues: Scientific reasons are impartial/social reasons for belief (and thus evidentially optional), but that doesn’t diminish its authority.</li>
    </ul>
  </li>
  <li>Not externally necessarily justifiable, like all normative domains
    <ul>
      <li>Deduction/induction/abduction/evidence/science cannot be reasonable to someone who doesn’t care for those forms of reasoning</li>
    </ul>
  </li>
  <li>Not ontologically independent
    <ul>
      <li>Who cares about ontology</li>
    </ul>
  </li>
  <li>No shared inputs
    <ul>
      <li>With science, we share the same perceptions/observations?</li>
      <li>With morality, there is widespread disagreement. Might there be a general principle that all must agree to?</li>
    </ul>
  </li>
</ul>

<p>There are no judgment-independent standards of moral truth, but that’s a good thing:</p>

<ul>
  <li>People cannot just come with arbitrary principles and claim them as the moral virtues.</li>
  <li>They are forced to take into account the interests of others.</li>
  <li>They are forced to make their demands reasonable to others.</li>
  <li>Moral reasoning is a process of negotiation rather than of discovery.</li>
</ul>

<p>Objectivity: imagine people have widely divergent beliefs. Objectivity is possible when there happens to be an intersection in the beliefs held by these people. More specifically, it’s possible when there is an intersection in what these people judge to be solid methods for establishing truth. E.g. think of science. People might have widely different beliefs. But everyone agrees that one’s beliefs should cohere with their other beliefs, and we happen to be beings with sensory inputs that automatically impress beliefs within us (which means our beliefs must cohere with our sensory inputs), and our sensory inputs happen to converge a lot of the time. There are other features we happen to agree with as well (or can be shown to agree with), e.g. repeated observations from different independent sources/experiments provide more evidence for a hypothesis than one-offs, etc. It is this convergence that grounds the objectivity of science. I.e. two people might disagree over whether theory X or Y is true, but they can agree on method for determining whether X or Y is true, e.g. by appealing to observation, abduction, induction. Without this, objectivity is impossible. Even if we disagree on method, we can ideally point to a meta-principle that we both agree with (or can be shown to agree with) that settles which method is valid (e.g. reflective equilibrium).</p>

<p>Might there be a similar methodology for practical rationality or ethics? There is no reliable, impartial, etc. methodology for determining what a person has reason to do, so there is clearly no such methodology for ethics. So how can we determine the content of moral principles? (1) We determine the content of practical rationality (what is good for individuals, or what individuals have reason to do) and (2) We determine how morality relates to practical rationality. Once we agree on what makes an ordinary person’s life go well and determine how wellness relates to morality, we can determine moral content. We must determine what is good by appealing to intuitions we already agree with. If someone completely disagrees with what makes one’s life go good, then surely they will never agree with any moral principles. However, appealing to shared intuitions about goodness is useful: people are more likely to agree on what makes one’s life go best than they are to agree with what is morally right or wrong. E.g. at a minimum, people must agree that one’s life goes best when provided with positive liberty to do what they want. Note that we don’t need agreement in our moral views; we need agreement in what constitutes a good life.</p>

<p>Disagreement</p>
<ul>
  <li>There is widespread moral disagreement. This is explained by intuitionist by the fact that we have different beliefs, different circumstances (circumstances which justify different moral positions, e.g. infanticide in food-sparse areas) or different levels of rationality. The basic moral perceptions, it is claimed are actually identical.</li>
  <li>I agree that much disagreement can be reduced to these features and not disagerements in basic moral values (I don’t use perceptions). However, there is no reason to believe that all fully informed, fully rational beings would agree about that is morally appropriate in different circumstances.</li>
  <li>I can agree that there would be near-unanimous agreement about what kinds of considerations are relevant and irrelevant (see above: well-being, liberty, autonomy, etc.) in fully informed, fully rational humans.</li>
  <li>However, there will be widespread disagreement on what to do when these considerations conflict (e.g. harm one person to help another). In developed socities, for example, there is widespread disagremeent about using force against innocent to assist the disadvantaged. We need a procedure to determine which considerations are to trump others in which circumstances.</li>
</ul>

<p>Some notes:</p>
<ul>
  <li>Reason is purely procedural. It is concerned with amelierating <em>conflicts</em> and striving for <em>coherence</em> of our aims.</li>
  <li>Badness only occurs when one’s idealized aims are suppressed in some way.</li>
  <li>Moral wrongness occurs only if it results in someone’s life being worse in some way.
    <ul>
      <li>If action X resulted in no one being worse-off or everyone better-off, then it cannot be morally wrong.</li>
      <li>This is not to make a claim about consequentialism or deontology. One might say its morally wrong to make anyone worse off.</li>
    </ul>
  </li>
</ul>

    </li>
  
    <li>
      <h2><a href="/2019/06/19/Non-naturalism.html">Non-Naturalism</a></h2>
      <p></p>
<p>This concerns <em>metaphysical</em> non-naturalism which has the following components:</p>
<ol>
  <li>Normative concepts refer to normative properties (against non-cognitivism / constructivism).</li>
  <li>Some normative propositions are true (against Error Theory).</li>
  <li>Normative concepts cannot be reduced to non-normative concepts (against analytic naturalism).</li>
  <li>Normative properties cannot be reduced to non-normative properties (against reductive synthetic naturalism).</li>
  <li>Normative properties cannot be explained by the entities studied by physics (against non-reductive synthetic naturalism).</li>
</ol>

<p>Forms of metaphysically naturalistic ethical non-naturalism, which deny 5 (e.g. Landau, Scanlon, etc.), are edge cases not considered here.</p>

<p>It is not clear what the difference is between non-reductive naturalism (analytic and Synthetic) and metaphysically naturalist forms of non-naturalism. Perhaps one difference is that naturalistic theories appeal to explanation. Nor is it clear what the difference is bewteen Realism with non-ontologically committed conceptions of truth and constructivism/non-cognitivism. The difference seems to amount to difference in a conceptual scheme (e.g. like the differences between saying a statue is identical with its constituent marble versus being seperate). The difference must lie in the attitudinal nature of the judgments. Is motivation necessarily entailed or not?</p>

<p>These objections must not prove too much. Some or all of the above features are also true of counterfactual, probabilistic and causal properties, and many other a priori realms of knowledge (e.g. philosophy in general, mathematics, etc.). For each of these types of properties, either an explanation must be given as to how they can exist but not non-natural moral properties, or an explanation must be given as to why such properties do not really exist.</p>

<ul>
  <li>Counterfactual statements: do not really exist. They are constructs we use to aid in considering other possibilities. They are features we apply to propositions that are consistent with some proposition of the current set of known propositions.</li>
  <li>Causal statements: causation cannot perceived. Moreover, causation is not even something that means anything. If there are two realities with all the same events that take place, except where one there is casuation and one where there is complete randomness, then the worlds are identical. Causation doesn’t exist. Causation is merely a useful heuristic tool that we attribute to events to plan for future scenarios.</li>
  <li>Probabilistic statements: there are no genuine stochastic processes, not because our reality doesn’t have them, but because it wouldn’t mean anything for them to be true. Again, these are useful linguistic tools.</li>
  <li>Predictive statements:</li>
</ul>

<p>Each of the above class of statements can be given a constructivist/anti-realist analysis.</p>

<p>Noteably, Hume found that the following cannot be derived from statements about the way the world is:</p>

<ul>
  <li>Statements about the way the world will be.</li>
  <li>Statements about the way the world ought to be.</li>
  <li>Statements about what caused what.</li>
</ul>

<h2 id="causal-inertness">Causal Inertness</h2>

<p>The lack of influence that normative properties place on the world pose the following three problems:</p>

<ol>
  <li>
<strong>Concept</strong>: <em>There is no evolutionary benefit to developing a capacity to track these properties</em>. In order for there to be a benefit in developing a perceptual faculty, that faculty must be useful at increasing an organism’s biological fitness. The only perceptual faculties useful in increasing an organism’s biological fitness are faculties that track relevant natural facts, as natural facts are the only facts that influence an organism’s chance at reproducing.</li>
  <li>
<strong>Epistemology</strong>: <em>We have no epistemic access to non-natural facts</em>. It is a necessary condition on justified belief that one’s belief be explained by the facts in question. Perceptions of natural facts are good evidence for natural properties not because of an intrinsic connection between <em>perceiving</em> p and p being true. Rather, <em>perceiving</em> p is good evidence for p only if p <em>being true</em> causally exlpains why one perceives p. The reliable causal connection between <em>p being true</em> and <em>perceiving p</em> is required to treat <em>perceiving p</em> as a relibable detection of p. There is no way that a non-natural fact p could ever causally explain how we perceive or judge p to be true. Thus, we cannot treat our judging that non-natural fact p as evidence that p is true. This means none of our normative beliefs are ever justified.</li>
  <li>
<strong>Ontology</strong>: <em>Parsimony is preferrable to complexity with regard to ontology</em>. When determining which entities exist in the world, we should use inference to the best explanation. Theories with fewer assumptions and better explanatory power are superior. Imagine a world without any non-natural properties but with all the same natural properties. These two worlds would have equal explanatory power, but the world without unneeded properties would have less assumptions and would therefore be superior. The reason is because non-natural properties must be causally inert. The existing of non-natural properties is not necessary to explain reality as we see it.</li>
</ol>

<h2 id="moral-supervenience">Moral Supervenience</h2>

<p>It seems to be an a priori conceptual truth that moral properties supervene on the non-moral properties, i.e. two circumstances which have identical non-moral properties must also have identical moral properties. This can be easily explained by naturalism, but it is difficult to see how this is explained by non-naturalism. There are two issues here, one epistemological and one ontological.</p>

<ol>
  <li>
<strong>Epistemology</strong>: When we see an action that we judge to be wrong, we don’t just judge it to be wrong in that particular circumstance. We judge that a particular action with certain natural properties always coinstantiates normative properties. Non-naturalism purports that we perceive the non-natural moral facts as we perceive certain natural facts. But there is nothing about this perceptual model that <em>necessarily guarantees</em> that we will perceive the same moral facts in circumstances where we perceive the same natural facts. Any perceived supervenience would be, at best, a posteriori; the supervenience relation couldn’t be perceived, for have only perceived the one circumstance Thus, the perceptual model of non-naturalism cannot explain the supervenience of the moral on the non-moral.</li>
  <li>
<strong>Ontology</strong>: It is a <em>conceptual</em> truth that the normative supervenes on the non-normative. No two worlds can have the same non-normative properties yet have different normative properties. Thus, normative properties and non-normative properties are not just coextensive, they are <em>necessarily</em> coexstensive; they are coexstensive in all possible worlds. However, there are no distinct properties that are coextensive in all possible worlds. If two properties are distinct, then there must be <em>some</em> possible worlds where only one of the properties obtain. Thus, normative properties, <em>if they are properties</em>, must be natural.</li>
</ol>

<h2 id="motivation">Motivation</h2>

<p>Non-naturalism fails to account for the motivational feature of normative judgments for the very same reasons that mind-independent naturalism fails. The fact that moral properties move from the natural realm to the non-natural realm does not increase the motivational weight. Attributions of goodness to P appear to have a conceptual link with the guidance of action towards promoting P (judgment internalism). For any non-naturalistic property R, we can imagine clear-headed beings who would fail to find appropriate reason or motive to action in the mere fact that R obtains regarding P. The fact that attributions of goodness are necessarily action-guiding whereas attributions of R are only contingently action-guiding suggests that goodness and R are not analytically equivalent.</p>

<h2 id="others">Others</h2>

<p>How to know when our perceptions go astray? How to know if we’re suffering from an optical illusions? How to know what’s the best state of mind to be in when evaluating the reliability of intuitions?</p>

    </li>
  
    <li>
      <h2><a href="/2019/06/19/Naturalism.html">Naturalism</a></h2>
      <p></p>
<p>This concerns <em>reductive</em> naturalism the view that contains the following components:</p>
<ol>
  <li>Normative concepts refer to normative properties (against non-cognitivism / constructivism).</li>
  <li>Some normative propositions are true (against Error Theory).</li>
  <li>Normative properties can be reduced to entities which are the subject matter of physics (synthetic naturalism).</li>
  <li>Normative properties can be reduced to non-normative properties (reductive synthetic naturalism) (optional).</li>
  <li>Normative concepts can be reduced to non-normative concepts (analytic naturalism) (optional).</li>
</ol>

<p>Forms of non-reductive naturalism, which deny both 4 and 5 (e.g. David Brink and Nicholas Sturgeon), are edge cases not considered here.</p>

<p>Also, analytic non-reductive naturalism (e.g. Michael Smith) is not considered here.</p>

<p>It is not clear what the difference is between non-reductive naturalism (analytic and Synthetic) and metaphysically naturalist forms of non-naturalism. Perhaps one difference is that naturalistic theories appeal to explanation. Nor is it clear what the difference is bewteen Realism with non-ontologically committed conceptions of truth and constructivism/non-cognitivism. The difference seems to amount to difference in a conceptual scheme (e.g. like the differences between saying a statue is identical with its constituent marble versus being seperate). The difference must lie in the attitudinal nature of the judgments. Is motivation necessarily entailed or not?</p>

<h2 id="analytic-naturalism">Analytic Naturalism</h2>

<p>Note: some of the arguments here seem similar to the arguments shown in Descriptivism.md. The reason these arguments are also here is because they don’t defeat descriptivism broadly. Because, these arguments, by not mentioning the importance of attitudes, don’t generally defeat cognitive theories that ignore attitudes.</p>

<p><em>Open Question Argument</em>. (1) Any proposed analytic reduction of a term must be uninformative and obvious. (2) Any analytic reduction of goodness would be informative and nonobvious. (3) Therefore, there can be no analytic reduction of moral terms. Consider the question “Is X good”. Now, imagine that a proposed complex analysis of goodness states that all questions of the form ‘Is X good’ are questions of the form ‘Does X have naturalistic property Y’. The problem with this is that, we can always further ask “Is it good that X has property Y”. This further question is clearly intelligible and coherent. But, if goodness that could be analyzed in terms of Y, then such a question would not be intelligible.</p>

<p><em>Descriptive beliefs don’t entail normative judgments</em>. If M and N are <em>definitionally</em> identical, then if A <em>believes</em> that X has property M, then it logically follows that A also <em>believes</em> X has property N (and vice-versa). Note that this is stronger than mere <em>property</em> identity, e.g. H2O might be identical to water, but the fact that A believes water is H2O does not logically entail that A believes it is water (or vice-versa). However, this logical relation does not hold between and normative property and any natural property. If we know that A believes that X has natural property N and he later says that “X has moral property M”, then we have always learned something new about A.</p>

<p><em>Insistence on Normative Language</em>. If normative term N really meant natural term M, then why not carry on making claims about M? If the thesis were true, this would be equivalent to making claims about N, so there should be no difference. The fact that one chooses not to do so implies either (1) he believes that there really is something about N not captured in M, or (2) he believes that society believes that there is something about N not captured in M. Either way, either he or society believes that N and M are not analytically equivalent.</p>

<p>Response: deny that all analytic reductions must be trivial and uninformative. Counter: Explain why the normative instance of the paradox of analysis differs from other cases. Normative judgments are supposed to provide reasons for action. In other cases, we would be fine to abandon the terms being analyzed (i.e. no problem switching from “knowledge” to “justified true belief”). But this is not true in the normative case.</p>

<p><em>Normativity reduced to Tautology</em>. While it may be appropriate for an analytic reduction to be nontrivial, it is not appropriate that an analytic reduction could ever provide one with a <em>reason</em> for action. If normative concept M can be analytically reduced to natural concept N, then saying “N is M” would be a tautology, and thus could provide no reason for action. For example, if goodness could be analytically reduced to pleasure, then if someone said “pleasure is good”, then this would be equivalent to saying “pleasure is pleasure” or “goodness is goodness”. But presumably the claim “pleasure is good” is supposed to provide someone with reason for action. But no tautology such as “pleasure is pleasure” or “goodness is goodness” could ever provide a reason or motive for someone to promote pleasure.</p>

<p><em>Ethical disagreements reduced to disputed semantics or descriptions.</em> If analytic naturalism is true, then two parties disagree ethically only if they disagree descriptively. But people can disagree ethically without disagreeing descriptively. There can be two people who represent reality identically without having similar ethical attitudes with regard to that representation. This can only be explained by positing that the two parties have different semantics, but then this wouldn’t even be a genuine disagreement. This means that two societies with ethical terms that had different semantic meaning (but were identical in that those terms guided the respective society’s behavior) would not really disagree with each other. They would be talking passed one another.</p>

<h2 id="reductive-synthetic-naturalism">Reductive Synthetic Naturalism</h2>

<p><em>A Priori Argument</em>. It seems we can come to learn about normative truths a priori. This is inexplicable if there is an a posteriori synthetic relationship between normative facts and non-normative facts. I.e. we cannot learn a priori that yellow is such and such wavelength, or that water is H2O. Yet how can it be the case that we can learn a priori that, e.g. some natural property <em>necessarily</em> co-instantiates a normative property?</p>

<p><em>Lack of Disagreement</em>. Synthetic identities can be found in other domains because we can easily fix the referrents of terms like “water” or “yellow”, and then we can find that property that is always instantiated with that referrent. One strategy for doing this is to present a dispositional analysis: an entity is “yellow” just in case it causes sensation that we normally perceive as “yellow”. Such a dispositional analysis is not promising for moral terms. Imagine that two societies are lingustically identical except when one society used the word “good” they referred to pleasure and the other society referred to God’s will. On this reading, the two cultures wouldn’t even disagree with each other, since the content of “good” in these two societies are different - they are using the same word to track different phenomenon. But it seems that these cultures can coherently disagree with each other, especailly if they each act in accordance with what is good.</p>

<h3 id="cornell-realism">Cornell Realism</h3>

<p>These take a <em>causal reference theory</em> for moral properties, because a causal reference theory is the standard theory of reference for natural kind terms. This rejects the <em>description theory of reference</em>. What determines whether a natural property is good is not whether it has the attributes ascribed to it by the term “good”, but whether it causally regulates our use of the word “good”. We are looking not at the semantic attribution behind the term, but rather at the properties causally responsible for that word.</p>

<p>This is similar to how we use the word “health”. When we say that someone is “healthy”, it’s unclear what the <em>meaning</em> of that might be. “Healthiness” is a complex natural property that is not directly observable. Thus, “healthiness” cannot be <em>equated</em> with any simpler set of properties that are directly observable. However, we can determine what property “healthy” <em>refers to</em> by finding what causally regulates our use of the term “health”. This can be done by looking at the simpler set of properties that <em>are</em> directly observable; these would be <em>indicators</em> of “healthiness” rather than <em>equivalent</em>. “Healthiness” thus has a robust causal profile, which means the property of being healthy can figure into causal explanations of our observations. Much the same is true of moral properties.</p>

    </li>
  
    <li>
      <h2><a href="/2019/06/19/Descriptivism.html">Descriptivism</a></h2>
      <p></p>
<h2 id="key-features-of-normativitys">Key features of Normativitys</h2>
<ul>
  <li>Ubiquitous -</li>
  <li>Disagreement (especially with morality) regardless of empirical agreement or linguistic/societal differences</li>
  <li>Rational/Deliberative - a priori</li>
  <li>Motivational - world to mind fit that sometimes conflicts with other motivations</li>
  <li>Supervenience - normative properties supervene on the natural properties</li>
</ul>

<h2 id="requirements-for-descriptivism">Requirements for descriptivism</h2>

<ol>
  <li>Must explain how the normative supervenes on the non-normative.</li>
  <li>Must explain how a mind-to-world-fit state of mind can produce a mind-to-world fit sate of mind.</li>
  <li>If there are normative facts, then either the normative facts need to somehow explain our normative judgments or else normative facts must consist in our (hypothetical or idealized) normative judgments. Otherwise, there would be no causal connection bewteen our normative judgments, on the one hand, and the normative facts, on the other. That would mean we could have no justification for any of our normative judgments, because in order to have justified belief in p, it must be the case that one’s belief in p is reliably explained by the fact that p (e.g. the perception that the Earth is not moving is not evidence that the Earth is not moving, because that perception is not better explained by the fact that the Earth is not moving).</li>
  <li>Attitude-independent theories of normative facts would have to posit that the normative facts are ontologically prior to our normative judgments, but nevertheless explain our normative judgments. This seems impossible under non-naturalism. Under naturalism, it gets more complicated.</li>
  <li>Attitude-dependent theories of normative facts must not reduce normative facts to our actual attitudes, as this would prevent disconnections between our actual attitudes and our normative judgments, and it would also preclude coherent questioning of one’s actual attitudes. Cannot be the basis of moral judgments because that would prevent coherent moral disagreement assuming all partiies were fully rational.</li>
  <li>Must provide an explanation for how to translate our moral terms to/from cultures with other languages.</li>
  <li>Under analytic naturalism, we must be able to replace our normative terms with non-normative terms without losing meaning.</li>
</ol>

<h2 id="general-problems">General Problems</h2>

<p>General problems with ignoring non-descriptive attitudes</p>

<h3 id="understanding-non-descriptivism">Understanding non-descriptivism</h3>

<p><em>The dynamic meaning of judgments</em>. Consider two uses of the same term with the same descriptive content but with different meaning, e.g. using “gay” purely descriptively versus derogatorily. Now consider two different terms with the same meaning but whereby one has the dynamic content implicitly associated with it, e.g. “skinny” versus “bony”.</p>

<p><em>Examples of other domains of non-descriptive judgments</em>. E.g. aesthetics, tastes, etc.</p>

<p><em>Necessity of non-descriptive judgments.</em> We would have needed to develop a system for expressing attitudes of approval, disapproval, and also for modifying the attitudes of others. It seems normative judgments definitely fulfill this role.</p>

<h3 id="normativity-doesnt-require-descriptivism">Normativity doesn’t require descriptivism</h3>

<h4 id="normative-educationexpressions">Normative education/expressions.</h4>

<p>We teach children to form certain moral judgments by molding their non-descriptive attitudes. 
This is done by rewarding/punishing behavior with various non-descriptive attitudes.
This shows examples of appropriate attitudes in certain circumstances.</p>

<h4 id="flexibility-of-language">Flexibility of language</h4>

<p>A ought to X, A needs to X, A must X, X is crappy, X is disgusting, etc. can all mean the same thing. 
This is best explained as prescriptions and/or expressions, rather than reports/descriptions. 
It is unlikely that the referrents of the terms in each of these expressions are descriptive of the same entity.
if they were descriptive of the same entity, how would we know?</p>

<h4 id="descriptivism-unnecessary">Descriptivism unnecessary.</h4>

<p>All of our normative discourse can be explained without appeal to the existence of normative entities, or judgments about such properties.</p>

<h3 id="arguments-against-realism">Arguments against Realism</h3>

<p><em>Motivation</em>. One can infer that an agent has a world-to-mind fit state of mind with respect to X if they judge that they have normative reason to X. With moral judgments, this is particularly true if they <em>exclaim</em> that a certain action is (im)moral. This is easy to explain if judgments of normative reasons are themselves world-to-mind fits. Otherwise, this is difficult to explain. Attributions of goodness to P have a conceptual link with the guidance of action towards promoting P (judgment internalism). For any (non-)naturalistic property R, we can imagine clear-headed beings who would fail to find appropriate reason or motive to action in the mere fact that R obtains regarding P. The fact that attributions of goodness are <em>necessarily</em> action-guiding whereas attributions of R are only <em>contingently</em> action-guiding suggests that goodness and R are not analytically equivalent.</p>

<p><em>Translation</em> Imagine we are trying to translate words for descriptive concepts to another language. This involves picking an extension of the relevant concept that we can all agree with and finding the word from the other language that correlates with this extension. For example, if we want to find the translation for the word “red”, we would establish an extension of the concept RED - e.g. blood, stop signs, crayons, etc. Then we would find which word in the other language is often used to refer to the entities in that extension. On the other hand, we cannot do this for normative terms. Firstly, it is doubtful that we could establish an extension of any normative concept that we all agree on. But, more importantly, even if we could, it would not be enough to find the foreign word that corresponds to this extension in order to translate the term. We would also need to know the other society’s motivational and non-cognitive attitudes and dispositions with regard to the extension. For, it is conceivable that they could think that the extensions was either good or bad. This attacks all forms of non-naturalism and objectivist forms of naturalism.
-&gt; Also imagine a culture with an identical nonverbal language of our own except that they didn’t speak verbally. They used sign language predominantly to communicate. Some analysis of their movements would be reducible to expressions of beliefs. How would we analyze the meaning of showing a middle finger? How would we analyze a parent who angrily points at a child’s bedroom (ordering him to go)? Imagine they needed to express more sophisticated thoughts using this language. Is it truly questionable whether they could express the entire range of human attitudes, including the attitudes themselves, dispositions to have the attitudes, endorsement of the attitudes? Is it questionable whether questionable whether they could use their language in a way to influence the behavior of others? Would we have any need to posit the existence of mind-independent action-guiding properties to explain the phenomenon? Would it change if they spoke verbally?</p>

<h3 id="arguments-against-all-descriptivism">Arguments against all Descriptivism</h3>

<p><em>Non-predicating</em>. Imagine someone asserts that some state of affairs or object has a certain normative property. What are they asserting is a property of that state of affairs or object? Nothing.</p>

<p><em>Disagreement</em>. Descriptivism cannot explain the role of attitude in ethical disagreements. There are two forms of disagreement, (1) disagreements in belief (both cannot be true) and (2) disagreement in attitudes (cannot be satisfied). Note that reducing ethical judgments to <em>beliefs about attitudes</em> cannot account for this. If A believes he desires X and B believes he desires not-X, then these beliefs are not in disagreement because they can both be <em>correct</em>. E.g. A saying “X is good” and B saying “X is not good” would not be a contradiction, since it would amount to “A desires X” and “B does not desire X”. In fact, they would both be <em>true</em>. But it seems that ethical disagreement can persist despite accepting these truths.</p>

<p>Ethical disagreements commonly feature disagreements in attitudes and in beliefs. But attitudes play the primary role because (1) The attitudes determine which beliefs are relevant, and (2) Ethical disagreement persist after agreement in belief. Perhaps this is actually a disagreement in beliefs about each agent’s idealized attitudes, where idealized attitudes are assumed to be convergent. Disagreement in idealized attitudes maybe can account for disagreements in certain normative domains, e.g. disagreements in desires, emotions, maybe even beliefs (i.e. we think other people would come to similar beliefs as us under idealized conditions, because our epistemic frameworks are assumed to be similar). But ethical disagreement can persist despite agreement about the beliefs of everyone’s fully rational, fully informed attitudes. This is not the case with something like think art, humor, taste, etc. This is because ethical judgments have a <em>prescriptive</em> aspect in that they are meant to guide the behavior of other agents. Such prescriptions cannot <em>both</em> be actualized when they conflict.</p>

<p><em>Beliefs and attitudes are logically independent</em> Take a descriptivist theory of normative judgment which says that ascriptions of goodness to x express belief p to x. Take a non-descriptivist theory of normative judgment which says that such ascriptions express non-descriptivist attitude q to x. Imagine an agent held q with regard to x but they did not hold p with regard to x. It seems safe to say that they judge x to be good. Now imagine that they held p with regard to x but they did not hold q with regard to x. It seems safe to say that they don’t judge to be good.</p>

<p><em>Expanded Twin Earth</em>. What our terms refer is a contingent matter that depends upon our culture and history. It is a feature of our contingent culture that we happened to have hooked up the term “good” with any particular natural or non-natural property good. So, imagine that a group of people whom you disagreed with merely stipulated that what they meant by “good” was not the (natural or non-natural) property that you refered to by “good” and they went on using their terms to regulate their behavior in their society. It still seems that you would disagree with them and think that they were incorrect.</p>

    </li>
  
    <li>
      <h2><a href="/2018/07/01/welcome.html">Welcome</a></h2>
      <p></p>
<p>If you see this page, that means you have setup your site. enjoy! <img class="emoji" title=":ghost:" alt=":ghost:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f47b.png" height="20" width="20"> <img class="emoji" title=":ghost:" alt=":ghost:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f47b.png" height="20" width="20"> <img class="emoji" title=":ghost:" alt=":ghost:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f47b.png" height="20" width="20"></p>

<p>You may want to <a href="https://tianqi.name/jekyll-TeXt-theme/docs/en/configuration">config the site</a> or <a href="https://tianqi.name/jekyll-TeXt-theme/docs/en/writing-posts">writing a post</a> next. Please feel free to <a href="https://github.com/kitian616/jekyll-TeXt-theme/issues">create an issue</a> or <a href="mailto:kitian616@outlook.com">send me email</a> if you have any questions.</p>


    </li>
  
    <li>
      <h2><a href="/2018/06/01/header-image.html">Post with Header Image</a></h2>
      <p></p>
<p>A Post with Header Image, See <a href="https://tianqi.name/jekyll-TeXt-theme/samples.html#page-layout">Page layout</a> for more examples.</p>


    </li>
  
</ul>
    </div>
    <script>(function () {
  var $root = document.getElementsByClassName('root')[0];
  if (window.hasEvent('touchstart')) {
    $root.dataset.isTouch = true;
    document.addEventListener('touchstart', function(){}, false);
  }
})();
</script>
  </body>
</html>